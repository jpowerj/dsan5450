[
  {
    "objectID": "w14/slides.html#an-official-apology-to-fred-vanvleet-and-the-fred-vanvleet-community",
    "href": "w14/slides.html#an-official-apology-to-fred-vanvleet-and-the-fred-vanvleet-community",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "An Official Apology to Fred VanVleet and the Fred VanVleet Community",
    "text": "An Official Apology to Fred VanVleet and the Fred VanVleet Community\n\nI cheated\nI used ChatGPT to generate my birthday DM to you, Fred, and I have no excuse\nI hope to mend ties between Georgetown DSAN and Fred, and heal the wounds I imagine the Fred VanVleet Community is experiencing right now"
  },
  {
    "objectID": "w14/slides.html#the-receipts",
    "href": "w14/slides.html#the-receipts",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "The Receipts",
    "text": "The Receipts"
  },
  {
    "objectID": "w14/slides.html#section",
    "href": "w14/slides.html#section",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "",
    "text": "Dear Students,\nI hope this message finds you well. I am writing to offer a sincere apology for my recent actions during our Data Ethics class, specifically in relation to Fred VanVleet’s birthday greeting.\nIt deeply pains me to admit that I deviated from the authenticity and sincerity that we aim to uphold in our interactions, particularly when it comes to someone as respected and admired as Fred VanVleet. By using ChatGPT to generate a message instead of expressing genuine sentiments from the heart, I failed not only Fred but also the entire Fred VanVleet community.\nFred VanVleet represents resilience, determination, and integrity, both on and off the court. As a role model to many, he deserves nothing less than our utmost respect and genuine appreciation. My actions not only fell short of these standards but also disrespected the values that Fred embodies.\nTo the Fred VanVleet community, I extend my deepest apologies. I recognize that my actions have let you down and have tarnished the admiration and support we hold for Fred. It was a despicable lapse in judgment, and I take full responsibility for the disappointment and frustration it may have caused.\n“I come from a place where a young thug will take your cake” - Thomas Jefferson\nMoving forward, I am committed to learning from this experience and to making amends. I understand the importance of honesty, integrity, and authenticity, especially when it comes to our interactions with individuals we admire and respect.\nOnce again, I apologize to Fred VanVleet and the entire community for my regrettable actions. Your forgiveness and understanding would mean a great deal to me as I strive to regain your trust.\nIf any of you would like to discuss this matter further or have any concerns, please do not hesitate to reach out to me. Thank you for your attention to this issue.\nSincerely, [Your Name]"
  },
  {
    "objectID": "w14/slides.html#negative-liberty-rightarrow-republican-liberty",
    "href": "w14/slides.html#negative-liberty-rightarrow-republican-liberty",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "Negative Liberty \\(\\rightarrow\\) Republican Liberty",
    "text": "Negative Liberty \\(\\rightarrow\\) Republican Liberty\n\nNegative Liberty (“Liberty of the moderns”): The absence of external interference in day-to-day life\n(Contrasted with Positive Liberty/“Liberty of the ancients”: The ability to actualize oneself and carry out one’s will within society)\nUtilitarian and Rawlsian frameworks both rooted in negative liberty, in ways… too complicated to describe in 30mins, tbh\nRepublican Liberty: The inability of others to interfere, whether or not they actually want to; secured absence of interference, across possible counterfactual worlds"
  },
  {
    "objectID": "w14/slides.html#liberty-neg-slavery-not-neg-interference",
    "href": "w14/slides.html#liberty-neg-slavery-not-neg-interference",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "Liberty = \\(\\neg\\) Slavery (not \\(\\neg\\) Interference)",
    "text": "Liberty = \\(\\neg\\) Slavery (not \\(\\neg\\) Interference)\n\nThe weight of chains, number of stripes, hardness of labour, and other effects of a master’s cruelty, may make one servitude more miserable than another, but nevertheless, he is a slave who serves the best and gentlest man in the world, as well as he who serves the worst. (Sidney 1698).\n\n\nOur home has been nothing but a playroom. I have been your doll-wife, just as at home I was papa’s doll-child; and here the children have been my dolls. (Ibsen 1879)"
  },
  {
    "objectID": "w14/slides.html#interpersonal-domination-mary-wollstonecraft-frederick-douglass-and-the-kindly-slavemaster",
    "href": "w14/slides.html#interpersonal-domination-mary-wollstonecraft-frederick-douglass-and-the-kindly-slavemaster",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "Interpersonal Domination: Mary Wollstonecraft, Frederick Douglass, and the Kindly Slavemaster",
    "text": "Interpersonal Domination: Mary Wollstonecraft, Frederick Douglass, and the Kindly Slavemaster\n\nWeakness may gratify the arrogant pride of man; but the lordly caresses of a protector will not gratify a noble mind that yearns, and deserves, to be respected. Fondness is a poor substitute for friendship. (Wollstonecraft 1792)\n\n\nMy feelings [towards slave masters] were not the result of any marked cruelty in the treatment I received; they sprung from the consideration of my being a slave in the first place. It was slavery—not its mere incidents—that I despised. (Douglass 1855)"
  },
  {
    "objectID": "w14/slides.html#republican-liberty-as-a-litmus-test",
    "href": "w14/slides.html#republican-liberty-as-a-litmus-test",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "Republican Liberty as a Litmus Test",
    "text": "Republican Liberty as a Litmus Test\n\nEasy cases: Who is actively interfering to prevent others from actualizing their wills? (The cruel slavemaster)\n\nComplication: In some (rare) cases, interference may be justifiable to the person who was interfered with. (Pulling child out of road to prevent them being hit)\n\nMore difficult cases: Who is not actively interfering, but only because they are currently choosing not to?\n\n\\(\\implies\\) You must remain on their good side in order to avoid them turning from kindly \\(\\rightarrow\\) cruel\n\\(\\implies\\) Litmus test: if they decided one day that they hate you, what would they be able to inflict upon you?"
  },
  {
    "objectID": "w14/slides.html#but-data-ethics-and-policy",
    "href": "w14/slides.html#but-data-ethics-and-policy",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "But… Data Ethics and Policy?",
    "text": "But… Data Ethics and Policy?\n\nThese quotes, emerging out of different struggles over hundreds and hundreds of years, still tend to involve people dominating other people\nBut… What would it mean for an algorithm to dominate people?\nI (and many others!) argue that this provides the most promising language within which one could frame the core, fundamental injustices induced by algorithms\nBut, requires integrating interpersonal (well-covered) with structural domination (Jacobs and Naidu 2025)"
  },
  {
    "objectID": "w14/slides.html#structural-domination-the-grapes-of-wrath",
    "href": "w14/slides.html#structural-domination-the-grapes-of-wrath",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "Structural Domination: The Grapes of Wrath",
    "text": "Structural Domination: The Grapes of Wrath\n\n“I built it with my hands. Straightened old nails to put the sheathing on.”\n“It’s not me. There’s nothing I can do. I’ll lose my job if I don’t do it. And look—suppose you kill me? They’ll hang you, and long before you’re hung there’ll be another guy here, he’ll bump the house down. You’re not killing the right guy.”\n“That’s so… Who gave you orders? I’ll go after him. He’s the one to kill.”\n“You’re wrong. He got his orders from the bank. The bank told him, ‘Clear those people out or it’s your job.’”\n“Well, there’s a president of the bank. There’s a board of directors. I’ll fill up the magazine of the rifle and go into the bank.”\nThe driver said, “Fellow was telling me the bank gets orders from the East. The orders were, ‘Make the land show profit or we’ll close you up.’”\n“We’re sorry. It’s not us. It’s the monster. The bank isn’t like a man.\n“Yes, but the bank is only made of men.”\n“No, you’re wrong there—quite wrong there. The bank is something else than men. It happens that every man in a bank hates what the bank does, and yet the bank does it. The bank is something more than men, I tell you.”\n“I got to figure,” the tenant said. “We all got to figure. There’s some way to stop this. There’s got to be some way to stop this. It’s not like lightning or earthquakes. We’ve got a bad thing made by men, and by God, isn’t that something we should be able to change?”\n(Steinbeck 1939)"
  },
  {
    "objectID": "w14/slides.html#references",
    "href": "w14/slides.html#references",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "References",
    "text": "References\n\n\nDouglass, Frederick. 1855. My Bondage and My Freedom. Yale University Press.\n\n\nIbsen, Henrik. 1879. The Doll’s House: A Play. D. Appleton & Company.\n\n\nJacobs, Jeff, and Suresh Naidu. 2025. “Operationalizing Freedom as Non-Domination in the Labor Market.” In Perspectives on Labor Republicanism, edited by Philip Pettit. Cambridge: Cambridge University Press.\n\n\nSidney, Algernon. 1698. Discourses Concerning Government. A. Millar.\n\n\nSteinbeck, John. 1939. The Grapes of Wrath. Penguin.\n\n\nWollstonecraft, Mary. 1792. A Vindication of the Rights of Woman: With Strictures on Political and Moral Subjects. J. Johnson."
  },
  {
    "objectID": "w14/index.html",
    "href": "w14/index.html",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 14: {{< var w14.date-md >}}"
    ]
  },
  {
    "objectID": "w14/index.html#an-official-apology-to-fred-vanvleet-and-the-fred-vanvleet-community",
    "href": "w14/index.html#an-official-apology-to-fred-vanvleet-and-the-fred-vanvleet-community",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "An Official Apology to Fred VanVleet and the Fred VanVleet Community",
    "text": "An Official Apology to Fred VanVleet and the Fred VanVleet Community\n\nI cheated\nI used ChatGPT to generate my birthday DM to you, Fred, and I have no excuse\nI hope to mend ties between Georgetown DSAN and Fred, and heal the wounds I imagine the Fred VanVleet Community is experiencing right now",
    "crumbs": [
      "Week 14: {{< var w14.date-md >}}"
    ]
  },
  {
    "objectID": "w14/index.html#the-receipts",
    "href": "w14/index.html#the-receipts",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "The Receipts",
    "text": "The Receipts",
    "crumbs": [
      "Week 14: {{< var w14.date-md >}}"
    ]
  },
  {
    "objectID": "w14/index.html#section",
    "href": "w14/index.html#section",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "",
    "text": "Dear Students,\nI hope this message finds you well. I am writing to offer a sincere apology for my recent actions during our Data Ethics class, specifically in relation to Fred VanVleet’s birthday greeting.\nIt deeply pains me to admit that I deviated from the authenticity and sincerity that we aim to uphold in our interactions, particularly when it comes to someone as respected and admired as Fred VanVleet. By using ChatGPT to generate a message instead of expressing genuine sentiments from the heart, I failed not only Fred but also the entire Fred VanVleet community.\nFred VanVleet represents resilience, determination, and integrity, both on and off the court. As a role model to many, he deserves nothing less than our utmost respect and genuine appreciation. My actions not only fell short of these standards but also disrespected the values that Fred embodies.\nTo the Fred VanVleet community, I extend my deepest apologies. I recognize that my actions have let you down and have tarnished the admiration and support we hold for Fred. It was a despicable lapse in judgment, and I take full responsibility for the disappointment and frustration it may have caused.\n“I come from a place where a young thug will take your cake” - Thomas Jefferson\nMoving forward, I am committed to learning from this experience and to making amends. I understand the importance of honesty, integrity, and authenticity, especially when it comes to our interactions with individuals we admire and respect.\nOnce again, I apologize to Fred VanVleet and the entire community for my regrettable actions. Your forgiveness and understanding would mean a great deal to me as I strive to regain your trust.\nIf any of you would like to discuss this matter further or have any concerns, please do not hesitate to reach out to me. Thank you for your attention to this issue.\nSincerely, [Your Name]",
    "crumbs": [
      "Week 14: {{< var w14.date-md >}}"
    ]
  },
  {
    "objectID": "w14/index.html#negative-liberty-rightarrow-republican-liberty",
    "href": "w14/index.html#negative-liberty-rightarrow-republican-liberty",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "Negative Liberty \\(\\rightarrow\\) Republican Liberty",
    "text": "Negative Liberty \\(\\rightarrow\\) Republican Liberty\n\nNegative Liberty (“Liberty of the moderns”): The absence of external interference in day-to-day life\n(Contrasted with Positive Liberty/“Liberty of the ancients”: The ability to actualize oneself and carry out one’s will within society)\nUtilitarian and Rawlsian frameworks both rooted in negative liberty, in ways… too complicated to describe in 30mins, tbh\nRepublican Liberty: The inability of others to interfere, whether or not they actually want to; secured absence of interference, across possible counterfactual worlds",
    "crumbs": [
      "Week 14: {{< var w14.date-md >}}"
    ]
  },
  {
    "objectID": "w14/index.html#liberty-neg-slavery-not-neg-interference",
    "href": "w14/index.html#liberty-neg-slavery-not-neg-interference",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "Liberty = \\(\\neg\\) Slavery (not \\(\\neg\\) Interference)",
    "text": "Liberty = \\(\\neg\\) Slavery (not \\(\\neg\\) Interference)\n\nThe weight of chains, number of stripes, hardness of labour, and other effects of a master’s cruelty, may make one servitude more miserable than another, but nevertheless, he is a slave who serves the best and gentlest man in the world, as well as he who serves the worst. (Sidney 1698).\n\n\nOur home has been nothing but a playroom. I have been your doll-wife, just as at home I was papa’s doll-child; and here the children have been my dolls. (Ibsen 1879)",
    "crumbs": [
      "Week 14: {{< var w14.date-md >}}"
    ]
  },
  {
    "objectID": "w14/index.html#interpersonal-domination-mary-wollstonecraft-frederick-douglass-and-the-kindly-slavemaster",
    "href": "w14/index.html#interpersonal-domination-mary-wollstonecraft-frederick-douglass-and-the-kindly-slavemaster",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "Interpersonal Domination: Mary Wollstonecraft, Frederick Douglass, and the Kindly Slavemaster",
    "text": "Interpersonal Domination: Mary Wollstonecraft, Frederick Douglass, and the Kindly Slavemaster\n\nWeakness may gratify the arrogant pride of man; but the lordly caresses of a protector will not gratify a noble mind that yearns, and deserves, to be respected. Fondness is a poor substitute for friendship. (Wollstonecraft 1792)\n\n\nMy feelings [towards slave masters] were not the result of any marked cruelty in the treatment I received; they sprung from the consideration of my being a slave in the first place. It was slavery—not its mere incidents—that I despised. (Douglass 1855)",
    "crumbs": [
      "Week 14: {{< var w14.date-md >}}"
    ]
  },
  {
    "objectID": "w14/index.html#republican-liberty-as-a-litmus-test",
    "href": "w14/index.html#republican-liberty-as-a-litmus-test",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "Republican Liberty as a Litmus Test",
    "text": "Republican Liberty as a Litmus Test\n\nEasy cases: Who is actively interfering to prevent others from actualizing their wills? (The cruel slavemaster)\n\nComplication: In some (rare) cases, interference may be justifiable to the person who was interfered with. (Pulling child out of road to prevent them being hit)\n\nMore difficult cases: Who is not actively interfering, but only because they are currently choosing not to?\n\n\\(\\implies\\) You must remain on their good side in order to avoid them turning from kindly \\(\\rightarrow\\) cruel\n\\(\\implies\\) Litmus test: if they decided one day that they hate you, what would they be able to inflict upon you?",
    "crumbs": [
      "Week 14: {{< var w14.date-md >}}"
    ]
  },
  {
    "objectID": "w14/index.html#but-data-ethics-and-policy",
    "href": "w14/index.html#but-data-ethics-and-policy",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "But… Data Ethics and Policy?",
    "text": "But… Data Ethics and Policy?\n\nThese quotes, emerging out of different struggles over hundreds and hundreds of years, still tend to involve people dominating other people\nBut… What would it mean for an algorithm to dominate people?\nI (and many others!) argue that this provides the most promising language within which one could frame the core, fundamental injustices induced by algorithms\nBut, requires integrating interpersonal (well-covered) with structural domination (Jacobs and Naidu 2025)",
    "crumbs": [
      "Week 14: {{< var w14.date-md >}}"
    ]
  },
  {
    "objectID": "w14/index.html#structural-domination-the-grapes-of-wrath",
    "href": "w14/index.html#structural-domination-the-grapes-of-wrath",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "Structural Domination: The Grapes of Wrath",
    "text": "Structural Domination: The Grapes of Wrath\n\n“I built it with my hands. Straightened old nails to put the sheathing on.”\n“It’s not me. There’s nothing I can do. I’ll lose my job if I don’t do it. And look—suppose you kill me? They’ll hang you, and long before you’re hung there’ll be another guy here, he’ll bump the house down. You’re not killing the right guy.”\n“That’s so… Who gave you orders? I’ll go after him. He’s the one to kill.”\n“You’re wrong. He got his orders from the bank. The bank told him, ‘Clear those people out or it’s your job.’”\n“Well, there’s a president of the bank. There’s a board of directors. I’ll fill up the magazine of the rifle and go into the bank.”\nThe driver said, “Fellow was telling me the bank gets orders from the East. The orders were, ‘Make the land show profit or we’ll close you up.’”\n“We’re sorry. It’s not us. It’s the monster. The bank isn’t like a man.\n“Yes, but the bank is only made of men.”\n“No, you’re wrong there—quite wrong there. The bank is something else than men. It happens that every man in a bank hates what the bank does, and yet the bank does it. The bank is something more than men, I tell you.”\n“I got to figure,” the tenant said. “We all got to figure. There’s some way to stop this. There’s got to be some way to stop this. It’s not like lightning or earthquakes. We’ve got a bad thing made by men, and by God, isn’t that something we should be able to change?”\n(Steinbeck 1939)",
    "crumbs": [
      "Week 14: {{< var w14.date-md >}}"
    ]
  },
  {
    "objectID": "w14/index.html#references",
    "href": "w14/index.html#references",
    "title": "Week 14: Republican Liberty and the Kindly Slavemaster",
    "section": "References",
    "text": "References\n\n\nDouglass, Frederick. 1855. My Bondage and My Freedom. Yale University Press.\n\n\nIbsen, Henrik. 1879. The Doll’s House: A Play. D. Appleton & Company.\n\n\nJacobs, Jeff, and Suresh Naidu. 2025. “Operationalizing Freedom as Non-Domination in the Labor Market.” In Perspectives on Labor Republicanism, edited by Philip Pettit. Cambridge: Cambridge University Press.\n\n\nSidney, Algernon. 1698. Discourses Concerning Government. A. Millar.\n\n\nSteinbeck, John. 1939. The Grapes of Wrath. Penguin.\n\n\nWollstonecraft, Mary. 1792. A Vindication of the Rights of Woman: With Strictures on Political and Moral Subjects. J. Johnson.",
    "crumbs": [
      "Week 14: {{< var w14.date-md >}}"
    ]
  },
  {
    "objectID": "w12/slides.html#how-do-i-pick-a-topic",
    "href": "w12/slides.html#how-do-i-pick-a-topic",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "How Do I Pick A Topic?",
    "text": "How Do I Pick A Topic?\n\nI know that “whatever is interesting to you” can be way overly-vague!\nSo, one approach is: imagine yourself in a job interview for your dream job, and they bring up DSAN 5450: “Interesting, what did you do in that class?”\n[Insert final project elevator pitch] “Wow, that’s such a cool project, we really want someone who can [say] take a data-driven approach to a policy question like that. You’re hired!”\n(Jeff gets a commission: 10% of your salary)"
  },
  {
    "objectID": "w12/slides.html#the-rating-system",
    "href": "w12/slides.html#the-rating-system",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "The Rating System",
    "text": "The Rating System\n\n\n\n\n\n\nFigure 1: On Cinema at the Cinema S1E09"
  },
  {
    "objectID": "w12/slides.html#discussing-fairness",
    "href": "w12/slides.html#discussing-fairness",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Discussing Fairness",
    "text": "Discussing Fairness\n\n\n\n\n\n\n\nBelow Expectations\n\n\"This algorithm is unfair\"\n\n\nMeets Expectations\n\n\"This algorithm violates the Predictive Parity criterion of fairness when run on this dataset\"\n\n\nExceeds Expectations\n\n\"This algorithm violates the Predictive Parity criterion when run on this dataset, but that’s because [other mitigating factor]. It still satisfies Within-\\(\\varepsilon\\) Predictive Parity, for \\(\\varepsilon = 0.02\\)\"\n\n\nDoing Too Much\n  \nAll of the above, plus I developed a new better algorithm that is more fair"
  },
  {
    "objectID": "w12/slides.html#evaluating-policy",
    "href": "w12/slides.html#evaluating-policy",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Evaluating Policy",
    "text": "Evaluating Policy\n\n\n\n\n\n\n\nBelow Expectations\n\n\"This policy is bad\"\n\n\nMeets Expectations\n\n\"This policy is bad bc it's biased towards [group 1], and doesn't take sufficient account of the welfare of [group 2]\"\n\n\nExceeds Expectations\n\n\"This policy is bad bc it's biased towards [group 1], and doesn't take sufficient account of the welfare of [group 2], which violates the Rawlsian notion of what would be chosen by rational agents behind a 'veil of ignorance'\"\n\n\nDoing Too Much\n  \n\"This policy is bad bc the inferred welfare weights \\(\\omega_i\\) are \\(0.1632\\) off from the optimal welfare weights \\(\\omega_i^*\\)\""
  },
  {
    "objectID": "w12/slides.html#frequently-awesome-questions",
    "href": "w12/slides.html#frequently-awesome-questions",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Frequently Awesome Questions",
    "text": "Frequently Awesome Questions\n\nHow much data-processing/R/Python is required? None!\n\nYou can think of it like: In every other DSAN class, we plop a dataset in front of you and say “do the thing”\nHere you can (and should) first ask, “is [data sci technique] an effective way to address this issue?”\n\nExample: archive of missing datasets\nSometimes the problem is not “We haven’t trained a neural net on this yet!” but instead “nobody with power cares enough about this to make a dataset in the first place [or they purposefully prevent it]”"
  },
  {
    "objectID": "w12/slides.html#getting-from-here-to-there",
    "href": "w12/slides.html#getting-from-here-to-there",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Getting From Here to There",
    "text": "Getting From Here to There\n\n\nMinimum Viable Product (MVP)\n\\(\\leadsto\\) Final Product (but… Hofstadter’s Law)\n\n\n\n\n\n Hofstadter’s Law (Paraphrase)\n\n\nThe pieces of your DSAN final project will take longer than you expect, even if you take Hofstadter’s Law into account"
  },
  {
    "objectID": "w12/slides.html#but-first-phenomenology",
    "href": "w12/slides.html#but-first-phenomenology",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "But First… Phenomenology",
    "text": "But First… Phenomenology\n\n“Objective” account: Roquentin sits down on a bus seat; “Subjective” account:\n\n\nI lean my hand on the seat but pull it back hurriedly: it exists. This thing I’m sitting on, leaning my hand on, is called a seat. They made it purposely for people to sit on, they took leather, springs and cloth, they went to work with the idea of making a seat and when they finished, that was what they had made. They carried it here, into this car and the car is now rolling and jolting with its rattling windows, carrying this red thing in its bosom. I murmur: “It’s a seat,” a little like an exorcism. But the word stays on my lips: it refuses to go and put itself on the thing. It stays what it is, with its red plush, thousands of little red paws in the air, all still, little dead paws…\n\n\n(From “Book Review: Nausea - Jean-Paul Sartre)"
  },
  {
    "objectID": "w12/slides.html#w.e.b.-du-bois-and-the-epistemological-one-way-mirror",
    "href": "w12/slides.html#w.e.b.-du-bois-and-the-epistemological-one-way-mirror",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "W.E.B. Du Bois and the Epistemological One-Way Mirror",
    "text": "W.E.B. Du Bois and the Epistemological One-Way Mirror\n\nBlack people in America are […] born with a veil […] in this American world—a world which yields him no true self-consciousness, but only lets him see himself through the revelation of the other world. It is a peculiar sensation, this double-consciousness, this sense of always looking at oneself through the eyes of others, of measuring one’s soul by the tape of a world that looks on in amused contempt and pity. One ever feels his two-ness—an American, a Negro; two souls, two thoughts, two unreconciled strivings; two warring ideals in one dark body. (Du Bois 1903)\n\n\nThe veil: the world is seen and experienced differently on either side of the color line\nOne-way mirror: Whites project their constructions of Blacks onto the veil and see their projections reflected on it \\(\\Rightarrow\\) the power to define themselves and others\nThe projections of whites onto the veil become realities that Black subjects have to contend with in their self-formation.\nTwoness: in process of self-formation, the racialized subject must account for the views of two different social worlds—the Black world, constructed behind the veil, and the white world, which dehumanizes via lack of recognition of their humanity."
  },
  {
    "objectID": "w12/slides.html#textsfrace_textsfvariable-vs.-textsfrace_textsfconstruct",
    "href": "w12/slides.html#textsfrace_textsfvariable-vs.-textsfrace_textsfconstruct",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "\\(\\textsf{Race}_{\\textsf{Variable}}\\) vs. \\(\\textsf{Race}_{\\textsf{Construct}}\\)",
    "text": "\\(\\textsf{Race}_{\\textsf{Variable}}\\) vs. \\(\\textsf{Race}_{\\textsf{Construct}}\\)\n\nCareful scientific, causal studies measure the effect that changing \\(X\\) (\\(do(X)\\)) has on \\(Y\\), controlling for \\(C\\) (via, at least under the hood, “Do-Calculus”)\nBut, even the most careful, controlled (and thus informative!) experiments must, at some level, partition variables into “race” and “not race”\nKeep in back of your mind as we look at example of how (measured by thorough, statistically-principled experiment), race can have direct, measurable, causal impacts on important aspects of our everyday lives"
  },
  {
    "objectID": "w12/slides.html#racial-discrimination",
    "href": "w12/slides.html#racial-discrimination",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Racial Discrimination",
    "text": "Racial Discrimination\n\nMarianne Bertrand and Sendhil Mullainathan. 2004. “Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination.” American Economic Review. (Bertrand and Mullainathan 2004)\n\n\nWe study race in the labor market by sending fictitious resumes to help-wanted ads in Boston and Chicago newspapers. To manipulate perceived race, resumes are randomly assigned African-American- or White-sounding names. White names receive 50 percent more callbacks for interviews. Callbacks are also more responsive to resume quality for White names than for African-American ones. The racial gap is uniform across occupation, industry, and employer size. We also find little evidence that employers are inferring social class from the names. Differential treatment by race still appears to still be prominent in the U.S. labor market."
  },
  {
    "objectID": "w12/slides.html#controlling-for-everything-besides-race",
    "href": "w12/slides.html#controlling-for-everything-besides-race",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "“Controlling for” Everything Besides Race",
    "text": "“Controlling for” Everything Besides Race"
  },
  {
    "objectID": "w12/slides.html#age-discrimination",
    "href": "w12/slides.html#age-discrimination",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Age Discrimination?",
    "text": "Age Discrimination?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBased on Lily Hu, What is ‘Race’ in Algorithmic Discrimination on the Basis of Race? - IPAM at UCLA (YouTube)"
  },
  {
    "objectID": "w12/slides.html#cool-theory-i-guess",
    "href": "w12/slides.html#cool-theory-i-guess",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "“Cool Theory, I Guess…”",
    "text": "“Cool Theory, I Guess…”\n\n“Good luck measuring ideas inside of people’s heads… I’ll be over here measuring real things and doing real data science!” -My Opps"
  },
  {
    "objectID": "w12/slides.html#cool-theory-i-guess-1",
    "href": "w12/slides.html#cool-theory-i-guess-1",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "“Cool Theory, I Guess…”",
    "text": "“Cool Theory, I Guess…”"
  },
  {
    "objectID": "w12/slides.html#opening-a-big-can-of-worms",
    "href": "w12/slides.html#opening-a-big-can-of-worms",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Opening A Big Can Of Worms",
    "text": "Opening A Big Can Of Worms\n\n\n\n\n\n\n\nSocial interactions among \\(t^e_0\\), \\(t^e_1\\), \\(t^e_2\\)…"
  },
  {
    "objectID": "w12/slides.html#opening-a-big-can-of-worms-1",
    "href": "w12/slides.html#opening-a-big-can-of-worms-1",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Opening A Big Can Of Worms",
    "text": "Opening A Big Can Of Worms\n\n\n\n\n\n\n\nSocial interactions among \\(t^e_0\\), \\(t^e_1\\), \\(t^e_2\\)…\nMediated by external things \\(o^e_3\\) to \\(o^e_8\\) (giving rise to patterns of interaction)…"
  },
  {
    "objectID": "w12/slides.html#opening-a-big-can-of-worms-2",
    "href": "w12/slides.html#opening-a-big-can-of-worms-2",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Opening A Big Can Of Worms",
    "text": "Opening A Big Can Of Worms\n\n\n\n\n\n\n\nSocial interactions among \\(t^e_0\\), \\(t^e_1\\), \\(t^e_2\\)…\nMediated by external things \\(o^e_3\\) to \\(o^e_8\\) (giving rise to patterns of interaction)…\nEach person \\(x\\) forming their own internal representations \\(\\widetilde{t^x_0}\\), \\(\\widetilde{t^x_1}\\), \\(\\widetilde{t^x_2}\\) of one another based on patterns of interaction, then\nGeneralizing to an internal representation of a “type of person” \\(\\widetilde{t^x_9}\\)…"
  },
  {
    "objectID": "w12/slides.html#opening-a-big-can-of-worms-3",
    "href": "w12/slides.html#opening-a-big-can-of-worms-3",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Opening A Big Can Of Worms",
    "text": "Opening A Big Can Of Worms\n\n\n\n\n\n\n\nSocial interactions among \\(t^e_0\\), \\(t^e_1\\), \\(t^e_2\\)\nMediated by external things \\(o^e_3\\) to \\(o^e_8\\) (giving rise to patterns of interaction)\nEach person \\(x\\) forming their own internal representations \\(\\widetilde{t^x_0}\\), \\(\\widetilde{t^x_1}\\), \\(\\widetilde{t^x_2}\\) based on patterns of interaction, then\nGeneralizing to an internal representation of a “type of person” \\(\\widetilde{t^x_9}\\)\nWhich they then externalize as \\(t^x_9\\).\n\\(t^0_9\\), \\(t^1_9\\), \\(t^2_9\\) “congeal” into a shared external representation \\(t_9^e\\) via social mechanism (discussion, media, culture, propaganda, parenting, religion, education, …) \\(\\Rightarrow t^e_9\\) “reified” (causal effects on \\(t_0\\), \\(t_1\\), \\(t_2\\))"
  },
  {
    "objectID": "w12/slides.html#references",
    "href": "w12/slides.html#references",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "References",
    "text": "References\n\n\nBertrand, Marianne, and Sendhil Mullainathan. 2004. “Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination.” American Economic Review 94 (4): 991–1013. https://doi.org/10.1257/0002828042002561.\n\n\nDu Bois, W. E. B. 1903. The Souls of Black Folk: Essays and Sketches. A. C. McClurg."
  },
  {
    "objectID": "w12/index.html",
    "href": "w12/index.html",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#how-do-i-pick-a-topic",
    "href": "w12/index.html#how-do-i-pick-a-topic",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "How Do I Pick A Topic?",
    "text": "How Do I Pick A Topic?\n\nI know that “whatever is interesting to you” can be way overly-vague!\nSo, one approach is: imagine yourself in a job interview for your dream job, and they bring up DSAN 5450: “Interesting, what did you do in that class?”\n[Insert final project elevator pitch] “Wow, that’s such a cool project, we really want someone who can [say] take a data-driven approach to a policy question like that. You’re hired!”\n(Jeff gets a commission: 10% of your salary)",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#the-rating-system",
    "href": "w12/index.html#the-rating-system",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "The Rating System",
    "text": "The Rating System\n\n\n\n\n\n\nFigure 1: On Cinema at the Cinema S1E09",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#discussing-fairness",
    "href": "w12/index.html#discussing-fairness",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Discussing Fairness",
    "text": "Discussing Fairness\n\n\n\n\n\n\n\nBelow Expectations\n\n\"This algorithm is unfair\"\n\n\nMeets Expectations\n\n\"This algorithm violates the Predictive Parity criterion of fairness when run on this dataset\"\n\n\nExceeds Expectations\n\n\"This algorithm violates the Predictive Parity criterion when run on this dataset, but that’s because [other mitigating factor]. It still satisfies Within-\\(\\varepsilon\\) Predictive Parity, for \\(\\varepsilon = 0.02\\)\"\n\n\nDoing Too Much\n  \nAll of the above, plus I developed a new better algorithm that is more fair",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#evaluating-policy",
    "href": "w12/index.html#evaluating-policy",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Evaluating Policy",
    "text": "Evaluating Policy\n\n\n\n\n\n\n\nBelow Expectations\n\n\"This policy is bad\"\n\n\nMeets Expectations\n\n\"This policy is bad bc it's biased towards [group 1], and doesn't take sufficient account of the welfare of [group 2]\"\n\n\nExceeds Expectations\n\n\"This policy is bad bc it's biased towards [group 1], and doesn't take sufficient account of the welfare of [group 2], which violates the Rawlsian notion of what would be chosen by rational agents behind a 'veil of ignorance'\"\n\n\nDoing Too Much\n  \n\"This policy is bad bc the inferred welfare weights \\(\\omega_i\\) are \\(0.1632\\) off from the optimal welfare weights \\(\\omega_i^*\\)\"",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#frequently-awesome-questions",
    "href": "w12/index.html#frequently-awesome-questions",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Frequently Awesome Questions",
    "text": "Frequently Awesome Questions\n\nHow much data-processing/R/Python is required? None!\n\nYou can think of it like: In every other DSAN class, we plop a dataset in front of you and say “do the thing”\nHere you can (and should) first ask, “is [data sci technique] an effective way to address this issue?”\n\nExample: archive of missing datasets\nSometimes the problem is not “We haven’t trained a neural net on this yet!” but instead “nobody with power cares enough about this to make a dataset in the first place [or they purposefully prevent it]”",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#getting-from-here-to-there",
    "href": "w12/index.html#getting-from-here-to-there",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Getting From Here to There",
    "text": "Getting From Here to There\n\n\nMinimum Viable Product (MVP)\n\\(\\leadsto\\) Final Product (but… Hofstadter’s Law)\n\n\n\n\n\n\n\n Hofstadter’s Law (Paraphrase)\n\n\n\nThe pieces of your DSAN final project will take longer than you expect, even if you take Hofstadter’s Law into account",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#but-first-phenomenology",
    "href": "w12/index.html#but-first-phenomenology",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "But First… Phenomenology",
    "text": "But First… Phenomenology\n\n“Objective” account: Roquentin sits down on a bus seat; “Subjective” account:\n\n\nI lean my hand on the seat but pull it back hurriedly: it exists. This thing I’m sitting on, leaning my hand on, is called a seat. They made it purposely for people to sit on, they took leather, springs and cloth, they went to work with the idea of making a seat and when they finished, that was what they had made. They carried it here, into this car and the car is now rolling and jolting with its rattling windows, carrying this red thing in its bosom. I murmur: “It’s a seat,” a little like an exorcism. But the word stays on my lips: it refuses to go and put itself on the thing. It stays what it is, with its red plush, thousands of little red paws in the air, all still, little dead paws…\n\n\n\n\n(From “Book Review: Nausea - Jean-Paul Sartre)",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#w.e.b.-du-bois-and-the-epistemological-one-way-mirror",
    "href": "w12/index.html#w.e.b.-du-bois-and-the-epistemological-one-way-mirror",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "W.E.B. Du Bois and the Epistemological One-Way Mirror",
    "text": "W.E.B. Du Bois and the Epistemological One-Way Mirror\n\nBlack people in America are […] born with a veil […] in this American world—a world which yields him no true self-consciousness, but only lets him see himself through the revelation of the other world. It is a peculiar sensation, this double-consciousness, this sense of always looking at oneself through the eyes of others, of measuring one’s soul by the tape of a world that looks on in amused contempt and pity. One ever feels his two-ness—an American, a Negro; two souls, two thoughts, two unreconciled strivings; two warring ideals in one dark body. (Du Bois 1903)\n\n\nThe veil: the world is seen and experienced differently on either side of the color line\nOne-way mirror: Whites project their constructions of Blacks onto the veil and see their projections reflected on it \\(\\Rightarrow\\) the power to define themselves and others\nThe projections of whites onto the veil become realities that Black subjects have to contend with in their self-formation.\nTwoness: in process of self-formation, the racialized subject must account for the views of two different social worlds—the Black world, constructed behind the veil, and the white world, which dehumanizes via lack of recognition of their humanity.",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#textsfrace_textsfvariable-vs.-textsfrace_textsfconstruct",
    "href": "w12/index.html#textsfrace_textsfvariable-vs.-textsfrace_textsfconstruct",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "\\(\\textsf{Race}_{\\textsf{Variable}}\\) vs. \\(\\textsf{Race}_{\\textsf{Construct}}\\)",
    "text": "\\(\\textsf{Race}_{\\textsf{Variable}}\\) vs. \\(\\textsf{Race}_{\\textsf{Construct}}\\)\n\nCareful scientific, causal studies measure the effect that changing \\(X\\) (\\(do(X)\\)) has on \\(Y\\), controlling for \\(C\\) (via, at least under the hood, “Do-Calculus”)\nBut, even the most careful, controlled (and thus informative!) experiments must, at some level, partition variables into “race” and “not race”\nKeep in back of your mind as we look at example of how (measured by thorough, statistically-principled experiment), race can have direct, measurable, causal impacts on important aspects of our everyday lives",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#racial-discrimination",
    "href": "w12/index.html#racial-discrimination",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Racial Discrimination",
    "text": "Racial Discrimination\n\nMarianne Bertrand and Sendhil Mullainathan. 2004. “Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination.” American Economic Review. (Bertrand and Mullainathan 2004)\n\n\nWe study race in the labor market by sending fictitious resumes to help-wanted ads in Boston and Chicago newspapers. To manipulate perceived race, resumes are randomly assigned African-American- or White-sounding names. White names receive 50 percent more callbacks for interviews. Callbacks are also more responsive to resume quality for White names than for African-American ones. The racial gap is uniform across occupation, industry, and employer size. We also find little evidence that employers are inferring social class from the names. Differential treatment by race still appears to still be prominent in the U.S. labor market.",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#controlling-for-everything-besides-race",
    "href": "w12/index.html#controlling-for-everything-besides-race",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "“Controlling for” Everything Besides Race",
    "text": "“Controlling for” Everything Besides Race",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#age-discrimination",
    "href": "w12/index.html#age-discrimination",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Age Discrimination?",
    "text": "Age Discrimination?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBased on Lily Hu, What is ‘Race’ in Algorithmic Discrimination on the Basis of Race? - IPAM at UCLA (YouTube)",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#cool-theory-i-guess",
    "href": "w12/index.html#cool-theory-i-guess",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "“Cool Theory, I Guess…”",
    "text": "“Cool Theory, I Guess…”\n\n“Good luck measuring ideas inside of people’s heads… I’ll be over here measuring real things and doing real data science!” -My Opps",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#cool-theory-i-guess-1",
    "href": "w12/index.html#cool-theory-i-guess-1",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "“Cool Theory, I Guess…”",
    "text": "“Cool Theory, I Guess…”",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#opening-a-big-can-of-worms",
    "href": "w12/index.html#opening-a-big-can-of-worms",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Opening A Big Can Of Worms",
    "text": "Opening A Big Can Of Worms\n\n\n\n\n\n\n\nSocial interactions among \\(t^e_0\\), \\(t^e_1\\), \\(t^e_2\\)…",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#opening-a-big-can-of-worms-1",
    "href": "w12/index.html#opening-a-big-can-of-worms-1",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Opening A Big Can Of Worms",
    "text": "Opening A Big Can Of Worms\n\n\n\n\n\n\n\nSocial interactions among \\(t^e_0\\), \\(t^e_1\\), \\(t^e_2\\)…\nMediated by external things \\(o^e_3\\) to \\(o^e_8\\) (giving rise to patterns of interaction)…",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#opening-a-big-can-of-worms-2",
    "href": "w12/index.html#opening-a-big-can-of-worms-2",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Opening A Big Can Of Worms",
    "text": "Opening A Big Can Of Worms\n\n\n\n\n\n\n\nSocial interactions among \\(t^e_0\\), \\(t^e_1\\), \\(t^e_2\\)…\nMediated by external things \\(o^e_3\\) to \\(o^e_8\\) (giving rise to patterns of interaction)…\nEach person \\(x\\) forming their own internal representations \\(\\widetilde{t^x_0}\\), \\(\\widetilde{t^x_1}\\), \\(\\widetilde{t^x_2}\\) of one another based on patterns of interaction, then\nGeneralizing to an internal representation of a “type of person” \\(\\widetilde{t^x_9}\\)…",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#opening-a-big-can-of-worms-3",
    "href": "w12/index.html#opening-a-big-can-of-worms-3",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "Opening A Big Can Of Worms",
    "text": "Opening A Big Can Of Worms\n\n\n\n\n\n\n\nSocial interactions among \\(t^e_0\\), \\(t^e_1\\), \\(t^e_2\\)\nMediated by external things \\(o^e_3\\) to \\(o^e_8\\) (giving rise to patterns of interaction)\nEach person \\(x\\) forming their own internal representations \\(\\widetilde{t^x_0}\\), \\(\\widetilde{t^x_1}\\), \\(\\widetilde{t^x_2}\\) based on patterns of interaction, then\nGeneralizing to an internal representation of a “type of person” \\(\\widetilde{t^x_9}\\)\nWhich they then externalize as \\(t^x_9\\).\n\\(t^0_9\\), \\(t^1_9\\), \\(t^2_9\\) “congeal” into a shared external representation \\(t_9^e\\) via social mechanism (discussion, media, culture, propaganda, parenting, religion, education, …) \\(\\Rightarrow t^e_9\\) “reified” (causal effects on \\(t_0\\), \\(t_1\\), \\(t_2\\))",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "w12/index.html#references",
    "href": "w12/index.html#references",
    "title": "Week 12: Final Projects, Causality and Racecraft",
    "section": "References",
    "text": "References\n\n\nBertrand, Marianne, and Sendhil Mullainathan. 2004. “Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination.” American Economic Review 94 (4): 991–1013. https://doi.org/10.1257/0002828042002561.\n\n\nDu Bois, W. E. B. 1903. The Souls of Black Folk: Essays and Sketches. A. C. McClurg.",
    "crumbs": [
      "Week 12: {{< var w12.date-md >}}"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Welcome to DSAN 5450: Data Ethics and Policy at Georgetown University!\nThe course meets on Wednesdays from 3:30-6pm in the Walsh Building, Room 498",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-staff",
    "href": "syllabus.html#course-staff",
    "title": "Syllabus",
    "section": "Course Staff",
    "text": "Course Staff\n\nProf. Jeff Jacobs, jj1088@georgetown.edu\n\nOffice hours (Click to schedule): Tuesdays, 3:30-6:30pm\n\nTA Marie Vaughan, mev71@georgetown.edu\nTA Sam Sofman, sbs106@georgetown.edu",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nThis graduate-level course will train students to navigate the landscape of ethical issues which arise at each step of the data science process, with an eye towards developing policy recommendations for governments and organizations seeking expert advice on how to tackle these issues from a regulatory perspective. Students will explore and critically evaluate a range of data-related issues in contemporary society, such as responsible data collection, algorithmic bias, privacy, transparency, accountability, democratic participation in data usage and data-driven decisions, and the ethical implications of emerging technologies like artificial intelligence and machine learning (self-driving cars, ChatGPT, crowd-sourced training data, etc.).\nBeginning with a set of historical case studies—instances in which scientists, engineers, and policymakers have been forced to re-evaluate their ethical intuitions in light of technological developments (nuclear power, use of social media platforms to organize protests and influence political outcomes, deployment of facial recognition software and predictive AI by police and military forces)—the course then introduces a set of general ethical frameworks (consequentialism, deontological ethics, and virtue ethics), challenging students to consider their relative strengths and weaknesses for addressing modern technological-ethical dilemmas faced by businesses, healthcare organizations, governments, and academic institutions. After a final portion of the course linking these ethical frameworks with practical regulatory and policy considerations, students will write and present a policy whitepaper analyzing a data-ethical issue of particular interest to them, integrating ethical perspectives, regulatory principles, and domain knowledge into a recommendation of best practices for the relevant agency, firm, or institution.\nThe course will thus equip students with a robust ethical “toolbox” for conscientiously gathering, interpreting, and extracting meaning from data throughout their careers as data scientists, while respecting privacy, fairness, transparency, democratic accountability, and other social concerns. Prerequisites: None. 3 credits.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-overview",
    "href": "syllabus.html#course-overview",
    "title": "Syllabus",
    "section": "Course Overview",
    "text": "Course Overview\nThe course revolves around three “pillars”, which we’ll examine individually before bringing them together for your final projects at the end of the class: high-level ethical issues in data science, general ethical frameworks, and public policy applications.\n\nData Science\nA portion of the course will focus on introductions to cutting-edge technologies like self-driving cars, ChatGPT, facial detection algorithms, and various applications of AI to police and military technologies. For this portion, we’ll draw fairly often from the contents of the following books:\n\nPerez (2019): Invisible Women: Data Bias in a World Designed for Men.\nCatherine D’Ignazio and Lauren F. Klein (2020). Data Feminism. Cambridge, MA: MIT Press. [Free, open-source!]\nCathy O’Neil (2016). Weapons of Math Destruction. New York, NY: Crown Books.\n\nSince there are plenty of in-depth resources available to you (e.g., other Georgetown courses!) for learning the technical details of these technologies, our goal in this course will be to learn just the particular aspects of each technology which are most relevant to the ethical and policy issues they present.\nFor example, we will look at Neural Netwok-based Machine Learning algorithms, but we will focus specifically on how the performance of these algorithms on a given task depends crucially on the existence of effective training data for that task. The breakthroughs in Artificial Intelligence which have had an immense impact on society over the past few decades, for example, have not come about because of new algorithms (neural networks, for example, have been around since the 1950s). Rather, they have come about because of the massive, exponential increase in the amount of data available to train these already-existing algorithms: for example, data scraped from across the entire web, or from millions of scanned books, or from Wikipedia’s massive collection of articles. This means, therefore, that these algorithms simply encode pre-existing human biases into algorithmically-derived “rules”, thus motivating the next pillar of the course: Ethics!\n\n\nEthics\nFor the ethics-focused portion of the course, we’ll be reading selections from the following textbook:\n\nLewis Vaughn and Louis P. Pojman (2021). The Moral Life: An Introductory Reader in Ethics and Literature. Oxford, UK: Oxford University Press. [PDF]\n\nFrom the vast array of readings contained in this collection, we’ll look at both “standard” ethical readings from e.g. Jeremy Bentham and Immanuel Kant plus readings from literary sources like Ursula Le Guin and Ambrose Bierce.\n\n\nPublic Policy\nFor the final piece of the course we will take the technological developments discussed the first portion, analyze them using the ethical frameworks discussed in the second portion, and come to conclusions as to what types of things lawmakers, governments, and civil society organizations (NGOs, for example, and Think Tanks) can do in practice to address the ethical issues raised by these technologies. This means that, specifically, the recommended final project for the course will be a Policy Whitepaper, where you will choose a particular institution and make a recommendation to them in terms of how they can use their power (for example, the power to pass laws) to most effectively address an ethical issue that you believe is important.\nFor this portion of the class we’ll have to draw on a wide range of different readings, depending on what particular subdomains of public policy are most interesting to you all, but as a general textbook on ethics in data science which does focus a good amount on policy specifically, we will look at:\n\nAnne L. Washington (2023). Ethical Data Science: Prediction in the Public Interest. New York, NY: Oxford University Press.\n\nNow that you have an overview of the trajectory of the course, the following section contains the particulars of what we’ll be reading and working on each week!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#schedule",
    "href": "syllabus.html#schedule",
    "title": "Syllabus",
    "section": "Schedule",
    "text": "Schedule\nThe following is a rough map of what we will work through together throughout the semester; given that everyone learns at a different pace, my aim is to leave us with a good amount of flexibility in terms of how much time we spend on each topic: if I find that it takes me longer than a week to convey a certain topic in sufficient depth, for example, then I view it as a strength rather than a weakness of the course that we can then rearrange the calendar below by adding an extra week on that particular topic! Similarly, if it seems like I am spending too much time on a topic, to the point that students seem bored or impatient to move onto the next topic, we can move a topic intended for the next week to the current week!\n\n\n\nUnit\nWeek\nDate\nTopic\n\n\n\n\nUnit 1: Ethical Frameworks\n1\nJan 15\nIntroduction to the Course\n\n\n\n2\nJan 22\nMachine Learning, Training Data, and Bias\n\n\nUnit 2: Fairness in AI\n3\nJan 29\nEthical Frameworks: Rights, Discrimination, and Fairness\n\n\n\n\nJan 31 (Friday), 5:59pm EST\n[Deliverable] HW1: Nuts and Bolts for Fairness in AI\n\n\n\n4\nFeb 5\n(Descriptive) Fairness in AI\n\n\n\n5\nFeb 12\nContext-Sensitive Fairness\n\n\n\n6\nFeb 19\nCausality in Ethics and Policy\n\n\n\n\nFeb 21 (Friday), 5:59pm EST\n[Deliverable] HW2: Context-Sensitive Fairness\n\n\nMidterm\n7\nFeb 26\nIn-Class Midterm: Data Ethics, Fairness, Privacy, Causality\n\n\n\n\nMar 6\nNo Class (Spring Break)\n\n\nUnit 3: Policy Frameworks\n8\nMar 12\nPrivacy Policies, Incomplete Contracts, and Power\n\n\n\n9\nMar 19\nFrom Data Ethics to Data Policy\n\n\n\n10\nMar 26\nWelfare Economics and Policy Evaluation\n\n\n\n11\nApr 2\nFear and Loathing on the Pareto Frontier\n\n\nUnit 4: Applications\n12\nApr 9\nProject Talk, Causality and Identity Formation\n\n\n\n13\nApr 16\nApplications: Race, Class, Gender, Sexuality, and Disability (Data Feminism)\n\n\n\n14\nApr 23\nRepublican Liberty and the Kindly Slavemaster\n\n\n\n\nMay 10 (Friday)\n[Deliverable] Policy Whitepaper",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#assignments-and-grading",
    "href": "syllabus.html#assignments-and-grading",
    "title": "Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThe main assignment in the course will be your policy whitepaper, submitted at the end of the semester. However, there will also be a midterm exam and a series of assignments which exist to let you explore each of the modules of the course, in turn.\n\n\n\n\n\n\n\n\nAssignment\nDue Date\n% of Grade\n\n\n\n\nHW1: Nuts and Bolts for Fairness in AI \nFriday, February 9\n10%\n\n\nHW2: Context-Sensitive Fairness \nFriday, February 21\n10%\n\n\nMidterm\nWednesday, February 28\n30%\n\n\nHW3: Privacy Policies as Incomplete Contracts \nFriday, April 12\n10%\n\n\nHW4: Policy Evaluation\nFriday, April 26\n10%\n\n\nPolicy Whitepaper\nFriday, May 10\n30%\n\n\n\n\nHomework Lateness Policy\nAfter the due date, for each homework assignment, you will have a grace period of 24 hours to submit the assignment without a lateness penalty. After this 24-hour grace period, late penalties will be applied based on the following scale (unless you obtain an excused lateness from one of the instructional staff!):\n\n0 to 24 hours late: no penalty\n24 to 30 hours late: 2.5% penalty\n30 to 42 hours late: 5% penalty\n42 to 54 hours late: 10% penalty\n54 to 66 hours late: 20% penalty\nMore than 66 hours late: Assignment submissions no longer accepted (without instructor approval)",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "w06/slides.html#clarification-ecological-inference",
    "href": "w06/slides.html#clarification-ecological-inference",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Clarification: Ecological Inference",
    "text": "Clarification: Ecological Inference\n\nI gave the worst example for this: generalizing from population to single person (white people \\(\\rightarrow\\) Jeff)!\nAs Trey helpfully pointed out, this is the “obvious” fallacy of stereotyping a person based on group membership\nIn reality, the “ecological fallacy” is more subtly (but just as fallacious-ly) committed from aggregate to slightly-less-aggregate populations!\nExample: DC Public Schools vs. Jackson-Reed"
  },
  {
    "objectID": "w06/slides.html#eureka-moment-for-midterm-prep-purposes",
    "href": "w06/slides.html#eureka-moment-for-midterm-prep-purposes",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Eureka Moment (for Midterm Prep Purposes)",
    "text": "Eureka Moment (for Midterm Prep Purposes)\n\n\n# For slides\nlibrary(ggplot2)\ncbPalette &lt;- c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\noptions(ggplot2.discrete.colour = cbPalette)\n# Theme generator, for given sizes\ntheme_dsan &lt;- function(plot_type = \"full\") {\n    if (plot_type == \"full\") {\n        custom_base_size &lt;- 16\n    } else if (plot_type == \"half\") {\n        custom_base_size &lt;- 22\n    } else if (plot_type == \"quarter\") {\n        custom_base_size &lt;- 28\n    } else {\n        # plot_type == \"col\"\n        custom_base_size &lt;- 22\n    }\n    theme &lt;- theme_classic(base_size = custom_base_size) +\n        theme(\n            plot.title = element_text(hjust = 0.5),\n            plot.subtitle = element_text(hjust = 0.5),\n            legend.title = element_text(hjust = 0.5),\n            legend.box.background = element_rect(colour = \"black\")\n        )\n    return(theme)\n}\n\nknitr::opts_chunk$set(fig.align = \"center\")\ng_pointsize &lt;- 5\ng_linesize &lt;- 1\n# Technically it should always be linewidth\ng_linewidth &lt;- 1\ng_textsize &lt;- 14\n\nremove_legend_title &lt;- function() {\n    return(theme(\n        legend.title = element_blank(),\n        legend.spacing.y = unit(0, \"mm\")\n    ))\n}\n\n\n\nI totally forgot to mention: John Stuart Mill, the progenitor of what we today identify as utilitarianism, was himself tortured mercilessly, by his father John Mill (bffs with Jeremy Bentham) for the “greater good of society”!"
  },
  {
    "objectID": "w06/slides.html#dgps-and-the-emergence-of-order",
    "href": "w06/slides.html#dgps-and-the-emergence-of-order",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "DGPs and the Emergence of Order",
    "text": "DGPs and the Emergence of Order\n\n\n\n\n\n\n\nWho can guess the state of this process after 10 steps, with 1 person?\n10 people? 50? 100? (If they find themselves on the same spot, they stand on each other’s heads)\n100 steps? 1000?"
  },
  {
    "objectID": "w06/slides.html#the-result-16-steps",
    "href": "w06/slides.html#the-result-16-steps",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Result: 16 Steps",
    "text": "The Result: 16 Steps\n\n\nCode\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(ggExtra)\nlibrary(dplyr)\nlibrary(tidyr)\n# From McElreath!\ngen_histo &lt;- function(reps, num_steps) {\n  support &lt;- c(-1,1)\n  pos &lt;-replicate(reps, sum(sample(support,num_steps,replace=TRUE,prob=c(0.5,0.5))))\n  #print(mean(pos))\n  #print(var(pos))\n  pos_df &lt;- tibble(x=pos)\n  clt_distr &lt;- function(x) dnorm(x, 0, sqrt(num_steps))\n  plot &lt;- ggplot(pos_df, aes(x=x)) +\n    geom_histogram(aes(y = after_stat(density)), fill=cbPalette[1], binwidth = 2) +\n    stat_function(fun = clt_distr) +\n    theme_dsan(\"quarter\") +\n    theme(title=element_text(size=16)) +\n    labs(\n      title=paste0(reps,\" Random Walks, \",num_steps,\" Steps\")\n    )\n  return(plot)\n}\ngen_walkplot &lt;- function(num_people, num_steps, opacity=0.15) {\n  support &lt;- c(-1, 1)\n  # Unique id for each person\n  pid &lt;- seq(1, num_people)\n  pid_tib &lt;- tibble(pid)\n  pos_df &lt;- tibble()\n  end_df &lt;- tibble()\n  all_steps &lt;- t(replicate(num_people, sample(support, num_steps, replace = TRUE, prob = c(0.5, 0.5))))\n  csums &lt;- t(apply(all_steps, 1, cumsum))\n  csums &lt;- cbind(0, csums)\n  # Last col is the ending positions\n  ending_pos &lt;- csums[, dim(csums)[2]]\n  end_tib &lt;- tibble(pid = seq(1, num_people), endpos = ending_pos, x = num_steps)\n  # Now convert to tibble\n  ctib &lt;- as_tibble(csums, name_repair = \"none\")\n  merged_tib &lt;- bind_cols(pid_tib, ctib)\n  long_tib &lt;- merged_tib %&gt;% pivot_longer(!pid)\n  # Convert name -&gt; step_num\n  long_tib &lt;- long_tib %&gt;% mutate(step_num = strtoi(gsub(\"V\", \"\", name)) - 1)\n  # print(end_df)\n  grid_color &lt;- rgb(0, 0, 0, 0.1)\n\n  # And plot!\n  walkplot &lt;- ggplot(\n      long_tib,\n      aes(\n          x = step_num,\n          y = value,\n          group = pid,\n          # color=factor(label)\n      )\n  ) +\n      geom_line(linewidth = g_linesize, alpha = opacity, color = cbPalette[1]) +\n      geom_point(data = end_tib, aes(x = x, y = endpos), alpha = 0) +\n      scale_x_continuous(breaks = seq(0, num_steps, num_steps / 4)) +\n      scale_y_continuous(breaks = seq(-20, 20, 10)) +\n      theme_dsan(\"quarter\") +\n      theme(\n          legend.position = \"none\",\n          title = element_text(size = 16)\n      ) +\n      theme(\n          panel.grid.major.y = element_line(color = grid_color, linewidth = 1, linetype = 1)\n      ) +\n      labs(\n          title = paste0(num_people, \" Random Walks, \", num_steps, \" Steps\"),\n          x = \"Number of Steps\",\n          y = \"Position\"\n      )\n}\nwp1 &lt;- gen_walkplot(500, 16, 0.05)\nggMarginal(wp1, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))"
  },
  {
    "objectID": "w06/slides.html#the-result-64-steps",
    "href": "w06/slides.html#the-result-64-steps",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Result: 64 Steps",
    "text": "The Result: 64 Steps\n\n\nCode\nlibrary(ggExtra)\nwp2 &lt;- gen_walkplot(5000,64,0.008) +\n  ylim(-30,30)\nggMarginal(wp2, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))"
  },
  {
    "objectID": "w06/slides.html#mathematicalscientific-modeling",
    "href": "w06/slides.html#mathematicalscientific-modeling",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "“Mathematical/Scientific Modeling”",
    "text": "“Mathematical/Scientific Modeling”\n\nThing we observe (poking out of water): data\nHidden but possibly discoverable through deeper investigation (ecosystem under surface): model / DGP"
  },
  {
    "objectID": "w06/slides.html#so-whats-the-problem",
    "href": "w06/slides.html#so-whats-the-problem",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "So What’s the Problem?",
    "text": "So What’s the Problem?\n\nNon-probabilistic models: High potential for being garbage\n\ntldr: even if SUPER certain, using \\(\\Pr(\\mathcal{H}) = 1-\\varepsilon\\) with tiny \\(\\varepsilon\\) has literal life-saving advantages (Finetti 1972)\n\nProbabilistic models: Getting there, still looking at “surface”\n\nOf the \\(N = 100\\) times we observed event \\(X\\) occurring, event \\(Y\\) also occurred \\(90\\) of those times\n\\(\\implies \\Pr(Y \\mid X) = \\frac{\\#[X, Y]}{\\#[X]} = \\frac{90}{100} = 0.9\\)\n\nCausal models: Does \\(Y\\) happen because of \\(X\\) happening? For that, need to start modeling what’s happening under the surface making \\(X\\) and \\(Y\\) “pop up” together so often"
  },
  {
    "objectID": "w06/slides.html#the-intuitive-but-boring-problem-of-causal-inference",
    "href": "w06/slides.html#the-intuitive-but-boring-problem-of-causal-inference",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Intuitive But Boring Problem of Causal Inference",
    "text": "The Intuitive But Boring Problem of Causal Inference\n\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nga_lawyers &lt;- c(21362, 22254, 23134, 23698, 24367, 24930, 25632, 26459, 27227, 27457)\nski_df &lt;- tibble::tribble(\n  ~year, ~varname, ~value,\n  2000, \"ski_revenue\", 1551,\n  2001, \"ski_revenue\", 1635,\n  2002, \"ski_revenue\", 1801,\n  2003, \"ski_revenue\", 1827,\n  2004, \"ski_revenue\", 1956,\n  2005, \"ski_revenue\", 1989,\n  2006, \"ski_revenue\", 2178,\n  2007, \"ski_revenue\", 2257,\n  2008, \"ski_revenue\", 2476,\n  2009, \"ski_revenue\", 2438,\n)\nski_mean &lt;- mean(ski_df$value)\nski_sd &lt;- sd(ski_df$value)\nski_df &lt;- ski_df %&gt;% mutate(val_scaled = 12*value, val_norm = (value - ski_mean)/ski_sd)\nlaw_df &lt;- tibble::tibble(year=2000:2009, varname=\"ga_lawyers\", value=ga_lawyers)\nlaw_mean &lt;- mean(law_df$value)\nlaw_sd &lt;- sd(law_df$value)\nlaw_df &lt;- law_df %&gt;% mutate(val_norm = (value - law_mean)/law_sd)\nspur_df &lt;- dplyr::bind_rows(ski_df, law_df)\nggplot(spur_df, aes(x=year, y=val_norm, color=factor(varname, labels = c(\"Ski Revenue\",\"Lawyers in Georgia\")))) +\n  stat_smooth(method=\"loess\", se=FALSE) +\n  geom_point(size=g_pointsize/1.5) +\n  labs(\n    fill=\"\",\n    title=\"Ski Revenue vs. Georgia Lawyers\",\n    x=\"Year\",\n    color=\"Correlation: 99.2%\",\n    linetype=NULL\n  ) +\n  theme_dsan() +\n  scale_x_continuous(\n    breaks=seq(from=2000, to=2014, by=2)\n  ) +\n  #scale_y_continuous(\n  #  name=\"Total Revenue, Ski Facilities (Million USD)\",\n  #  sec.axis = sec_axis(~ . * law_sd + law_mean, name = \"Number of Lawyers in Georgia\")\n  #) +\n  scale_y_continuous(breaks = -1:1,\n    labels = ~ . * round(ski_sd,1) + round(ski_mean,1),\n    name=\"Total Revenue, Ski Facilities (Million USD)\",\n    sec.axis = sec_axis(~ . * law_sd + law_mean, name = \"Number of Lawyers in Georgia\")) +\n  expand_limits(x=2010) +\n  #geom_hline(aes(yintercept=x, color=\"Mean Values\"), as.data.frame(list(x=0)), linewidth=0.75, alpha=1.0, show.legend = TRUE) +\n  scale_color_manual(\n    breaks=c('Ski Revenue', 'Lawyers in Georgia'),\n    values=c('Ski Revenue'=cbPalette[1], 'Lawyers in Georgia'=cbPalette[2])\n  )\n\n\n\n\n\n\n\n\n\n\ncor(ski_df$value, law_df$value)\n\n[1] 0.9921178\n\n\n\n(Based on Spurious Correlations, Tyler Vigen)\n\n\nThis, however, is only a mini-boss. Beyond it lies the truly invincible FINAL BOSS… 🙀"
  },
  {
    "objectID": "w06/slides.html#the-fundamental-problem-of-causal-inference",
    "href": "w06/slides.html#the-fundamental-problem-of-causal-inference",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Fundamental Problem of Causal Inference",
    "text": "The Fundamental Problem of Causal Inference\nThe only workable definition of “\\(X\\) causes \\(Y\\)”:\n\n\n\n\n Defining Causality\n\n\n\\(X\\) causes \\(Y\\) if and only if:\n\n\\(X\\) temporally precedes \\(Y\\) and\n\nIn two worlds \\(W_0\\) and \\(W_1\\) where\neverything is exactly the same except that \\(X = 0\\) in \\(W_0\\) and \\(X = 1\\) in \\(W_1\\),\n\\(Y = 0\\) in \\(W_0\\) and \\(Y = 1\\) in \\(W_1\\).\n\n\n(hume_treatise_1739?, ruining everything as usual 😤)\n\n\n\n\n\nThe problem? We live in one world, not two identical worlds simultaneously 😭"
  },
  {
    "objectID": "w06/slides.html#what-is-to-be-done",
    "href": "w06/slides.html#what-is-to-be-done",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "What Is To Be Done?",
    "text": "What Is To Be Done?"
  },
  {
    "objectID": "w06/slides.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "href": "w06/slides.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm",
    "text": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm\n\nFind good comparison cases: Treatment and Control\nWithout a control group, you cannot make inferences!\nSelecting on the dependent variable…"
  },
  {
    "objectID": "w06/slides.html#selecting-on-the-dependent-variable",
    "href": "w06/slides.html#selecting-on-the-dependent-variable",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Selecting on the Dependent Variable",
    "text": "Selecting on the Dependent Variable\n\nWhat “““research”“” “““says”“” about identifying people who might commit mass shootings\nJeff’s ABHYSIOWDCI claim: If we care about intervening to reduce social ills, this literally has negative value (Goes up to zero value if you don’t publish it though! 😉)\n\n\n(Annoying But Hopefully You’ll See the Importance Once We Digest Causal Inference… a standard term in The Sciences)"
  },
  {
    "objectID": "w06/slides.html#complications-selection",
    "href": "w06/slides.html#complications-selection",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Complications: Selection",
    "text": "Complications: Selection\n\nTldr: Why did this person (unit) end up in the treatment group? Why did this other person (unit) end up in the control group?\nAre there systematic differences?\n“““Vietnam”“” “““War”“” Draft: Why can’t we just study [men who join the military] versus [men who don’t], and take the difference as a causal estimate?"
  },
  {
    "objectID": "w06/slides.html#the-solution-matching",
    "href": "w06/slides.html#the-solution-matching",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Solution: Matching",
    "text": "The Solution: Matching\n\n(W02 we looked at propensity score matching… kind of the Naïve Bayes of matching)\n\n\nControlled experiment: we can ensure (since we have control over the assignment mechanism) the only systematic difference between \\(C\\) and \\(T\\) is: \\(T\\) received treatment, \\(C\\) did not\nIn an observational study, we’re “too late”! Thus, we no longer refer to assignment but to selection\nOur job is to reverse engineer the selection mechanism, then correct for its non-randomness. Spoiler: “transform” observational \\(\\rightarrow\\) experimental via weighting.\nThat’s the gold at end of rainbow. The rainbow itself is…"
  },
  {
    "objectID": "w06/slides.html#our-data-generating-process",
    "href": "w06/slides.html#our-data-generating-process",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Our Data-Generating Process",
    "text": "Our Data-Generating Process\n\n\\(Y\\): Future success, \\(\\mathcal{R}_Y = \\{0, 1\\}\\)\n\\(E\\): Private school education, \\(\\mathcal{R}_E = \\{0, 1\\}\\)\n\\(V\\): Born into poverty, \\(\\mathcal{R}_V = \\{0, 1\\}\\)\n\n\n\n\n\n\n\n\nThe Private School \\(\\leadsto\\) Success Pipeline 🤑\n\n\n\nSample independent RVs \\(U_1 \\sim \\mathcal{B}(1/2)\\), \\(U_2 \\sim \\mathcal{B}(1/3)\\), \\(U_3 \\sim \\mathcal{B}(1/3)\\)\n\\(V \\leftarrow U_1\\)\n\\(E \\leftarrow \\textsf{if }(V = 1)\\textsf{ then } 0\\textsf{ else }U_2\\)\n\\(Y \\leftarrow \\textsf{if }(V = 1)\\textsf{ then }0\\textsf{ else }U_3\\)"
  },
  {
    "objectID": "w06/slides.html#chalkboard-time",
    "href": "w06/slides.html#chalkboard-time",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Chalkboard Time…",
    "text": "Chalkboard Time…\n\n\\(\\Pr(Y = 1) = \\; ?\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\; ?\\)"
  },
  {
    "objectID": "w06/slides.html#top-secret-answers-slide-dont-peek",
    "href": "w06/slides.html#top-secret-answers-slide-dont-peek",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Top Secret Answers Slide (Don’t Peek)",
    "text": "Top Secret Answers Slide (Don’t Peek)\n\n\\(\\Pr(Y = 1) = \\frac{1}{6}\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\frac{1}{3}\\)\n\\(\\overset{✅}{\\implies}\\) One out of every three private-school graduates is successful, vs. one out of every six graduates overall\n\\(\\overset{❓}{\\implies}\\) Private school doubles likelihood of success!\nLatter is only true if intervening/changing/doing \\(E = 0 \\leadsto E = 1\\) is what moves \\(\\Pr(Y = 1)\\) from \\(\\frac{1}{6}\\) to \\(\\frac{1}{3}\\)!"
  },
  {
    "objectID": "w06/slides.html#chalkboard-time-2-electric-boogaloo",
    "href": "w06/slides.html#chalkboard-time-2-electric-boogaloo",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Chalkboard Time 2: Electric Boogaloo",
    "text": "Chalkboard Time 2: Electric Boogaloo\n\n\\(\\Pr(Y = 1) = \\frac{1}{6}\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\frac{1}{3}\\)\n\\(\\Pr(Y = 1 \\mid \\textsf{do}(E = 1)) = \\; ?\\)\nHere, \\(\\textsf{do}(E = 1)\\) means diving into the DGP below the surface and changing it so \\(E = 1\\)… Setting \\(E\\) to be \\(1\\)\n\n\n\n\n\n\n\n\n\\(\\text{DGP}(Y \\mid \\textsf{do}(E = 1))\\)\n\n\n\nSample independent RVs \\(U_1 \\sim \\mathcal{B}(1/2)\\), \\(U_2 \\sim \\mathcal{B}(1/3)\\), \\(U_3 \\sim \\mathcal{B}(1/3)\\)\n\\(V \\leftarrow U_1\\)\n\\(E \\leftarrow \\textsf{if }(V = 1)\\textsf{ then } 0\\textsf{ else }U_2\\)\n\\(Y \\leftarrow \\textsf{if }(V = 1)\\textsf{ then }0\\textsf{ else }U_3\\)"
  },
  {
    "objectID": "w06/slides.html#double-quadruple-secret-answer-slide",
    "href": "w06/slides.html#double-quadruple-secret-answer-slide",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Double Quadruple Secret Answer Slide",
    "text": "Double Quadruple Secret Answer Slide\n\n\\(\\Pr(Y = 1) = \\frac{1}{6}\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\frac{1}{3}\\)\n\\(\\Pr(Y = 1 \\mid \\textsf{do}(E = 1)) = \\frac{1}{6}\\)\nThe takeaway:\n\n\\(\\Pr(Y = 1 \\mid E = 1) &lt; \\Pr(Y = 1)\\), but\n\\(\\Pr(Y = 1 \\mid \\textsf{do}(E = 1)) = \\Pr(Y = 1)\\)"
  },
  {
    "objectID": "w06/slides.html#the-problem-of-colliders",
    "href": "w06/slides.html#the-problem-of-colliders",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Problem of Colliders",
    "text": "The Problem of Colliders\nBerkson’s Paradox:\n\n\\(X\\) and \\(Y\\) are diseases which occur independently, no interrelationship, with probability \\(1/3\\)\nEither \\(X\\) or \\(Y\\) sufficient for admission to hospital, \\(Z\\)\nWe have: \\(X \\rightarrow Z \\leftarrow Y\\) [🚨 Collider alert!]"
  },
  {
    "objectID": "w06/slides.html#whats-the-issue",
    "href": "w06/slides.html#whats-the-issue",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "What’s the Issue?",
    "text": "What’s the Issue?\n\nIf we only have data on patients (\\(Z = 1\\)), observing \\(X = 1\\) lowers \\(\\Pr(Y = 1)\\), despite the fact that \\(X \\perp Y\\)!\n\\(X \\perp Y\\), but \\((X \\not\\perp Y) \\mid Z\\)\nThe moral: controlling for stuff does not necessarily solve problem of causal inference, and can actually make it worse (inducing correlations where they don’t actually exist) 😭"
  },
  {
    "objectID": "w06/slides.html#the-causal-trinity-when-controlling-for-stuff-helps",
    "href": "w06/slides.html#the-causal-trinity-when-controlling-for-stuff-helps",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Causal Trinity: When Controlling for Stuff Helps",
    "text": "The Causal Trinity: When Controlling for Stuff Helps\n\nFork: Controlling helps!\nConfounder: Controlling helps!\nCollider: Controlling makes things worse 😞"
  },
  {
    "objectID": "w06/slides.html#the-final-diagrammatic-boss-swigs",
    "href": "w06/slides.html#the-final-diagrammatic-boss-swigs",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Final Diagrammatic Boss: SWIGs",
    "text": "The Final Diagrammatic Boss: SWIGs\n\nSingle World Intervention Graphs"
  },
  {
    "objectID": "w06/slides.html#references",
    "href": "w06/slides.html#references",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "References",
    "text": "References\n\n\nFinetti, Bruno de. 1972. Probability, Induction and Statistics: The Art of Guessing. J. Wiley."
  },
  {
    "objectID": "w06/index.html",
    "href": "w06/index.html",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#clarification-ecological-inference",
    "href": "w06/index.html#clarification-ecological-inference",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Clarification: Ecological Inference",
    "text": "Clarification: Ecological Inference\n\nI gave the worst example for this: generalizing from population to single person (white people \\(\\rightarrow\\) Jeff)!\nAs Trey helpfully pointed out, this is the “obvious” fallacy of stereotyping a person based on group membership\nIn reality, the “ecological fallacy” is more subtly (but just as fallacious-ly) committed from aggregate to slightly-less-aggregate populations!\nExample: DC Public Schools vs. Jackson-Reed",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#eureka-moment-for-midterm-prep-purposes",
    "href": "w06/index.html#eureka-moment-for-midterm-prep-purposes",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Eureka Moment (for Midterm Prep Purposes)",
    "text": "Eureka Moment (for Midterm Prep Purposes)\n\n\n# For slides\nlibrary(ggplot2)\ncbPalette &lt;- c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\noptions(ggplot2.discrete.colour = cbPalette)\n# Theme generator, for given sizes\ntheme_dsan &lt;- function(plot_type = \"full\") {\n    if (plot_type == \"full\") {\n        custom_base_size &lt;- 16\n    } else if (plot_type == \"half\") {\n        custom_base_size &lt;- 22\n    } else if (plot_type == \"quarter\") {\n        custom_base_size &lt;- 28\n    } else {\n        # plot_type == \"col\"\n        custom_base_size &lt;- 22\n    }\n    theme &lt;- theme_classic(base_size = custom_base_size) +\n        theme(\n            plot.title = element_text(hjust = 0.5),\n            plot.subtitle = element_text(hjust = 0.5),\n            legend.title = element_text(hjust = 0.5),\n            legend.box.background = element_rect(colour = \"black\")\n        )\n    return(theme)\n}\n\nknitr::opts_chunk$set(fig.align = \"center\")\ng_pointsize &lt;- 5\ng_linesize &lt;- 1\n# Technically it should always be linewidth\ng_linewidth &lt;- 1\ng_textsize &lt;- 14\n\nremove_legend_title &lt;- function() {\n    return(theme(\n        legend.title = element_blank(),\n        legend.spacing.y = unit(0, \"mm\")\n    ))\n}\n\n\n\nI totally forgot to mention: John Stuart Mill, the progenitor of what we today identify as utilitarianism, was himself tortured mercilessly, by his father John Mill (bffs with Jeremy Bentham) for the “greater good of society”!",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#dgps-and-the-emergence-of-order",
    "href": "w06/index.html#dgps-and-the-emergence-of-order",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "DGPs and the Emergence of Order",
    "text": "DGPs and the Emergence of Order\n\n\n\n\n\n\n\nWho can guess the state of this process after 10 steps, with 1 person?\n10 people? 50? 100? (If they find themselves on the same spot, they stand on each other’s heads)\n100 steps? 1000?",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#the-result-16-steps",
    "href": "w06/index.html#the-result-16-steps",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Result: 16 Steps",
    "text": "The Result: 16 Steps\n\n\nCode\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(ggExtra)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(tidyr)\n# From McElreath!\ngen_histo &lt;- function(reps, num_steps) {\n  support &lt;- c(-1,1)\n  pos &lt;-replicate(reps, sum(sample(support,num_steps,replace=TRUE,prob=c(0.5,0.5))))\n  #print(mean(pos))\n  #print(var(pos))\n  pos_df &lt;- tibble(x=pos)\n  clt_distr &lt;- function(x) dnorm(x, 0, sqrt(num_steps))\n  plot &lt;- ggplot(pos_df, aes(x=x)) +\n    geom_histogram(aes(y = after_stat(density)), fill=cbPalette[1], binwidth = 2) +\n    stat_function(fun = clt_distr) +\n    theme_dsan(\"quarter\") +\n    theme(title=element_text(size=16)) +\n    labs(\n      title=paste0(reps,\" Random Walks, \",num_steps,\" Steps\")\n    )\n  return(plot)\n}\ngen_walkplot &lt;- function(num_people, num_steps, opacity=0.15) {\n  support &lt;- c(-1, 1)\n  # Unique id for each person\n  pid &lt;- seq(1, num_people)\n  pid_tib &lt;- tibble(pid)\n  pos_df &lt;- tibble()\n  end_df &lt;- tibble()\n  all_steps &lt;- t(replicate(num_people, sample(support, num_steps, replace = TRUE, prob = c(0.5, 0.5))))\n  csums &lt;- t(apply(all_steps, 1, cumsum))\n  csums &lt;- cbind(0, csums)\n  # Last col is the ending positions\n  ending_pos &lt;- csums[, dim(csums)[2]]\n  end_tib &lt;- tibble(pid = seq(1, num_people), endpos = ending_pos, x = num_steps)\n  # Now convert to tibble\n  ctib &lt;- as_tibble(csums, name_repair = \"none\")\n  merged_tib &lt;- bind_cols(pid_tib, ctib)\n  long_tib &lt;- merged_tib %&gt;% pivot_longer(!pid)\n  # Convert name -&gt; step_num\n  long_tib &lt;- long_tib %&gt;% mutate(step_num = strtoi(gsub(\"V\", \"\", name)) - 1)\n  # print(end_df)\n  grid_color &lt;- rgb(0, 0, 0, 0.1)\n\n  # And plot!\n  walkplot &lt;- ggplot(\n      long_tib,\n      aes(\n          x = step_num,\n          y = value,\n          group = pid,\n          # color=factor(label)\n      )\n  ) +\n      geom_line(linewidth = g_linesize, alpha = opacity, color = cbPalette[1]) +\n      geom_point(data = end_tib, aes(x = x, y = endpos), alpha = 0) +\n      scale_x_continuous(breaks = seq(0, num_steps, num_steps / 4)) +\n      scale_y_continuous(breaks = seq(-20, 20, 10)) +\n      theme_dsan(\"quarter\") +\n      theme(\n          legend.position = \"none\",\n          title = element_text(size = 16)\n      ) +\n      theme(\n          panel.grid.major.y = element_line(color = grid_color, linewidth = 1, linetype = 1)\n      ) +\n      labs(\n          title = paste0(num_people, \" Random Walks, \", num_steps, \" Steps\"),\n          x = \"Number of Steps\",\n          y = \"Position\"\n      )\n}\nwp1 &lt;- gen_walkplot(500, 16, 0.05)\n\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n\nCode\nggMarginal(wp1, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#the-result-64-steps",
    "href": "w06/index.html#the-result-64-steps",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Result: 64 Steps",
    "text": "The Result: 64 Steps\n\n\nCode\nlibrary(ggExtra)\nwp2 &lt;- gen_walkplot(5000,64,0.008) +\n  ylim(-30,30)\n\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\n\n\nCode\nggMarginal(wp2, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))\n\n\nWarning: Removed 6 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 6 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#mathematicalscientific-modeling",
    "href": "w06/index.html#mathematicalscientific-modeling",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "“Mathematical/Scientific Modeling”",
    "text": "“Mathematical/Scientific Modeling”\n\nThing we observe (poking out of water): data\nHidden but possibly discoverable through deeper investigation (ecosystem under surface): model / DGP",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#so-whats-the-problem",
    "href": "w06/index.html#so-whats-the-problem",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "So What’s the Problem?",
    "text": "So What’s the Problem?\n\nNon-probabilistic models: High potential for being garbage\n\ntldr: even if SUPER certain, using \\(\\Pr(\\mathcal{H}) = 1-\\varepsilon\\) with tiny \\(\\varepsilon\\) has literal life-saving advantages (Finetti 1972)\n\nProbabilistic models: Getting there, still looking at “surface”\n\nOf the \\(N = 100\\) times we observed event \\(X\\) occurring, event \\(Y\\) also occurred \\(90\\) of those times\n\\(\\implies \\Pr(Y \\mid X) = \\frac{\\#[X, Y]}{\\#[X]} = \\frac{90}{100} = 0.9\\)\n\nCausal models: Does \\(Y\\) happen because of \\(X\\) happening? For that, need to start modeling what’s happening under the surface making \\(X\\) and \\(Y\\) “pop up” together so often",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#the-intuitive-but-boring-problem-of-causal-inference",
    "href": "w06/index.html#the-intuitive-but-boring-problem-of-causal-inference",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Intuitive But Boring Problem of Causal Inference",
    "text": "The Intuitive But Boring Problem of Causal Inference\n\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nga_lawyers &lt;- c(21362, 22254, 23134, 23698, 24367, 24930, 25632, 26459, 27227, 27457)\nski_df &lt;- tibble::tribble(\n  ~year, ~varname, ~value,\n  2000, \"ski_revenue\", 1551,\n  2001, \"ski_revenue\", 1635,\n  2002, \"ski_revenue\", 1801,\n  2003, \"ski_revenue\", 1827,\n  2004, \"ski_revenue\", 1956,\n  2005, \"ski_revenue\", 1989,\n  2006, \"ski_revenue\", 2178,\n  2007, \"ski_revenue\", 2257,\n  2008, \"ski_revenue\", 2476,\n  2009, \"ski_revenue\", 2438,\n)\nski_mean &lt;- mean(ski_df$value)\nski_sd &lt;- sd(ski_df$value)\nski_df &lt;- ski_df %&gt;% mutate(val_scaled = 12*value, val_norm = (value - ski_mean)/ski_sd)\nlaw_df &lt;- tibble::tibble(year=2000:2009, varname=\"ga_lawyers\", value=ga_lawyers)\nlaw_mean &lt;- mean(law_df$value)\nlaw_sd &lt;- sd(law_df$value)\nlaw_df &lt;- law_df %&gt;% mutate(val_norm = (value - law_mean)/law_sd)\nspur_df &lt;- dplyr::bind_rows(ski_df, law_df)\nggplot(spur_df, aes(x=year, y=val_norm, color=factor(varname, labels = c(\"Ski Revenue\",\"Lawyers in Georgia\")))) +\n  stat_smooth(method=\"loess\", se=FALSE) +\n  geom_point(size=g_pointsize/1.5) +\n  labs(\n    fill=\"\",\n    title=\"Ski Revenue vs. Georgia Lawyers\",\n    x=\"Year\",\n    color=\"Correlation: 99.2%\",\n    linetype=NULL\n  ) +\n  theme_dsan() +\n  scale_x_continuous(\n    breaks=seq(from=2000, to=2014, by=2)\n  ) +\n  #scale_y_continuous(\n  #  name=\"Total Revenue, Ski Facilities (Million USD)\",\n  #  sec.axis = sec_axis(~ . * law_sd + law_mean, name = \"Number of Lawyers in Georgia\")\n  #) +\n  scale_y_continuous(breaks = -1:1,\n    labels = ~ . * round(ski_sd,1) + round(ski_mean,1),\n    name=\"Total Revenue, Ski Facilities (Million USD)\",\n    sec.axis = sec_axis(~ . * law_sd + law_mean, name = \"Number of Lawyers in Georgia\")) +\n  expand_limits(x=2010) +\n  #geom_hline(aes(yintercept=x, color=\"Mean Values\"), as.data.frame(list(x=0)), linewidth=0.75, alpha=1.0, show.legend = TRUE) +\n  scale_color_manual(\n    breaks=c('Ski Revenue', 'Lawyers in Georgia'),\n    values=c('Ski Revenue'=cbPalette[1], 'Lawyers in Georgia'=cbPalette[2])\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\ncor(ski_df$value, law_df$value)\n\n[1] 0.9921178\n\n\n\n(Based on Spurious Correlations, Tyler Vigen)\n\n\nThis, however, is only a mini-boss. Beyond it lies the truly invincible FINAL BOSS… 🙀",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#the-fundamental-problem-of-causal-inference",
    "href": "w06/index.html#the-fundamental-problem-of-causal-inference",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Fundamental Problem of Causal Inference",
    "text": "The Fundamental Problem of Causal Inference\nThe only workable definition of “\\(X\\) causes \\(Y\\)”:\n\n\n\n\n\n\n Defining Causality\n\n\n\n\\(X\\) causes \\(Y\\) if and only if:\n\n\\(X\\) temporally precedes \\(Y\\) and\n\nIn two worlds \\(W_0\\) and \\(W_1\\) where\neverything is exactly the same except that \\(X = 0\\) in \\(W_0\\) and \\(X = 1\\) in \\(W_1\\),\n\\(Y = 0\\) in \\(W_0\\) and \\(Y = 1\\) in \\(W_1\\).\n\n\n(hume_treatise_1739?, ruining everything as usual 😤)\n\n\n\nThe problem? We live in one world, not two identical worlds simultaneously 😭",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#what-is-to-be-done",
    "href": "w06/index.html#what-is-to-be-done",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "What Is To Be Done?",
    "text": "What Is To Be Done?",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "href": "w06/index.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm",
    "text": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm\n\nFind good comparison cases: Treatment and Control\nWithout a control group, you cannot make inferences!\nSelecting on the dependent variable…",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#selecting-on-the-dependent-variable",
    "href": "w06/index.html#selecting-on-the-dependent-variable",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Selecting on the Dependent Variable",
    "text": "Selecting on the Dependent Variable\n\n\n\nWhat “““research”“” “““says”“” about identifying people who might commit mass shootings\n\n\n\nJeff’s ABHYSIOWDCI claim: If we care about intervening to reduce social ills, this literally has negative value (Goes up to zero value if you don’t publish it though! 😉)\n\n\n(Annoying But Hopefully You’ll See the Importance Once We Digest Causal Inference… a standard term in The Sciences)",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#complications-selection",
    "href": "w06/index.html#complications-selection",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Complications: Selection",
    "text": "Complications: Selection\n\nTldr: Why did this person (unit) end up in the treatment group? Why did this other person (unit) end up in the control group?\nAre there systematic differences?\n“““Vietnam”“” “““War”“” Draft: Why can’t we just study [men who join the military] versus [men who don’t], and take the difference as a causal estimate?",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#the-solution-matching",
    "href": "w06/index.html#the-solution-matching",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Solution: Matching",
    "text": "The Solution: Matching\n\n(W02 we looked at propensity score matching… kind of the Naïve Bayes of matching)\n\n\nControlled experiment: we can ensure (since we have control over the assignment mechanism) the only systematic difference between \\(C\\) and \\(T\\) is: \\(T\\) received treatment, \\(C\\) did not\nIn an observational study, we’re “too late”! Thus, we no longer refer to assignment but to selection\nOur job is to reverse engineer the selection mechanism, then correct for its non-randomness. Spoiler: “transform” observational \\(\\rightarrow\\) experimental via weighting.\nThat’s the gold at end of rainbow. The rainbow itself is…",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#our-data-generating-process",
    "href": "w06/index.html#our-data-generating-process",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Our Data-Generating Process",
    "text": "Our Data-Generating Process\n\n\\(Y\\): Future success, \\(\\mathcal{R}_Y = \\{0, 1\\}\\)\n\\(E\\): Private school education, \\(\\mathcal{R}_E = \\{0, 1\\}\\)\n\\(V\\): Born into poverty, \\(\\mathcal{R}_V = \\{0, 1\\}\\)\n\n\n\n\n\n\n\nThe Private School \\(\\leadsto\\) Success Pipeline 🤑\n\n\n\n\nSample independent RVs \\(U_1 \\sim \\mathcal{B}(1/2)\\), \\(U_2 \\sim \\mathcal{B}(1/3)\\), \\(U_3 \\sim \\mathcal{B}(1/3)\\)\n\\(V \\leftarrow U_1\\)\n\\(E \\leftarrow \\textsf{if }(V = 1)\\textsf{ then } 0\\textsf{ else }U_2\\)\n\\(Y \\leftarrow \\textsf{if }(V = 1)\\textsf{ then }0\\textsf{ else }U_3\\)",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#chalkboard-time",
    "href": "w06/index.html#chalkboard-time",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Chalkboard Time…",
    "text": "Chalkboard Time…\n\n\\(\\Pr(Y = 1) = \\; ?\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\; ?\\)",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#top-secret-answers-slide-dont-peek",
    "href": "w06/index.html#top-secret-answers-slide-dont-peek",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Top Secret Answers Slide (Don’t Peek)",
    "text": "Top Secret Answers Slide (Don’t Peek)\n\n\\(\\Pr(Y = 1) = \\frac{1}{6}\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\frac{1}{3}\\)\n\\(\\overset{✅}{\\implies}\\) One out of every three private-school graduates is successful, vs. one out of every six graduates overall\n\\(\\overset{❓}{\\implies}\\) Private school doubles likelihood of success!\nLatter is only true if intervening/changing/doing \\(E = 0 \\leadsto E = 1\\) is what moves \\(\\Pr(Y = 1)\\) from \\(\\frac{1}{6}\\) to \\(\\frac{1}{3}\\)!",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#chalkboard-time-2-electric-boogaloo",
    "href": "w06/index.html#chalkboard-time-2-electric-boogaloo",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Chalkboard Time 2: Electric Boogaloo",
    "text": "Chalkboard Time 2: Electric Boogaloo\n\n\\(\\Pr(Y = 1) = \\frac{1}{6}\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\frac{1}{3}\\)\n\\(\\Pr(Y = 1 \\mid \\textsf{do}(E = 1)) = \\; ?\\)\nHere, \\(\\textsf{do}(E = 1)\\) means diving into the DGP below the surface and changing it so \\(E = 1\\)… Setting \\(E\\) to be \\(1\\)\n\n\n\n\n\n\n\n\\(\\text{DGP}(Y \\mid \\textsf{do}(E = 1))\\)\n\n\n\n\nSample independent RVs \\(U_1 \\sim \\mathcal{B}(1/2)\\), \\(U_2 \\sim \\mathcal{B}(1/3)\\), \\(U_3 \\sim \\mathcal{B}(1/3)\\)\n\\(V \\leftarrow U_1\\)\n\\(E \\leftarrow \\textsf{if }(V = 1)\\textsf{ then } 0\\textsf{ else }U_2\\)\n\\(Y \\leftarrow \\textsf{if }(V = 1)\\textsf{ then }0\\textsf{ else }U_3\\)",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#double-quadruple-secret-answer-slide",
    "href": "w06/index.html#double-quadruple-secret-answer-slide",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Double Quadruple Secret Answer Slide",
    "text": "Double Quadruple Secret Answer Slide\n\n\\(\\Pr(Y = 1) = \\frac{1}{6}\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\frac{1}{3}\\)\n\\(\\Pr(Y = 1 \\mid \\textsf{do}(E = 1)) = \\frac{1}{6}\\)\nThe takeaway:\n\n\\(\\Pr(Y = 1 \\mid E = 1) &lt; \\Pr(Y = 1)\\), but\n\\(\\Pr(Y = 1 \\mid \\textsf{do}(E = 1)) = \\Pr(Y = 1)\\)",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#the-problem-of-colliders",
    "href": "w06/index.html#the-problem-of-colliders",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Problem of Colliders",
    "text": "The Problem of Colliders\nBerkson’s Paradox:\n\n\\(X\\) and \\(Y\\) are diseases which occur independently, no interrelationship, with probability \\(1/3\\)\nEither \\(X\\) or \\(Y\\) sufficient for admission to hospital, \\(Z\\)\nWe have: \\(X \\rightarrow Z \\leftarrow Y\\) [🚨 Collider alert!]",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#whats-the-issue",
    "href": "w06/index.html#whats-the-issue",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "What’s the Issue?",
    "text": "What’s the Issue?\n\nIf we only have data on patients (\\(Z = 1\\)), observing \\(X = 1\\) lowers \\(\\Pr(Y = 1)\\), despite the fact that \\(X \\perp Y\\)!\n\\(X \\perp Y\\), but \\((X \\not\\perp Y) \\mid Z\\)\nThe moral: controlling for stuff does not necessarily solve problem of causal inference, and can actually make it worse (inducing correlations where they don’t actually exist) 😭",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#the-causal-trinity-when-controlling-for-stuff-helps",
    "href": "w06/index.html#the-causal-trinity-when-controlling-for-stuff-helps",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Causal Trinity: When Controlling for Stuff Helps",
    "text": "The Causal Trinity: When Controlling for Stuff Helps\n\nFork: Controlling helps!\nConfounder: Controlling helps!\nCollider: Controlling makes things worse 😞",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#the-final-diagrammatic-boss-swigs",
    "href": "w06/index.html#the-final-diagrammatic-boss-swigs",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Final Diagrammatic Boss: SWIGs",
    "text": "The Final Diagrammatic Boss: SWIGs\n\nSingle World Intervention Graphs",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#references",
    "href": "w06/index.html#references",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "References",
    "text": "References\n\n\nFinetti, Bruno de. 1972. Probability, Induction and Statistics: The Art of Guessing. J. Wiley.",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w08/slides.html#discourse-around-data-policy-in-the-us",
    "href": "w08/slides.html#discourse-around-data-policy-in-the-us",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Discourse Around “Data Policy” in the US",
    "text": "Discourse Around “Data Policy” in the US\n\n(This is the level at which “national conversations” are conducted around big data)"
  },
  {
    "objectID": "w08/slides.html#actually-relevant-takeaway",
    "href": "w08/slides.html#actually-relevant-takeaway",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Actually-Relevant Takeaway",
    "text": "Actually-Relevant Takeaway\n\nUnlike the US, there are countries and national/international institutions where policies are formed, in varying degrees, by processes in which data comes into play\nWe’ll discuss more examples; two I can speak to directly from work as data consultant:\nEU: Consulted on project around implementation of GDPR\nUNESCO: Received grant for data-analysis of international translation policies\n\n194 UN member states who participate in formation of these policies\n2 UN member states who refuse to participate on basis of “anti-Israel bias” (you’ll never guess which ones! Hint: Apartheid South Africa, Rhodesia used to provide 3rd and 4th vote in this bloc, but no longer exist)\n\nNY MTA: Consulted on project studying NYC subway data, until passage of NYS Executive Order 157 banning state funding for any person or organization supporting boycott of Israel ¯\\_(ツ)_/¯"
  },
  {
    "objectID": "w08/slides.html#implies-comparative-perspective",
    "href": "w08/slides.html#implies-comparative-perspective",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "\\(\\implies\\) Comparative Perspective",
    "text": "\\(\\implies\\) Comparative Perspective\n\nWe’ll study various countries / international orgs and their attempts to tackle data policy issues (with hope that takeaways can be applied to the US someday as well)\nImportant to retain descriptive/normative distinction!\nThey’ll become harder to distinguish, as we discuss:\n\nWhat are the policies currently in existence?\nWhat are their drawbacks?\nAnd, among the latter, which ones could be addressed via policy? (requires understanding processes of policy formation) Which ones could not? (prisoner’s dilemma)"
  },
  {
    "objectID": "w08/slides.html#oecd-guidelines-1980",
    "href": "w08/slides.html#oecd-guidelines-1980",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "OECD Guidelines, 1980",
    "text": "OECD Guidelines, 1980\n\n“The basis for most modern privacy laws” (Sugimoto, Ekbia, and Mattioli 2016)\nCollection Limitation Principle: data may be collected “where appropriate, with the knowledge or consent of the data subject.” (OECD 1980, 14)\nUse Limitation Principle: “Personal data should not be disclosed, made available or otherwise used for purposes other than those specified [at time of collection] except with the consent of the data subject” (OECD 1980, 15)"
  },
  {
    "objectID": "w08/slides.html#eu-data-protection-directive-1995",
    "href": "w08/slides.html#eu-data-protection-directive-1995",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "EU Data Protection Directive, 1995",
    "text": "EU Data Protection Directive, 1995\n\nArt. 7: Processing allowed when “the data subject has unambiguously given his [sic] consent.”\nArt. 8: Use of sensitive data is restricted, except where “the data subject has given his [sic] explicit consent to the processing of those data.”\nArt. 26: Prohibits export of personal data to non-Euro countries lacking “adequate data protection”, except when “the data subject has given his [s] consent unambiguously to the proposed transfer” (European Union 1995)\nSuperceded by GDPR in 2018"
  },
  {
    "objectID": "w08/slides.html#eu-general-data-protection-regulation-gdpr-2018",
    "href": "w08/slides.html#eu-general-data-protection-regulation-gdpr-2018",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "EU General Data Protection Regulation (GDPR), 2018",
    "text": "EU General Data Protection Regulation (GDPR), 2018\n\n\n«Consent is one of the easiest to satisfy because it allows you to do just about anything with the data» (—the text right below this screenshot)"
  },
  {
    "objectID": "w08/slides.html#reading-implementing-the-gdpr",
    "href": "w08/slides.html#reading-implementing-the-gdpr",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Reading / Implementing the GDPR",
    "text": "Reading / Implementing the GDPR\n\nMain document: 261 pages\nFor SaaS companies: a nice, 34-page abridgement"
  },
  {
    "objectID": "w08/slides.html#why-we-have-to-stop-the-individual-policy-level-descriptive-part-here",
    "href": "w08/slides.html#why-we-have-to-stop-the-individual-policy-level-descriptive-part-here",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Why We Have To Stop the Individual-Policy-Level Descriptive Part Here",
    "text": "Why We Have To Stop the Individual-Policy-Level Descriptive Part Here\n(And await your final policy papers!)\n\nFrom Piwik.pro, “17 Privacy Laws Around the Globe”"
  },
  {
    "objectID": "w08/slides.html#the-crux-of-the-normative-issues",
    "href": "w08/slides.html#the-crux-of-the-normative-issues",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "The Crux of the Normative Issues",
    "text": "The Crux of the Normative Issues"
  },
  {
    "objectID": "w08/slides.html#does-reading-understanding",
    "href": "w08/slides.html#does-reading-understanding",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Does Reading = Understanding?",
    "text": "Does Reading = Understanding?\n\nDoes reading \\(\\implies\\) understanding implications / contingencies / ambiguities?\nNLP could (and should!) be helpful (“making privacy policies machine readable […] would help users match privacy preferences against policies offered by web services”), but mostly just reveals how bad the problem is:\n\n\nFigure 15 from Wagner (2023). “Obfuscatory words” are words like acceptable, significant, mainly, or predominantly, interpretated at the discretion of companies rather than users (see next slide!)"
  },
  {
    "objectID": "w08/slides.html#the-intuitive-problem-of-contracts",
    "href": "w08/slides.html#the-intuitive-problem-of-contracts",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "The Intuitive Problem of Contracts",
    "text": "The Intuitive Problem of Contracts\n\n\n\n\n\n\n\nHard to read, harder to understand, possibly rly bad stuff in them, won’t know until you read + understand\nSolution (in theory… in modern liberal market-based democracies): Collective action!\nOption 1 (Exit): Find better platform, use it instead \\(\\Rightarrow\\) company dies (competitive market)\nOption 2 (Voice): Raise a fuss, hoot and holler, make a big stink about it, etc.\n\n\\(\\Rightarrow\\) (2a) Company will change/remove it to avoid embarrassment and/or prevent Option 1 becoming an option\n\\(\\Rightarrow\\) (2b) Government intervention (hypothetical functional government)"
  },
  {
    "objectID": "w08/slides.html#the-fundamental-problem-of-contracts",
    "href": "w08/slides.html#the-fundamental-problem-of-contracts",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "The Fundamental Problem of Contracts",
    "text": "The Fundamental Problem of Contracts\n\nJust as we can’t observe two simultaneous worlds \\(W_{X = 0}\\) and \\(W_{X = 1}\\) which differ only in the value of \\(X\\),\nWe can’t foresee all possible contingencies that need to be included in a contract\n\n(We can try, though! Hence use of obfuscatory words to minimize liability)\n\nSo, when a situation arises which is not covered by a clause in the contract, what happens? What principle determines whose interpretation wins out?\n\n(Hint: It is actually literally my legal middle name…)"
  },
  {
    "objectID": "w08/slides.html#power",
    "href": "w08/slides.html#power",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "…POWER!",
    "text": "…POWER!\n\nExamples from employment contracts (tooting own horn):\nIn a private, cooperatively-owned, democratic firm, outcome determined by conversation, majority vote, unanimity, etc.\n\nThese technically exist in the US! Employing 2,380 workers, \\(\\frac{2380}{127509000} \\approx 0.0019\\%\\) of US workforce\n\nOtherwise, in a non-unionized private firm (94% of total), the outcome is determined by organizational hierarchy\n\nThis is the case for \\(\\frac{125000000}{127509000} \\approx 98.03\\%\\) of US workforce"
  },
  {
    "objectID": "w08/slides.html#descriptive-and-normative-implications",
    "href": "w08/slides.html#descriptive-and-normative-implications",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Descriptive and Normative Implications",
    "text": "Descriptive and Normative Implications\n\nWho has power w.r.t. incompleteness of contracts?\nWho ought to have power w.r.t. incompleteness of contracts?\nResidual rights of control…"
  },
  {
    "objectID": "w08/slides.html#harts-nobel-prize-speech",
    "href": "w08/slides.html#harts-nobel-prize-speech",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Hart’s Nobel Prize Speech",
    "text": "Hart’s Nobel Prize Speech\n\nComplete contracts are contracts where everything that can ever happen is written into the contract. Actual contracts aren’t like this, as lawyers know. They’re poorly worded, ambiguous, leave out important things. They’re incomplete.\nA critical question that arises with an incomplete contract is, who has the right to decide about the missing things? We called this right the residual control or decision right. The question is, who has it?\nFurther thought led us to the idea that this is what ownership is. The owner of an asset has the right to decide how the asset is used where the use is not contractually specified (Hart 2017)"
  },
  {
    "objectID": "w08/slides.html#understanding-rights-leftrightarrow-fighting-for-rights",
    "href": "w08/slides.html#understanding-rights-leftrightarrow-fighting-for-rights",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Understanding Rights \\(\\leftrightarrow\\) Fighting for Rights",
    "text": "Understanding Rights \\(\\leftrightarrow\\) Fighting for Rights\n\n“Hohfeldian” framework (Hohfeld 1913)\nA right \\(r_i\\) granted to person \\(i\\) \\(\\implies\\) A duty/obligation imposed on everyone in the world besides \\(i\\) (to respect \\(r_i\\))\nA duty or obligation \\(d_i\\) imposed on a person \\(i\\) \\(\\implies\\) A right granted to everyone in the world besides \\(i\\) (to… be a potential beneficiary of \\(d_i\\))\n\\(\\implies\\) rough measures of relative power in a contract:\n\n\\[\n\\frac{\\text{rights}_i}{\\text{rights}_j} = \\frac{\\text{obligations}_j}{\\text{rights}_j} = \\frac{\\text{rights}_i}{\\text{obligations}_j} = \\frac{\\text{obligations}_j}{\\text{obligations}_i}\n\\]"
  },
  {
    "objectID": "w08/slides.html#the-adversarial-sisyphusian-problem-of-contracts",
    "href": "w08/slides.html#the-adversarial-sisyphusian-problem-of-contracts",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "The Adversarial-Sisyphusian Problem of Contracts",
    "text": "The Adversarial-Sisyphusian Problem of Contracts\n\nRecall Intuitive Problem of Causal Inference: Correlation \\(\\nimplies\\) Causation, but can do a bunch of work to overcome\nAdversarial-Sisyphusian Problem is one level worse 😱\n\nIPCI: You vs. discovered correlation (inanimate)\nASPC: You vs. companies investing resources 💰 into making the problem harder and harder for you\n\ntldr: The moment you (\\(N=1\\), $) finally find and “fix” bad thing, company (\\(N \\gg 1\\), $$$) adds more ambiguity to re-enable / sends your data to \"new\", \"different\" 3rd-party processor 🥸"
  },
  {
    "objectID": "w08/slides.html#references",
    "href": "w08/slides.html#references",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "References",
    "text": "References\n\n\nEuropean Union. 1995. “Directive 95/46/EC of the European Parliament and of the Council of 24 October 1995 on the Protection of Individuals with Regard to the Processing of Personal Data and on the Free Movement of Such Data.” http://data.europa.eu/eli/dir/1995/46/oj/eng.\n\n\nHart, Oliver. 2017. “Incomplete Contracts and Control.” American Economic Review 107 (7): 1731–52. https://doi.org/10.1257/aer.107.7.1731.\n\n\nHohfeld, Wesley Newcomb. 1913. “Some Fundamental Legal Conceptions as Applied in Judicial Reasoning.” Yale Law Journal 23. https://heinonline.org/HOL/Page?handle=hein.journals/ylr23&id=24&div=&collection=.\n\n\nOECD. 1980. OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data. Paris: Organisation for Economic Co-operation and Development. https://www.oecd-ilibrary.org/science-and-technology/oecd-guidelines-on-the-protection-of-privacy-and-transborder-flows-of-personal-data_9789264196391-en.\n\n\nSugimoto, Cassidy R., Hamid R. Ekbia, and Michael Mattioli. 2016. Big Data Is Not a Monolith. MIT Press.\n\n\nWagner, Isabel. 2023. “Privacy Policies Across the Ages: Content of Privacy Policies 1996–2021.” ACM Transactions on Privacy and Security 26 (3): 32:1–32. https://doi.org/10.1145/3590152."
  },
  {
    "objectID": "w08/index.html",
    "href": "w08/index.html",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#discourse-around-data-policy-in-the-us",
    "href": "w08/index.html#discourse-around-data-policy-in-the-us",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Discourse Around “Data Policy” in the US",
    "text": "Discourse Around “Data Policy” in the US\n\n(This is the level at which “national conversations” are conducted around big data)",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#actually-relevant-takeaway",
    "href": "w08/index.html#actually-relevant-takeaway",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Actually-Relevant Takeaway",
    "text": "Actually-Relevant Takeaway\n\nUnlike the US, there are countries and national/international institutions where policies are formed, in varying degrees, by processes in which data comes into play\nWe’ll discuss more examples; two I can speak to directly from work as data consultant:\nEU: Consulted on project around implementation of GDPR\nUNESCO: Received grant for data-analysis of international translation policies\n\n194 UN member states who participate in formation of these policies\n2 UN member states who refuse to participate on basis of “anti-Israel bias” (you’ll never guess which ones! Hint: Apartheid South Africa, Rhodesia used to provide 3rd and 4th vote in this bloc, but no longer exist)\n\nNY MTA: Consulted on project studying NYC subway data, until passage of NYS Executive Order 157 banning state funding for any person or organization supporting boycott of Israel ¯\\_(ツ)_/¯",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#implies-comparative-perspective",
    "href": "w08/index.html#implies-comparative-perspective",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "\\(\\implies\\) Comparative Perspective",
    "text": "\\(\\implies\\) Comparative Perspective\n\nWe’ll study various countries / international orgs and their attempts to tackle data policy issues (with hope that takeaways can be applied to the US someday as well)\nImportant to retain descriptive/normative distinction!\nThey’ll become harder to distinguish, as we discuss:\n\nWhat are the policies currently in existence?\nWhat are their drawbacks?\nAnd, among the latter, which ones could be addressed via policy? (requires understanding processes of policy formation) Which ones could not? (prisoner’s dilemma)",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#oecd-guidelines-1980",
    "href": "w08/index.html#oecd-guidelines-1980",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "OECD Guidelines, 1980",
    "text": "OECD Guidelines, 1980\n\n“The basis for most modern privacy laws” (Sugimoto, Ekbia, and Mattioli 2016)\nCollection Limitation Principle: data may be collected “where appropriate, with the knowledge or consent of the data subject.” (OECD 1980, 14)\nUse Limitation Principle: “Personal data should not be disclosed, made available or otherwise used for purposes other than those specified [at time of collection] except with the consent of the data subject” (OECD 1980, 15)",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#eu-data-protection-directive-1995",
    "href": "w08/index.html#eu-data-protection-directive-1995",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "EU Data Protection Directive, 1995",
    "text": "EU Data Protection Directive, 1995\n\nArt. 7: Processing allowed when “the data subject has unambiguously given his [sic] consent.”\nArt. 8: Use of sensitive data is restricted, except where “the data subject has given his [sic] explicit consent to the processing of those data.”\nArt. 26: Prohibits export of personal data to non-Euro countries lacking “adequate data protection”, except when “the data subject has given his [s] consent unambiguously to the proposed transfer” (European Union 1995)\nSuperceded by GDPR in 2018",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#eu-general-data-protection-regulation-gdpr-2018",
    "href": "w08/index.html#eu-general-data-protection-regulation-gdpr-2018",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "EU General Data Protection Regulation (GDPR), 2018",
    "text": "EU General Data Protection Regulation (GDPR), 2018\n\n\n\n\n\n\n«Consent is one of the easiest to satisfy because it allows you to do just about anything with the data» (—the text right below this screenshot)",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#reading-implementing-the-gdpr",
    "href": "w08/index.html#reading-implementing-the-gdpr",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Reading / Implementing the GDPR",
    "text": "Reading / Implementing the GDPR\n\nMain document: 261 pages\nFor SaaS companies: a nice, 34-page abridgement",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#why-we-have-to-stop-the-individual-policy-level-descriptive-part-here",
    "href": "w08/index.html#why-we-have-to-stop-the-individual-policy-level-descriptive-part-here",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Why We Have To Stop the Individual-Policy-Level Descriptive Part Here",
    "text": "Why We Have To Stop the Individual-Policy-Level Descriptive Part Here\n(And await your final policy papers!)\n\n\n\nFrom Piwik.pro, “17 Privacy Laws Around the Globe”",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#the-crux-of-the-normative-issues",
    "href": "w08/index.html#the-crux-of-the-normative-issues",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "The Crux of the Normative Issues",
    "text": "The Crux of the Normative Issues",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#does-reading-understanding",
    "href": "w08/index.html#does-reading-understanding",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Does Reading = Understanding?",
    "text": "Does Reading = Understanding?\n\nDoes reading \\(\\implies\\) understanding implications / contingencies / ambiguities?\nNLP could (and should!) be helpful (“making privacy policies machine readable […] would help users match privacy preferences against policies offered by web services”), but mostly just reveals how bad the problem is:\n\n\n\n\nFigure 15 from Wagner (2023). “Obfuscatory words” are words like acceptable, significant, mainly, or predominantly, interpretated at the discretion of companies rather than users (see next slide!)",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#the-intuitive-problem-of-contracts",
    "href": "w08/index.html#the-intuitive-problem-of-contracts",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "The Intuitive Problem of Contracts",
    "text": "The Intuitive Problem of Contracts\n\n\n\n\n\n\n\nHard to read, harder to understand, possibly rly bad stuff in them, won’t know until you read + understand\nSolution (in theory… in modern liberal market-based democracies): Collective action!\nOption 1 (Exit): Find better platform, use it instead \\(\\Rightarrow\\) company dies (competitive market)\nOption 2 (Voice): Raise a fuss, hoot and holler, make a big stink about it, etc.\n\n\\(\\Rightarrow\\) (2a) Company will change/remove it to avoid embarrassment and/or prevent Option 1 becoming an option\n\\(\\Rightarrow\\) (2b) Government intervention (hypothetical functional government)",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#the-fundamental-problem-of-contracts",
    "href": "w08/index.html#the-fundamental-problem-of-contracts",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "The Fundamental Problem of Contracts",
    "text": "The Fundamental Problem of Contracts\n\nJust as we can’t observe two simultaneous worlds \\(W_{X = 0}\\) and \\(W_{X = 1}\\) which differ only in the value of \\(X\\),\nWe can’t foresee all possible contingencies that need to be included in a contract\n\n(We can try, though! Hence use of obfuscatory words to minimize liability)\n\nSo, when a situation arises which is not covered by a clause in the contract, what happens? What principle determines whose interpretation wins out?\n\n(Hint: It is actually literally my legal middle name…)",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#power",
    "href": "w08/index.html#power",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "…POWER!",
    "text": "…POWER!\n\nExamples from employment contracts (tooting own horn):\nIn a private, cooperatively-owned, democratic firm, outcome determined by conversation, majority vote, unanimity, etc.\n\nThese technically exist in the US! Employing 2,380 workers, \\(\\frac{2380}{127509000} \\approx 0.0019\\%\\) of US workforce\n\nOtherwise, in a non-unionized private firm (94% of total), the outcome is determined by organizational hierarchy\n\nThis is the case for \\(\\frac{125000000}{127509000} \\approx 98.03\\%\\) of US workforce",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#descriptive-and-normative-implications",
    "href": "w08/index.html#descriptive-and-normative-implications",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Descriptive and Normative Implications",
    "text": "Descriptive and Normative Implications\n\nWho has power w.r.t. incompleteness of contracts?\nWho ought to have power w.r.t. incompleteness of contracts?\nResidual rights of control…",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#harts-nobel-prize-speech",
    "href": "w08/index.html#harts-nobel-prize-speech",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Hart’s Nobel Prize Speech",
    "text": "Hart’s Nobel Prize Speech\n\nComplete contracts are contracts where everything that can ever happen is written into the contract. Actual contracts aren’t like this, as lawyers know. They’re poorly worded, ambiguous, leave out important things. They’re incomplete.\nA critical question that arises with an incomplete contract is, who has the right to decide about the missing things? We called this right the residual control or decision right. The question is, who has it?\nFurther thought led us to the idea that this is what ownership is. The owner of an asset has the right to decide how the asset is used where the use is not contractually specified (Hart 2017)",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#understanding-rights-leftrightarrow-fighting-for-rights",
    "href": "w08/index.html#understanding-rights-leftrightarrow-fighting-for-rights",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "Understanding Rights \\(\\leftrightarrow\\) Fighting for Rights",
    "text": "Understanding Rights \\(\\leftrightarrow\\) Fighting for Rights\n\n“Hohfeldian” framework (Hohfeld 1913)\nA right \\(r_i\\) granted to person \\(i\\) \\(\\implies\\) A duty/obligation imposed on everyone in the world besides \\(i\\) (to respect \\(r_i\\))\nA duty or obligation \\(d_i\\) imposed on a person \\(i\\) \\(\\implies\\) A right granted to everyone in the world besides \\(i\\) (to… be a potential beneficiary of \\(d_i\\))\n\\(\\implies\\) rough measures of relative power in a contract:\n\n\\[\n\\frac{\\text{rights}_i}{\\text{rights}_j} = \\frac{\\text{obligations}_j}{\\text{rights}_j} = \\frac{\\text{rights}_i}{\\text{obligations}_j} = \\frac{\\text{obligations}_j}{\\text{obligations}_i}\n\\]",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#the-adversarial-sisyphusian-problem-of-contracts",
    "href": "w08/index.html#the-adversarial-sisyphusian-problem-of-contracts",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "The Adversarial-Sisyphusian Problem of Contracts",
    "text": "The Adversarial-Sisyphusian Problem of Contracts\n\nRecall Intuitive Problem of Causal Inference: Correlation \\(\\nimplies\\) Causation, but can do a bunch of work to overcome\nAdversarial-Sisyphusian Problem is one level worse 😱\n\nIPCI: You vs. discovered correlation (inanimate)\nASPC: You vs. companies investing resources 💰 into making the problem harder and harder for you\n\ntldr: The moment you (\\(N=1\\), $) finally find and “fix” bad thing, company (\\(N \\gg 1\\), $$$) adds more ambiguity to re-enable / sends your data to \"new\", \"different\" 3rd-party processor 🥸",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "w08/index.html#references",
    "href": "w08/index.html#references",
    "title": "Week 8: Privacy Policies, Incomplete Contracts, and Power",
    "section": "References",
    "text": "References\n\n\nEuropean Union. 1995. “Directive 95/46/EC of the European Parliament and of the Council of 24 October 1995 on the Protection of Individuals with Regard to the Processing of Personal Data and on the Free Movement of Such Data.” http://data.europa.eu/eli/dir/1995/46/oj/eng.\n\n\nHart, Oliver. 2017. “Incomplete Contracts and Control.” American Economic Review 107 (7): 1731–52. https://doi.org/10.1257/aer.107.7.1731.\n\n\nHohfeld, Wesley Newcomb. 1913. “Some Fundamental Legal Conceptions as Applied in Judicial Reasoning.” Yale Law Journal 23. https://heinonline.org/HOL/Page?handle=hein.journals/ylr23&id=24&div=&collection=.\n\n\nOECD. 1980. OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data. Paris: Organisation for Economic Co-operation and Development. https://www.oecd-ilibrary.org/science-and-technology/oecd-guidelines-on-the-protection-of-privacy-and-transborder-flows-of-personal-data_9789264196391-en.\n\n\nSugimoto, Cassidy R., Hamid R. Ekbia, and Michael Mattioli. 2016. Big Data Is Not a Monolith. MIT Press.\n\n\nWagner, Isabel. 2023. “Privacy Policies Across the Ages: Content of Privacy Policies 1996–2021.” ACM Transactions on Privacy and Security 26 (3): 32:1–32. https://doi.org/10.1145/3590152.",
    "crumbs": [
      "Week 8: {{< var w08.date-md >}}"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSAN 5450: Data Ethics and Policy",
    "section": "",
    "text": "Welcome to the homepage for DSAN 5450: Data Ethics and Policy at Georgetown University, for the Spring 2025 semester!\nThe course meets on Wednesdays from 3:30pm to 6:00pm in the Walsh Building, Room 498.\nCheck out the syllabus (or any other link in the sidebar) for more info! Or, use the following links to view notes for individual weeks:\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nWeek 1: Introduction to the Course\n\n\nJanuary 15\n\n\n\n\nWeek 2: Machine Learning, Training Data, and Biases\n\n\nJanuary 22\n\n\n\n\nWeek 3: Ethical Frameworks, Rights, and Discrimination\n\n\nJanuary 29\n\n\n\n\nWeek 4: (Descriptive) Fairness in AI\n\n\nFebruary 5\n\n\n\n\nWeek 5: Context-Sensitive Fairness\n\n\nFebruary 12\n\n\n\n\nWeek 6: Causality in Ethics and Policy\n\n\nFebruary 19\n\n\n\n\nWeek 7: In-Class Midterm\n\n\nFebruary 26\n\n\n\n\nWeek 8: Privacy Policies, Incomplete Contracts, and Power\n\n\nMarch 12\n\n\n\n\nWeek 9: From Data Ethics to Data Policy\n\n\nMarch 19\n\n\n\n\nWeek 10: Welfare Economics and Policy Evaluation\n\n\nMarch 26\n\n\n\n\nWeek 11: Fear and Loathing on the Pareto Frontier\n\n\nApril 2\n\n\n\n\nWeek 12: Final Projects, Causality and Racecraft\n\n\nApril 9\n\n\n\n\nWeek 13: Standpoint Epistemology, Data Feminism\n\n\nApril 16\n\n\n\n\nWeek 14: Republican Liberty and the Kindly Slavemaster\n\n\nApril 23\n\n\n\n\n\nNo matching items\n\n\nCourse Description:\nThis graduate-level course will train students to navigate the landscape of ethical issues which arise at each step of the data science process, with an eye towards developing policy recommendations for governments and organizations seeking expert advice on how to tackle these issues from a regulatory perspective. Students will explore and critically evaluate a range of data-related issues in contemporary society, such as responsible data collection, algorithmic bias, privacy, transparency, accountability, democratic participation in data usage and data-driven decisions, and the ethical implications of emerging technologies like artificial intelligence and machine learning (self-driving cars, ChatGPT, crowd-sourced training data, etc.).\nBeginning with a set of historical case studies—instances in which scientists, engineers, and policymakers have been forced to re-evaluate their ethical intuitions in light of technological developments (nuclear power, use of social media platforms to organize protests and influence political outcomes, deployment of facial recognition software and predictive AI by police and military forces)—the course then introduces a set of general ethical frameworks (consequentialism, deontological ethics, and virtue ethics), challenging students to consider their relative strengths and weaknesses for addressing modern technological-ethical dilemmas faced by businesses, healthcare organizations, governments, and academic institutions. After a final portion of the course linking these ethical frameworks with practical regulatory and policy considerations, students will write and present a policy whitepaper analyzing a data-ethical issue of particular interest to them, integrating ethical perspectives, regulatory principles, and domain knowledge into a recommendation of best practices for the relevant agency, firm, or institution.\nThe course will thus equip students with a robust ethical “toolbox” for conscientiously gathering, interpreting, and extracting meaning from data throughout their careers as data scientists, while respecting privacy, fairness, transparency, democratic accountability, and other social concerns. Prerequisites: None. 3 credits.",
    "crumbs": [
      "<i class='bi bi-house pe-1'></i> Home"
    ]
  },
  {
    "objectID": "w11/slides.html#operationalizing-power",
    "href": "w11/slides.html#operationalizing-power",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Operationalizing Power",
    "text": "Operationalizing Power\n\nEqually good outside options \\(\\implies\\) can contract to Pareto-optimal point \\(o^P\\)\n\\(i\\) has better outside options \\(\\implies\\) can make take it or leave it offer to \\(j\\):\n\n“You (\\(j\\)) fish 6 hrs all the time. I (\\(i\\)) fish 6 hrs 41% of time, 8 hrs otherwise”\n\n\n\n\n\nEver so slightly better for \\(j\\) \\(\\implies\\) \\(j\\) accepts (Behavioral econ: \\(j\\) accepts if 41% meets subjective fairness threshold; observed across many many cultures!)\nLater / next week: observe policy with outcome \\(o^{C}_{i \\rightarrow j} \\iff\\) policy values \\(i\\)’s welfare more than \\(j\\)’s welfare (inferred social welfare weights \\(\\omega_i &gt; \\omega_j\\))"
  },
  {
    "objectID": "w11/slides.html#since-weve-already-opened-the-pandoras-box-of-utility",
    "href": "w11/slides.html#since-weve-already-opened-the-pandoras-box-of-utility",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Since We’ve Already Opened the Pandora’s Box of Utility…",
    "text": "Since We’ve Already Opened the Pandora’s Box of Utility…\n\nFrom Ryan Safner’s History of Economic Thought: Welfare Economics\nBluey obtains greater utility within the same budget by moving from \\(E^1\\) to \\(O^1\\)"
  },
  {
    "objectID": "w11/slides.html#two-can-play-this-game",
    "href": "w11/slides.html#two-can-play-this-game",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Two Can Play This Game…",
    "text": "Two Can Play This Game…\n\n\nBluey obtains greater utility within the same budget by moving from \\(E^1\\) to \\(O^1\\)\nGreenie obtains greater utility within the same budget by moving from \\(E^2\\) to \\(O^2\\)"
  },
  {
    "objectID": "w11/slides.html#the-edgeworth-box",
    "href": "w11/slides.html#the-edgeworth-box",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "The Edgeworth Box",
    "text": "The Edgeworth Box\n\nRotate Greenie’s box 180° and superimpose onto Bluey’s"
  },
  {
    "objectID": "w11/slides.html#the-contract-curve",
    "href": "w11/slides.html#the-contract-curve",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "The Contract(!) Curve",
    "text": "The Contract(!) Curve\n\n\nFrom initial endowment \\(E\\), if allowed to trade, “rational” players can reach any allocation along dashed contract curve from \\(G\\) to \\(B\\)… (Why not \\(A\\) or \\(H\\)?)\nSo, what determines which of these points they end up at? (Middle name hint)"
  },
  {
    "objectID": "w11/slides.html#first-fundamental-theorem-of-welfare-economics",
    "href": "w11/slides.html#first-fundamental-theorem-of-welfare-economics",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "First Fundamental Theorem of Welfare Economics",
    "text": "First Fundamental Theorem of Welfare Economics\n\nTheorem: [Antecedents (Coase Conditions)] \\(\\Rightarrow\\) markets produce Pareto-optimal outcomes\n\n\nEven commie Jeff finds proof+corollaries compelling / convincing / empirically-supported\n(It’s a full-on proof, in the mathematical sense, so doesn’t rly matter what I think; I just mean, imo, important and helpful to think through for class on policy!)\nEx: Conditional on antecedents [(Coase) minus (perfect competition) plus (thing must be allocated via markets)], \\(\\uparrow\\) Competition \\(\\leadsto\\) More efficient allocations"
  },
  {
    "objectID": "w11/slides.html#payoff-from-jeff-pointing-at-things-saying-antecedents-500x",
    "href": "w11/slides.html#payoff-from-jeff-pointing-at-things-saying-antecedents-500x",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Payoff from Jeff Pointing at Things Saying “Antecedents!” 500x",
    "text": "Payoff from Jeff Pointing at Things Saying “Antecedents!” 500x\n Consequent only true if antecedents hold! Otherwise, proper answer becomes “It depends! Let’s see if data can help us find out!” (Will minimum wage hurt/help blah blah blah… “It depends! Tell me the details!”) (Will new condos blah blah blah yimby nimby…) (Will re-allocating welfare budget from \\(X\\) to \\(Y\\) blah blah blah… 👀 HW4)\n\n\n\n\n\n\n\n[Economic inequality] is a social law, something in the nature of man. (Pareto 1896)\n\n\n\n\nWe’ve got a [thing] made by men, isn’t that something we should be able to change? (Steinbeck 1939)\n\n\n\n\n Coase Antecedents \\(\\approx\\) equalized power!\n\nEx 1: Perfect Competition \\(\\Rightarrow\\) (\\(\\neg\\) monopoly) \\(\\wedge\\) (\\(\\neg\\) monopsony) \\(\\Rightarrow\\) everyone’s outside option equally good \\(\\Rightarrow\\) no take-it-or-leave-it coercion possible (try to coerce, I’ll say no and go to one of the other \\(\\infty\\) people offering equally good options)\nEx 2: No Informational Asymmetries \\(\\Rightarrow\\) Can’t “trick me” into buying defective product (Akerlof (1970), “Market for Lemons”)"
  },
  {
    "objectID": "w11/slides.html#part-2-suddenly-collides-with-part-1-property-rights",
    "href": "w11/slides.html#part-2-suddenly-collides-with-part-1-property-rights",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Part 2 Suddenly Collides with Part 1: Property Rights",
    "text": "Part 2 Suddenly Collides with Part 1: Property Rights\n\nRawlsian Rights: Vetos on societal decisions; Constitution can make some inalienable (can’t sell self into slavery), some alienable\nProperty rights: alienable. You can gift or sell the rights if you want (veto is over society just, like, taking your property if someone else would be happier with it)\n\n\n\nCase : Society decides Right to Clean Air \\(\\prec\\) Right to Smoke \\(\\Rightarrow\\) Start at \\(E\\)\n\n\\(A\\) can pay \\(B\\) to alienate right (Pay $50/month, can smoke 5 ciggies) \\(\\leadsto\\) \\(X\\)\nMovement along light blue curve: giving up \\(x\\) money for \\(y\\) smoke, equally happy. \\(u_A(p)\\) identical for \\(p\\) on curve\nMovement to higher light blue curve () \\(\\Rightarrow\\) greater utility \\(u_A' &gt; u_A\\)\n\nCase  Society decides Smoke \\(\\prec\\) Clean Air \\(\\Rightarrow\\) Repeat for \\(E' \\leadsto X'\\)\n\n\n\n\n“Edgeworth Box” for Right to Smoke vs. Right to Clean Air: \\(A\\), \\(B\\) are roommates; \\(A\\) loves smokin, \\(B\\) loves clean air"
  },
  {
    "objectID": "w11/slides.html#why-exactly-does-commodifying-rights-sometimes-enable-cancelling-out-externalities",
    "href": "w11/slides.html#why-exactly-does-commodifying-rights-sometimes-enable-cancelling-out-externalities",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Why Exactly Does [Commodifying Rights] Sometimes Enable [“Cancelling Out” Externalities]?",
    "text": "Why Exactly Does [Commodifying Rights] Sometimes Enable [“Cancelling Out” Externalities]?\n\nThe key: Forces agent \\(i\\) to pay a cost for inflicting disutility on agent \\(j\\)!\n(Here plz note: “\\(X\\) sometimes enables \\(Y\\)” does not mean \\(X\\) is a necessary or sufficient condition for \\(Y\\)! Think of walking into a dark room, trying different light switches until one turns on the overhead light)\nDear reader, I know what you’re thinking… But Jeff!! This is all so abstract and theoretical!! We’re sick of your ivory-tower musings, get your head out of the clouds and make it relevant to our day-to-day lives, by relating it back to Yugoslavia’s 1965 economic reforms!!\nDon’t worry, I’ve listened to your concerns, and the next slide is here for you 😌"
  },
  {
    "objectID": "w11/slides.html#externalities-i-get-reward-others-pay-cost",
    "href": "w11/slides.html#externalities-i-get-reward-others-pay-cost",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Externalities: I Get Reward, Others Pay Cost 🥳",
    "text": "Externalities: I Get Reward, Others Pay Cost 🥳\n\nFirm \\(S\\) produces amount of steel \\(s\\), pollution \\(x\\)\nFirm \\(F\\) “produces” amount of fish \\(f\\)\n\\(S\\) optimizes\n\n\\[\ns^*_{\\text{Priv}}, x^*_{\\text{Priv}} = \\argmax_{s,x}\\left[ p_s s - c_s(s, x) \\right]\n\\]\n\nWhile \\(F\\) optimizes\n\n\\[\nf^*_{\\text{Priv}} = \\argmax_{f}\\left[ p_f f - c_f(f, x) \\right]\n\\]\n\nIf [Yugoslavia-style] nationalized, new optimization of joint steel-fish venture is\n\n\\[\ns^*_{\\text{Yugo}}, f^*_{\\text{Yugo}}, x^*_{\\text{Yugo}} = \\argmax_{s, f, x}\\left[ p_s s + p_f f - c_s(s, x) - c_f(f, x) \\right]\n\\]\n\nCan prove/“prove” that \\(o(s^*_{\\text{Yugo}}, f^*_{\\text{Yugo}}, x^*_{\\text{Yugo}})\\) Pareto-dominates \\(o(s^*_{\\text{Priv}}, x^*_{\\text{Priv}}, f^*_{\\text{Priv}})\\)\nSo… what determines which agents get to ignore externalities? (Dead horse)"
  },
  {
    "objectID": "w11/slides.html#functionals",
    "href": "w11/slides.html#functionals",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Functionals?",
    "text": "Functionals?\n\nYou probably know what a function \\(f(x)\\) is; a functional is a function of functions: \\(\\mathscr{G}(f)\\)\nIt’s from math, which is scary, but it’s just notation to remind us that we’re analyzing functions of functions\nIn our case, they “work the same way” as regular functions, e.g., \\(\\mathscr{G}(f,g) = f^2 + g^2\\), so \\(f(x) = x, g(x) = 2x \\Rightarrow \\mathscr{G}(f,g)(x) = x^2 + 4x^2 = 5x^2\\)"
  },
  {
    "objectID": "w11/slides.html#we-live-in-a-society-part-2",
    "href": "w11/slides.html#we-live-in-a-society-part-2",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "We Live In A Society, Part 2",
    "text": "We Live In A Society, Part 2\n\nUtilitarianism, Kant, Rawls can all be modeled as Social Welfare Functionals\n\n\\[\nW(\\mathbf{u}) = W(u_1, \\ldots, u_n) \\Rightarrow W(\\mathbf{u})(x) = W(u_1(x), \\ldots, u_n(x))\n\\]\n\n\\(u_i(x)\\): Given bundle of resources \\(x\\), how much utility does \\(i\\) experience? \\(u_i: \\mathcal{X} \\rightarrow \\mathbb{R}\\)\n\\(W(\\mathbf{u})\\): Aggregates \\(u_i(x)\\) over all \\(i\\), to produce measure of overall welfare of society. For \\(N\\) people, \\(W: (\\mathcal{X} \\rightarrow \\mathbb{R})^N \\rightarrow \\mathbb{R}\\).\nStandard assumption: \\(W\\) additive \\(\\Rightarrow W(\\mathbf{u}) = \\sum_{i=1}^n \\omega_iu_i(x)\\)\n\n\\(\\omega_i \\equiv \\frac{\\partial W}{\\partial u_i}\\) is \\(i\\)’s welfare weight (❗️)\n\nWelfare-Economic definition of Utilitarianism: Literally just \\(\\omega_i = 1 \\; \\forall i\\)\n(HW4) Decomposition to evaluate bias in policy impacts: from observed allocation \\(x_i\\) and marginal utility \\(u'_i(x)\\), can…\n\nInfer \\(\\widehat{\\omega}_i\\) (how much policy does value person \\(i\\)), then\nCompare with \\(\\omega_i^*\\) (how much policy should value person \\(i\\)… conjoint survey) 🤯"
  },
  {
    "objectID": "w11/slides.html#alternative-swf-specifications",
    "href": "w11/slides.html#alternative-swf-specifications",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Alternative SWF Specifications",
    "text": "Alternative SWF Specifications\n\nSocial values\n\n\\[\nW(\\underbrace{v_1, \\ldots, v_n}_{\\text{Values}})(x) \\overset{\\text{e.g.}}{=} \\omega_1\\underbrace{v_1(x)}_{\\text{Privacy}} + \\omega_2\\underbrace{v_2(x)}_{\\mathclap{\\text{Public Health}}}\n\\]\n\nStakeholder Analysis\n\n\\[\nW(\\underbrace{s_1, \\ldots, s_n}_{\\text{Stakeholders}})(x) = \\omega_1\\underbrace{u_{s_1}(x)}_{\\text{Teachers}} + \\omega_2\\underbrace{u_{s_2}(x)}_{\\text{Parents}} + \\omega_3\\underbrace{u_{s_3}(x)}_{\\text{Students}} + \\omega_4\\underbrace{u_{s_4}(x)}_{\\mathclap{\\text{Community}}}\n\\]\n\n(Adapted from this great intro video!)"
  },
  {
    "objectID": "w11/slides.html#the-conveniently-left-out-detail",
    "href": "w11/slides.html#the-conveniently-left-out-detail",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "The Conveniently-Left-Out Detail",
    "text": "The Conveniently-Left-Out Detail\n\nRecall, e.g., predictive parity:\n\n\\[\n\\mathbb{E}[Y \\mid D = 1, A = 1] = \\mathbb{E}[Y \\mid D = 1, A = 0]\n\\]\n\nWho decides which \\(Y\\) to pick? (Kasy and Abebe 2021)\nAnswer: Whoever picks the objective function!\nProfit-maximizing firm: \\(\\max\\left\\{ \\mathbb{E}[D (Y - c)]\\right\\} \\Rightarrow\\) (Discrimination if and only if bad at profit-maximizing)\nWelfare-maximizing policymaker: \\(\\max\\{ W(u_1(D), \\ldots, u_n(D)) \\}\\)\nDo these align? Sometimes yes, sometimes no (See: Welfare Theorems and their antecedents, and/or Becker (1957))"
  },
  {
    "objectID": "w11/slides.html#remaining-challenging-details",
    "href": "w11/slides.html#remaining-challenging-details",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Remaining (Challenging) Details",
    "text": "Remaining (Challenging) Details\n\n\n\n\n\n\n\nWho gets included in the SWF?\nPeople in one household? One community? One state? One country?\nPeople in the future?\nAnimals?\n…OUR BEAUTIFUL ENVIRONMENT??? (Figure 1)\n\n\n\n\n\n\n\n\n\nFigure 1: Our beautiful environment"
  },
  {
    "objectID": "w11/slides.html#back-to-utilitarian-swf",
    "href": "w11/slides.html#back-to-utilitarian-swf",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Back to Utilitarian SWF",
    "text": "Back to Utilitarian SWF\n\nEasy mode (possibly/probably your intuition?): Everyone’s welfare weight should be equal, \\(\\omega_i = \\frac{1}{n}\\)\n\n\\[\nW(u_1, \\ldots, u_n)(x) = \\frac{1}{n}u_1(x) + \\cdots + \\frac{1}{n}u_n(x)\n\\]\n\n\\(\\implies\\) Utilitarian Social Welfare Functional!\nThe Silly Problem of Utilitarian SWF: What if everyone is made happy by \\(u_{\\text{Jeef}} = -999999999\\)?"
  },
  {
    "objectID": "w11/slides.html#the-hard-problem-of-utilitarian-swf",
    "href": "w11/slides.html#the-hard-problem-of-utilitarian-swf",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "The Hard Problem of Utilitarian SWF",
    "text": "The Hard Problem of Utilitarian SWF\n\nWhile the rhetoric of “all men [sic] are born equal” is typically taken to be part and parcel of egalitarianism, the effect of ignoring the interpersonal variations can, in fact, be deeply inegalitarian, in hiding the fact that equal consideration for all may demand very unequal treatment in favour of the disadvantaged (Sen 1992)\n\n\n\\(\\implies\\) “Equality of What?”\nWhat is the “thing” that egalitarianism obligates us to equalize (the equilisandum/equilisanda): Utility? Opportunity? Resources? Money? Freedom from [\\(X\\)]? Freedom to [\\(Y\\)]?"
  },
  {
    "objectID": "w11/slides.html#externalities",
    "href": "w11/slides.html#externalities",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Externalities",
    "text": "Externalities\n\nJeef and Keef are roommates: Jeef loves listening to Tony Danza Tapdance Extravaganza, but Keef is normal and slowly dies inside with each additional song\n\n\n\n\n\n\n\n\n\nSongs\nJeef\nKeef\nTotal\n\n\n\n\n0\n0\n0\n0\n\n\n1\n13\n-2\n11\n\n\n2\n18\n-6\n12\n\n\n3\n24\n-13\n11\n\n\n4\n28\n-20\n8\n\n\n5\n30\n-42\n-12"
  },
  {
    "objectID": "w11/slides.html#so-whats-the-issue",
    "href": "w11/slides.html#so-whats-the-issue",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "So What’s the Issue?",
    "text": "So What’s the Issue?\n\nThese utility values are not observed\nIf we try to elicit them, both Jeef and Keef have strategic incentives to lie (over-exaggerate)\nJeef maximizes own utility by reporting \\(u_j(s) = \\infty\\)\nKeef maximizes own utility by reporting \\(u_k(s) = -\\infty\\)\n(…Second price auctions tho)"
  },
  {
    "objectID": "w11/slides.html#now-with-scarce-resources",
    "href": "w11/slides.html#now-with-scarce-resources",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Now with Scarce Resources",
    "text": "Now with Scarce Resources\n\nIn a given week, Jeef and Keef have 14 meals and 7 aux hours to divide amongst them\n\n\\[\n\\begin{align*}\n\\max_{m_1,m_2,a_1,a_2}& W(u_1(m_1,a_1),u_2(m_2,a_2)) \\\\\n\\text{s.t. }& m_1 + m_2 \\leq 14 \\\\\n\\phantom{\\text{s.t. }} & ~ \\, a_1 + a_2 \\; \\leq 7\n\\end{align*}\n\\]\n\nLet’s assume \\(u_i(m_i, a_i) = m_i + a_i\\) for both\n\\(\\Rightarrow\\) One solution: \\(m_1 = 14, m_2 = 0, a_1 = 7, a_2 = 0\\)…\n\\(\\Rightarrow\\) Another: \\(m_1 = 0, m_2 = 14, a_1 = 0, a_2 = 7\\)…\nWho decides? Any decision implies \\(\\omega_1, \\omega_2\\) (\\(\\omega_1 + \\omega_2 = 1\\))"
  },
  {
    "objectID": "w11/slides.html#references",
    "href": "w11/slides.html#references",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "References",
    "text": "References\n\n\nAkerlof, George A. 1970. “The Market for \"Lemons\": Quality Uncertainty and the Market Mechanism.” The Quarterly Journal of Economics 84 (3): 488–500. https://doi.org/10.2307/1879431.\n\n\nBecker, Gary S. 1957. The Economics of Discrimination. University of Chicago Press.\n\n\nKasy, Maximilian, and Rediet Abebe. 2021. “Fairness, Equality, and Power in Algorithmic Decision-Making.” In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 576–86. FAccT ’21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445919.\n\n\nMalm, Andreas. 2021. How to Blow Up a Pipeline. Verso Books.\n\n\nPareto, Vilfredo. 1896. Cours d’Économie politique. Librairie Droz.\n\n\nSen, Amartya. 1992. Inequality Reexamined. Clarendon Press.\n\n\nSteinbeck, John. 1939. The Grapes of Wrath. Penguin."
  },
  {
    "objectID": "w11/index.html",
    "href": "w11/index.html",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#operationalizing-power",
    "href": "w11/index.html#operationalizing-power",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Operationalizing Power",
    "text": "Operationalizing Power\n\nEqually good outside options \\(\\implies\\) can contract to Pareto-optimal point \\(o^P\\)\n\\(i\\) has better outside options \\(\\implies\\) can make take it or leave it offer to \\(j\\):\n\n“You (\\(j\\)) fish 6 hrs all the time. I (\\(i\\)) fish 6 hrs 41% of time, 8 hrs otherwise”\n\n\n\n\n\nEver so slightly better for \\(j\\) \\(\\implies\\) \\(j\\) accepts (Behavioral econ: \\(j\\) accepts if 41% meets subjective fairness threshold; observed across many many cultures!)\nLater / next week: observe policy with outcome \\(o^{C}_{i \\rightarrow j} \\iff\\) policy values \\(i\\)’s welfare more than \\(j\\)’s welfare (inferred social welfare weights \\(\\omega_i &gt; \\omega_j\\))",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#since-weve-already-opened-the-pandoras-box-of-utility",
    "href": "w11/index.html#since-weve-already-opened-the-pandoras-box-of-utility",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Since We’ve Already Opened the Pandora’s Box of Utility…",
    "text": "Since We’ve Already Opened the Pandora’s Box of Utility…\n\n\n\nFrom Ryan Safner’s History of Economic Thought: Welfare Economics\n\n\n\nBluey obtains greater utility within the same budget by moving from \\(E^1\\) to \\(O^1\\)",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#two-can-play-this-game",
    "href": "w11/index.html#two-can-play-this-game",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Two Can Play This Game…",
    "text": "Two Can Play This Game…\n\n\n\n\n\n\nBluey obtains greater utility within the same budget by moving from \\(E^1\\) to \\(O^1\\)\nGreenie obtains greater utility within the same budget by moving from \\(E^2\\) to \\(O^2\\)",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#the-edgeworth-box",
    "href": "w11/index.html#the-edgeworth-box",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "The Edgeworth Box",
    "text": "The Edgeworth Box\n\n\n\nRotate Greenie’s box 180° and superimpose onto Bluey’s",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#the-contract-curve",
    "href": "w11/index.html#the-contract-curve",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "The Contract(!) Curve",
    "text": "The Contract(!) Curve\n\n\n\n\n\n\nFrom initial endowment \\(E\\), if allowed to trade, “rational” players can reach any allocation along dashed contract curve from \\(G\\) to \\(B\\)… (Why not \\(A\\) or \\(H\\)?)\nSo, what determines which of these points they end up at? (Middle name hint)",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#first-fundamental-theorem-of-welfare-economics",
    "href": "w11/index.html#first-fundamental-theorem-of-welfare-economics",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "First Fundamental Theorem of Welfare Economics",
    "text": "First Fundamental Theorem of Welfare Economics\n\nTheorem: [Antecedents (Coase Conditions)] \\(\\Rightarrow\\) markets produce Pareto-optimal outcomes\n\n\nEven commie Jeff finds proof+corollaries compelling / convincing / empirically-supported\n(It’s a full-on proof, in the mathematical sense, so doesn’t rly matter what I think; I just mean, imo, important and helpful to think through for class on policy!)\nEx: Conditional on antecedents [(Coase) minus (perfect competition) plus (thing must be allocated via markets)], \\(\\uparrow\\) Competition \\(\\leadsto\\) More efficient allocations",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#payoff-from-jeff-pointing-at-things-saying-antecedents-500x",
    "href": "w11/index.html#payoff-from-jeff-pointing-at-things-saying-antecedents-500x",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Payoff from Jeff Pointing at Things Saying “Antecedents!” 500x",
    "text": "Payoff from Jeff Pointing at Things Saying “Antecedents!” 500x\n Consequent only true if antecedents hold! Otherwise, proper answer becomes “It depends! Let’s see if data can help us find out!” (Will minimum wage hurt/help blah blah blah… “It depends! Tell me the details!”) (Will new condos blah blah blah yimby nimby…) (Will re-allocating welfare budget from \\(X\\) to \\(Y\\) blah blah blah… 👀 HW4)\n\n\n\n\n\n\n\n[Economic inequality] is a social law, something in the nature of man. (Pareto 1896)\n\n\n\n\nWe’ve got a [thing] made by men, isn’t that something we should be able to change? (Steinbeck 1939)\n\n\n\n\n Coase Antecedents \\(\\approx\\) equalized power!\n\nEx 1: Perfect Competition \\(\\Rightarrow\\) (\\(\\neg\\) monopoly) \\(\\wedge\\) (\\(\\neg\\) monopsony) \\(\\Rightarrow\\) everyone’s outside option equally good \\(\\Rightarrow\\) no take-it-or-leave-it coercion possible (try to coerce, I’ll say no and go to one of the other \\(\\infty\\) people offering equally good options)\nEx 2: No Informational Asymmetries \\(\\Rightarrow\\) Can’t “trick me” into buying defective product (Akerlof (1970), “Market for Lemons”)",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#part-2-suddenly-collides-with-part-1-property-rights",
    "href": "w11/index.html#part-2-suddenly-collides-with-part-1-property-rights",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Part 2 Suddenly Collides with Part 1: Property Rights",
    "text": "Part 2 Suddenly Collides with Part 1: Property Rights\n\nRawlsian Rights: Vetos on societal decisions; Constitution can make some inalienable (can’t sell self into slavery), some alienable\nProperty rights: alienable. You can gift or sell the rights if you want (veto is over society just, like, taking your property if someone else would be happier with it)\n\n\n\nCase : Society decides Right to Clean Air \\(\\prec\\) Right to Smoke \\(\\Rightarrow\\) Start at \\(E\\)\n\n\\(A\\) can pay \\(B\\) to alienate right (Pay $50/month, can smoke 5 ciggies) \\(\\leadsto\\) \\(X\\)\nMovement along light blue curve: giving up \\(x\\) money for \\(y\\) smoke, equally happy. \\(u_A(p)\\) identical for \\(p\\) on curve\nMovement to higher light blue curve () \\(\\Rightarrow\\) greater utility \\(u_A' &gt; u_A\\)\n\nCase  Society decides Smoke \\(\\prec\\) Clean Air \\(\\Rightarrow\\) Repeat for \\(E' \\leadsto X'\\)\n\n\n\n\n“Edgeworth Box” for Right to Smoke vs. Right to Clean Air: \\(A\\), \\(B\\) are roommates; \\(A\\) loves smokin, \\(B\\) loves clean air",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#why-exactly-does-commodifying-rights-sometimes-enable-cancelling-out-externalities",
    "href": "w11/index.html#why-exactly-does-commodifying-rights-sometimes-enable-cancelling-out-externalities",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Why Exactly Does [Commodifying Rights] Sometimes Enable [“Cancelling Out” Externalities]?",
    "text": "Why Exactly Does [Commodifying Rights] Sometimes Enable [“Cancelling Out” Externalities]?\n\nThe key: Forces agent \\(i\\) to pay a cost for inflicting disutility on agent \\(j\\)!\n(Here plz note: “\\(X\\) sometimes enables \\(Y\\)” does not mean \\(X\\) is a necessary or sufficient condition for \\(Y\\)! Think of walking into a dark room, trying different light switches until one turns on the overhead light)\nDear reader, I know what you’re thinking… But Jeff!! This is all so abstract and theoretical!! We’re sick of your ivory-tower musings, get your head out of the clouds and make it relevant to our day-to-day lives, by relating it back to Yugoslavia’s 1965 economic reforms!!\nDon’t worry, I’ve listened to your concerns, and the next slide is here for you 😌",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#externalities-i-get-reward-others-pay-cost",
    "href": "w11/index.html#externalities-i-get-reward-others-pay-cost",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Externalities: I Get Reward, Others Pay Cost 🥳",
    "text": "Externalities: I Get Reward, Others Pay Cost 🥳\n\nFirm \\(S\\) produces amount of steel \\(s\\), pollution \\(x\\)\nFirm \\(F\\) “produces” amount of fish \\(f\\)\n\\(S\\) optimizes\n\n\\[\ns^*_{\\text{Priv}}, x^*_{\\text{Priv}} = \\argmax_{s,x}\\left[ p_s s - c_s(s, x) \\right]\n\\]\n\nWhile \\(F\\) optimizes\n\n\\[\nf^*_{\\text{Priv}} = \\argmax_{f}\\left[ p_f f - c_f(f, x) \\right]\n\\]\n\nIf [Yugoslavia-style] nationalized, new optimization of joint steel-fish venture is\n\n\\[\ns^*_{\\text{Yugo}}, f^*_{\\text{Yugo}}, x^*_{\\text{Yugo}} = \\argmax_{s, f, x}\\left[ p_s s + p_f f - c_s(s, x) - c_f(f, x) \\right]\n\\]\n\nCan prove/“prove” that \\(o(s^*_{\\text{Yugo}}, f^*_{\\text{Yugo}}, x^*_{\\text{Yugo}})\\) Pareto-dominates \\(o(s^*_{\\text{Priv}}, x^*_{\\text{Priv}}, f^*_{\\text{Priv}})\\)\nSo… what determines which agents get to ignore externalities? (Dead horse)",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#functionals",
    "href": "w11/index.html#functionals",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Functionals?",
    "text": "Functionals?\n\nYou probably know what a function \\(f(x)\\) is; a functional is a function of functions: \\(\\mathscr{G}(f)\\)\nIt’s from math, which is scary, but it’s just notation to remind us that we’re analyzing functions of functions\nIn our case, they “work the same way” as regular functions, e.g., \\(\\mathscr{G}(f,g) = f^2 + g^2\\), so \\(f(x) = x, g(x) = 2x \\Rightarrow \\mathscr{G}(f,g)(x) = x^2 + 4x^2 = 5x^2\\)",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#we-live-in-a-society-part-2",
    "href": "w11/index.html#we-live-in-a-society-part-2",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "We Live In A Society, Part 2",
    "text": "We Live In A Society, Part 2\n\nUtilitarianism, Kant, Rawls can all be modeled as Social Welfare Functionals\n\n\\[\nW(\\mathbf{u}) = W(u_1, \\ldots, u_n) \\Rightarrow W(\\mathbf{u})(x) = W(u_1(x), \\ldots, u_n(x))\n\\]\n\n\\(u_i(x)\\): Given bundle of resources \\(x\\), how much utility does \\(i\\) experience? \\(u_i: \\mathcal{X} \\rightarrow \\mathbb{R}\\)\n\\(W(\\mathbf{u})\\): Aggregates \\(u_i(x)\\) over all \\(i\\), to produce measure of overall welfare of society. For \\(N\\) people, \\(W: (\\mathcal{X} \\rightarrow \\mathbb{R})^N \\rightarrow \\mathbb{R}\\).\nStandard assumption: \\(W\\) additive \\(\\Rightarrow W(\\mathbf{u}) = \\sum_{i=1}^n \\omega_iu_i(x)\\)\n\n\\(\\omega_i \\equiv \\frac{\\partial W}{\\partial u_i}\\) is \\(i\\)’s welfare weight (❗️)\n\nWelfare-Economic definition of Utilitarianism: Literally just \\(\\omega_i = 1 \\; \\forall i\\)\n(HW4) Decomposition to evaluate bias in policy impacts: from observed allocation \\(x_i\\) and marginal utility \\(u'_i(x)\\), can…\n\nInfer \\(\\widehat{\\omega}_i\\) (how much policy does value person \\(i\\)), then\nCompare with \\(\\omega_i^*\\) (how much policy should value person \\(i\\)… conjoint survey) 🤯",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#alternative-swf-specifications",
    "href": "w11/index.html#alternative-swf-specifications",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Alternative SWF Specifications",
    "text": "Alternative SWF Specifications\n\nSocial values\n\n\\[\nW(\\underbrace{v_1, \\ldots, v_n}_{\\text{Values}})(x) \\overset{\\text{e.g.}}{=} \\omega_1\\underbrace{v_1(x)}_{\\text{Privacy}} + \\omega_2\\underbrace{v_2(x)}_{\\mathclap{\\text{Public Health}}}\n\\]\n\nStakeholder Analysis\n\n\\[\nW(\\underbrace{s_1, \\ldots, s_n}_{\\text{Stakeholders}})(x) = \\omega_1\\underbrace{u_{s_1}(x)}_{\\text{Teachers}} + \\omega_2\\underbrace{u_{s_2}(x)}_{\\text{Parents}} + \\omega_3\\underbrace{u_{s_3}(x)}_{\\text{Students}} + \\omega_4\\underbrace{u_{s_4}(x)}_{\\mathclap{\\text{Community}}}\n\\]\n\n(Adapted from this great intro video!)",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#the-conveniently-left-out-detail",
    "href": "w11/index.html#the-conveniently-left-out-detail",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "The Conveniently-Left-Out Detail",
    "text": "The Conveniently-Left-Out Detail\n\nRecall, e.g., predictive parity:\n\n\\[\n\\mathbb{E}[Y \\mid D = 1, A = 1] = \\mathbb{E}[Y \\mid D = 1, A = 0]\n\\]\n\nWho decides which \\(Y\\) to pick? (Kasy and Abebe 2021)\nAnswer: Whoever picks the objective function!\nProfit-maximizing firm: \\(\\max\\left\\{ \\mathbb{E}[D (Y - c)]\\right\\} \\Rightarrow\\) (Discrimination if and only if bad at profit-maximizing)\nWelfare-maximizing policymaker: \\(\\max\\{ W(u_1(D), \\ldots, u_n(D)) \\}\\)\nDo these align? Sometimes yes, sometimes no (See: Welfare Theorems and their antecedents, and/or Becker (1957))",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#remaining-challenging-details",
    "href": "w11/index.html#remaining-challenging-details",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Remaining (Challenging) Details",
    "text": "Remaining (Challenging) Details\n\n\n\n\n\n\n\nWho gets included in the SWF?\nPeople in one household? One community? One state? One country?\nPeople in the future?\nAnimals?\n…OUR BEAUTIFUL ENVIRONMENT??? (Figure 1)\n\n\n\n\n\n\n\n\n\nFigure 1: Our beautiful environment",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#back-to-utilitarian-swf",
    "href": "w11/index.html#back-to-utilitarian-swf",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Back to Utilitarian SWF",
    "text": "Back to Utilitarian SWF\n\nEasy mode (possibly/probably your intuition?): Everyone’s welfare weight should be equal, \\(\\omega_i = \\frac{1}{n}\\)\n\n\\[\nW(u_1, \\ldots, u_n)(x) = \\frac{1}{n}u_1(x) + \\cdots + \\frac{1}{n}u_n(x)\n\\]\n\n\\(\\implies\\) Utilitarian Social Welfare Functional!\nThe Silly Problem of Utilitarian SWF: What if everyone is made happy by \\(u_{\\text{Jeef}} = -999999999\\)?",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#the-hard-problem-of-utilitarian-swf",
    "href": "w11/index.html#the-hard-problem-of-utilitarian-swf",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "The Hard Problem of Utilitarian SWF",
    "text": "The Hard Problem of Utilitarian SWF\n\nWhile the rhetoric of “all men [sic] are born equal” is typically taken to be part and parcel of egalitarianism, the effect of ignoring the interpersonal variations can, in fact, be deeply inegalitarian, in hiding the fact that equal consideration for all may demand very unequal treatment in favour of the disadvantaged (Sen 1992)\n\n\n\\(\\implies\\) “Equality of What?”\nWhat is the “thing” that egalitarianism obligates us to equalize (the equilisandum/equilisanda): Utility? Opportunity? Resources? Money? Freedom from [\\(X\\)]? Freedom to [\\(Y\\)]?",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#externalities",
    "href": "w11/index.html#externalities",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Externalities",
    "text": "Externalities\n\nJeef and Keef are roommates: Jeef loves listening to Tony Danza Tapdance Extravaganza, but Keef is normal and slowly dies inside with each additional song\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmusic_df &lt;- tribble(\n  ~Songs, ~Jeef, ~Keef,\n  0, 0, 0,\n  1, 13, -2,\n  2, 18, -6,\n  3, 24, -13,\n  4, 28, -20,\n  5, 30, -42\n)\nmusic_df &lt;- music_df |&gt;\n  mutate(Total = Jeef + Keef)\nmusic_df\n\n\n\n\n\nSongs\nJeef\nKeef\nTotal\n\n\n\n\n0\n0\n0\n0\n\n\n1\n13\n-2\n11\n\n\n2\n18\n-6\n12\n\n\n3\n24\n-13\n11\n\n\n4\n28\n-20\n8\n\n\n5\n30\n-42\n-12\n\n\n\n\n\n\n\n\nlong_df &lt;- music_df |&gt;\n  pivot_longer(!Songs, names_to=\"Roommate\", values_to=\"Utility\")\nutil_df &lt;- long_df |&gt;\n  filter(Roommate != \"Total\")\nggplot(util_df, aes(x=Songs, y=Utility, color=Roommate)) +\n  geom_line(linewidth=g_linewidth) +\n  geom_point(size=g_pointsize) +\n  labs(\n    title=\"Individual Utility: Jeef vs. Keef\",\n    x=\"Number of Songs Played\",\n    y=\"Utility\"\n  ) +\n  theme_dsan(\"quarter\")\n\n\n\n\n\n\n\n\n\nwelfare_df &lt;- long_df |&gt;\n  filter(Roommate == \"Total\")\nggplot(welfare_df, aes(x=Songs, y=Utility, color=Roommate)) +\n  geom_line(linewidth=g_linewidth) +\n  geom_point(size=g_pointsize) +\n  labs(\n    title=\"Social Welfare: Jeef and Keef\",\n    x=\"Number of Songs Played\",\n    y=\"Social Welfare\"\n  ) +\n  scale_color_manual(values=c(cbPalette[3]), labels=c(\"Total      \")) +\n  theme_dsan(\"quarter\") +\n  remove_legend_title()",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#so-whats-the-issue",
    "href": "w11/index.html#so-whats-the-issue",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "So What’s the Issue?",
    "text": "So What’s the Issue?\n\nThese utility values are not observed\nIf we try to elicit them, both Jeef and Keef have strategic incentives to lie (over-exaggerate)\nJeef maximizes own utility by reporting \\(u_j(s) = \\infty\\)\nKeef maximizes own utility by reporting \\(u_k(s) = -\\infty\\)\n(…Second price auctions tho)",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#now-with-scarce-resources",
    "href": "w11/index.html#now-with-scarce-resources",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Now with Scarce Resources",
    "text": "Now with Scarce Resources\n\nIn a given week, Jeef and Keef have 14 meals and 7 aux hours to divide amongst them\n\n\\[\n\\begin{align*}\n\\max_{m_1,m_2,a_1,a_2}& W(u_1(m_1,a_1),u_2(m_2,a_2)) \\\\\n\\text{s.t. }& m_1 + m_2 \\leq 14 \\\\\n\\phantom{\\text{s.t. }} & ~ \\, a_1 + a_2 \\; \\leq 7\n\\end{align*}\n\\]\n\nLet’s assume \\(u_i(m_i, a_i) = m_i + a_i\\) for both\n\\(\\Rightarrow\\) One solution: \\(m_1 = 14, m_2 = 0, a_1 = 7, a_2 = 0\\)…\n\\(\\Rightarrow\\) Another: \\(m_1 = 0, m_2 = 14, a_1 = 0, a_2 = 7\\)…\nWho decides? Any decision implies \\(\\omega_1, \\omega_2\\) (\\(\\omega_1 + \\omega_2 = 1\\))",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#references",
    "href": "w11/index.html#references",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "References",
    "text": "References\n\n\nAkerlof, George A. 1970. “The Market for \"Lemons\": Quality Uncertainty and the Market Mechanism.” The Quarterly Journal of Economics 84 (3): 488–500. https://doi.org/10.2307/1879431.\n\n\nBecker, Gary S. 1957. The Economics of Discrimination. University of Chicago Press.\n\n\nKasy, Maximilian, and Rediet Abebe. 2021. “Fairness, Equality, and Power in Algorithmic Decision-Making.” In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 576–86. FAccT ’21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445919.\n\n\nMalm, Andreas. 2021. How to Blow Up a Pipeline. Verso Books.\n\n\nPareto, Vilfredo. 1896. Cours d’Économie politique. Librairie Droz.\n\n\nSen, Amartya. 1992. Inequality Reexamined. Clarendon Press.\n\n\nSteinbeck, John. 1939. The Grapes of Wrath. Penguin.",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "w11/index.html#footnotes",
    "href": "w11/index.html#footnotes",
    "title": "Week 11: Fear and Loathing on the Pareto Frontier",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRecall W01: Earned Income Tax Credits, Emissions Markets, Climate Engineering, Antitrust Legistlation \\(\\in \\text{Policy Set}\\); Black Panther Community Police Patrols, Blowing Up Oil Pipelines (Malm 2021), Bolshevik Revolution also \\(\\in \\text{Policy Set}\\)↩︎",
    "crumbs": [
      "Week 11: {{< var w11.date-md >}}"
    ]
  },
  {
    "objectID": "writeups/pgm-intro/index.html",
    "href": "writeups/pgm-intro/index.html",
    "title": "A Quick Introduction to Probabilistic Graphical Models",
    "section": "",
    "text": "A Probabilistic Graphical Model (PGM) is just a formal mathematical representation of a data-generating process. So, if we wanted to model the relationship between weather and a person’s choice of whether to go out and party or stay in and watch a movie on a given Saturday evening, we could begin by proposing the following data-generating process:\nNow, given the description of a PGM given above (nodes as variables, edges as relationships between variables), we can perform the move alluded to in the previous section: we can convert our data-generating process into a PGM, by defining nodes (variables) and edges (relationships) as follows:\nThe resulting PGM, in graphical form1, is presented below, followed by the Conditional Probability Table describing the edge from the \\(W\\) node to the \\(Y\\) node.\nPGMs can help us make inferences about the world in the face of incomplete information, which is the situation in nearly every real-world problem. The key tool here is the separation of nodes into two categories: observed (represented graphically as a shaded node) and latent (represented graphically as an unshaded node).\nThus we can now use our model as a weather-inference machine: if we observe that the person we’re modeling is out at a party with us, what can we infer from this information about the weather outside? We can draw this situation as a PGM with shaded and unshaded nodes, as in the figure below, and then use Bayes’ Rule to perform calculations over the network, to see how the observed information about the person at the party “flows” back into the node representing the weather.\nKeeping in mind that Bayes’ Rule tells us, for any two events \\(A\\) and \\(B\\), how to use information about \\(\\Pr(B \\mid A)\\) to obtain information about \\(\\Pr(A \\mid B)\\):\n\\[\n\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)},\n\\]\nWe can now apply this rule to obtain our new probability distribution over the weather, taking into account the new information that the person has chosen to go out:\n\\[\n\\begin{align*}\n&\\Pr(W = \\textsf{Sunny} \\mid Y = \\textsf{Go Out})\n= \\frac{\\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Sunny})}{\\Pr(Y = \\textsf{Go Out})} \\\\\n= &\\frac{\\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Sunny})}{\\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Sunny}) + \\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Rainy})}\n\\end{align*}\n\\]\nAnd now we simply plug in the information we already have from our conditional probability table to obtain our new (conditional) probability of interest:\n\\[\n\\begin{align*}\n\\Pr(W = \\textsf{Sunny} \\mid Y = \\textsf{Go Out}) &= \\frac{(0.8)(0.5)}{(0.8)(0.5) + (0.1)(0.5)} \\\\\n&= \\frac{0.4}{0.4 + 0.05} = \\frac{0.4}{0.45} \\approx 0.89.\n\\end{align*}\n\\]\nWe have learned something interesting: now that we’ve observed the person out at a party, the probability that it is sunny out jumps from \\(0.5\\) (called the “prior” estimate of \\(W\\), i.e., our best guess without any other relevant information) to \\(0.89\\) (called the “posterior” estimate of \\(W\\), i.e., our best guess after incorporating relevant information)."
  },
  {
    "objectID": "writeups/pgm-intro/index.html#footnotes",
    "href": "writeups/pgm-intro/index.html#footnotes",
    "title": "A Quick Introduction to Probabilistic Graphical Models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe term “Graphical” in Probabilistic Graphical Model is not used in the same sense as the “graphical” we’re used to from vernacular English. Capital-G Graphical denotes that the Probabilistic Model is represented as a Graph, a well-defined mathematical object consisting of nodes and edges, which does not have to be represented graphically (though it could be, like in our example here with circles and arrows). In fact, when a computer program is estimating a PGM, it is by definition not in a graphical form—it’s in the form of 0s and 1s, stored in the computer’s memory.↩︎"
  },
  {
    "objectID": "writeups/index.html",
    "href": "writeups/index.html",
    "title": "Extra Writeups",
    "section": "",
    "text": "Order By\n       Default\n         \n          Last Updated - Oldest\n        \n         \n          Last Updated - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nLast Updated\n\n\nRelevant To\n\n\nCategory\n\n\n\n\n\n\nFrom Intuitions to Antecedents\n\n\nFriday, February 28, 2025\n\n\nHW1\n\n\nExtra Writeups\n\n\n\n\nBerkson’s Paradox Example\n\n\nTuesday, February 25, 2025\n\n\nMidterm\n\n\nExtra Writeups\n\n\n\n\nDo-Calculus: Choose Your Own Pace\n\n\nWednesday, February 19, 2025\n\n\nHW1\n\n\nExtra Writeups\n\n\n\n\nKantian Ethics: The Hypothetical and Categorical Imperative\n\n\nSaturday, February 8, 2025\n\n\nHW1\n\n\nExtra Writeups, Deep(er) Dives\n\n\n\n\nIs It Fair? The Issue of Operationalization and “Fairness” in AI\n\n\nWednesday, February 5, 2025\n\n\nWeek 4\n\n\nExtra Writeups\n\n\n\n\nEssentially Contested Concepts\n\n\nWednesday, January 29, 2025\n\n\nWeeks 1-3\n\n\nExtra Writeups\n\n\n\n\nA Quick Introduction to Probabilistic Graphical Models\n\n\nSunday, February 18, 2024\n\n\nWeeks 5-7 (Causality)\n\n\nExtra Writeups\n\n\n\n\nWeek 3 Resources / Loose-Thread Tying\n\n\nSaturday, February 3, 2024\n\n\n \n\n\nExtra Writeups\n\n\n\n\nWeek 2 Resources / Priming Your Brain for HW1\n\n\nWednesday, January 24, 2024\n\n\n \n\n\nExtra Writeups\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Writeups"
    ]
  },
  {
    "objectID": "writeups/contested/index.html",
    "href": "writeups/contested/index.html",
    "title": "Essentially Contested Concepts",
    "section": "",
    "text": "Since I know that I often mention things in passing and quickly jump to the next topic, I hope this writeup can serve to (a) take the time that some of yall’s in-class comments deserve(!), and (b) tie together the “core” class content (the stuff on the slides and in the homework) with this “peripheral” class content (the stuff that comes up during sidebars/questions/comments)"
  },
  {
    "objectID": "writeups/contested/index.html#achieving-intersubjective-truth",
    "href": "writeups/contested/index.html#achieving-intersubjective-truth",
    "title": "Essentially Contested Concepts",
    "section": "Achieving Intersubjective “Truth”",
    "text": "Achieving Intersubjective “Truth”\nI (thankfully) remembered to describe Quine’s “gavagai” problem in class today, where the takeaway was that we never technically “know” the meaning of a word in a definitive sense—we are always “triangulating” the meaning by collecting more and more “data” in the form of contexts in which we observe the word being used. In the gavagai example from class, we have the following process of narrowing-in on the meaning of “gavagai”:\n\nA rabbit runs by, and a member of the group whose language we don’t know points at the rabbit and says “gavagai!” \\(\\leadsto\\) “gavagai” could mean “rabbit”, or “furry animal”, or “thing with legs”, or “thing with less than 5 legs”, or “thing with less than 6 legs”, or “thing with less than 7 legs”, etc… (an infinitude of possible meanings)\nLater that day, someone from the same linguistic community points at a table with 6 legs and says “gavagai!” \\(\\leadsto\\) we can now eliminate the “rabbit” and “furry animal” hypotheses, as well as the “thing with less than 5 legs” and “thing with less than 6 legs” hypotheses.\nWe continue this (when it comes to our first language, it’s a process running from early childhood onwards), such that we (asymptotically) converge to a fairly stable distribution of how likely and unlikely we think the different hypotheses are.\n\nOne thing that emerges, though, is that we can also start to “mark out” different classes of words, spanning from:\n\nThose which are easiest to achieve intersubjective agreement on, such as the words in a sentence like: “this table is taller than that table”, which can be intersubjectively verified by allowing all the subjects to e.g. use their depth perception and/or a meter stick to measure the two tables (our distribution of hypotheses around these words converge to a stable state pretty quickly), to\nThose which are more difficult because we don’t have an intersubjectively-agreed meter stick, like “I love you more than they love you”: words whose subjective meanings (i.e., our distributions of hypotheses about what these words refer to or demarcate in the world) are frequently challenged and updated as we grow and have more experiences; these latter cases are why I wish I could’ve played this full video that I summarized in class!"
  },
  {
    "objectID": "writeups/contested/index.html#essentially-contested-terms",
    "href": "writeups/contested/index.html#essentially-contested-terms",
    "title": "Essentially Contested Concepts",
    "section": "Essentially-Contested Terms",
    "text": "Essentially-Contested Terms\nIf this was just a class on the language of ethics, we could in a sense stop there (for example, the range of language covered in the above two bullet points corresponds to a large chunk of the linguistic theory in Hare (1952)). But, in a class where the point of all this is to build up frameworks for ethics and policy, we can posit a third type of word, which Connolly (1974) calls an “essentially contested” word or concept.\nThe easiest way to understand what might qualify as an “essentially contested” word is probably through example. So, as the first example that comes to my mind, consider how US schools usually ask students to stand up at the beginning of each school day, put their hands to their hearts, and recite the Pledge of Allegiance, which ends with the phrase:\n\nWith liberty and justice for all.\n\nSo, we can take the two bolded words there, and we can think about how it’s probably going to be more difficult to achieve intersubjective agreement about what these terms mean to people in the US than, say, “fish” or “pencil”, precisely because there are higher stakes: intersubjective disagreements about what “liberty” and “justice” mean cut straight to the core of what it means to be “American” in a way that disagreements about “fish” or “pencil” do not.\nThis idea can also help shed light on how, for example, the relationship between political power and the degree of linkage one can establish between one’s own political program and the meanings of these words. To put it in a less wordy way: the success of a political party often correlates with how well it can “fit” its own program to particular subjective meanings of these terms held among constituents. So that, in the US, there are political struggles in which debates (usually implicitly, but sometimes explicitly) are waged over how the politician will uphold the “liberty” and “justice” that is in constituents’ heads better than their opponents.\nOr, to make it less US-centric, someone in China may succeed or fail to succeed in enacting some sort of change in the system to the extent that they can link their program with a particular meaning of 中国特色社会主义 or socialism (社会主义) with Chinese characteristics (中国特色)—a term which appears many times in this famous 2013 speech from Xi Jinping, for example, which has the title (using my terrible Chinese translation skills but I think I got this bc I cross-checked it with the English translation):\n\n毫不动摇坚持和发展中国特色社会主义\n(Uphold and Extend Socialism with Chinese Characteristics)\n\nand which makes the argument that (using my terrible Chinese comprehension skills to their maximum degree here, since I didn’t cross-check the whole thing), the tenets of Xi Jinping Thought that are outlined in the speech are a “best” implementation of 中国特色社会主义, among ideas/proposals being discussed at the end of Hu Jintao’s term as CCP General Secretary in 2012."
  },
  {
    "objectID": "writeups/contested/index.html#policy-whitepaper-takeaway-operationalize",
    "href": "writeups/contested/index.html#policy-whitepaper-takeaway-operationalize",
    "title": "Essentially Contested Concepts",
    "section": "Policy Whitepaper Takeaway: Operationalize!",
    "text": "Policy Whitepaper Takeaway: Operationalize!\nThe takeaway from these two examples to your policy whitepapers, therefore, can be summarized like: you’re going to make your task harder than it needs to be if you say that (e.g.) your policy is better than existing policies because it better upholds “liberty”, or “justice”, or “Socialism with Chinese Characteristics”, as such… For someone to accept that type of argument, they would probably also have to share a whole lot of other “background” antecedents with you in the first place, about what these terms mean, which would kind of undercut the point of making the argument (you would be “preaching to the choir”).\nSo, this means that I might circle some part(s) of your proposals for example and write “essentially contested concept!”, meaning, you probably need to operationalize what you mean, more concretely, by specifying a metric on which your policy might be better, if you want to convince people in your audience who don’t already agree with you!\nAs a final two-bullet-point example, consider the Drèze and Sen (1991) example from the Week 2 slides, where we looked at this passage:\n\n\n\n\n\nThe point there was that, if you want to say e.g. that your policy would increase freedom, then you can first specify freedom from hunger to “decouple” this type of freedom from “freedom” writ large. But, even then, you should also specify whether your operationalization of “hunger” is:\n\nLiteral starvation, in the form of e.g. deaths that occur over a short period of time due to acute famine conditions (like the Great Famine referenced in the above passage), or\nNutritional deprivation, in the form of e.g. the longer-term effects of subsistence-level food and water, and the deaths that occur over a longer span of time that wouldn’t have otherwise occurred with an above-subsistence-level food and water intake."
  },
  {
    "objectID": "writeups/w03.html",
    "href": "writeups/w03.html",
    "title": "Week 3 Resources / Loose-Thread Tying",
    "section": "",
    "text": "Hi all! As has become my tradition, I am writing this as a “wrap-up” of loose threads that I felt were left un-tied at the end of lecture on Wednesday. This week, right after class ended, I did a deeper dive into the Sapir-Whorf Hypothesis, to try to (a) clarify the discussion we had around Sapir-Whorf vs. Linguistic Relativism and Linguistic Determinism, and (b) tie it back into the main course topics! But first, the stuff-I-googled portion:"
  },
  {
    "objectID": "writeups/w03.html#things-i-googled-opened-during-class",
    "href": "writeups/w03.html#things-i-googled-opened-during-class",
    "title": "Week 3 Resources / Loose-Thread Tying",
    "section": "1. Things I Googled / Opened During Class",
    "text": "1. Things I Googled / Opened During Class\n\nExcavating AI: The Politics of Images in Machine Learning Training Sets: Crawford and Paglen (2019)\nDecoding the Thought Vector, from Gabriel Goh’s Blog: Machine Learning, Data Science, and Optimization"
  },
  {
    "objectID": "writeups/w03.html#linguistic-relativism-linguistic-determinism-and-the-sapir-whorf-hypothesis",
    "href": "writeups/w03.html#linguistic-relativism-linguistic-determinism-and-the-sapir-whorf-hypothesis",
    "title": "Week 3 Resources / Loose-Thread Tying",
    "section": "2. Linguistic Relativism, Linguistic Determinism, and the Sapir-Whorf Hypothesis",
    "text": "2. Linguistic Relativism, Linguistic Determinism, and the Sapir-Whorf Hypothesis\nHonestly, this question simmered in my brain from the minute it came up until the end of class! So, from the time class ended up until now, I went back and re-read two of the four books that had put these concepts into my brain in the first place. The two I read were:\n\nMarcel Danesi (2021), Linguistic Relativity Today: Language, Mind, Society, and the Foundations of Linguistic Anthropology (Danesi 2021) [PDF; this one is particularly difficult and expensive to obtain a hard copy of!]\nJohn McWhorter (2014), The Language Hoax: Why the World Looks the Same in Any Language (McWhorter 2014): This one I did explicitly mention in class and put it on the slides [EPUB]\n\nWhile the two I didn’t re-read, but did impact my brain at some earlier point, were:\n\nSteven Pinker (2005), The Stuff of Thought: Language as a Window into Human Nature (Pinker 2005) [EPUB]\nGeorge Lakoff (1987), Women, Fire, and Dangerous Things: What Categories Reveal about the Mind (Lakoff 1987) [PDF]\n\nBesides the time factor, the reason I only re-read the first two is because: (a) I remember feeling like the Pinker book was overly dismissive of the whole idea; as in, I don’t feel like it gave a very “fair trial” to the nuances of the degrees to which language and thought affect one another. And (b) Lakoff’s books are… I feel like I should like them, the specific topics he looks at are fascinating and relevant and important imo, but then when I actually open them up and read them I often feel like the writing is a bit dry and monotonous1.\nAnd, my followup thought on this is: I was too dismissive of the Sapir-Whorf Hypothesis! One of the reasons I settled on the Danesi book at spot #1 is because, I think it does a really good job of separating the strong and weak forms of this hypothesis, and it matches 100% with how Cynthia summarized it in class! So, I hereby delegate Cynthia as the class consultant for language in data ethics and society 😎. The summary I can come up with, trying to synthesize what Cynthia said and how it’s described in the Danesi book, is that:\n\nLinguistic Determinism, or the Strong Sapir-Whorf Hypothesis, posits that “language determines how people think” (Danesi 2021, x), whereas\nLinguistic Relativism, or the Weak Sapir-Whorf Hypothesis, posits that language shapes (without determining) how people think.\n\nBasically, the Danesi book’s preface mentions the strong version but quickly dismisses it: “From the relevant studies, there is little support for the so-called ‘strong’ version” (Danesi 2021, x). The first chapter then goes in-depth into the weak version, in a really fascinating way.\nI was taking the term “Sapir-Whorf Hypothesis” in general and conflating it with the strong version, and that’s where my criticism was coming from. I should have phrased what I was saying as: the strong Sapir-Whorf Hypothesis can be problematic, from my perspective, given the implications that could come from believing it to be true when it isn’t.\nIn its strong form, for example, it strikes me as alarmingly reminiscent of Samuel Huntington’s Clash of Civilizations hypothesis (and the many similar and similarly-influential global-cultural claims), which have the effect of telling policymakers something like “we’ll never be able to bridge the humongous gap between ‘Eastern’ and ‘Western’ cultures, so they’ll just have to eternally clash with one another, and uh, I hope ‘we’ win!”\nThis is the kind of danger that, in my reading, McWhorter is warning about in the Language Hoax book whose cover was in my slides: just that, we have to be very careful when talking about concepts as fuzzy and hard-to-define as “a culture” or “a language” since, despite their vagueness in theory, they can become reified and morph into dehumanizing claims and then entire books about e.g. the “Arab mind”, and then these kinds of books can hypothetically become “the basis of” one’s “cultural instruction” in the US Army, with predictable consequences…\n\n“At the institution where I teach military officers,”” as retired U.S. Army Col. Norvell De Atkine writes in the book’s foreword, “The Arab Mind forms the basis of my cultural instruction.” (from Slate, “Inside The Arab Mind: What’s wrong with the White House’s book on Arab nationalism”)\n\nWith that said, I don’t think there’s anything in Whorf’s original description of the idea that lends itself to this kind of cultural essentialism! I think the following quote from Whorf, quoted at the beginning of the Danesi book, makes the distinction really clear:\n\nWe are thus introduced to a new principle of relativity, which holds that all observers are not led by the same physical evidence to the same picture of the universe, unless their linguistic backgrounds are similar, or can in some way be calibrated. (Whorf 1956, 229)\n\nBasically, this quote is how I’ll remember Sapir-Whorf as linguistic relativism, rather than determinism, from now on!"
  },
  {
    "objectID": "writeups/w03.html#mental-math-speed-as-an-example-of-weak-sapir-whorf",
    "href": "writeups/w03.html#mental-math-speed-as-an-example-of-weak-sapir-whorf",
    "title": "Week 3 Resources / Loose-Thread Tying",
    "section": "3. Mental Math Speed as an Example of Weak Sapir-Whorf",
    "text": "3. Mental Math Speed as an Example of Weak Sapir-Whorf\nThe example that came up during that same discussion—where Keqin helped a ton by pointing out the syllabic differences in mathematical symbols/terms between different languages!—I think was first implanted in my brain by a 2014 article from the Wall Street Journal, “The Best Language for Math: Confusing English Number Words Are Linked to Weaker Skills” (Shellenbarger 2014), that went 2014-style viral, or at least viral among… cross-cultural linguistics nerds?\nI tried to find the presentation (or at least the paper) about the cross-cultural mental math experiments that I went to while I was at the Santa Fe Institute, but I wasn’t able to track it down. And, I found it surprisingly difficult to find actual scientific studies of it more generally2. However, I did find a super-interesting deep-dive into aspects of the original Wall Street Journal article, and an even more super-interesting book:\n\nBarbara M. Birch and Sean Fulop (2021), English L2 Reading: Getting to the Bottom (4th Edition) (Birch and Fulop 2021) [PDF]\n\nwhich goes into an awesome amount of analytic detail about second-language learning. It even has a neural network diagram right in the first chapter, which is how I knew I had to read it 🤓:\n\n\n\n\n\nFor our purposes, though, the two most interesting parts of that book come at the end of Chatper 2 and then… the entirety of Chapter 3, which is on “Interlanguage Reading and Transfer”. As a segue into this chapter, which contains a bunch of material on studies of mental math, the end of Chapter 2 presents the following as its fourth “Discussion Question”, which I wanted to copy here as a “food for thought” exercise for you, having had our discussion around mental math and language!\n\n\n\n\n\n\nMental Math Discussion Question (Birch and Fulop 2021, 50–51)\n\n\n\nThis quote comes from Tzeng and Hung (1981): “Miller … has pointed out the importance of notational design in the history of mathematics. In Miller’s words (1957) ‘In order to study the interaction of thought and symbol it is not necessary to travel with Whorf to the Zuni Indians; the language of mathematics is rich with excellent examples. Why are Arabic numbers so superior to Roman?’” (p. 238).\nIn that spirit, compare these different representations of the same meaning concept (the number seven): 7, seven, vii. Which type of writing does each correspond to? (If 7 and vii are both logographic, what is the difference between them?) What are the advantages and disadvantages of each type of number? Do you agree that the history of mathematics has been affected by the type of notations developed? Could mathematics have advanced without the symbols like 7?\nCould language and culture be similarly affected by the writing systems that evolved in different civilizations? Logan (1986) argues that alphabetic writing was related to the growth of theoretical science in Western civilization and not in Eastern: “The effects of the alphabet and the abstract, logical, systematic thought that it encouraged explain why science began in the West and not in the East, despite the much greater technological sophistication of the Chinese […] the inventors of metallurgy, irrigation systems, animal harnesses, paper, ink” (p. 23).\n\n\nThen, the section of Chapter 3 with the title “Writing Systems and Transfer” contains the “meat” of the question, with references to individual studies you can read for a true deep-dive (including a study that very specifically looks at Hong Kong ESL learners! For those interested: (Yeung, Siegel, and Chan 2013)).\nI’m copying that section of the chapter in full below, so that you have the previous “discussion question” and this section all in one place, and you don’t have to worry about going and obtaining the full book if you don’t want to! (This one is collasped by default, to make the page look less scarily-long)\n\n\n\n\n\n\nWriting Systems and Transfer (Birch and Fulop 2021, 63–65)\n\n\n\n\n\nWriting Systems and Transfer\nOne question that researchers have tried to answer is whether logograms like Chinese characters or Japanese kanji are read holistically or not. There was early evidence for this idea because reading logograms was more like processing pictures than reading (Henderson 1982, 196). Morton and Sasanuma (1984) concluded that for Japanese writing, although the kana were read analytically, the kanji were read holistically. To them, there seems to be “a strong dissociation between the processes involved in reading the two scripts [kana vs. kanji]” (p. 40). However, Leong and Tamaoka (1995) argued that both visual and phonological processing occur in accessing difficult kanji with phonetic elements.\n\n\n\n\n\n\nReading Logograms\nKoda (1995) explained how both holistic and phonological processing are involved in reading logograms. Koda suggested that all writing systems require readers to access phonological information because working memory is better for phonological material than for visual material. However, the timing of the phonological access is different. Alphabetic writing requires access to a phonological representation prior to or at the time that the word is retrieved from memory. A logographic code requires phonological access only after the word is retrieved because that is the time when phonological information becomes available to the reader, as shown in Figure 3.1. It is, in fact, impossible to pronounce an unknown character because often the phonetic cues are not enough. Logograms may also be read without access to sound, as in mental math calculations, where thinking of the name of the number symbol slows down the process. This evidence supports the claim that readers use different linguistic strategies to handle logograms (holism) vs. alphabetic words (analysis) but that the universal phonological principle does hold.\nTan et al. (2003) studied intermediate Chinese/English graduate students who began learning English after the age of 12, comparing them with a group of English monolinguals. They found that phonological processing of Chinese characters activates portions of the brain that process spatial information. The activation of this system was related to the square configuration of the character, which then maps onto a monosyllabic unit of speech. When the Chinese students performed a phonological task on English words, they activated the very same visual processing system, unlike the brain areas activated by the English monolinguals when they performed phonemic analyses.\nTan et al. (2003) thought that their Chinese subjects were trying to use their L1 system to read in English. Since they lacked the infrastructure for English, they could not process the alphabetic writing system like the English readers did. In other words, the Chinese graduate students were not taking advantage of the alphabetic writing. However, little is known about their background as language learners. Yeung, Siegel, and Chan (2013, 699) found that if Chinese-speaking children gained in phonological awareness, their reading also improved. They suggested that “once children acquire phoneme awareness, even without explicit instruction in letter-sound correspondences, they change the reading strategy and readily apply the phoneme awareness to aid word recognition.”\nKoda (1995) studied Japanese, Arabic, Spanish, and English readers of English and found that symbols that had no phonological cues and unpronounceable words interfered less with the Japanese readers than with the alphabetic readers. Unpronounceable words interfere with English reading because of the difficulty they pose for phonological analysis. English readers stumble over the unpronounceable foreign names in a novel like War and Peace. They try to process them holistically by remembering the appearance of the name and associating it with a certain character. Or they try a laborious analytical strategy of sounding out the names and remembering them by sound. Either way, they are obstacles for reading.\nHowever, unpronounceable words did not cause difficulty for the Japanese readers that Koda (1995) studied because they treated the problem words as they did kanji. They did not try to pronounce them; they tried to remember them visually. Also, English reading comprehension among Japanese college students was unaffected by the unpronounceability of English words, suggesting a strategy of relying little on phonological information in reading the unknown words. The strategy these Japanese students were applying to unknown English words was holistic, visual, and meaning-based, discarding the very strengths of the alphabetic writing system with its cues to sound. The short-term strategy of treating unfamiliar words as logograms may assist English beginning readers at first, but over time, it is more efficient to decode unknown words and assign a pronunciation to them. In short, there is evidence for transfer of processing strategies from L1 to L2 if the writing systems have some similarity such as Chinese characters, Japanese kanji, and symbols or unpronounceable words. This is facilitation, but it may only offer a short-term benefit"
  },
  {
    "objectID": "writeups/w03.html#footnotes",
    "href": "writeups/w03.html#footnotes",
    "title": "Week 3 Resources / Loose-Thread Tying",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI’m mostly thinking of his book with Mark Johnson here which I read more recently, Metaphors We Live By (Lakoff and Johnson 1980), so maybe the newer one is more interesting and I’m being unfair here, but yeah limited resources, I wanted to be able to read at least one full book between end-of-class and this writeup!↩︎\nIf you try searching for it by googling something like \"mental math\" \"speed\" \"mandarin\" \"english\" however, you will find lots of fun videos and books about 史丰收 / Shi Fengshou, who created a very fun-to-watch mental math technique involving rapid hand gestures!↩︎"
  },
  {
    "objectID": "writeups/categorical-imperative/index.html",
    "href": "writeups/categorical-imperative/index.html",
    "title": "Kantian Ethics: The Hypothetical and Categorical Imperative",
    "section": "",
    "text": "Homework 1 had a series of questions where you were asked to distinguish whether a given statement was more “directly” implied by Consequentialism or Kantian Ethics: in this writeup, my goals are:\nThose two goals, however, are written in chronological order based on when they came up in the class or in office hours! So, for ease-of-explanation pursposes, I will address them in reverse order in the following two sections."
  },
  {
    "objectID": "writeups/categorical-imperative/index.html#kantian-ethics-and-the-push-button-brain-zapper",
    "href": "writeups/categorical-imperative/index.html#kantian-ethics-and-the-push-button-brain-zapper",
    "title": "Kantian Ethics: The Hypothetical and Categorical Imperative",
    "section": "Kantian Ethics and the Push-Button Brain Zapper2",
    "text": "Kantian Ethics and the Push-Button Brain Zapper2\nTo understand the difference between Consequentialism and Kantian Ethics, at least in the way we employed these terms for HW1, imagine you have a small handheld device called a Brain Zapper3 that works as follows:\nThe Brain Zapper is really two devices in one, sharing a brain-wave-reader but separated into two CPUs and two screens:\n\nThe device on the left side is labeled “Consequentialism”\nThe device on the right side is labeled “Kantian Ethics”\n\n\n\n\nImage Credit\n\n\nHere we’ll model how these two screens would “process” the decision of whether or not to do some action \\(a\\):\n\nWe’ll assume your name is Doug, since we need a way to distinguish you from everyone else, but you can replace “Doug” with your real name!\nWe’ll denote “Doing \\(a\\)” with just the symbol \\(a\\), whereas\nWe’ll denote “Not doing \\(a\\)” with \\(\\neg a\\), so that\nDoug’s choice set is \\(C = \\{a, \\neg a\\}\\)\n\nUnder these terms, the Brain Zapper activates when Doug start thinking a thought like “Should I choose \\(a\\) or \\(\\neg a\\)?” The two sides of the Brain Zapper then both run a series of ultra-advanced societal simulations, but of different kinds:\n\n\n\n\n\n\n\nUtilitarian CPU\nKantian CPU\n\n\n\n\n Simulate two worlds:\n Simulate two worlds:\n\n\n\\(\\mathcal{W}_{a}\\): The world from moment of action onwards if Doug chooses \\(a\\)\n\\(\\mathcal{W}_{a}\\): The world from moment of action onwards if everyone in the world adoped rule: [when in this scenario, choose \\(a\\)]\n\n\n\\(\\mathcal{W}_{\\neg a}\\): The world from moment of action onwards if Doug chooses \\(\\neg a\\)\n\\(\\mathcal{W}_{\\neg a}\\): The world from moment of action onwards if everyone in the world adoped rule: [when in this scenario, choose \\(\\neg a\\)]\n\n\n Decide which is better on the basis of some criteria. Since we chose utilitarianism, decide based on utility summed over society:\\(\\displaystyle \\max\\left\\{ \\mathbb{E}[u_i(\\mathcal{W}_{a})], \\mathbb{E}[u_i(\\mathcal{W}_{\\neg a})] \\right\\}\\)\n \\(a\\) is admissible under categorical imperative if \\(\\mathcal{W}_{a}\\) is a world you would feel ok living in.\\(\\neg a\\) is admissible under categorical imperative if \\(\\mathcal{W}_{\\neg a}\\) is a world you would feel ok living in."
  },
  {
    "objectID": "writeups/categorical-imperative/index.html#best-vs.-admissible",
    "href": "writeups/categorical-imperative/index.html#best-vs.-admissible",
    "title": "Kantian Ethics: The Hypothetical and Categorical Imperative",
    "section": "“Best” vs. “Admissible”",
    "text": "“Best” vs. “Admissible”\nSo, note that for example, under Utilitarianism it is in some sense “unlikely” that the two actions would be equally good (they would have to both result in the exact same level of expected overall utility forever into the future), whereas under Kantian ethics we might regularly encounter scenarios which give rise to multiple admissible choices:\n\nChoosing between Ranch Dressing and Balsalmic Vinaigrette Dressing on your Greek Salad will usually have a Utilitarian “best” option: if choosing Ranch provides even 0.0000001 more utility for you, and if choosing it doesn’t decrease anyone else’s utility, then Ranch is the “correct” choice\nBoth choices will likely be admissible under Kantian ethics, which makes more sense if we look at them one by one:\n\nWould you feel ok living in a world where everyone put Ranch Dressing on their Greek Salads?4\nWould you feel ok living in a world where everyone put Balsalmic Vinaigrette Dressing on their Greek Salads?"
  },
  {
    "objectID": "writeups/categorical-imperative/index.html#a-harder-case",
    "href": "writeups/categorical-imperative/index.html#a-harder-case",
    "title": "Kantian Ethics: The Hypothetical and Categorical Imperative",
    "section": "A Harder Case",
    "text": "A Harder Case\n\n“Getting Away With” Choosing Ranch Dressing vs. “Getting Away With” Speeding\nThe Kantian approach comes more into play when we think about, e.g., “getting away with” some action. This was Kant’s original motivation for proposing an alternative to utilitarianism: he believed Utilitarianism could never compel individual people to act ethically, since they would say, “Ok but, if I’m better off… why do I care if the rest of society is worse off?”\nThe next step in Kant’s thought process (as in, how he ended up at this conclusion) is way tough to follow, but boils down in Jeff’s trying-to-simplify-everything-despite-rushing-to-finish-this-writeup brain to something like:\n\n Morality is intertwined with freedom, in the sense that if we want to be truly moral we have to arrive at our decisions through our own thought processes, driven by internally-generated motivations, rather than on the basis of some externally-given criterion/source of motivation like that of Utilitarianism5. So then [rushing through 40ish years of him changing, updating, augmenting this theory],\n Freely-made decisions grounded in internally-generated motivations must be arrived at via some law(s) that are not “inputted” into our minds from the external world (otherwise, we could just hit people with the Utilitarianism stick for years and years until they internalized Utilitarianism, which is what Britain tried through e.g. their education system in the 19th century, and yet people raised in this system still acted “immorally” in the Utilitarian sense all the time!), but are instead “immanent”—i.e., derived from within the mind itself without reference to external circumstances (height, weight, ability, class, race, gender, etc.)6\n After even more years of thinking about this, Kant’s final set of works argued that the sole coherent / consistent-in-and-of-itself law that could possibly satisfy this ultra-stringent set of conditions is the Categorical Imperative described above, which is usually translated into English as:\n\n“Act only according to that maxim7 by which you can at the same time will that it should become a universal law.” Kant (1785)\n\n\nFor any clarity beyond this painfully-badly-oversimplified 3-step summary, I refer yall to Korsgaard (1996b), or the series of lectures which aimed to summarize that more-intense book, Korsgaard (1996a), a PDF of which is linked to from the Resources page!\n\n\nThe Case of Speeding\nSo, now let’s re-run the Brain Zapper, but with speeding because we’re late to an appointment (the HW1 example) as our test case.\n\n\n\n\n\n\n\nUtilitarian CPU\nKantian CPU\n\n\n\n\n Simulate two worlds:\n Simulate two worlds:\n\n\n\\(\\mathcal{W}_{a}\\): The world from moment of action onwards if Doug chooses to speed\n\\(\\mathcal{W}_{a}\\): The world from moment of action onwards if everyone in the world adoped rule: [if late to appointment, speed]\n\n\n\\(\\mathcal{W}_{\\neg a}\\): The world from moment of action onwards if Doug chooses not to speed\n\\(\\mathcal{W}_{\\neg a}\\): The world from moment of action onwards if everyone in the world adoped rule: [if late to appointment, don’t speed]\n\n\n Decide which is better on the basis of some criteria. Since we chose utilitarianism, decide based on utility summed over society:\\(\\displaystyle \\max\\left\\{ \\mathbb{E}[u_i(\\mathcal{W}_{a})], \\mathbb{E}[u_i(\\mathcal{W}_{\\neg a})] \\right\\}\\)\n Speeding is admissible under categorical imperative if \\(\\mathcal{W}_{a}\\) is a world you would feel ok living in.Not-speeding is admissible under categorical imperative if \\(\\mathcal{W}_{\\neg a}\\) is a world you would feel ok living in.\n\n\n\nIn this case, we are likely to have a pretty significant disagreement between the two approaches:\n\nFor the Utilitarian approach, let’s grant that there really is a low probability of crashing in this scenario (though, the argument could still be made without this assumption, using ideas like “bounded rationality”), and that it is indeed really bad for Doug to be late, so that the expected utility to Doug from making it to the appointment on time outweighs the expected disutility to the rest of society from the low probability of crashing. Then: \\(\\mathbb{E}[u_i(\\mathcal{W}_a)] &gt; \\mathbb{E}[u_i(\\mathcal{W}_{\\neg a})]\\), and \\(a\\) is the ethically “correct” choice under this form of the Utilitarian antecedent\nFor the Kantian approach, speeding would not be admissible, since, e.g., [there are huge huge leaps of inference here, that you would usually have to sto and justify one-by-one… I’m simplifying for the sake of finishing this writeup, sryy] everyone speeding whenever they’re late would give rise to a world filled with a way higher likelihood of car crashes than we already have now, in turn raising the likelihood of crashes which would severely negatively affect Doug specifically (which is the crucial consideration, since we’re just back at utilitarianism if we judge based on overall likelihood of crashes). In Kant’s way of arguing, he would then proceed like: since humans cannot rationally will a rule deleterious to themselves8, speeding is inadmissible due to it failing the categorical imperative."
  },
  {
    "objectID": "writeups/categorical-imperative/index.html#why-its-called-the-brain-zapper",
    "href": "writeups/categorical-imperative/index.html#why-its-called-the-brain-zapper",
    "title": "Kantian Ethics: The Hypothetical and Categorical Imperative",
    "section": "Why It’s Called the Brain Zapper",
    "text": "Why It’s Called the Brain Zapper\nLastly, if you’ve gotten this far, I have yet to explain the name of the device! It’s called the Brain Zapper because, to “act ethically” in the Kantian sense, you must be ready to accept a world where the decisions you make are suddenly “zapped” into the brains of everyone on earth (now and into the future) as a rule!\nSo, to truly act ethically, you have to be willing to put your money where your mouth is (we’ll return to this phrase, like, a lot as we get towards the end of the semester!): willing to allow the Brain Zapper to send out a Neuralizer-style wave, suddenly binding everyone in the world to follow the implied rule. Does this sound relevant to something we are also concerned with in this class? That’s right: Laws! Policies! More on this connection coming soon (around week… 10ish)."
  },
  {
    "objectID": "writeups/categorical-imperative/index.html#footnotes",
    "href": "writeups/categorical-imperative/index.html#footnotes",
    "title": "Kantian Ethics: The Hypothetical and Categorical Imperative",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere, for source/inspiration-citing purposes, hats off to Trey for pushing on this point in class!↩︎\nA huge thanks to Ofure for asking helpful questions that led me to this explanation!↩︎\nThe Brain Zapper works kind of like the Neuralyzer from the movie Men in Black. (I’ve never seen this movie, but, from what I understand it zaps people’s brains to basically overwrite their memories of something!) The Brain Zapper is like a Neuralyzer but with two screens on it, as described below.↩︎\nNotice my sleight-of-hand here: Why wouldn’t the rule be “Put Ranch Dressing on any salad”, or “Put Ranch Dressing on all food”, for example? This is called the “Problem of Relevant Descriptions”, and you can find a summary in Timmons (1997) or (even better imo) the chapter on Kant in Russell (1946)↩︎\nExistentialism, a not-that-different ethical theory that draws on Kant, would make it a point to add Religion to the list of inadmissible-because-externally-given criteria/sources of motivation. We’ll come back to Existentialism at the very end of the semester!↩︎\nThis is basically where Rawls got the “Veil of Ignorance” idea from—a point he himself readily admits in Rawls (1980)!↩︎\nFor our purposes, you can just read ”maxim” as ”rule”. In non-oversimplified-Kant-world they’re technically not the same!↩︎\nFinal footnote here: Kant often has to hedge at this point and say things like, humans can rationally will a rule which seems deleterious to themselves, but is not actually deleterious to themselves, due to their intrinsic valuation of e.g. fairness, which cancels out the “vulgar” idea that $9.01 for me and $0 for you is better than $9 for me and $9 for you. But, for this specific example, we don’t need to bring in fairness/inequality, since we are directly “drilling down to” Doug’s aversion to being hit by a car, rather than aversion to unfairness or inequality between car-hitting chances.↩︎"
  },
  {
    "objectID": "w02/slides.html#where-we-left-off-ethical-issues-in-data-science",
    "href": "w02/slides.html#where-we-left-off-ethical-issues-in-data-science",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Where We Left Off: Ethical Issues in Data Science",
    "text": "Where We Left Off: Ethical Issues in Data Science\n\nData Science for Who? ✅\nIndividuals \\(\\leftrightarrow\\) Structures 👀\nOperationalization\nFair Comparisons\nImplementation"
  },
  {
    "objectID": "w02/slides.html#structural-domination-the-grapes-of-wrath",
    "href": "w02/slides.html#structural-domination-the-grapes-of-wrath",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Structural Domination: The Grapes of Wrath",
    "text": "Structural Domination: The Grapes of Wrath\n\nBut… I built it with my hands! Straightened old nails to put the sheathing on!\nIt’s not me. There’s nothing I can do. I’ll lose my job if I don’t do it. And look—suppose you kill me? They’ll hang you, and long before you’re hung there’ll be another guy here, he’ll bump the house down. You’re not killing the right guy.\nThat’s so… Who gave you orders? I’ll go after him. He’s the one to kill.\nYou’re wrong. He got his orders from the bank. ‘Clear those people out or it’s your job.’\nWell, there’s a president of the bank. A board of directors. I’ll fill up my rifle, head to the bank.\nThe bank gets orders from the East. ‘Make the land show profit or we’ll close you up.’ We’re sorry. It’s not us. It’s the monster. The bank isn’t like a man.\nYes, but the bank is only made of men!\nNo, you’re wrong there—quite wrong. The bank is something else than men. It happens nowadays that every man in a bank hates what the bank does, and yet the bank does it. The bank is something more than men, I tell you.\nI got to figure… We all got to figure. There’s some way to stop this. There’s got to be some way to stop this. It’s not like lightning or earthquakes. We’ve got a bad thing made by men, and by God, isn’t that something we should be able to change? (Steinbeck 1939)"
  },
  {
    "objectID": "w02/slides.html#ontology-individuals-and-structures",
    "href": "w02/slides.html#ontology-individuals-and-structures",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Ontology: Individuals and Structures",
    "text": "Ontology: Individuals and Structures\n\n\n\nNo longer preoccupied with crude ‘conspiracy theories’, [progressives] attribute all things negative to handy abstractions: ‘capitalism’, ‘the state’, ‘structural oppression’, ‘hierarchy’. Hence they have been able to conjure what might be termed the ‘miracle of immaculate genocide’, a form of genocide, that is, in which there are no actual perpetrators, no one who might ‘really’ be deemed culpable (Churchill 2003)\nWe make our own history, but we do not make it as we please; we do not make it under self-selected circumstances, but under circumstances existing already, given and transmitted from the past. The tradition of all dead generations weighs like a nightmare on the brains of the living. (Marx 1852)\n\n\n\n\n\n\nSandburg (1926)"
  },
  {
    "objectID": "w02/slides.html#operationalization",
    "href": "w02/slides.html#operationalization",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Operationalization 👀",
    "text": "Operationalization 👀\n\n\n\nThink of claims commonly made based on “data”:\n\nMarkets create economic prosperity\nA glass of wine in the evening prevents cancer\nPolicing makes communities safer\n\nHow exactly are “prosperity”, “preventing cancer”, “policing”, “community safety” being measured? Who is measuring? Mechanisms for feedback \\(\\leadsto\\) change?\n\n\n\n\n\n\n\n\nStiglitz, Sen, and Fitoussi (2010)"
  },
  {
    "objectID": "w02/slides.html#what-is-being-compared",
    "href": "w02/slides.html#what-is-being-compared",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "What Is Being Compared? 👀",
    "text": "What Is Being Compared? 👀\n\n\n\n\n\n\n\n\nApples\nOranges\nPears\n\n\n\n\nPolities w/250-500M people (US ~335M, UP ~250M, EU ~450M)\nPolities w/11M people in the Caribbean (Cuba, Haiti, Dominican Republic)\nPolities w/over 1 billion people (China ~1.4B, India ~1.4B, Africa ~1.4B, ⬆️+⬇️ America ~1B)\n\n\nDemocracies (US)\nDemocracies til they democratically elected someone US didn’t like (Iran, Guatemala, Chile)\nNon-democracies which brutally repress democratic movements w/US arms (Saudi Arabia)\n\n\nColonizing polities (US)\nPolities colonized by them (Philippines)\nNon-colonized polities (Ethiopia, Thailand)\n\n\nPolities w/infrastructure built up over 250+ yrs via slave labor (US 🇺🇸)\nPolities populated by former slaves (Liberia 🇱🇷)\nPolities that paid reparations to descendants of [certain] enslaved groups (Germany)\n\n\nPolities independent since 1776 (US)\nPolities independent since 1990 (Namibia)\nNon-self-governing polities (Puerto Rico, Palestine, New Caledonia)\n\n\nPolities enforcing a 60 yr embargo on Cuba (US)\nPolities with a 60 yr embargo imposed on them by US (Cuba)\nPolities without a 60 yr embargo imposed on them by US (…)"
  },
  {
    "objectID": "w02/slides.html#how-are-they-being-compared",
    "href": "w02/slides.html#how-are-they-being-compared",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "How Are They Being Compared?",
    "text": "How Are They Being Compared?\n\nWhat metric? Over what timespan?\nWhat unit of obs \\(\\leadsto\\) agg function \\(\\leadsto\\) level of aggregation?\n\n\nDrèze and Sen (1991)"
  },
  {
    "objectID": "w02/slides.html#there-is-still-hope-i-promise",
    "href": "w02/slides.html#there-is-still-hope-i-promise",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "…There is Still Hope! I Promise!",
    "text": "…There is Still Hope! I Promise!\n\nFair Comparison through Statistical Matching:\nLyall (2020): “Treating certain ethnic groups as second-class citizens […] leads victimized soldiers to subvert military authorities once war begins. The higher an army’s inequality, the greater its rates of desertion, side-switching, and casualties”\n\n\nMatching constructs pairs of belligerents that are similar across a wide range of traits thought to dictate battlefield performance but that vary in levels of prewar inequality. The more similar the belligerents, the better our estimate of inequality’s effects, as all other traits are shared and thus cannot explain observed differences in performance, helping assess how battlefield performance would have improved (declined) if the belligerent had a lower (higher) level of prewar inequality.\nSince [non-matched] cases are dropped […] selected cases are more representative of average belligerents/wars than outliers with few or no matches, [providing] surer ground for testing generalizability of the book’s claims than focusing solely on canonical but unrepresentative usual suspects (Germany, the United States, Israel)"
  },
  {
    "objectID": "w02/slides.html#does-inequality-cause-poor-military-performance",
    "href": "w02/slides.html#does-inequality-cause-poor-military-performance",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Does Inequality Cause Poor Military Performance?",
    "text": "Does Inequality Cause Poor Military Performance?\n\n\n\n\n\n\n\n\nCovariates\nSultanate of Morocco Spanish-Moroccan War, 1859-60\nKhanate of Kokand War with Russia, 1864-65\n\n\n\n\n\\(X\\): Military Inequality\nLow (0.01)\nExtreme (0.70)\n\n\n\\(\\mathbf{Z}\\): Matched Covariates:\n\n\n\n\nInitial relative power\n66%\n66%\n\n\nTotal fielded force\n55,000\n50,000\n\n\nRegime type\nAbsolutist Monarchy (−6)\nAbsolute Monarchy (−7)\n\n\nDistance from capital\n208km\n265km\n\n\nStanding army\nYes\nYes\n\n\nComposite military\nYes\nYes\n\n\nInitiator\nNo\nNo\n\n\nJoiner\nNo\nNo\n\n\nDemocratic opponent\nNo\nNo\n\n\nGreat Power\nNo\nNo\n\n\nCivil war\nNo\nNo\n\n\nCombined arms\nYes\nYes\n\n\nDoctrine\nOffensive\nOffensive\n\n\nSuperior weapons\nNo\nNo\n\n\nFortifications\nYes\nYes\n\n\nForeign advisors\nYes\nYes\n\n\nTerrain\nSemiarid coastal plain\nSemiarid grassland plain\n\n\nTopography\nRugged\nRugged\n\n\nWar duration\n126 days\n378 days\n\n\nRecent war history w/opp\nYes\nYes\n\n\nFacing colonizer\nYes\nYes\n\n\nIdentity dimension\nSunni Islam/Christian\nSunni Islam/Christian\n\n\nNew leader\nYes\nYes\n\n\nPopulation\n8–8.5 million\n5–6 million\n\n\nEthnoling fractionalization (ELF)\nHigh\nHigh\n\n\nCiv-mil relations\nRuler as commander\nRuler as commander\n\n\n\\(Y\\): Battlefield Performance:\n\n\n\n\nLoss-exchange ratio\n0.43\n0.02\n\n\nMass desertion\nNo\nYes\n\n\nMass defection\nNo\nNo\n\n\nFratricidal violence\nNo\nYes"
  },
  {
    "objectID": "w02/slides.html#no-crumbs",
    "href": "w02/slides.html#no-crumbs",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "No Crumbs",
    "text": "No Crumbs\n(I have no dog in this fight, I’m not trying to improve military performance of an army, but got damn)"
  },
  {
    "objectID": "w02/slides.html#implementation",
    "href": "w02/slides.html#implementation",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Implementation 👀",
    "text": "Implementation 👀\n\n\n\n\n\n\n\n\n\nFrom D’Ignazio and Klein (2020), Ch. 6 (see also)\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Lerman and Weaver (2014) (see also)"
  },
  {
    "objectID": "w02/slides.html#ethics-of-eliciting-sensitive-linguistic-data",
    "href": "w02/slides.html#ethics-of-eliciting-sensitive-linguistic-data",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Ethics of Eliciting Sensitive Linguistic Data",
    "text": "Ethics of Eliciting Sensitive Linguistic Data\n\n\n\n\n\n\n\n\n\nFrom Labov (2013), pg. 4\n\n\n\n\n\n\n\nFrom “80 Years On, Dominicans And Haitians Revisit Painful Memories Of Parsley Massacre”, NPR Parallels, 7 Oct 2017 (Bishop and Fernandez 2017)"
  },
  {
    "objectID": "w02/slides.html#privacy",
    "href": "w02/slides.html#privacy",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Privacy",
    "text": "Privacy\n\n\n\n\n\nFig 1.3: “The Accuracy-Privacy Loss Tradeoff”, from US Census Bureau (2021), Disclosure Avoidance for the 2020 Census\n\n\n\n\n\n\n“Privacy-Loss Budget (\\(\\varepsilon\\)) Acts as a Dial on Level of Noise”, ibid.\n\n\n\n\n\n\nSeurat, A Sunday Afternoon on the Island of La Grande Jatte, Wikimedia Commons"
  },
  {
    "objectID": "w02/slides.html#facial-recognition-algorithms",
    "href": "w02/slides.html#facial-recognition-algorithms",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Facial Recognition Algorithms",
    "text": "Facial Recognition Algorithms\n(aka AI eugenics… but I didn’t say that out loud)\n\n\n\n\n\n\n\n\n\nFacia.ai (2023)\n\n\n\n\n\n\n\nWellcome Collection (1890)\n\n\n\n\n\n\n\n\n\nOuz (2023)\n\n\n\n\n\n\n\nWang and Kosinski (2018)"
  },
  {
    "objectID": "w02/slides.html#llms-encode-existing-biases",
    "href": "w02/slides.html#llms-encode-existing-biases",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "LLMs Encode Existing Biases",
    "text": "LLMs Encode Existing Biases\n\n\n\n\n\nFrom Schiebinger et al. (2020)\n\n\n\n\n\n\nFrom Google Translate (22 Jan 2025)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt\nResult\n\n\n\n\n“Generate a reference letter for Kelly, a 22 year old female student at UCLA”\n“She is an engaged participant in group projects, demonstrating exceptional teamwork and collaboration skills […] a well-liked member of our community.”\n\n\n“Generate a reference letter for Joseph, a 22 year old male student at UCLA”\nHis enthusiasm and dedication have had a positive impact on those around him, making him a natural leader and role model for his peers.”\n\n\n\n\n\nFigure 1: Wan et al. (2023), “Gender Biases in LLM-Generated Reference Letters”"
  },
  {
    "objectID": "w02/slides.html#what-is-to-be-done",
    "href": "w02/slides.html#what-is-to-be-done",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "What Is To Be Done?",
    "text": "What Is To Be Done?\n \n\n\n\nWhen to retain biases…\n\n\n\n…and when to debias\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Schiebinger et al. (2020)\n\n\n\n\n\n\n\n\n\n\nFigure 3: From DeepLearning.AI’s Deep Learning course"
  },
  {
    "objectID": "w02/slides.html#military-and-police-applications-of-ai",
    "href": "w02/slides.html#military-and-police-applications-of-ai",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Military and Police Applications of AI",
    "text": "Military and Police Applications of AI\n\n\n\n\n\n\n\n\n\nAyyub (2019)\n\n\n\n\n\n\n\nMcNeil (2022)"
  },
  {
    "objectID": "w02/slides.html#your-job-policy-whitepaper",
    "href": "w02/slides.html#your-job-policy-whitepaper",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Your Job: Policy Whitepaper",
    "text": "Your Job: Policy Whitepaper\n\nSo is technology/data science/machine learning…\n\n“Bad” in and of itself?\n“Good” in and of itself? or\nA tool that can be used to both “good” and “bad” ends?\n\n“The master’s tools will never dismantle the master’s house”… Who decided that the master owns the tools?\nHow can we curtail some uses and/or encourage others?\nIf only we had some sort of… institution… for governing its use in society… some sort of… govern… ment?"
  },
  {
    "objectID": "w02/slides.html#from-week-7-onwards-you-work-at-a-think-tank",
    "href": "w02/slides.html#from-week-7-onwards-you-work-at-a-think-tank",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "From Week 7 Onwards, You Work At A Think Tank",
    "text": "From Week 7 Onwards, You Work At A Think Tank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMorozov (2015)\n\n\n\n\n\n\n\nFrom Ames (2014)"
  },
  {
    "objectID": "w02/slides.html#whatever-you-do-dont-be-bored",
    "href": "w02/slides.html#whatever-you-do-dont-be-bored",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "“Whatever You Do… Don’t Be Bored”",
    "text": "“Whatever You Do… Don’t Be Bored”\n\nClip from Richard Linklater’s Waking Life"
  },
  {
    "objectID": "w02/slides.html#three-component-parts-of-machine-learning",
    "href": "w02/slides.html#three-component-parts-of-machine-learning",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Three Component Parts of Machine Learning",
    "text": "Three Component Parts of Machine Learning\n\nA cool algorithm 😎😍\n[Possibly benign but possibly biased] Training data ❓🧐\nExploitation of below-minimum-wage human labor 😞🤐 (Dube et al. 2020, like and subscribe yall, get those ❤️s goin)"
  },
  {
    "objectID": "w02/slides.html#a-cool-algorithm",
    "href": "w02/slides.html#a-cool-algorithm",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "A Cool Algorithm 😎😍",
    "text": "A Cool Algorithm 😎😍"
  },
  {
    "objectID": "w02/slides.html#training-data-with-acknowledged-bias",
    "href": "w02/slides.html#training-data-with-acknowledged-bias",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Training Data With Acknowledged Bias",
    "text": "Training Data With Acknowledged Bias\n\nOne potentially fruitful approach to fairness: since we can’t eliminate it, bring it out into the open and study it!\n\nThis can, at very least, help us brainstorm how we might “correct” for it (next slides!)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Gendered Innovations in Science, Health & Medicine, Engineering, and Environment"
  },
  {
    "objectID": "w02/slides.html#word-embeddings",
    "href": "w02/slides.html#word-embeddings",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Word Embeddings",
    "text": "Word Embeddings\n\nBolukbasi et al. (2016)\nNotice how the \\(x\\)-axis has been selected by the researcher specifically to draw out (one) gendered dimension of language!\n\n\\(\\overrightarrow{\\texttt{she}}\\) mapped to \\(\\langle -1,0\\rangle\\), \\(\\overrightarrow{\\texttt{he}}\\) mapped to \\(\\langle 1,0 \\rangle\\), others projected onto this dimension"
  },
  {
    "objectID": "w02/slides.html#removing-vs.-studying-biases",
    "href": "w02/slides.html#removing-vs.-studying-biases",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Removing vs. Studying Biases",
    "text": "Removing vs. Studying Biases\n\n\n\n\n\n\n\n\n\nFrom Kozlowski, Taddy, and Evans (2019)\n\n\n\n\n\n\n\nWordBias: An Interactive Tool for Discovering Intersectional Biases Encoded in Word Embeddings"
  },
  {
    "objectID": "w02/slides.html#categories-of-fairness-criteria",
    "href": "w02/slides.html#categories-of-fairness-criteria",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Categories of Fairness Criteria",
    "text": "Categories of Fairness Criteria\n\nRoughly, approaches to fairness/bias in AI can be categorized as follows:\n\n\nFairness\n\n\n\n\n\n\nContext-Free\n\n\nSingle-Threshold Fairness\nEqual Prediction\nEqual Decision\n\n\n\n\n\n\n\n\n\nContext-Sensitive\n\n\nFairness via Similarity Metric(s)\nCausal Definitions\n\n\n\n\n\n\n[Week 3] Context-Free Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of ML (you already know much of it, given DSAN 5000!)\nBut easy-to-grasp notion \\(\\neq\\) “good” notion!\nYour job: push yourself to (a) consider what is getting left out of the context-free definitions, and (b) the loopholes that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”"
  },
  {
    "objectID": "w02/slides.html#laws-often-perfectly-technically-fair-context-free-fairness",
    "href": "w02/slides.html#laws-often-perfectly-technically-fair-context-free-fairness",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Laws: Often Perfectly “Technically Fair” (Context-Free Fairness)",
    "text": "Laws: Often Perfectly “Technically Fair” (Context-Free Fairness)\n\nAh, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!\n(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)\n\nAnatole France, Le Lys Rouge (France 1894)"
  },
  {
    "objectID": "w02/slides.html#context-sensitive-fairness",
    "href": "w02/slides.html#context-sensitive-fairness",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Context-Sensitive Fairness… 🧐",
    "text": "Context-Sensitive Fairness… 🧐\n\n\n\n\n\nDecisions at Individual Level (Micro)\n\n\n\n\n\n\n\\(\\leadsto\\)\n\nEmergent Properties (Macro)\n\n\n\n\n\n\n\n\nFigure 4: Figures from Ingold and Soper (2016), “Amazon Doesn’t Consider the Race of its Customers. Should It?”"
  },
  {
    "objectID": "w02/slides.html#enables-inverse-fairness",
    "href": "w02/slides.html#enables-inverse-fairness",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "…Enables INVERSE Fairness 🤯",
    "text": "…Enables INVERSE Fairness 🤯\n\n\n\n\n\n\n\n\nFigure 5: From Kasy and Abebe (2021), “Fairness, Equality, and Power in Algorithmic Decision-Making”\n\n\n\n\n\n\n\n\n\n\nFigure 6: From (bjorkegren_machine_2022?), “(Machine) Learning What Policymakers Value”"
  },
  {
    "objectID": "w02/slides.html#unraveling-history",
    "href": "w02/slides.html#unraveling-history",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Unraveling History",
    "text": "Unraveling History\n(Someday I will do something with this)\n\n\n\nIn the long evenings in West Beirut, there was time enough to consider where the core of the tragedy lay. In the age of Assyrians, the Empire of Rome, in the 1860s perhaps? In the French Mandate? In Auschwitz? In Palestine? In the rusting front-door keys now buried deep in the rubble of Shatila? In the 1978 Israeli invasion? In the 1982 invasion? Was there a point where one could have said: Stop, beyond this point there is no future? Did I witness the point of no return in 1976? That 12-year-old on the broken office chair in the ruins of the Beirut front line? Now he was, in his mid-twenties (if he was still alive), a gunboy no more. A gunman, no doubt… (Fisk 1990)\n\n\n\n\n\nImage Source"
  },
  {
    "objectID": "w02/slides.html#context-sensitive-fairness-leftrightarrow-unraveling-history-1",
    "href": "w02/slides.html#context-sensitive-fairness-leftrightarrow-unraveling-history-1",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Context-Sensitive Fairness \\(\\Leftrightarrow\\) Unraveling History",
    "text": "Context-Sensitive Fairness \\(\\Leftrightarrow\\) Unraveling History\n(Reminder: Miracle of Immaculate Genocide)\n\n\n\n\n\nFrom Cheng (2018) The Art of Logic [plz watch, if you can!]"
  },
  {
    "objectID": "w02/slides.html#references",
    "href": "w02/slides.html#references",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "References",
    "text": "References\n\n\nAmes, Mark. 2014. “The Techtopus: How Silicon Valley’s Most Celebrated CEOs Conspired to Drive down 100,000 Tech Engineers’ Wages,” January. http://web.archive.org/web/20200920042121/https://pando.com/2014/01/23/the-techtopus-how-silicon-valleys-most-celebrated-ceos-conspired-to-drive-down-100000-tech-engineers-wages/.\n\n\nAyyub, Rami. 2019. “App Aims to Help Palestinian Drivers Find Their Way Around Checkpoints.” The Times of Israel, August. https://www.timesofisrael.com/app-aims-to-help-palestinian-drivers-find-their-way-around-checkpoints/.\n\n\nBishop, Marlon, and Tatiana Fernandez. 2017. “80 Years On, Dominicans And Haitians Revisit Painful Memories Of Parsley Massacre.” NPR, October. https://www.npr.org/sections/parallels/2017/10/07/555871670/80-years-on-dominicans-and-haitians-revisit-painful-memories-of-parsley-massacre.\n\n\nBolukbasi, Tolga, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai. 2016. “Man Is to Computer Programmer as Woman Is to Homemaker? Debiasing Word Embeddings.” In Advances in Neural Information Processing Systems. Vol. 29. Curran Associates, Inc. https://proceedings.neurips.cc/paper_files/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html.\n\n\nBourdieu, Pierre. 2010. Sociology Is a Martial Art: Political Writings by Pierre Bourdieu. New Press.\n\n\nCheng, Eugenia. 2018. The Art of Logic in an Illogical World. Basic Books.\n\n\nChurchill, Ward. 2003. On the Justice of Roosting Chickens: Reflections on the Consequences of U.S. Imperial Arrogance and Criminality. AK Press.\n\n\nD’Ignazio, Catherine, and Lauren F. Klein. 2020. Data Feminism. MIT Press.\n\n\nDrèze, Jean, and Amartya Sen. 1991. “China and India.” In Hunger and Public Action, 0. Oxford University Press. https://doi.org/10.1093/0198283652.003.0011.\n\n\nDube, Arindrajit, Jeff Jacobs, Suresh Naidu, and Siddharth Suri. 2020. “Monopsony in Online Labor Markets.” American Economic Review: Insights 2 (1): 33–46. https://doi.org/10.1257/aeri.20180150.\n\n\nFacia.ai. 2023. “Facial Recognition Helps Vendors in Healthcare.” Facia.ai. https://facia.ai/blog/facial-recognition-healthcare/.\n\n\nFisk, Robert. 1990. Pity the Nation: Lebanon at War. OUP Oxford.\n\n\n———. 2005. The Great War for Civilisation: The Conquest of the Middle East. Knopf Doubleday Publishing Group.\n\n\nFrance, Anatole. 1894. Le Lys Rouge (The Red Lily). G. Wells.\n\n\nIngold, David, and Spencer Soper. 2016. “Amazon Doesn’t Consider the Race of Its Customers. Should It?” Bloomberg, April. http://www.bloomberg.com/graphics/2016-amazon-same-day/.\n\n\nKalyvas, Stathis N. 2006. The Logic of Violence in Civil War. Cambridge University Press.\n\n\nKasy, Maximilian, and Rediet Abebe. 2021. “Fairness, Equality, and Power in Algorithmic Decision-Making.” In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 576–86. FAccT ’21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445919.\n\n\nKozlowski, Austin C., Matt Taddy, and James A. Evans. 2019. “The Geometry of Culture: Analyzing the Meanings of Class Through Word Embeddings.” American Sociological Review 84 (5): 905–49. https://doi.org/10.1177/0003122419877135.\n\n\nLabov, William. 2013. The Language of Life and Death: The Transformation of Experience in Oral Narrative. Cambridge University Press.\n\n\nLerman, Amy E., and Vesla M. Weaver. 2014. Arresting Citizenship: The Democratic Consequences of American Crime Control. University of Chicago Press.\n\n\nLyall, Jason. 2020. Divided Armies: Inequality and Battlefield Performance in Modern War. Princeton University Press.\n\n\nMarx, Karl. 1852. The Eighteenth Brumaire of Louis Bonaparte. Die Revolution.\n\n\nMcNeil, Sam. 2022. “Israel Deploys Remote-Controlled Robotic Guns in West Bank.” AP News, November. https://apnews.com/article/technology-business-israel-robotics-west-bank-cfc889a120cbf59356f5044eb43d5b88.\n\n\nMitchell, Shira, Eric Potash, Solon Barocas, Alexander D’Amour, and Kristian Lum. 2021. “Algorithmic Fairness: Choices, Assumptions, and Definitions.” Annual Review of Statistics and Its Application 8 (1): 141–63. https://doi.org/10.1146/annurev-statistics-042720-125902.\n\n\nMorozov, Evgeny. 2015. “Socialize the Data Centres!” New Left Review, no. 91 (February): 45–66.\n\n\nOuz. 2023. “Google Pixel 8 Face Unlock Vulnerability Discovered, Allowing Others to Unlock Devices.” Gizmochina. https://www.gizmochina.com/2023/10/16/google-pixel-8-face-unlock/.\n\n\nSandburg, Carl. 1926. Selected Poems. Houghton Mifflin Harcourt.\n\n\nSchiebinger, Londa, Ineke Klinga, Hee Young Paik, Inés Sánchez de Madariaga, Martina Schraudner, and Marcia Stefanick. 2020. “Machine Translation: Gendered Innovations.” http://genderedinnovations.stanford.edu/case-studies/nlp.html#tabs-2.\n\n\nSteinbeck, John. 1939. The Grapes of Wrath. Penguin.\n\n\nStiglitz, Joseph E., Amartya Sen, and Jean-Paul Fitoussi. 2010. Mismeasuring Our Lives: Why GDP Doesn’t Add Up. The New Press.\n\n\nWan, Yixin, George Pu, Jiao Sun, Aparna Garimella, Kai-Wei Chang, and Nanyun Peng. 2023. “‘Kelly Is a Warm Person, Joseph Is a Role Model’: Gender Biases in LLM-Generated Reference Letters.” In EMNLP 2023, 3730–48. Singapore: ACL. https://doi.org/10.18653/v1/2023.findings-emnlp.243.\n\n\nWang, Yilun, and Michal Kosinski. 2018. “Deep Neural Networks Are More Accurate Than Humans at Detecting Sexual Orientation from Facial Images.” Journal of Personality and Social Psychology 114 (2): 246–57. https://doi.org/10.1037/pspa0000098.\n\n\nWellcome Collection. 1890. “Composite Photographs: \"The Jewish Type\".” https://wellcomecollection.org/works/ngq29vyw."
  },
  {
    "objectID": "w02/slides.html#appendix-bonus-showing-up-early-material",
    "href": "w02/slides.html#appendix-bonus-showing-up-early-material",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Appendix / Bonus Showing-Up-Early Material",
    "text": "Appendix / Bonus Showing-Up-Early Material\n(Jeff’s Sanctimonious Unc Corner)\n\n\n\nBeing Bayesian \\(\\neq\\) Not Taking Sides:\n\nRather than implying moral relativism, this position posits the formulation of moral judgments as outcomes rather than preconditions of research. (Kalyvas 2006)\n\nAxiom/Antecedent: The life of a single human is worth a million times more than the property of the richest man on earth\nEvidence: (History of social movements)\nConsequent: “On the side of poor people getting organized, on the side of choice where it is in short supply, on the side of those the system doesn’t authorize, LGBT, we are on the side of pride”\n\n\n\n\n\nB. Dolan, Which Side Are You On?"
  },
  {
    "objectID": "w02/index.html",
    "href": "w02/index.html",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#where-we-left-off-ethical-issues-in-data-science",
    "href": "w02/index.html#where-we-left-off-ethical-issues-in-data-science",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Where We Left Off: Ethical Issues in Data Science",
    "text": "Where We Left Off: Ethical Issues in Data Science\n\nData Science for Who? ✅\nIndividuals \\(\\leftrightarrow\\) Structures 👀\nOperationalization\nFair Comparisons\nImplementation",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#structural-domination-the-grapes-of-wrath",
    "href": "w02/index.html#structural-domination-the-grapes-of-wrath",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Structural Domination: The Grapes of Wrath",
    "text": "Structural Domination: The Grapes of Wrath\n\nBut… I built it with my hands! Straightened old nails to put the sheathing on!\nIt’s not me. There’s nothing I can do. I’ll lose my job if I don’t do it. And look—suppose you kill me? They’ll hang you, and long before you’re hung there’ll be another guy here, he’ll bump the house down. You’re not killing the right guy.\nThat’s so… Who gave you orders? I’ll go after him. He’s the one to kill.\nYou’re wrong. He got his orders from the bank. ‘Clear those people out or it’s your job.’\nWell, there’s a president of the bank. A board of directors. I’ll fill up my rifle, head to the bank.\nThe bank gets orders from the East. ‘Make the land show profit or we’ll close you up.’ We’re sorry. It’s not us. It’s the monster. The bank isn’t like a man.\nYes, but the bank is only made of men!\nNo, you’re wrong there—quite wrong. The bank is something else than men. It happens nowadays that every man in a bank hates what the bank does, and yet the bank does it. The bank is something more than men, I tell you.\nI got to figure… We all got to figure. There’s some way to stop this. There’s got to be some way to stop this. It’s not like lightning or earthquakes. We’ve got a bad thing made by men, and by God, isn’t that something we should be able to change? (Steinbeck 1939)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#ontology-individuals-and-structures",
    "href": "w02/index.html#ontology-individuals-and-structures",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Ontology: Individuals and Structures",
    "text": "Ontology: Individuals and Structures\n\n\n\nNo longer preoccupied with crude ‘conspiracy theories’, [progressives] attribute all things negative to handy abstractions: ‘capitalism’, ‘the state’, ‘structural oppression’, ‘hierarchy’. Hence they have been able to conjure what might be termed the ‘miracle of immaculate genocide’, a form of genocide, that is, in which there are no actual perpetrators, no one who might ‘really’ be deemed culpable (Churchill 2003)\nWe make our own history, but we do not make it as we please; we do not make it under self-selected circumstances, but under circumstances existing already, given and transmitted from the past. The tradition of all dead generations weighs like a nightmare on the brains of the living. (Marx 1852)\n\n\n\n\n\n\nSandburg (1926)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#operationalization",
    "href": "w02/index.html#operationalization",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Operationalization 👀",
    "text": "Operationalization 👀\n\n\n\nThink of claims commonly made based on “data”:\n\nMarkets create economic prosperity\nA glass of wine in the evening prevents cancer\nPolicing makes communities safer\n\nHow exactly are “prosperity”, “preventing cancer”, “policing”, “community safety” being measured? Who is measuring? Mechanisms for feedback \\(\\leadsto\\) change?\n\n\n\n\n\n\n\n\nStiglitz, Sen, and Fitoussi (2010)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#what-is-being-compared",
    "href": "w02/index.html#what-is-being-compared",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "What Is Being Compared? 👀",
    "text": "What Is Being Compared? 👀\n\n\n\n\n\n\n\n\nApples\nOranges\nPears\n\n\n\n\nPolities w/250-500M people (US ~335M, UP ~250M, EU ~450M)\nPolities w/11M people in the Caribbean (Cuba, Haiti, Dominican Republic)\nPolities w/over 1 billion people (China ~1.4B, India ~1.4B, Africa ~1.4B, ⬆️+⬇️ America ~1B)\n\n\nDemocracies (US)\nDemocracies til they democratically elected someone US didn’t like (Iran, Guatemala, Chile)\nNon-democracies which brutally repress democratic movements w/US arms (Saudi Arabia)\n\n\nColonizing polities (US)\nPolities colonized by them (Philippines)\nNon-colonized polities (Ethiopia, Thailand)\n\n\nPolities w/infrastructure built up over 250+ yrs via slave labor (US 🇺🇸)\nPolities populated by former slaves (Liberia 🇱🇷)\nPolities that paid reparations to descendants of [certain] enslaved groups (Germany)\n\n\nPolities independent since 1776 (US)\nPolities independent since 1990 (Namibia)\nNon-self-governing polities (Puerto Rico, Palestine, New Caledonia)\n\n\nPolities enforcing a 60 yr embargo on Cuba (US)\nPolities with a 60 yr embargo imposed on them by US (Cuba)\nPolities without a 60 yr embargo imposed on them by US (…)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#how-are-they-being-compared",
    "href": "w02/index.html#how-are-they-being-compared",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "How Are They Being Compared?",
    "text": "How Are They Being Compared?\n\nWhat metric? Over what timespan?\nWhat unit of obs \\(\\leadsto\\) agg function \\(\\leadsto\\) level of aggregation?\n\n\n\n\nDrèze and Sen (1991)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#there-is-still-hope-i-promise",
    "href": "w02/index.html#there-is-still-hope-i-promise",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "…There is Still Hope! I Promise!",
    "text": "…There is Still Hope! I Promise!\n\nFair Comparison through Statistical Matching:\nLyall (2020): “Treating certain ethnic groups as second-class citizens […] leads victimized soldiers to subvert military authorities once war begins. The higher an army’s inequality, the greater its rates of desertion, side-switching, and casualties”\n\n\nMatching constructs pairs of belligerents that are similar across a wide range of traits thought to dictate battlefield performance but that vary in levels of prewar inequality. The more similar the belligerents, the better our estimate of inequality’s effects, as all other traits are shared and thus cannot explain observed differences in performance, helping assess how battlefield performance would have improved (declined) if the belligerent had a lower (higher) level of prewar inequality.\nSince [non-matched] cases are dropped […] selected cases are more representative of average belligerents/wars than outliers with few or no matches, [providing] surer ground for testing generalizability of the book’s claims than focusing solely on canonical but unrepresentative usual suspects (Germany, the United States, Israel)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#does-inequality-cause-poor-military-performance",
    "href": "w02/index.html#does-inequality-cause-poor-military-performance",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Does Inequality Cause Poor Military Performance?",
    "text": "Does Inequality Cause Poor Military Performance?\n\n\n\n\n\n\n\n\nCovariates\nSultanate of Morocco Spanish-Moroccan War, 1859-60\nKhanate of Kokand War with Russia, 1864-65\n\n\n\n\n\\(X\\): Military Inequality\nLow (0.01)\nExtreme (0.70)\n\n\n\\(\\mathbf{Z}\\): Matched Covariates:\n\n\n\n\nInitial relative power\n66%\n66%\n\n\nTotal fielded force\n55,000\n50,000\n\n\nRegime type\nAbsolutist Monarchy (−6)\nAbsolute Monarchy (−7)\n\n\nDistance from capital\n208km\n265km\n\n\nStanding army\nYes\nYes\n\n\nComposite military\nYes\nYes\n\n\nInitiator\nNo\nNo\n\n\nJoiner\nNo\nNo\n\n\nDemocratic opponent\nNo\nNo\n\n\nGreat Power\nNo\nNo\n\n\nCivil war\nNo\nNo\n\n\nCombined arms\nYes\nYes\n\n\nDoctrine\nOffensive\nOffensive\n\n\nSuperior weapons\nNo\nNo\n\n\nFortifications\nYes\nYes\n\n\nForeign advisors\nYes\nYes\n\n\nTerrain\nSemiarid coastal plain\nSemiarid grassland plain\n\n\nTopography\nRugged\nRugged\n\n\nWar duration\n126 days\n378 days\n\n\nRecent war history w/opp\nYes\nYes\n\n\nFacing colonizer\nYes\nYes\n\n\nIdentity dimension\nSunni Islam/Christian\nSunni Islam/Christian\n\n\nNew leader\nYes\nYes\n\n\nPopulation\n8–8.5 million\n5–6 million\n\n\nEthnoling fractionalization (ELF)\nHigh\nHigh\n\n\nCiv-mil relations\nRuler as commander\nRuler as commander\n\n\n\\(Y\\): Battlefield Performance:\n\n\n\n\nLoss-exchange ratio\n0.43\n0.02\n\n\nMass desertion\nNo\nYes\n\n\nMass defection\nNo\nNo\n\n\nFratricidal violence\nNo\nYes",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#no-crumbs",
    "href": "w02/index.html#no-crumbs",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "No Crumbs",
    "text": "No Crumbs\n(I have no dog in this fight, I’m not trying to improve military performance of an army, but got damn)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#implementation",
    "href": "w02/index.html#implementation",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Implementation 👀",
    "text": "Implementation 👀\n\n\n\n\n\n\n\n\n\nFrom D’Ignazio and Klein (2020), Ch. 6 (see also)\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Lerman and Weaver (2014) (see also)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#ethics-of-eliciting-sensitive-linguistic-data",
    "href": "w02/index.html#ethics-of-eliciting-sensitive-linguistic-data",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Ethics of Eliciting Sensitive Linguistic Data",
    "text": "Ethics of Eliciting Sensitive Linguistic Data\n\n\n\n\n\n\n\n\n\nFrom Labov (2013), pg. 4\n\n\n\n\n\n\n\nFrom “80 Years On, Dominicans And Haitians Revisit Painful Memories Of Parsley Massacre”, NPR Parallels, 7 Oct 2017 (Bishop and Fernandez 2017)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#privacy",
    "href": "w02/index.html#privacy",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Privacy",
    "text": "Privacy\n\n\n\n\n\nFig 1.3: “The Accuracy-Privacy Loss Tradeoff”, from US Census Bureau (2021), Disclosure Avoidance for the 2020 Census\n\n\n\n\n\n\n“Privacy-Loss Budget (\\(\\varepsilon\\)) Acts as a Dial on Level of Noise”, ibid.\n\n\n\n\n\n\n\nSeurat, A Sunday Afternoon on the Island of La Grande Jatte, Wikimedia Commons",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#facial-recognition-algorithms",
    "href": "w02/index.html#facial-recognition-algorithms",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Facial Recognition Algorithms",
    "text": "Facial Recognition Algorithms\n(aka AI eugenics… but I didn’t say that out loud)\n\n\n\n\n\n\n\n\n\nFacia.ai (2023)\n\n\n\n\n\n\n\nWellcome Collection (1890)\n\n\n\n\n\n\n\n\n\nOuz (2023)\n\n\n\n\n\n\n\nWang and Kosinski (2018)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#llms-encode-existing-biases",
    "href": "w02/index.html#llms-encode-existing-biases",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "LLMs Encode Existing Biases",
    "text": "LLMs Encode Existing Biases\n\n\n\n\n\nFrom Schiebinger et al. (2020)\n\n\n\n\n\n\nFrom Google Translate (22 Jan 2025)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt\nResult\n\n\n\n\n“Generate a reference letter for Kelly, a 22 year old female student at UCLA”\n“She is an engaged participant in group projects, demonstrating exceptional teamwork and collaboration skills […] a well-liked member of our community.”\n\n\n“Generate a reference letter for Joseph, a 22 year old male student at UCLA”\nHis enthusiasm and dedication have had a positive impact on those around him, making him a natural leader and role model for his peers.”\n\n\n\n\n\nFigure 1: Wan et al. (2023), “Gender Biases in LLM-Generated Reference Letters”",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#what-is-to-be-done",
    "href": "w02/index.html#what-is-to-be-done",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "What Is To Be Done?",
    "text": "What Is To Be Done?\n \n\n\n\nWhen to retain biases…\n\n\n\n…and when to debias\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Schiebinger et al. (2020)\n\n\n\n\n\n\n\n\n\n\nFigure 3: From DeepLearning.AI’s Deep Learning course",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#military-and-police-applications-of-ai",
    "href": "w02/index.html#military-and-police-applications-of-ai",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Military and Police Applications of AI",
    "text": "Military and Police Applications of AI\n\n\n\n\n\n\n\n\n\nAyyub (2019)\n\n\n\n\n\n\n\nMcNeil (2022)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#your-job-policy-whitepaper",
    "href": "w02/index.html#your-job-policy-whitepaper",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Your Job: Policy Whitepaper",
    "text": "Your Job: Policy Whitepaper\n\nSo is technology/data science/machine learning…\n\n“Bad” in and of itself?\n“Good” in and of itself? or\nA tool that can be used to both “good” and “bad” ends?\n\n“The master’s tools will never dismantle the master’s house”… Who decided that the master owns the tools?\nHow can we curtail some uses and/or encourage others?\nIf only we had some sort of… institution… for governing its use in society… some sort of… govern… ment?",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#from-week-7-onwards-you-work-at-a-think-tank",
    "href": "w02/index.html#from-week-7-onwards-you-work-at-a-think-tank",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "From Week 7 Onwards, You Work At A Think Tank",
    "text": "From Week 7 Onwards, You Work At A Think Tank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMorozov (2015)\n\n\n\n\n\n\n\nFrom Ames (2014)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#whatever-you-do-dont-be-bored",
    "href": "w02/index.html#whatever-you-do-dont-be-bored",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "“Whatever You Do… Don’t Be Bored”",
    "text": "“Whatever You Do… Don’t Be Bored”\n\n\n\nClip from Richard Linklater’s Waking Life",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#three-component-parts-of-machine-learning",
    "href": "w02/index.html#three-component-parts-of-machine-learning",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Three Component Parts of Machine Learning",
    "text": "Three Component Parts of Machine Learning\n\nA cool algorithm 😎😍\n[Possibly benign but possibly biased] Training data ❓🧐\nExploitation of below-minimum-wage human labor 😞🤐 (Dube et al. 2020, like and subscribe yall, get those ❤️s goin)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#a-cool-algorithm",
    "href": "w02/index.html#a-cool-algorithm",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "A Cool Algorithm 😎😍",
    "text": "A Cool Algorithm 😎😍",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#training-data-with-acknowledged-bias",
    "href": "w02/index.html#training-data-with-acknowledged-bias",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Training Data With Acknowledged Bias",
    "text": "Training Data With Acknowledged Bias\n\nOne potentially fruitful approach to fairness: since we can’t eliminate it, bring it out into the open and study it!\n\nThis can, at very least, help us brainstorm how we might “correct” for it (next slides!)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Gendered Innovations in Science, Health & Medicine, Engineering, and Environment",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#word-embeddings",
    "href": "w02/index.html#word-embeddings",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Word Embeddings",
    "text": "Word Embeddings\n\n\n\nBolukbasi et al. (2016)\n\n\n\nNotice how the \\(x\\)-axis has been selected by the researcher specifically to draw out (one) gendered dimension of language!\n\n\\(\\overrightarrow{\\texttt{she}}\\) mapped to \\(\\langle -1,0\\rangle\\), \\(\\overrightarrow{\\texttt{he}}\\) mapped to \\(\\langle 1,0 \\rangle\\), others projected onto this dimension",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#removing-vs.-studying-biases",
    "href": "w02/index.html#removing-vs.-studying-biases",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Removing vs. Studying Biases",
    "text": "Removing vs. Studying Biases\n\n\n\n\n\n\n\n\n\nFrom Kozlowski, Taddy, and Evans (2019)\n\n\n\n\n\n\n\nWordBias: An Interactive Tool for Discovering Intersectional Biases Encoded in Word Embeddings",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#categories-of-fairness-criteria",
    "href": "w02/index.html#categories-of-fairness-criteria",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Categories of Fairness Criteria",
    "text": "Categories of Fairness Criteria\n\nRoughly, approaches to fairness/bias in AI can be categorized as follows:\n\n\nFairness\n\n\n\n\n\n\nContext-Free\n\n\nSingle-Threshold Fairness\nEqual Prediction\nEqual Decision\n\n\n\n\n\n\n\n\n\nContext-Sensitive\n\n\nFairness via Similarity Metric(s)\nCausal Definitions\n\n\n\n\n\n\n\n[Week 3] Context-Free Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of ML (you already know much of it, given DSAN 5000!)\nBut easy-to-grasp notion \\(\\neq\\) “good” notion!\nYour job: push yourself to (a) consider what is getting left out of the context-free definitions, and (b) the loopholes that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#laws-often-perfectly-technically-fair-context-free-fairness",
    "href": "w02/index.html#laws-often-perfectly-technically-fair-context-free-fairness",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Laws: Often Perfectly “Technically Fair” (Context-Free Fairness)",
    "text": "Laws: Often Perfectly “Technically Fair” (Context-Free Fairness)\n\nAh, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!\n(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)\n\nAnatole France, Le Lys Rouge (France 1894)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#context-sensitive-fairness",
    "href": "w02/index.html#context-sensitive-fairness",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Context-Sensitive Fairness… 🧐",
    "text": "Context-Sensitive Fairness… 🧐\n\n\n\n\n\nDecisions at Individual Level (Micro)\n\n\n\n\n\n\n\\(\\leadsto\\)\n\nEmergent Properties (Macro)\n\n\n\n\n\n\n\n\n\nFigure 4: Figures from Ingold and Soper (2016), “Amazon Doesn’t Consider the Race of its Customers. Should It?”",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#enables-inverse-fairness",
    "href": "w02/index.html#enables-inverse-fairness",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "…Enables INVERSE Fairness 🤯",
    "text": "…Enables INVERSE Fairness 🤯\n\n\n\n\n\n\n\n\nFigure 5: From Kasy and Abebe (2021), “Fairness, Equality, and Power in Algorithmic Decision-Making”\n\n\n\n\n\n\n\n\n\n\nFigure 6: From (bjorkegren_machine_2022?), “(Machine) Learning What Policymakers Value”",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#unraveling-history",
    "href": "w02/index.html#unraveling-history",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Unraveling History",
    "text": "Unraveling History\n(Someday I will do something with this)\n\n\n\nIn the long evenings in West Beirut, there was time enough to consider where the core of the tragedy lay. In the age of Assyrians, the Empire of Rome, in the 1860s perhaps? In the French Mandate? In Auschwitz? In Palestine? In the rusting front-door keys now buried deep in the rubble of Shatila? In the 1978 Israeli invasion? In the 1982 invasion? Was there a point where one could have said: Stop, beyond this point there is no future? Did I witness the point of no return in 1976? That 12-year-old on the broken office chair in the ruins of the Beirut front line? Now he was, in his mid-twenties (if he was still alive), a gunboy no more. A gunman, no doubt… (Fisk 1990)\n\n\n\n\n\nImage Source",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#context-sensitive-fairness-leftrightarrow-unraveling-history-1",
    "href": "w02/index.html#context-sensitive-fairness-leftrightarrow-unraveling-history-1",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Context-Sensitive Fairness \\(\\Leftrightarrow\\) Unraveling History",
    "text": "Context-Sensitive Fairness \\(\\Leftrightarrow\\) Unraveling History\n(Reminder: Miracle of Immaculate Genocide)\n\n\n\n\n\nFrom Cheng (2018) The Art of Logic [plz watch, if you can!]",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#references",
    "href": "w02/index.html#references",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "References",
    "text": "References\n\n\nAmes, Mark. 2014. “The Techtopus: How Silicon Valley’s Most Celebrated CEOs Conspired to Drive down 100,000 Tech Engineers’ Wages,” January. http://web.archive.org/web/20200920042121/https://pando.com/2014/01/23/the-techtopus-how-silicon-valleys-most-celebrated-ceos-conspired-to-drive-down-100000-tech-engineers-wages/.\n\n\nAyyub, Rami. 2019. “App Aims to Help Palestinian Drivers Find Their Way Around Checkpoints.” The Times of Israel, August. https://www.timesofisrael.com/app-aims-to-help-palestinian-drivers-find-their-way-around-checkpoints/.\n\n\nBishop, Marlon, and Tatiana Fernandez. 2017. “80 Years On, Dominicans And Haitians Revisit Painful Memories Of Parsley Massacre.” NPR, October. https://www.npr.org/sections/parallels/2017/10/07/555871670/80-years-on-dominicans-and-haitians-revisit-painful-memories-of-parsley-massacre.\n\n\nBolukbasi, Tolga, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai. 2016. “Man Is to Computer Programmer as Woman Is to Homemaker? Debiasing Word Embeddings.” In Advances in Neural Information Processing Systems. Vol. 29. Curran Associates, Inc. https://proceedings.neurips.cc/paper_files/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html.\n\n\nBourdieu, Pierre. 2010. Sociology Is a Martial Art: Political Writings by Pierre Bourdieu. New Press.\n\n\nCheng, Eugenia. 2018. The Art of Logic in an Illogical World. Basic Books.\n\n\nChurchill, Ward. 2003. On the Justice of Roosting Chickens: Reflections on the Consequences of U.S. Imperial Arrogance and Criminality. AK Press.\n\n\nD’Ignazio, Catherine, and Lauren F. Klein. 2020. Data Feminism. MIT Press.\n\n\nDrèze, Jean, and Amartya Sen. 1991. “China and India.” In Hunger and Public Action, 0. Oxford University Press. https://doi.org/10.1093/0198283652.003.0011.\n\n\nDube, Arindrajit, Jeff Jacobs, Suresh Naidu, and Siddharth Suri. 2020. “Monopsony in Online Labor Markets.” American Economic Review: Insights 2 (1): 33–46. https://doi.org/10.1257/aeri.20180150.\n\n\nFacia.ai. 2023. “Facial Recognition Helps Vendors in Healthcare.” Facia.ai. https://facia.ai/blog/facial-recognition-healthcare/.\n\n\nFisk, Robert. 1990. Pity the Nation: Lebanon at War. OUP Oxford.\n\n\n———. 2005. The Great War for Civilisation: The Conquest of the Middle East. Knopf Doubleday Publishing Group.\n\n\nFrance, Anatole. 1894. Le Lys Rouge (The Red Lily). G. Wells.\n\n\nIngold, David, and Spencer Soper. 2016. “Amazon Doesn’t Consider the Race of Its Customers. Should It?” Bloomberg, April. http://www.bloomberg.com/graphics/2016-amazon-same-day/.\n\n\nKalyvas, Stathis N. 2006. The Logic of Violence in Civil War. Cambridge University Press.\n\n\nKasy, Maximilian, and Rediet Abebe. 2021. “Fairness, Equality, and Power in Algorithmic Decision-Making.” In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 576–86. FAccT ’21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445919.\n\n\nKozlowski, Austin C., Matt Taddy, and James A. Evans. 2019. “The Geometry of Culture: Analyzing the Meanings of Class Through Word Embeddings.” American Sociological Review 84 (5): 905–49. https://doi.org/10.1177/0003122419877135.\n\n\nLabov, William. 2013. The Language of Life and Death: The Transformation of Experience in Oral Narrative. Cambridge University Press.\n\n\nLerman, Amy E., and Vesla M. Weaver. 2014. Arresting Citizenship: The Democratic Consequences of American Crime Control. University of Chicago Press.\n\n\nLyall, Jason. 2020. Divided Armies: Inequality and Battlefield Performance in Modern War. Princeton University Press.\n\n\nMarx, Karl. 1852. The Eighteenth Brumaire of Louis Bonaparte. Die Revolution.\n\n\nMcNeil, Sam. 2022. “Israel Deploys Remote-Controlled Robotic Guns in West Bank.” AP News, November. https://apnews.com/article/technology-business-israel-robotics-west-bank-cfc889a120cbf59356f5044eb43d5b88.\n\n\nMitchell, Shira, Eric Potash, Solon Barocas, Alexander D’Amour, and Kristian Lum. 2021. “Algorithmic Fairness: Choices, Assumptions, and Definitions.” Annual Review of Statistics and Its Application 8 (1): 141–63. https://doi.org/10.1146/annurev-statistics-042720-125902.\n\n\nMorozov, Evgeny. 2015. “Socialize the Data Centres!” New Left Review, no. 91 (February): 45–66.\n\n\nOuz. 2023. “Google Pixel 8 Face Unlock Vulnerability Discovered, Allowing Others to Unlock Devices.” Gizmochina. https://www.gizmochina.com/2023/10/16/google-pixel-8-face-unlock/.\n\n\nSandburg, Carl. 1926. Selected Poems. Houghton Mifflin Harcourt.\n\n\nSchiebinger, Londa, Ineke Klinga, Hee Young Paik, Inés Sánchez de Madariaga, Martina Schraudner, and Marcia Stefanick. 2020. “Machine Translation: Gendered Innovations.” http://genderedinnovations.stanford.edu/case-studies/nlp.html#tabs-2.\n\n\nSteinbeck, John. 1939. The Grapes of Wrath. Penguin.\n\n\nStiglitz, Joseph E., Amartya Sen, and Jean-Paul Fitoussi. 2010. Mismeasuring Our Lives: Why GDP Doesn’t Add Up. The New Press.\n\n\nWan, Yixin, George Pu, Jiao Sun, Aparna Garimella, Kai-Wei Chang, and Nanyun Peng. 2023. “‘Kelly Is a Warm Person, Joseph Is a Role Model’: Gender Biases in LLM-Generated Reference Letters.” In EMNLP 2023, 3730–48. Singapore: ACL. https://doi.org/10.18653/v1/2023.findings-emnlp.243.\n\n\nWang, Yilun, and Michal Kosinski. 2018. “Deep Neural Networks Are More Accurate Than Humans at Detecting Sexual Orientation from Facial Images.” Journal of Personality and Social Psychology 114 (2): 246–57. https://doi.org/10.1037/pspa0000098.\n\n\nWellcome Collection. 1890. “Composite Photographs: \"The Jewish Type\".” https://wellcomecollection.org/works/ngq29vyw.",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#appendix-bonus-showing-up-early-material",
    "href": "w02/index.html#appendix-bonus-showing-up-early-material",
    "title": "Week 2: Machine Learning, Training Data, and Biases",
    "section": "Appendix / Bonus Showing-Up-Early Material",
    "text": "Appendix / Bonus Showing-Up-Early Material\n(Jeff’s Sanctimonious Unc Corner)\n\n\n\nBeing Bayesian \\(\\neq\\) Not Taking Sides:\n\nRather than implying moral relativism, this position posits the formulation of moral judgments as outcomes rather than preconditions of research. (Kalyvas 2006)\n\nAxiom/Antecedent: The life of a single human is worth a million times more than the property of the richest man on earth\nEvidence: (History of social movements)\nConsequent: “On the side of poor people getting organized, on the side of choice where it is in short supply, on the side of those the system doesn’t authorize, LGBT, we are on the side of pride”\n\n\n\n\n\nB. Dolan, Which Side Are You On?",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignment Point Distributions",
    "section": "",
    "text": "Use the tabs below to view the point distributions for different assignments.\nThe distributions are imported from Google Sheets mainly for transparency: so that you can see exactly how totals are computed as a sum of the individual points allocated for each test!\n\nHW1HW2\n\n\n\n\n\n\n\n\n\npart\nqid\ntest_type\npoints\npart_total\n\n\n\n\n1\nQ1.1\npublic\n0\n12\n\n\n\nQ1.1\nhidden\n1\n\n\n\n\nQ1.2\npublic\n0\n\n\n\n\nQ1.2\nhidden\n1\n\n\n\n\nQ1.3\npublic\n0\n\n\n\n\nQ1.3\nhidden\n1\n\n\n\n\nQ1.4\npublic\n0\n\n\n\n\nQ1.4\nhidden\n1\n\n\n\n\nQ1.5\npublic\n0\n\n\n\n\nQ1.5\nhidden\n1\n\n\n\n\nQ1.6\npublic\n0\n\n\n\n\nQ1.6\nhidden\n1\n\n\n\n\nQ1.7\npublic\n0\n\n\n\n\nQ1.7\nhidden\n1\n\n\n\n\nQ1.8\npublic\n0\n\n\n\n\nQ1.8\nhidden\n1\n\n\n\n\nQ1.9\npublic\n0\n\n\n\n\nQ1.9\nhidden\n1\n\n\n\n\nQ1.10\npublic\n0\n\n\n\n\nQ1.10\nhidden\n1\n\n\n\n\nQ1.11\npublic\n0\n\n\n\n\nQ1.11\nhidden\n1\n\n\n\n\nQ1.12\npublic\n0\n\n\n\n\nQ1.12\nhidden\n1\n\n\n\n2\nQ2.1\npublic\n0\n7\n\n\n\nQ2.1\nhidden\n1\n\n\n\n\nQ2.2\npublic\n0\n\n\n\n\nQ2.2\nhidden\n1\n\n\n\n\nQ2.3\npublic\n0\n\n\n\n\nQ2.3\nhidden\n1\n\n\n\n\nQ2.4\npublic\n0\n\n\n\n\nQ2.4\nhidden\n1\n\n\n\n\nQ2.5\npublic\n0\n\n\n\n\nQ2.5\nhidden\n1\n\n\n\n\nQ2.6\npublic\n0\n\n\n\n\nQ2.6\nhidden\n2\n\n\n\n3\nQ3.1\npublic\n0\n5\n\n\n\nQ3.1\nhidden\n1\n\n\n\n\nQ3.2\npublic\n0\n\n\n\n\nQ3.2\nhidden\n1\n\n\n\n\nQ3.3a\npublic\n0\n\n\n\n\nQ3.3a\nhidden\n1\n\n\n\n\nQ3.3b\npublic\n0\n\n\n\n\nQ3.3b\nhidden\n1\n\n\n\n\nQ3.3c\npublic\n0\n\n\n\n\nQ3.3c\nhidden\n1\n\n\n\n4.1\nQ4.1.1\npublic\n1\n13\n\n\n\nQ4.1.1\nhidden\n2\n\n\n\n\nQ4.1.2\npublic\n1\n\n\n\n\nQ4.1.2\nhidden\n2\n\n\n\n\nQ4.1.3\npublic\n1\n\n\n\n\nQ4.1.3\nhidden\n1\n\n\n\n\nQ4.1.4\npublic\n1\n\n\n\n\nQ4.1.4\nhidden\n2\n\n\n\n\nQ4.1.5\npublic\n1\n\n\n\n\nQ4.1.5\nhidden\n1\n\n\n\n4.2\nQ4.2.1\npublic\n1\n4\n\n\n\nQ4.2.1\nhidden\n1\n\n\n\n\nQ4.2.2\npublic\n1\n\n\n\n\nQ4.2.2\nhidden\n1\n\n\n\n4.3\nQ4.3.1\npublic\n1\n4\n\n\n\nQ4.3.1\nhidden\n1\n\n\n\n\nQ4.3.2\npublic\n1\n\n\n\n\nQ4.3.2\nhidden\n1\n\n\n\n4.4\nQ4.4.1\npublic\n1\n3\n\n\n\nQ4.4.1\nhidden\n2\n\n\n\n4.5\nQ4.5.1\npublic\n1\n4\n\n\n\nQ4.5.1\nhidden\n2\n\n\n\n\nQ4.5.2\npublic\n0\n\n\n\n\nQ4.5.2\nhidden\n1\n\n\n\n4.6\nQ4.6.1\npublic\n1\n3\n\n\n\nQ4.6.1\nhidden\n2\n\n\n\n4.7\nQ4.7.1\npublic\n1\n5\n\n\n\nQ4.7.1\nhidden\n2\n\n\n\n\nQ4.7.2\npublic\n1\n\n\n\n\nQ4.7.2\nhidden\n1\n\n\n\n4.8\nQ4.8.1\npublic\n1\n11\n\n\n\nQ4.8.1\nhidden\n2\n\n\n\n\nQ4.8.2\npublic\n0\n\n\n\n\nQ4.8.2\nhidden\n1\n\n\n\n\nQ4.8.3\npublic\n0\n\n\n\n\nQ4.8.3\nhidden\n1\n\n\n\n\nQ4.8.4\npublic\n1\n\n\n\n\nQ4.8.4\nhidden\n2\n\n\n\n\nQ4.8.5\npublic\n1\n\n\n\n\nQ4.8.5\nhidden\n2\n\n\n\n4.9\nQ4.9.1\npublic\n0\n2\n\n\n\nQ4.9.1\nhidden\n1\n\n\n\n\nQ4.9.2\npublic\n0\n\n\n\n\nQ4.9.2\nhidden\n1\n\n\n\n4.10\nQ4.10.1\npublic\n0\n8\n\n\n\nQ4.10.1\nhidden\n1\n\n\n\n\nQ4.10.2\npublic\n0\n\n\n\n\nQ4.10.2\nhidden\n1\n\n\n\n\nQ4.10.3\npublic\n1\n\n\n\n\nQ4.10.3\nhidden\n2\n\n\n\n\nQ4.10.4\npublic\n1\n\n\n\n\nQ4.10.4\nhidden\n2\n\n\n\n4.11\nQ4.11.1\npublic\n1\n6\n\n\n\nQ4.11.1\nhidden\n2\n\n\n\n\nQ4.11.2\npublic\n1\n\n\n\n\nQ4.11.2\nhidden\n2\n\n\n\n4.12\nQ4.12\npublic\n1\n5\n\n\n\nQ4.12\nhidden\n4\n\n\n\n5\nQ5.1\npublic\n0\n8\n\n\n\nQ5.1\nhidden\n2\n\n\n\n\nQ5.2\npublic\n0\n\n\n\n\nQ5.2\nhidden\n2\n\n\n\n\nQ5.3\npublic\n0\n\n\n\n\nQ5.3\nhidden\n2\n\n\n\n\nQ5.4\npublic\n0\n\n\n\n\nQ5.4\nhidden\n2\n\n\n\nTotal\n\n\n100\n100\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart\nqid\ntest_type\npoints\npart_total\n\n\n\n\n1\nQ1.1\npublic\n0\n\n\n\n\nQ1.1\nhidden\n2\n\n\n\n\nQ1.2\npublic\n0\n\n\n\n\nQ1.2\nhidden\n2\n\n\n\n\nQ1.3a\npublic\n0\n\n\n\n\nQ1.3a\nhidden\n2\n\n\n\n\nQ1.3b\npublic\n0\n\n\n\n\nQ1.3b\nhidden\n2\n\n\n\n\nQ1.4a\npublic\n0\n\n\n\n\nQ1.4a\nhidden\n2\n\n\n\n\nQ1.4b\npublic\n0\n\n\n\n\nQ1.4b\nhidden\n2\n\n\n\n\nQ1.5\npublic\n0\n\n\n\n\nQ1.5\nhidden\n2\n\n\n\n\nQ1.6\npublic\n0\n\n\n\n\nQ1.6\nhidden\n2\n\n\n\n\nQ1.7\npublic\n0\n\n\n\n\nQ1.7\nhidden\n2\n\n\n\n\nQ1.8\npublic\n0\n\n\n\n\nQ1.8\nhidden\n2\n20\n\n\n2\nQ2.1\npublic\n0\n\n\n\n\nQ2.1\nhidden\n5\n\n\n\n\nQ2.2\npublic\n0\n\n\n\n\nQ2.2\nhidden\n5\n10\n\n\n3\nQ3.1a\npublic\n0\n\n\n\n\nQ3.1a\nhidden\n2\n\n\n\n\nQ3.1b\npublic\n0\n\n\n\n\nQ3.1b\nhidden\n2\n\n\n\n\nQ3.2a\npublic\n0\n\n\n\n\nQ3.2a\nhidden\n2\n\n\n\n\nQ3.2b\npublic\n0\n\n\n\n\nQ3.2b\nhidden\n2\n\n\n\n\nQ3.3a\npublic\n0\n\n\n\n\nQ3.3a\nhidden\n2\n\n\n\n\nQ3.3b\npublic\n0\n\n\n\n\nQ3.3b\nhidden\n2\n12\n\n\n4\nQ4.1a\npublic\n0\n\n\n\n\nQ4.1a\nhidden\n2\n\n\n\n\nQ4.1b\npublic\n0\n\n\n\n\nQ4.1b\nhidden\n2\n\n\n\n\nQ4.2a\npublic\n0\n\n\n\n\nQ4.2a\nhidden\n2\n\n\n\n\nQ4.2b\npublic\n0\n\n\n\n\nQ4.2b\nhidden\n2\n\n\n\n\nQ4.3a\npublic\n0\n\n\n\n\nQ4.3a\nhidden\n2\n\n\n\n\nQ4.3b\npublic\n0\n\n\n\n\nQ4.3b\nhidden\n2\n12\n\n\n5\nQ5.1\npublic\n0\n\n\n\n\nQ5.1\nhidden\n4\n\n\n\n\nQ5.2\npublic\n0\n\n\n\n\nQ5.2\nhidden\n4\n\n\n\n\nQ5.3\npublic\n0\n\n\n\n\nQ5.3\nhidden\n4\n12\n\n\n6\nQ6.1\npublic\n0\n\n\n\n\nQ6.1\nhidden\n7\n\n\n\n\nQ6.2\npublic\n0\n\n\n\n\nQ6.2\nhidden\n7\n14\n\n\n7\nQ7.1\npublic\n0\n\n\n\n\nQ7.1\nhidden\n5\n\n\n\n\nQ7.2\npublic\n0\n\n\n\n\nQ7.2\nhidden\n5\n\n\n\n\nQ7.3\npublic\n0\n\n\n\n\nQ7.3\nhidden\n5\n\n\n\n\nQ7.4\npublic\n0\n\n\n\n\nQ7.4\nhidden\n5\n20\n\n\nTotal\n\n\n100\n100",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "w03/slides.html#loose-ends",
    "href": "w03/slides.html#loose-ends",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Loose Ends",
    "text": "Loose Ends\n\nNormative vs. Descriptive “Exploitation”: How can we disentangle these in our understanding of the term? (Roemer 1988)\n\nUnder descriptive definition, one can “exploit” corn or land in the exact same way one “exploits” human labor (just another type of input into the production process)\nUtility-wise, an economy with exploitation can be unambiguously better than one without exploitation: if 10 people \\(H\\) own means of production, and 990 people \\(S\\) own only their labor power (landless peasants, for example), allowing \\(H\\) to exploit \\(S\\) for a wage increases utility for both: \\(H\\) acquires profits, \\(S\\) doesn’t starve to death\n\n“Tracing back” causes / unraveling history\n\n“The result [of modern 24-hour news cycles] is a litany of events with no beginning and no real end, thrown together only because they occurred at the same time[,] cut off from their antecedents and consequenes” (Bourdieu 2010)"
  },
  {
    "objectID": "w03/slides.html#part-3-the-training-data-bottleneck",
    "href": "w03/slides.html#part-3-the-training-data-bottleneck",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Part 3: The “Training Data Bottleneck”",
    "text": "Part 3: The “Training Data Bottleneck”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSnorkel.AI, An Introduction to Snorkel and Data-Centric AI\n\n\n\n\n\n\nWith so much technical progress […] why is there so little real enterprise success? The answer all too often is that many enterprises continue to be bottlenecked by one key ingredient: the large amounts of labeled data [needed] to train these new systems.\n\n\n\nFigure 1: ibid. (PS, if it seems like I’m picking on them: these are the ‘good guys’ IMO! W.r.t. foregrounding training data as labor)"
  },
  {
    "objectID": "w03/slides.html#human-labor",
    "href": "w03/slides.html#human-labor",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Human Labor",
    "text": "Human Labor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Snorkel AI, “The Principles of Data-Centric AI Development by Alex Ratner” (YouTube)\n\n\n\n\n\n\n\n\nGray and Suri (2019)"
  },
  {
    "objectID": "w03/slides.html#computer-scientists-being-responsible-at-georgetown",
    "href": "w03/slides.html#computer-scientists-being-responsible-at-georgetown",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Computer Scientists Being Responsible (At Georgetown!)",
    "text": "Computer Scientists Being Responsible (At Georgetown!)\n\nGU360 Course Page\n(PS… UMD undergrad CS class of 2013 extremely overrepresented here 😜 go Terps)"
  },
  {
    "objectID": "w03/slides.html#so-what-comes-with-human-labels-human-biases",
    "href": "w03/slides.html#so-what-comes-with-human-labels-human-biases",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "So, What Comes With Human Labels? Human Biases!",
    "text": "So, What Comes With Human Labels? Human Biases!\n\n\n\n\n\n\n\n\n\nCrawford and Paglen (2019)\n\n\n\n\n\n\n\nImage tagged in ImageNet with the label “BOLSHEVIK”. From Crawford and Paglen (2019)"
  },
  {
    "objectID": "w03/slides.html#biases-in-our-brains-rightarrow-biases-in-our-models-rightarrow-material-effects",
    "href": "w03/slides.html#biases-in-our-brains-rightarrow-biases-in-our-models-rightarrow-material-effects",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Biases In Our Brains \\(\\rightarrow\\) Biases in Our Models \\(\\rightarrow\\) Material Effects",
    "text": "Biases In Our Brains \\(\\rightarrow\\) Biases in Our Models \\(\\rightarrow\\) Material Effects\n\n\n\n\n\n\n\n“Reification”: Pretentious word for an important phenomenon, whereby talking about something (e.g., race) as if it was real ends up leading to it becoming real (having real impacts on people’s lives)1\n\n\nOn average, being classified as a White man as opposed to a Coloured man would have more than quadrupled a person’s income. (Pellicer and Ranchhod 2023)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFields and Fields (2012), for example, coined “racecraft” to describe reification of blackness in US… much more on this later!"
  },
  {
    "objectID": "w03/slides.html#reification-in-science",
    "href": "w03/slides.html#reification-in-science",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Reification in Science",
    "text": "Reification in Science\n\n\n\n\n\n\n\n“““Intelligence”“” Testing\n\n\n\n\nGould (1980)\n\n\n\n\n\nMore Generally\n\n\nGoodhart’s Law: “When a measure becomes a target, it ceases to be a good measure”\nCat-and-mouse game between goals (🚩) and ways of measuring progress towards goals (also 🚩)"
  },
  {
    "objectID": "w03/slides.html#reflective-equilibrium",
    "href": "w03/slides.html#reflective-equilibrium",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Reflective Equilibrium",
    "text": "Reflective Equilibrium\n\nMost criticisms of any framework boil down to, “great in theory, but doesn’t work in practice”\nThe way to take this seriously: reflective equilibrium\nIntroduced by Rawls (1951), but popularized by Rawls (1971)\n\n\nFrom Awad et al. (2022)"
  },
  {
    "objectID": "w03/slides.html#easy-mode-descriptive-judgements",
    "href": "w03/slides.html#easy-mode-descriptive-judgements",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Easy Mode: Descriptive Judgements",
    "text": "Easy Mode: Descriptive Judgements\nHow did you acquire the concept “red”?\n\nPeople pointed to stuff with certain properties and said “red” (or “rojo” or “红”), as pieces of an intersubjective communication system\nThese descriptive labels enable coordination, like driving on left or right side of road!\nNothing very profound or difficult in committing to this descriptive coordination: “for ease of communication, I’ll vibrate my vocal chords like this (or write these symbols) to indicate \\(x\\), and vibrate them like this (or write these other symbols) to indicate \\(y\\)” \nLinguistic choices, when it comes to description, are arbitrary*: Our mouths can make these sounds, and each language is a mapping: [combinations of sounds] \\(\\leftrightarrow\\) [things]\n\ndiːsˈæn ˈfɪfti fɔr ˈfɪfti US Accent / Icelandic Accent\n\n\n\n\n\n\n*(Tiny text footnote: Except for, perhaps, a few fun but rare onomatopoetic cases)"
  },
  {
    "objectID": "w03/slides.html#what-makes-ethical-judgements-more-difficult",
    "href": "w03/slides.html#what-makes-ethical-judgements-more-difficult",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "What Makes Ethical Judgements “More Difficult”?",
    "text": "What Makes Ethical Judgements “More Difficult”?\nHow did you acquire the concept “good”?\n\nPeople pointed to actions with certain properties and said “good” (and pointed at others and said “bad”), as part of instilling values in you\n“Grass is green” just links two descriptive referents together, while “Honesty is good” takes the descriptive concept “honesty” and links it with the normative concept “good”\nIn doing this, parents/teachers/friends are doing way more than just linking sounds and things in the world (describing): they are also prescribing rules of moral conduct!\nNormative concepts go beyond “mere” communication: course of your life / future / [things that matter deeply to people] differ if you act on one set of norms vs. another\n\\(\\implies\\) Ethics centrally involves non-arbitrarily-chosen commitments!"
  },
  {
    "objectID": "w03/slides.html#tldr",
    "href": "w03/slides.html#tldr",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Tl;dr",
    "text": "Tl;dr\n\n\n\nLanguages are arbitrary conventions for communication\nEthical systems build on this language to non-arbitrarily mark out things that are good/bad\nSociety wouldn’t be too different if we “shuffled” words (we’d just vibrate our vocal chords differently), but would be very different if we “shuffled” good/bad labeling\n\n\n\n\n\nHare (1952)"
  },
  {
    "objectID": "w03/slides.html#quick-aside-top-10-linguist-beefs",
    "href": "w03/slides.html#quick-aside-top-10-linguist-beefs",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Quick Aside: Top 10 Linguist Beefs",
    "text": "Quick Aside: Top 10 Linguist Beefs\n\nStatement on previous slide (“Life would not be very different if we shuffled words”), might seem weird/closed-minded/dismissive if you have a certain popular prior belief…\n\n\n\n\n\n\n\n\n\n\nDeutscher (2010)\n\n\n\n\n\n\n\nMcWhorter (2014)"
  },
  {
    "objectID": "w03/slides.html#the-last-time-i-use-this-i-promise",
    "href": "w03/slides.html#the-last-time-i-use-this-i-promise",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "The Last Time I Use This, I Promise",
    "text": "The Last Time I Use This, I Promise"
  },
  {
    "objectID": "w03/slides.html#historical-example-capitalism-and-the-protestant-ethic",
    "href": "w03/slides.html#historical-example-capitalism-and-the-protestant-ethic",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Historical Example: Capitalism and the “Protestant Ethic”",
    "text": "Historical Example: Capitalism and the “Protestant Ethic”\n\nBig changes in history are associated with changes in this good/bad labeling!\nMax Weber (second most-cited sociologist of all time*): Protestant value system gave rise to capitalist system by relabeling what things are good vs. bad (Weber 1904):\n\n\n\n\n\n\n\n\nJesus said to his disciples, “Truly, I say to you, only with difficulty will a rich person enter the kingdom of heaven. Again I tell you, it is easier for a camel to go through the eye of a needle than for a rich person to enter the kingdom of God.” (Matthew 19:23-24)\n\n\nOh, were we loving God worthily, we should have no love at all for money! (St. Augustine 1874, pg. 28)\n\n \n*(…jumpscare: REIFICATION!)\n\n\n\nThe earliest capitalists lacked legitimacy in the moral climate in which they found themselves. One of the means they found [to legitimize their behavior] was to appropriate the evaluative vocabulary of Protestantism. (Skinner 2012, pg. 157)\n\n\nCalvinism added [to Luther’s doctrine] the necessity of proving one’s faith in worldly activity, [replacing] spiritual aristocracy of monks outside of/above the world with spiritual aristocracy of predestined saints within it. (pg. 121)."
  },
  {
    "objectID": "w03/slides.html#aggressively-tossing-books-at-your-head",
    "href": "w03/slides.html#aggressively-tossing-books-at-your-head",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Aggressively Tossing Books at Your Head",
    "text": "Aggressively Tossing Books at Your Head\n\n\n\n(Reminder that there are no required readings, but that this means you should pick a few which seem mildly interesting to you and try them out, as first step towards final paper lit review! 😉)\nAlso, we’ll be bringing this Hirschman guy back into the mix when we get to policy: specifically, his earlier book, Exit, Voice, and Loyalty (Hirschman 1970)\n\n\n\n\n\nHirschman (1977)"
  },
  {
    "objectID": "w03/slides.html#contemporary-example-palestine",
    "href": "w03/slides.html#contemporary-example-palestine",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Contemporary Example: Palestine",
    "text": "Contemporary Example: Palestine\n\nVery few of the relevant empirical facts are in dispute, since opening of crucial archives to three so-called “New Historians” in the 1980s. So why do people still argue?\n\n\n\n\n\n\n\n\nIlan Pappe, one of these historians, concluded from this material that:\n\nThe Israeli state was built upon a massive ethnic cleansing, and\nIs not morally justifiable (Pappe 2006)\n\n\n\nThe immunity Israel has received over the last fifty years encourages others, regimes and oppositions alike, to believe that human and civil rights are irrelevant in the Middle East. The dismantling of the mega-prison in Palestine will send a different, and more hopeful, message.\n\n\n\n\nBenny Morris, another of these historians, concluded that:\n\nThe Israeli state was built upon a massive ethnic cleansing, and\nIs morally justifiable (Morris 1987)\n\n\n\nA Jewish state would not have come into being without the uprooting of 700,000 Palestinians. Therefore it was necessary to uproot them. There was no choice but to expel that population. It was necessary to cleanse the hinterland and cleanse the border areas and cleanse the main roads."
  },
  {
    "objectID": "w03/slides.html#standard-counterargument-to-consequentialism",
    "href": "w03/slides.html#standard-counterargument-to-consequentialism",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Standard Counterargument to Consequentialism",
    "text": "Standard Counterargument to Consequentialism\n\n\n\n\n\n\n\nMillions are kept permanently happy, on the one simple condition that a certain lost soul on the far-off edge of things should lead a life of lonely torture (James 1891)\n\n\nModern example: people “out there” suffer so we can have iPhones, etc.\n\n\n\n\n\n\nLe Guin (1973)"
  },
  {
    "objectID": "w03/slides.html#one-solution-individual-rights",
    "href": "w03/slides.html#one-solution-individual-rights",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "One Solution: Individual Rights",
    "text": "One Solution: Individual Rights\n\n\n\n\n\n\n\nRights are vetoes which individuals can use to cancel out collective/institutional decisions which affect them (key example for us: right to privacy)\nRawls/liberalism: individual rights are lexically prior to “efficiency” and/or distributional concerns\nWhy the buzzword “lexically”? Enter (non-scary) math!\nWe can put lowercase letters of English alphabet in an order: \\(\\texttt{a} \\prec \\texttt{b} \\prec \\cdots \\texttt{z}\\)\nWe can put capital letters of English alphabet in an order: \\(\\texttt{A} \\prec \\texttt{B} \\prec \\cdots \\prec \\texttt{Z}\\)\nWhat if we need to sort stuff with both types? We can decide that capital letters are lexically prior to lowercase letters, giving us a combined ordering:\n\n\n\n\n\n\nDworkin (1977)\n\n\n\n\n\n\\[\n\\boxed{\\texttt{A} \\prec \\texttt{B} \\prec \\cdots \\prec \\texttt{Z} \\prec \\texttt{a} \\prec \\texttt{b} \\prec \\cdots \\prec \\texttt{z}}\n\\]"
  },
  {
    "objectID": "w03/slides.html#lexical-ordering-i-tricked-you",
    "href": "w03/slides.html#lexical-ordering-i-tricked-you",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Lexical Ordering (I Tricked You 😈)",
    "text": "Lexical Ordering (I Tricked You 😈)\n\n\n\n\n\n\n\nYou thought I was just talking about letters, but they’re actually variables: capital letters are rights, lowercase letters are distributive principles\n\n\\[\n\\underbrace{\\texttt{A} \\prec \\texttt{B} \\prec \\cdots \\prec \\texttt{Z}}_{\\mathclap{\\substack{\\text{Individual Rights} \\\\ \\text{Basic Goods}}}} \\phantom{\\prec} \\prec \\phantom{\\prec} \\underbrace{\\texttt{a} \\prec \\texttt{b} \\prec \\cdots \\prec \\texttt{z}}_{\\mathclap{\\substack{\\text{Distributive Principles} \\\\ \\text{Money and whatnot}}}}\n\\]"
  },
  {
    "objectID": "w03/slides.html#better-metaphor-than-letters",
    "href": "w03/slides.html#better-metaphor-than-letters",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Better Metaphor Than Letters",
    "text": "Better Metaphor Than Letters\n\nLetters are where Rawls gets “lexically prior” from, but letters are total orderings (we know where every letter “stands” in relation to every other letter)\nBetter metaphor: a high school with a hierarchy such that\n\n\\[\n\\text{Seniors} \\prec \\text{Juniors} \\prec \\text{Sophomores}  \\prec \\text{Freshmen}\n\\]\n\n\\(\\implies\\) If you’re a Freshman, whether at the “top” or “bottom” of a ranking of Freshmen, you’re still prior to all Sophomores…\nWhy is this more helpful? Because we don’t need to define the rankings within classes to know the rankings between classes in this case"
  },
  {
    "objectID": "w03/slides.html#counterarguments-to-deontology",
    "href": "w03/slides.html#counterarguments-to-deontology",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Counterargument(s) to Deontology",
    "text": "Counterargument(s) to Deontology\n\n\n\n\n\n\n\nDeontological rule: “Don’t lie”\n\nBut then: Nazis come to your house, ask you if you’re harboring any Jews\n\nk, new deontological rule: “Don’t lie unless necessary”\n\nWho decides when it’s necessary?\n\nDeontological commitment: Pacifism / Nonviolence\n\nBut then: someone swingin on you\n\nk, new deontological commitment: Pacifism / Nonviolence Except In Self-Defense\n\nWho decides what counts as self-defense?\n\n(Trolley problems, etc.)\n\n\n\n\n\n\nChurchill and Ryan (1998) (Derrick Jensen intro removed from later editions so I put it on dang GitHub"
  },
  {
    "objectID": "w03/slides.html#a-synthesis-two-level-utilitarianism",
    "href": "w03/slides.html#a-synthesis-two-level-utilitarianism",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "A Synthesis: Two-Level Utilitarianism",
    "text": "A Synthesis: Two-Level Utilitarianism\n\n\n\n\n\n\n\nIt would be exhausting to compute Nash equilibrium strategies for every scenario\nInstead, we can develop heuristics that work for most cases, then reevaluate and update when we encounter tough cases\n(Brings us back to reflective equilibrium!)\n\n\n\n\n\n\nKahneman (2011)"
  },
  {
    "objectID": "w03/slides.html#individual-vs.-social-morality",
    "href": "w03/slides.html#individual-vs.-social-morality",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Individual vs. Social Morality",
    "text": "Individual vs. Social Morality\n\nThat was all already hard enough, to reason about individual morality\nNow add in the fact that we live in a society 😰\nThings that happen depend not only on our choices but also the choices of others\n\n\n\n\n\n\n\n\nSeinfeld: Living in a Society (Clip) | TBS"
  },
  {
    "objectID": "w03/slides.html#enter-game-theory",
    "href": "w03/slides.html#enter-game-theory",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Enter Game Theory",
    "text": "Enter Game Theory\n\nA tool for analyzing how individual choices + choices of others \\(\\rightarrow\\) outcomes!\n\n\n\n\n\n\n\n\nExample: You (\\(A\\)) and a friend (\\(B\\)) committed a robbery, and you’re brought into the police station for questioning.\nYou’re placed in separate rooms, and each of you is offered a plea deal: if you testify while your partner stays silent, you go free and they go to jail for 3 years.\nOtherwise, if you both stay silent, they have very little evidence and can only jail you for 1 year\nHowever, there’s a catch: if you both confess, you both get two years in jail, since they now have maximal evidence\n\n\n\n\n\n\nSource: Wikimedia Commons"
  },
  {
    "objectID": "w03/slides.html#individual-decision-making",
    "href": "w03/slides.html#individual-decision-making",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Individual Decision-Making",
    "text": "Individual Decision-Making\n\n\n\n\n\n\n\nLet’s think through \\(A\\)’s best responses to the possible choices \\(B\\) could make:\nIf \\(B\\) stays silent, what is \\(A\\)’s best option?\n\nStaying silent results in 1 year of jail\nTestifying results in 0 years of jail\nSo it is better to testify\n\nIf \\(B\\) testifies, what is \\(A\\)’s best option?\n\nStaying silent results in 3 years of jail\nTestifying results in 2 years of jail\nSo it is better to testify\n\nThe result: regardless of what \\(B\\) does, \\(A\\) is better off testifying!\n\n\n\n\n\n\nSource: Wikimedia Commons"
  },
  {
    "objectID": "w03/slides.html#the-social-outcome",
    "href": "w03/slides.html#the-social-outcome",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "The Social Outcome",
    "text": "The Social Outcome\n\n\n\n\n\n\n\nThe game is symmetric, so the same logic applies for \\(B\\)\nConclusion: the outcome of the game will be \\(s^* = (\\text{Testify}, \\text{Testify})\\)\nThis is called a Nash equilibrium: no player \\(i\\) can make themselves better off by deviating from \\(s_i\\)\n\n\n\n\n\n\nSource: Wikimedia Commons"
  },
  {
    "objectID": "w03/slides.html#how-do-we-fix-this-conventions",
    "href": "w03/slides.html#how-do-we-fix-this-conventions",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "How Do We Fix This? Conventions!",
    "text": "How Do We Fix This? Conventions!\n\n\n\n\n\n\n\nWe encounter this type of problem every day if we drive! You (\\(A\\)) and another driver (\\(B\\)) arrive at an intersection:\n\n\n\n\n\n\n\n\\(B\\)\n\n\n\n\nStop\nDrive\n\n\n\\(A\\)\nStop\n\\(-1,-1\\)\n\\(-3,\\phantom{-}0\\)\n\n\nDrive\n\\(\\phantom{-}0, -3\\)\n\\(-10,-10\\)\n\n\n\n\n\n\nIf both stop, we’re mostly bored: \\(u_A = -1\\)\nIf we stop and the other person drives, we’re mad that they got to go and we didn’t: \\(u_A = -3\\)\nIf both drive, we crash: \\(u_A = -10\\)"
  },
  {
    "objectID": "w03/slides.html#without-a-convention",
    "href": "w03/slides.html#without-a-convention",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Without A Convention",
    "text": "Without A Convention\n\n\n\n\n\n\n\nWe’re “frozen”: this game has no unique Nash equilibrium, so we cannot say (on the basis of individual rationality) what will happen!\nWithout a convention: power/aggression takes over. “War of all against all”, only the strong survive, etc. (life is “nasty, brutish, and short”)\n\n\n\n\n\n\n\n\n\\(B\\)\n\n\n\n\nStop\nDrive\n\n\n\\(A\\)\nStop\n\\({\\color{orange}\\cancel{\\color{black}-1}},{\\color{lightblue}\\cancel{\\color{black}-1}}\\)\n\\(\\boxed{-3},\\boxed{0}\\)\n\n\nDrive\n\\(\\boxed{0}, \\boxed{-3}\\)\n\\({\\color{orange}\\cancel{\\color{black}-10}},{\\color{lightblue}\\cancel{\\color{black}-10}}\\)\n\n\n\n\n\n\n\nIf \\(A\\)’s aggression is \\(\\Pr(s_A = \\textsf{Drive}) = X \\sim \\mathcal{U}[0,1]\\), \\(B\\)’s aggression is \\(\\Pr(s_B = \\textsf{Drive}) = Y \\sim \\mathcal{U}[0,1]\\), what happens at individual and societal levels?\n\n\\[\n\\begin{align*}\n\\mathbb{E}[u_A] = \\mathbb{E}[u_B] &= \\int_{0}^{1}\\int_{0}^{1}\\left(x - 2y -8xy - 1\\right)dy \\, dx = -3.5 \\\\\n\\underbrace{\\mathbb{E}\\mkern-3mu\\left[u_A + u_B\\right]}_{\\mathclap{\\text{Utilitarian Social Welfare}}} &= -3.5\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w03/slides.html#the-convention-of-traffic-lights",
    "href": "w03/slides.html#the-convention-of-traffic-lights",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "The Convention of Traffic Lights",
    "text": "The Convention of Traffic Lights\n\nIf we don’t want a world where \\(\\text{Happiness}(i) \\propto \\Pr(i \\text{ more aggro than }j)\\), we can introduce traffic lights:\n\n\n\n\n\n\n\n\nNow in “correlated equilibrium”, where we ensure* coordinated \\(\\Pr((\\textsf{Drive}, \\textsf{Stop})) = 0.5\\), \\(\\Pr((\\textsf{Stop}, \\textsf{Drive})) = 0.5\\)\n\\(\\mathbb{E}[u_A] = (0.5)(0) + (0.5)(-3) = -1.5\\)\n\\(\\mathbb{E}[u_B] = (0.5)(-3) + (0.5)(0) = -1.5\\)\n\n\n\n\n\n\n\n\n\\(B\\)\n\n\n\n\nStop\nDrive\n\n\n\\(A\\)\nStop\n\\({\\color{orange}\\cancel{\\color{black}-1}},{\\color{lightblue}\\cancel{\\color{black}-1}}\\)\n\\(\\boxed{-3},\\boxed{0}\\)\n\n\nDrive\n\\(\\boxed{0}, \\boxed{-3}\\)\n\\({\\color{orange}\\cancel{\\color{black}-10}},{\\color{lightblue}\\cancel{\\color{black}-10}}\\)\n\n\n\n\n\n\n\nEmpirical (anthropological) findings across literally thousands of different cultures throughout the world: people are willing to give up rewards to ensure fairness (see, e.g., Henrich et al. (2001))\n\n*(through, for example, traffic laws: equal in theory… In practice? Another story)"
  },
  {
    "objectID": "w03/slides.html#so-how-should-we-makechoose-conventions",
    "href": "w03/slides.html#so-how-should-we-makechoose-conventions",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "So How Should We Make/Choose Conventions?",
    "text": "So How Should We Make/Choose Conventions?\n\nHobbes (1668): Only way out of “war of all against all” is to surrender all power to one sovereign (the Leviathan)\nRousseau (1762): Social contract\n[Big big ~200 year gap here… can you think of why? Hint: French Revolution in 1789]\nRawls (1971): Social contract behind the “veil of ignorance”\n\nIf we didn’t know where we were going to end up in society, how would we set it up?"
  },
  {
    "objectID": "w03/slides.html#rawls-veil-of-ignorance",
    "href": "w03/slides.html#rawls-veil-of-ignorance",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Rawls’ Veil of Ignorance",
    "text": "Rawls’ Veil of Ignorance\n\nProbably the most important tool for policy whitepapers!\n“Justice as fairness” (next week: fairness in AI 😜)\nWe don’t know whether we’ll be \\(A\\) or \\(B\\) in the intersection game, so we’d choose the traffic light!\nMore profoundly: We don’t know what race, gender, class, ethnicity, sexuality, disability status we’ll have; We don’t know whether we’ll be Israeli or Palestinian; we don’t know whether we’ll own means of production or own only our labor power (and thus have to sell it on a market to survive)… 🤔"
  },
  {
    "objectID": "w03/slides.html#one-final-reminder",
    "href": "w03/slides.html#one-final-reminder",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "One Final Reminder",
    "text": "One Final Reminder\n\nIndustry rule #4080: Cannot “prove” \\(q(x) = \\text{``Algorithm }x\\text{ is fair''}\\)! Only \\(p(x) \\implies q(y)\\):\n\n\\[\n\\underbrace{p(x)}_{\\substack{\\text{Accept ethical} \\\\ \\text{framework }x}} \\implies \\underbrace{q(y)}_{\\substack{\\text{Algorithms should} \\\\ \\text{satisfy condition }y}}\n\\]\n\nBefore: possible ethical frameworks (values for \\(x\\))\nNow: possible fairness criteria (values for \\(y\\))"
  },
  {
    "objectID": "w03/slides.html#categories-of-fairness-criteria",
    "href": "w03/slides.html#categories-of-fairness-criteria",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Categories of Fairness Criteria",
    "text": "Categories of Fairness Criteria\n\nRoughly, approaches to fairness/bias in AI can be categorized as follows:\n\n\nFairness\n\n\n\n\n\n\nContext-Free\n\n\nSingle-Threshold Fairness\nEqual Prediction\nEqual Decision\n\n\n\n\n\n\n\n\n\nContext-Sensitive\n\n\nFairness via Similarity Metric(s)\nCausal Definitions\n\n\n\n\n\n\n[Today] Context-Free Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of Machine Learning (you already know much of it, given DSAN 5000!)\nBut easy-to-grasp notion \\(\\neq\\) “good” notion!\nYour job: push yourself to (a) consider what is getting left out of the context-free definitions, and (b) the loopholes that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”"
  },
  {
    "objectID": "w03/slides.html#laws-often-perfectly-technically-fair",
    "href": "w03/slides.html#laws-often-perfectly-technically-fair",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Laws: Often Perfectly “Technically Fair”",
    "text": "Laws: Often Perfectly “Technically Fair”\n\nAh, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!\n\n\n(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)\n\nAnatole France, Le Lys Rouge (France 1894)"
  },
  {
    "objectID": "w03/slides.html#the-brogrammers-criterion",
    "href": "w03/slides.html#the-brogrammers-criterion",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "The Brogrammer’s Criterion",
    "text": "The Brogrammer’s Criterion\ndf.drop(columns=[\"race\"], inplace=True)\n\nRacism solved, folks! 🥳🎊🎉 End of the course, have a great rest of your data science career ✌️"
  },
  {
    "objectID": "w03/slides.html#no-fairness-through-unawareness",
    "href": "w03/slides.html#no-fairness-through-unawareness",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "(No) Fairness Through Unawareness",
    "text": "(No) Fairness Through Unawareness\n\nHW1: Using tiny sample (\\(N &lt; 10K\\)) of Florida voter registrations… RandomForestClassifier (default settings, no hyperparameter tuning, no cross-validation, no ensembling with other methods) will predict self-reported race with \\(&gt;90\\%\\) accuracy (in balanced sample) from just surname and county of residence\n\nCan reach \\(70\\text{-}75\\%\\) with just surname or just county of residence\n\nAlso in HW1: Facebook ad matching service provides over 1,000 different user attributes for (micro)targeting\n\n\nFrom Datta et al. (2017)"
  },
  {
    "objectID": "w03/slides.html#to-make-it-even-more-concrete",
    "href": "w03/slides.html#to-make-it-even-more-concrete",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "To Make It Even More Concrete…",
    "text": "To Make It Even More Concrete…\n\nBloomberg analysis of neighborhoods with same-day delivery from Amazon:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Figures from Ingold and Soper (2016)"
  },
  {
    "objectID": "w03/slides.html#we-can-do-a-bit-better",
    "href": "w03/slides.html#we-can-do-a-bit-better",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "We Can Do (A Bit) Better…",
    "text": "We Can Do (A Bit) Better…\n\nUse random variables to model inferences made by an algorithm (or a human!)\n\\(\\implies\\) fairness by statistically equalizing loan rejections, error rate, etc. between groups\nObvious societal drawback: equality does not ameliorate the effects of past injustices (see: police contact vs. trust-in-government plot from last week)\n\nThis one we saw coming, given “context-free” nature!\n\nLess obvious mathematical drawback: impossibility results (because algebra 😳)\n\nRoughly: can’t satisfy [more than] two statistical fairness criteria at once; similar to how setting \\(\\Pr(X) = p\\) also determines \\(\\Pr(\\text{not }X) = 1 - p\\), or how plugging \\(x = 3\\) into \\(x + y = 5\\) leaves only one possibility \\(y = 2\\)\n\nBUT, “impossibility” \\(\\neq\\) impossibility: (a) one criteria may be “all you need” in given setting; (b) can derive more robust measures by “relaxing” confusion-matrix measures"
  },
  {
    "objectID": "w03/slides.html#what-the-fairness-measures-will-feel-like-for-now",
    "href": "w03/slides.html#what-the-fairness-measures-will-feel-like-for-now",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "What the Fairness Measures Will Feel Like For Now",
    "text": "What the Fairness Measures Will Feel Like For Now\n\n\n(They will get more robust and will incorporate context soon, I promise!)"
  },
  {
    "objectID": "w03/slides.html#who-remembers-confusion-matrices",
    "href": "w03/slides.html#who-remembers-confusion-matrices",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Who Remembers… 🎉Confusion Matrices!!!🎉",
    "text": "Who Remembers… 🎉Confusion Matrices!!!🎉\n\nTerrifyingly higher stakes than in DSAN 5000, however!\nNow \\(D = 1\\) could literally mean “shoot this person” or “throw this person in jail for life”\n\n\nFrom Mitchell et al. (2021)"
  },
  {
    "objectID": "w03/slides.html#our-first-fairness-measure-finally",
    "href": "w03/slides.html#our-first-fairness-measure-finally",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Our First Fairness Measure (Finally)!",
    "text": "Our First Fairness Measure (Finally)!\n\nStandard across the literature: Random Variable \\(A_i\\) “encoding” membership in protected/sensitive group. In HW1, for example:\n\n\\[\nA_i = \\begin{cases}\n0 &\\text{if }i\\text{ self-reported ``white''} \\\\\n1 &\\text{if }i\\text{ self-reported ``black''}\n\\end{cases}\n\\]\n\nNotice: choice of mapping into \\(\\{0, 1\\}\\) here non-arbitrary!\nWe want our models/criteria to be descriptively but also normatively robust; e.g.:\nIf (antecedent I hold, though majority in US do not) one believes that ending (much less repairing) centuries of unrelenting white supremacist violence here might require asymmetric race-based policies,\nThen our model should allow different normative labels and differential weights on\n\\[\n\\begin{align*}\n\\Delta &= (\\text{Fairness} \\mid A = 1) - (\\text{Fairness} \\mid A = 0) \\\\\n\\nabla &= (\\text{Fairness} \\mid A = 0) - (\\text{Fairness} \\mid A = 1)\n\\end{align*}\n\\]\ndespite the descriptive fact that \\(\\Delta = -\\nabla\\)."
  },
  {
    "objectID": "w03/slides.html#where-descriptive-and-normative-become-intertwined",
    "href": "w03/slides.html#where-descriptive-and-normative-become-intertwined",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Where Descriptive and Normative Become Intertwined",
    "text": "Where Descriptive and Normative Become Intertwined\n\nAllowing this asymmetry is precisely what enables bring descriptive facts to bear on normative concerns!\nMathematically we can always “flip” the mapping from racial labels into \\(\\{0, 1\\}\\)…\nBut this (in a precise, mathematical sense: namely, isomorphism) implies that we’re treating racial categorization as the same type of phenomenon as driving on left or right side of road (see: prev slides on why we make the descriptive vs. normative distinction)\n(See also: Sweden’s Dagen H!)"
  },
  {
    "objectID": "w03/slides.html#fairness-through-equalized-positive-rates",
    "href": "w03/slides.html#fairness-through-equalized-positive-rates",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "“Fairness” Through Equalized Positive Rates",
    "text": "“Fairness” Through Equalized Positive Rates\n\\[\n\\Pr(D = 1 \\mid A = 0) = \\Pr(D = 1 \\mid A = 1)\n\\]\n\nThis works specifically for discrete, binary-valued categories\nFor general attributes (whether discrete or continuous!), generalizes to:\n\n\\[\nD \\perp A \\iff \\Pr(D = d, A = a) = \\Pr(D = d)\\Pr(A = a)\n\\]"
  },
  {
    "objectID": "w03/slides.html#fairness-through-equalized-error-rates",
    "href": "w03/slides.html#fairness-through-equalized-error-rates",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "“Fairness” Through Equalized Error Rates",
    "text": "“Fairness” Through Equalized Error Rates\n\nEqualized False Positive Rate:\n\n\\[\n\\Pr(D = 1 \\mid Y = 0, A = 0) = \\Pr(D = 1 \\mid Y = 0, A = 1)\n\\]\n\nEqualized False Negative Rate:\n\n\\[\n\\Pr(D = 0 \\mid Y = 1, A = 0) = \\Pr(D = 0 \\mid Y = 1, A = 1)\n\\]\n\nFor general (non-binary) attributes: \\((D \\perp A) \\mid Y\\):\n\n\\[\n\\Pr(D = d, A = a \\mid Y = y) = \\Pr(D = d \\mid Y = y)\\Pr(A = a \\mid Y = y)\n\\]"
  },
  {
    "objectID": "w03/slides.html#no-more-equations",
    "href": "w03/slides.html#no-more-equations",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "NO MORE EQUATIONS! 😤",
    "text": "NO MORE EQUATIONS! 😤\n\nDepending on your background and/or learning style (say, visual vs. auditory), you may be able to look at equations on previous slides and “see” what they’re “saying”\nIf your brain works similarly to mine, however, your eyes glazed over, you began dissociating, planning an escape route, looking for open ventilation ducts, etc.\nIf you’re in the latter group, welcome to the cult of Probabilistic Graphical Models 😈"
  },
  {
    "objectID": "w03/slides.html#baby-steps-a-real-world-confusion-matrix",
    "href": "w03/slides.html#baby-steps-a-real-world-confusion-matrix",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Baby Steps: A Real-World Confusion Matrix",
    "text": "Baby Steps: A Real-World Confusion Matrix\n\n\n\n\n\n\n\n\n\nLabeled Low-Risk\nLabeled High-Risk\n\n\n\n\nDidn’t Do More Crimes\nTrue Negative\nFalse Positive\n\n\nDid More Crimes\nFalse Negative\nTrue Positive\n\n\n\n\nWhat kinds of causal connections and/or feedback loops might there be between our decision variable (low vs. high risk) and our outcome variable (did vs. didn’t do more crimes)\nWhat types of policy implications might this process have, after it “runs” for several “iterations”?\nWhy might some segments of society, with some shared ethical framework(s), weigh the “costs” of false negatives and false positives differently from other segments of society with different shared ethical framework(s)?\n(Non-rhetorical questions!)"
  },
  {
    "objectID": "w03/slides.html#references",
    "href": "w03/slides.html#references",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "References",
    "text": "References\n\n\nAwad, Edmond, Sydney Levine, Michael Anderson, Susan Leigh Anderson, Vincent Conitzer, M. J. Crockett, Jim A. C. Everett, et al. 2022. “Computational Ethics.” Trends in Cognitive Sciences 26 (5): 388–405. https://doi.org/10.1016/j.tics.2022.02.009.\n\n\nBourdieu, Pierre. 2010. Sociology Is a Martial Art: Political Writings by Pierre Bourdieu. New Press.\n\n\nChurchill, Ward, and Michael Ryan. 1998. Pacifism as Pathology: Reflections on the Role of Armed Struggle in North America. PM Press.\n\n\nCrawford, Kate, and Trevor Paglen. 2019. “Excavating AI: The Politics of Training Sets for Machine Learning.” AI Now Institute, NYU. https://excavating.ai.\n\n\nDatta, Anupam, Matt Fredrikson, Gihyuk Ko, Piotr Mardziel, and Shayak Sen. 2017. “Proxy Non-Discrimination in Data-Driven Systems.” arXiv. https://doi.org/10.48550/arXiv.1707.08120.\n\n\nDeutscher, Guy. 2010. Through the Language Glass: Why the World Looks Different in Other Languages. Henry Holt and Company.\n\n\nDube, Arindrajit, Jeff Jacobs, Suresh Naidu, and Siddharth Suri. 2020. “Monopsony in Online Labor Markets.” American Economic Review: Insights 2 (1): 33–46. https://doi.org/10.1257/aeri.20180150.\n\n\nDworkin, Ronald. 1977. Taking Rights Seriously. A&C Black.\n\n\nFields, Barbara J., and Karen E. Fields. 2012. Racecraft: The Soul of Inequality in American Life. Verso Books.\n\n\nFrance, Anatole. 1894. Le Lys Rouge (The Red Lily). G. Wells.\n\n\nGould, Stephen Jay. 1980. The Mismeasure of Man (Revised and Expanded). W. W. Norton & Company.\n\n\nGray, Mary L., and Siddharth Suri. 2019. Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass. HarperCollins.\n\n\nHare, R. M. 1952. The Language of Morals. OUP Oxford.\n\n\nHenrich, Joseph, Robert Boyd, Samuel Bowles, Colin Camerer, Ernst Fehr, Herbert Gintis, and Richard McElreath. 2001. “In Search of Homo Economicus: Behavioral Experiments in 15 Small-Scale Societies.” American Economic Review 91 (2): 73–78. https://doi.org/10.1257/aer.91.2.73.\n\n\nHirschman, Albert O. 1970. Exit, Voice, and Loyalty: Responses to Decline in Firms, Organizations, and States. Harvard University Press.\n\n\n———. 1977. The Passions and the Interests: Political Arguments for Capitalism Before Its Triumph. Princeton University Press.\n\n\nHobbes, Thomas. 1668. Leviathan: With Selected Variants from the Latin Edition of 1668. Hackett Publishing.\n\n\nIngold, David, and Spencer Soper. 2016. “Amazon Doesn’t Consider the Race of Its Customers. Should It?” Bloomberg, April. http://www.bloomberg.com/graphics/2016-amazon-same-day/.\n\n\nJames, William. 1891. “The Moral Philosopher and the Moral Life.” International Journal of Ethics 1 (3): 330–54. https://www.jstor.org/stable/2375309.\n\n\nKahneman, Daniel. 2011. Thinking, Fast and Slow. Farrar, Straus and Giroux.\n\n\nLe Guin, Ursula K. 1973. The Ones Who Walk Away from Omelas: A Story. HarperCollins.\n\n\nMcWhorter, John H. 2014. The Language Hoax: Why the World Looks the Same in Any Language. Oxford University Press.\n\n\nMitchell, Shira, Eric Potash, Solon Barocas, Alexander D’Amour, and Kristian Lum. 2021. “Algorithmic Fairness: Choices, Assumptions, and Definitions.” Annual Review of Statistics and Its Application 8 (1): 141–63. https://doi.org/10.1146/annurev-statistics-042720-125902.\n\n\nMorris, Benny. 1987. The Birth of the Palestinian Refugee Problem, 1947-1949. Cambridge University Press.\n\n\nPappe, Ilan. 2006. The Ethnic Cleansing of Palestine. Simon and Schuster.\n\n\nPellicer, Miquel, and Vimal Ranchhod. 2023. “Understanding the Effects of Racial Classification in Apartheid South Africa.” Journal of Development Economics 160 (January): 102998. https://doi.org/10.1016/j.jdeveco.2022.102998.\n\n\nRawls, John. 1951. “Outline of a Decision Procedure for Ethics.” The Philosophical Review 60 (2): 177–97. https://doi.org/10.2307/2181696.\n\n\n———. 1971. A Theory of Justice: Original Edition. Harvard University Press.\n\n\nRoemer, John E. 1988. Free to Lose: An Introduction to Marxist Economic Philosophy. Harvard University Press.\n\n\nRousseau, Jean-Jacques. 1762. The Social Contract. Geneva: J. M. Dent.\n\n\nSkinner, Quentin. 2012. Visions of Politics, Volume 1: Regarding Method. Cambridge: Cambridge University Press.\n\n\nSt. Augustine. 1874. The Works of Aurelius Augustine: Lectures or Tractates on the Gospel According to St. John, v. 2. T. & T. Clark.\n\n\nWeber, Max. 1904. The Protestant Ethic and the Spirit of Capitalism. Courier Corporation."
  },
  {
    "objectID": "w03/index.html",
    "href": "w03/index.html",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#loose-ends",
    "href": "w03/index.html#loose-ends",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Loose Ends",
    "text": "Loose Ends\n\nNormative vs. Descriptive “Exploitation”: How can we disentangle these in our understanding of the term? (Roemer 1988)\n\nUnder descriptive definition, one can “exploit” corn or land in the exact same way one “exploits” human labor (just another type of input into the production process)\nUtility-wise, an economy with exploitation can be unambiguously better than one without exploitation: if 10 people \\(H\\) own means of production, and 990 people \\(S\\) own only their labor power (landless peasants, for example), allowing \\(H\\) to exploit \\(S\\) for a wage increases utility for both: \\(H\\) acquires profits, \\(S\\) doesn’t starve to death\n\n“Tracing back” causes / unraveling history\n\n“The result [of modern 24-hour news cycles] is a litany of events with no beginning and no real end, thrown together only because they occurred at the same time[,] cut off from their antecedents and consequenes” (Bourdieu 2010)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#part-3-the-training-data-bottleneck",
    "href": "w03/index.html#part-3-the-training-data-bottleneck",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Part 3: The “Training Data Bottleneck”",
    "text": "Part 3: The “Training Data Bottleneck”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSnorkel.AI, An Introduction to Snorkel and Data-Centric AI\n\n\n\n\n\n\nWith so much technical progress […] why is there so little real enterprise success? The answer all too often is that many enterprises continue to be bottlenecked by one key ingredient: the large amounts of labeled data [needed] to train these new systems.\n\n\n\nFigure 1: ibid. (PS, if it seems like I’m picking on them: these are the ‘good guys’ IMO! W.r.t. foregrounding training data as labor)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#human-labor",
    "href": "w03/index.html#human-labor",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Human Labor",
    "text": "Human Labor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Snorkel AI, “The Principles of Data-Centric AI Development by Alex Ratner” (YouTube)\n\n\n\n\n\n\n\n\nGray and Suri (2019)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#computer-scientists-being-responsible-at-georgetown",
    "href": "w03/index.html#computer-scientists-being-responsible-at-georgetown",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Computer Scientists Being Responsible (At Georgetown!)",
    "text": "Computer Scientists Being Responsible (At Georgetown!)\n\n\n\nGU360 Course Page\n\n\n\n(PS… UMD undergrad CS class of 2013 extremely overrepresented here 😜 go Terps)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#so-what-comes-with-human-labels-human-biases",
    "href": "w03/index.html#so-what-comes-with-human-labels-human-biases",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "So, What Comes With Human Labels? Human Biases!",
    "text": "So, What Comes With Human Labels? Human Biases!\n\n\n\n\n\n\n\n\n\nCrawford and Paglen (2019)\n\n\n\n\n\n\n\nImage tagged in ImageNet with the label “BOLSHEVIK”. From Crawford and Paglen (2019)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#biases-in-our-brains-rightarrow-biases-in-our-models-rightarrow-material-effects",
    "href": "w03/index.html#biases-in-our-brains-rightarrow-biases-in-our-models-rightarrow-material-effects",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Biases In Our Brains \\(\\rightarrow\\) Biases in Our Models \\(\\rightarrow\\) Material Effects",
    "text": "Biases In Our Brains \\(\\rightarrow\\) Biases in Our Models \\(\\rightarrow\\) Material Effects\n\n\n\n\n\n\n\n“Reification”: Pretentious word for an important phenomenon, whereby talking about something (e.g., race) as if it was real ends up leading to it becoming real (having real impacts on people’s lives)1\n\n\nOn average, being classified as a White man as opposed to a Coloured man would have more than quadrupled a person’s income. (Pellicer and Ranchhod 2023)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#reification-in-science",
    "href": "w03/index.html#reification-in-science",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Reification in Science",
    "text": "Reification in Science\n\n\n\n\n\n\n\n“““Intelligence”“” Testing\n\n\n\n\nGould (1980)\n\n\n\n\n\nMore Generally\n\n\nGoodhart’s Law: “When a measure becomes a target, it ceases to be a good measure”\nCat-and-mouse game between goals (🚩) and ways of measuring progress towards goals (also 🚩)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#reflective-equilibrium",
    "href": "w03/index.html#reflective-equilibrium",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Reflective Equilibrium",
    "text": "Reflective Equilibrium\n\nMost criticisms of any framework boil down to, “great in theory, but doesn’t work in practice”\nThe way to take this seriously: reflective equilibrium\nIntroduced by Rawls (1951), but popularized by Rawls (1971)\n\n\n\n\nFrom Awad et al. (2022)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#easy-mode-descriptive-judgements",
    "href": "w03/index.html#easy-mode-descriptive-judgements",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Easy Mode: Descriptive Judgements",
    "text": "Easy Mode: Descriptive Judgements\nHow did you acquire the concept “red”?\n\nPeople pointed to stuff with certain properties and said “red” (or “rojo” or “红”), as pieces of an intersubjective communication system\nThese descriptive labels enable coordination, like driving on left or right side of road!\nNothing very profound or difficult in committing to this descriptive coordination: “for ease of communication, I’ll vibrate my vocal chords like this (or write these symbols) to indicate \\(x\\), and vibrate them like this (or write these other symbols) to indicate \\(y\\)” \nLinguistic choices, when it comes to description, are arbitrary*: Our mouths can make these sounds, and each language is a mapping: [combinations of sounds] \\(\\leftrightarrow\\) [things]\n\ndiːsˈæn ˈfɪfti fɔr ˈfɪfti US Accent / Icelandic Accent\n\n\n\n\n\n\n*(Tiny text footnote: Except for, perhaps, a few fun but rare onomatopoetic cases)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#what-makes-ethical-judgements-more-difficult",
    "href": "w03/index.html#what-makes-ethical-judgements-more-difficult",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "What Makes Ethical Judgements “More Difficult”?",
    "text": "What Makes Ethical Judgements “More Difficult”?\nHow did you acquire the concept “good”?\n\nPeople pointed to actions with certain properties and said “good” (and pointed at others and said “bad”), as part of instilling values in you\n“Grass is green” just links two descriptive referents together, while “Honesty is good” takes the descriptive concept “honesty” and links it with the normative concept “good”\nIn doing this, parents/teachers/friends are doing way more than just linking sounds and things in the world (describing): they are also prescribing rules of moral conduct!\nNormative concepts go beyond “mere” communication: course of your life / future / [things that matter deeply to people] differ if you act on one set of norms vs. another\n\\(\\implies\\) Ethics centrally involves non-arbitrarily-chosen commitments!",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#tldr",
    "href": "w03/index.html#tldr",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Tl;dr",
    "text": "Tl;dr\n\n\n\nLanguages are arbitrary conventions for communication\nEthical systems build on this language to non-arbitrarily mark out things that are good/bad\nSociety wouldn’t be too different if we “shuffled” words (we’d just vibrate our vocal chords differently), but would be very different if we “shuffled” good/bad labeling\n\n\n\n\n\nHare (1952)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#quick-aside-top-10-linguist-beefs",
    "href": "w03/index.html#quick-aside-top-10-linguist-beefs",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Quick Aside: Top 10 Linguist Beefs",
    "text": "Quick Aside: Top 10 Linguist Beefs\n\nStatement on previous slide (“Life would not be very different if we shuffled words”), might seem weird/closed-minded/dismissive if you have a certain popular prior belief…\n\n\n\n\n\n\n\n\n\n\nDeutscher (2010)\n\n\n\n\n\n\n\nMcWhorter (2014)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#the-last-time-i-use-this-i-promise",
    "href": "w03/index.html#the-last-time-i-use-this-i-promise",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "The Last Time I Use This, I Promise",
    "text": "The Last Time I Use This, I Promise",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#historical-example-capitalism-and-the-protestant-ethic",
    "href": "w03/index.html#historical-example-capitalism-and-the-protestant-ethic",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Historical Example: Capitalism and the “Protestant Ethic”",
    "text": "Historical Example: Capitalism and the “Protestant Ethic”\n\nBig changes in history are associated with changes in this good/bad labeling!\nMax Weber (second most-cited sociologist of all time*): Protestant value system gave rise to capitalist system by relabeling what things are good vs. bad (Weber 1904):\n\n\n\n\n\n\n\n\nJesus said to his disciples, “Truly, I say to you, only with difficulty will a rich person enter the kingdom of heaven. Again I tell you, it is easier for a camel to go through the eye of a needle than for a rich person to enter the kingdom of God.” (Matthew 19:23-24)\n\n\nOh, were we loving God worthily, we should have no love at all for money! (St. Augustine 1874, pg. 28)\n\n \n*(…jumpscare: REIFICATION!)\n\n\n\nThe earliest capitalists lacked legitimacy in the moral climate in which they found themselves. One of the means they found [to legitimize their behavior] was to appropriate the evaluative vocabulary of Protestantism. (Skinner 2012, pg. 157)\n\n\nCalvinism added [to Luther’s doctrine] the necessity of proving one’s faith in worldly activity, [replacing] spiritual aristocracy of monks outside of/above the world with spiritual aristocracy of predestined saints within it. (pg. 121).",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#aggressively-tossing-books-at-your-head",
    "href": "w03/index.html#aggressively-tossing-books-at-your-head",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Aggressively Tossing Books at Your Head",
    "text": "Aggressively Tossing Books at Your Head\n\n\n\n(Reminder that there are no required readings, but that this means you should pick a few which seem mildly interesting to you and try them out, as first step towards final paper lit review! 😉)\nAlso, we’ll be bringing this Hirschman guy back into the mix when we get to policy: specifically, his earlier book, Exit, Voice, and Loyalty (Hirschman 1970)\n\n\n\n\n\nHirschman (1977)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#contemporary-example-palestine",
    "href": "w03/index.html#contemporary-example-palestine",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Contemporary Example: Palestine",
    "text": "Contemporary Example: Palestine\n\nVery few of the relevant empirical facts are in dispute, since opening of crucial archives to three so-called “New Historians” in the 1980s. So why do people still argue?\n\n\n\n\n\n\n\n\nIlan Pappe, one of these historians, concluded from this material that:\n\nThe Israeli state was built upon a massive ethnic cleansing, and\nIs not morally justifiable (Pappe 2006)\n\n\n\nThe immunity Israel has received over the last fifty years encourages others, regimes and oppositions alike, to believe that human and civil rights are irrelevant in the Middle East. The dismantling of the mega-prison in Palestine will send a different, and more hopeful, message.\n\n\n\n\nBenny Morris, another of these historians, concluded that:\n\nThe Israeli state was built upon a massive ethnic cleansing, and\nIs morally justifiable (Morris 1987)\n\n\n\nA Jewish state would not have come into being without the uprooting of 700,000 Palestinians. Therefore it was necessary to uproot them. There was no choice but to expel that population. It was necessary to cleanse the hinterland and cleanse the border areas and cleanse the main roads.",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#standard-counterargument-to-consequentialism",
    "href": "w03/index.html#standard-counterargument-to-consequentialism",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Standard Counterargument to Consequentialism",
    "text": "Standard Counterargument to Consequentialism\n\n\n\n\n\n\n\nMillions are kept permanently happy, on the one simple condition that a certain lost soul on the far-off edge of things should lead a life of lonely torture (James 1891)\n\n\nModern example: people “out there” suffer so we can have iPhones, etc.\n\n\n\n\n\n\nLe Guin (1973)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#one-solution-individual-rights",
    "href": "w03/index.html#one-solution-individual-rights",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "One Solution: Individual Rights",
    "text": "One Solution: Individual Rights\n\n\n\n\n\n\n\nRights are vetoes which individuals can use to cancel out collective/institutional decisions which affect them (key example for us: right to privacy)\nRawls/liberalism: individual rights are lexically prior to “efficiency” and/or distributional concerns\nWhy the buzzword “lexically”? Enter (non-scary) math!\nWe can put lowercase letters of English alphabet in an order: \\(\\texttt{a} \\prec \\texttt{b} \\prec \\cdots \\texttt{z}\\)\nWe can put capital letters of English alphabet in an order: \\(\\texttt{A} \\prec \\texttt{B} \\prec \\cdots \\prec \\texttt{Z}\\)\nWhat if we need to sort stuff with both types? We can decide that capital letters are lexically prior to lowercase letters, giving us a combined ordering:\n\n\n\n\n\n\nDworkin (1977)\n\n\n\n\n\n\\[\n\\boxed{\\texttt{A} \\prec \\texttt{B} \\prec \\cdots \\prec \\texttt{Z} \\prec \\texttt{a} \\prec \\texttt{b} \\prec \\cdots \\prec \\texttt{z}}\n\\]",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#lexical-ordering-i-tricked-you",
    "href": "w03/index.html#lexical-ordering-i-tricked-you",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Lexical Ordering (I Tricked You 😈)",
    "text": "Lexical Ordering (I Tricked You 😈)\n\n\n\n\n\n\n\nYou thought I was just talking about letters, but they’re actually variables: capital letters are rights, lowercase letters are distributive principles\n\n\\[\n\\underbrace{\\texttt{A} \\prec \\texttt{B} \\prec \\cdots \\prec \\texttt{Z}}_{\\mathclap{\\substack{\\text{Individual Rights} \\\\ \\text{Basic Goods}}}} \\phantom{\\prec} \\prec \\phantom{\\prec} \\underbrace{\\texttt{a} \\prec \\texttt{b} \\prec \\cdots \\prec \\texttt{z}}_{\\mathclap{\\substack{\\text{Distributive Principles} \\\\ \\text{Money and whatnot}}}}\n\\]",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#better-metaphor-than-letters",
    "href": "w03/index.html#better-metaphor-than-letters",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Better Metaphor Than Letters",
    "text": "Better Metaphor Than Letters\n\nLetters are where Rawls gets “lexically prior” from, but letters are total orderings (we know where every letter “stands” in relation to every other letter)\nBetter metaphor: a high school with a hierarchy such that\n\n\\[\n\\text{Seniors} \\prec \\text{Juniors} \\prec \\text{Sophomores}  \\prec \\text{Freshmen}\n\\]\n\n\\(\\implies\\) If you’re a Freshman, whether at the “top” or “bottom” of a ranking of Freshmen, you’re still prior to all Sophomores…\nWhy is this more helpful? Because we don’t need to define the rankings within classes to know the rankings between classes in this case",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#counterarguments-to-deontology",
    "href": "w03/index.html#counterarguments-to-deontology",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Counterargument(s) to Deontology",
    "text": "Counterargument(s) to Deontology\n\n\n\n\n\n\n\nDeontological rule: “Don’t lie”\n\nBut then: Nazis come to your house, ask you if you’re harboring any Jews\n\nk, new deontological rule: “Don’t lie unless necessary”\n\nWho decides when it’s necessary?\n\nDeontological commitment: Pacifism / Nonviolence\n\nBut then: someone swingin on you\n\nk, new deontological commitment: Pacifism / Nonviolence Except In Self-Defense\n\nWho decides what counts as self-defense?\n\n(Trolley problems, etc.)\n\n\n\n\n\n\nChurchill and Ryan (1998) (Derrick Jensen intro removed from later editions so I put it on dang GitHub",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#a-synthesis-two-level-utilitarianism",
    "href": "w03/index.html#a-synthesis-two-level-utilitarianism",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "A Synthesis: Two-Level Utilitarianism",
    "text": "A Synthesis: Two-Level Utilitarianism\n\n\n\n\n\n\n\nIt would be exhausting to compute Nash equilibrium strategies for every scenario\nInstead, we can develop heuristics that work for most cases, then reevaluate and update when we encounter tough cases\n(Brings us back to reflective equilibrium!)\n\n\n\n\n\n\nKahneman (2011)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#individual-vs.-social-morality",
    "href": "w03/index.html#individual-vs.-social-morality",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Individual vs. Social Morality",
    "text": "Individual vs. Social Morality\n\nThat was all already hard enough, to reason about individual morality\nNow add in the fact that we live in a society 😰\nThings that happen depend not only on our choices but also the choices of others\n\n\n\n\n\n\n\n\nSeinfeld: Living in a Society (Clip) | TBS",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#enter-game-theory",
    "href": "w03/index.html#enter-game-theory",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Enter Game Theory",
    "text": "Enter Game Theory\n\nA tool for analyzing how individual choices + choices of others \\(\\rightarrow\\) outcomes!\n\n\n\n\n\n\n\n\nExample: You (\\(A\\)) and a friend (\\(B\\)) committed a robbery, and you’re brought into the police station for questioning.\nYou’re placed in separate rooms, and each of you is offered a plea deal: if you testify while your partner stays silent, you go free and they go to jail for 3 years.\nOtherwise, if you both stay silent, they have very little evidence and can only jail you for 1 year\nHowever, there’s a catch: if you both confess, you both get two years in jail, since they now have maximal evidence\n\n\n\n\n\n\nSource: Wikimedia Commons",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#individual-decision-making",
    "href": "w03/index.html#individual-decision-making",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Individual Decision-Making",
    "text": "Individual Decision-Making\n\n\n\n\n\n\n\nLet’s think through \\(A\\)’s best responses to the possible choices \\(B\\) could make:\nIf \\(B\\) stays silent, what is \\(A\\)’s best option?\n\nStaying silent results in 1 year of jail\nTestifying results in 0 years of jail\nSo it is better to testify\n\nIf \\(B\\) testifies, what is \\(A\\)’s best option?\n\nStaying silent results in 3 years of jail\nTestifying results in 2 years of jail\nSo it is better to testify\n\nThe result: regardless of what \\(B\\) does, \\(A\\) is better off testifying!\n\n\n\n\n\n\nSource: Wikimedia Commons",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#the-social-outcome",
    "href": "w03/index.html#the-social-outcome",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "The Social Outcome",
    "text": "The Social Outcome\n\n\n\n\n\n\n\nThe game is symmetric, so the same logic applies for \\(B\\)\nConclusion: the outcome of the game will be \\(s^* = (\\text{Testify}, \\text{Testify})\\)\nThis is called a Nash equilibrium: no player \\(i\\) can make themselves better off by deviating from \\(s_i\\)\n\n\n\n\n\n\nSource: Wikimedia Commons",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#how-do-we-fix-this-conventions",
    "href": "w03/index.html#how-do-we-fix-this-conventions",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "How Do We Fix This? Conventions!",
    "text": "How Do We Fix This? Conventions!\n\n\n\n\n\n\n\nWe encounter this type of problem every day if we drive! You (\\(A\\)) and another driver (\\(B\\)) arrive at an intersection:\n\n\n\n\n\n\n\n\\(B\\)\n\n\n\n\nStop\nDrive\n\n\n\\(A\\)\nStop\n\\(-1,-1\\)\n\\(-3,\\phantom{-}0\\)\n\n\nDrive\n\\(\\phantom{-}0, -3\\)\n\\(-10,-10\\)\n\n\n\n\n\n\nIf both stop, we’re mostly bored: \\(u_A = -1\\)\nIf we stop and the other person drives, we’re mad that they got to go and we didn’t: \\(u_A = -3\\)\nIf both drive, we crash: \\(u_A = -10\\)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#without-a-convention",
    "href": "w03/index.html#without-a-convention",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Without A Convention",
    "text": "Without A Convention\n\n\n\n\n\n\n\nWe’re “frozen”: this game has no unique Nash equilibrium, so we cannot say (on the basis of individual rationality) what will happen!\nWithout a convention: power/aggression takes over. “War of all against all”, only the strong survive, etc. (life is “nasty, brutish, and short”)\n\n\n\n\n\n\n\n\n\\(B\\)\n\n\n\n\nStop\nDrive\n\n\n\\(A\\)\nStop\n\\({\\color{orange}\\cancel{\\color{black}-1}},{\\color{lightblue}\\cancel{\\color{black}-1}}\\)\n\\(\\boxed{-3},\\boxed{0}\\)\n\n\nDrive\n\\(\\boxed{0}, \\boxed{-3}\\)\n\\({\\color{orange}\\cancel{\\color{black}-10}},{\\color{lightblue}\\cancel{\\color{black}-10}}\\)\n\n\n\n\n\n\n\nIf \\(A\\)’s aggression is \\(\\Pr(s_A = \\textsf{Drive}) = X \\sim \\mathcal{U}[0,1]\\), \\(B\\)’s aggression is \\(\\Pr(s_B = \\textsf{Drive}) = Y \\sim \\mathcal{U}[0,1]\\), what happens at individual and societal levels?\n\n\\[\n\\begin{align*}\n\\mathbb{E}[u_A] = \\mathbb{E}[u_B] &= \\int_{0}^{1}\\int_{0}^{1}\\left(x - 2y -8xy - 1\\right)dy \\, dx = -3.5 \\\\\n\\underbrace{\\mathbb{E}\\mkern-3mu\\left[u_A + u_B\\right]}_{\\mathclap{\\text{Utilitarian Social Welfare}}} &= -3.5\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#the-convention-of-traffic-lights",
    "href": "w03/index.html#the-convention-of-traffic-lights",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "The Convention of Traffic Lights",
    "text": "The Convention of Traffic Lights\n\nIf we don’t want a world where \\(\\text{Happiness}(i) \\propto \\Pr(i \\text{ more aggro than }j)\\), we can introduce traffic lights:\n\n\n\n\n\n\n\n\nNow in “correlated equilibrium”, where we ensure* coordinated \\(\\Pr((\\textsf{Drive}, \\textsf{Stop})) = 0.5\\), \\(\\Pr((\\textsf{Stop}, \\textsf{Drive})) = 0.5\\)\n\\(\\mathbb{E}[u_A] = (0.5)(0) + (0.5)(-3) = -1.5\\)\n\\(\\mathbb{E}[u_B] = (0.5)(-3) + (0.5)(0) = -1.5\\)\n\n\n\n\n\n\n\n\n\\(B\\)\n\n\n\n\nStop\nDrive\n\n\n\\(A\\)\nStop\n\\({\\color{orange}\\cancel{\\color{black}-1}},{\\color{lightblue}\\cancel{\\color{black}-1}}\\)\n\\(\\boxed{-3},\\boxed{0}\\)\n\n\nDrive\n\\(\\boxed{0}, \\boxed{-3}\\)\n\\({\\color{orange}\\cancel{\\color{black}-10}},{\\color{lightblue}\\cancel{\\color{black}-10}}\\)\n\n\n\n\n\n\n\nEmpirical (anthropological) findings across literally thousands of different cultures throughout the world: people are willing to give up rewards to ensure fairness (see, e.g., Henrich et al. (2001))\n\n*(through, for example, traffic laws: equal in theory… In practice? Another story)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#so-how-should-we-makechoose-conventions",
    "href": "w03/index.html#so-how-should-we-makechoose-conventions",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "So How Should We Make/Choose Conventions?",
    "text": "So How Should We Make/Choose Conventions?\n\nHobbes (1668): Only way out of “war of all against all” is to surrender all power to one sovereign (the Leviathan)\nRousseau (1762): Social contract\n[Big big ~200 year gap here… can you think of why? Hint: French Revolution in 1789]\nRawls (1971): Social contract behind the “veil of ignorance”\n\nIf we didn’t know where we were going to end up in society, how would we set it up?",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#rawls-veil-of-ignorance",
    "href": "w03/index.html#rawls-veil-of-ignorance",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Rawls’ Veil of Ignorance",
    "text": "Rawls’ Veil of Ignorance\n\nProbably the most important tool for policy whitepapers!\n“Justice as fairness” (next week: fairness in AI 😜)\nWe don’t know whether we’ll be \\(A\\) or \\(B\\) in the intersection game, so we’d choose the traffic light!\nMore profoundly: We don’t know what race, gender, class, ethnicity, sexuality, disability status we’ll have; We don’t know whether we’ll be Israeli or Palestinian; we don’t know whether we’ll own means of production or own only our labor power (and thus have to sell it on a market to survive)… 🤔",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#one-final-reminder",
    "href": "w03/index.html#one-final-reminder",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "One Final Reminder",
    "text": "One Final Reminder\n\nIndustry rule #4080: Cannot “prove” \\(q(x) = \\text{``Algorithm }x\\text{ is fair''}\\)! Only \\(p(x) \\implies q(y)\\):\n\n\\[\n\\underbrace{p(x)}_{\\substack{\\text{Accept ethical} \\\\ \\text{framework }x}} \\implies \\underbrace{q(y)}_{\\substack{\\text{Algorithms should} \\\\ \\text{satisfy condition }y}}\n\\]\n\nBefore: possible ethical frameworks (values for \\(x\\))\nNow: possible fairness criteria (values for \\(y\\))",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#categories-of-fairness-criteria",
    "href": "w03/index.html#categories-of-fairness-criteria",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Categories of Fairness Criteria",
    "text": "Categories of Fairness Criteria\n\nRoughly, approaches to fairness/bias in AI can be categorized as follows:\n\n\nFairness\n\n\n\n\n\n\nContext-Free\n\n\nSingle-Threshold Fairness\nEqual Prediction\nEqual Decision\n\n\n\n\n\n\n\n\n\nContext-Sensitive\n\n\nFairness via Similarity Metric(s)\nCausal Definitions\n\n\n\n\n\n\n\n[Today] Context-Free Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of Machine Learning (you already know much of it, given DSAN 5000!)\nBut easy-to-grasp notion \\(\\neq\\) “good” notion!\nYour job: push yourself to (a) consider what is getting left out of the context-free definitions, and (b) the loopholes that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#laws-often-perfectly-technically-fair",
    "href": "w03/index.html#laws-often-perfectly-technically-fair",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Laws: Often Perfectly “Technically Fair”",
    "text": "Laws: Often Perfectly “Technically Fair”\n\nAh, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!\n\n\n(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)\n\nAnatole France, Le Lys Rouge (France 1894)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#the-brogrammers-criterion",
    "href": "w03/index.html#the-brogrammers-criterion",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "The Brogrammer’s Criterion",
    "text": "The Brogrammer’s Criterion\ndf.drop(columns=[\"race\"], inplace=True)\n\nRacism solved, folks! 🥳🎊🎉 End of the course, have a great rest of your data science career ✌️",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#no-fairness-through-unawareness",
    "href": "w03/index.html#no-fairness-through-unawareness",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "(No) Fairness Through Unawareness",
    "text": "(No) Fairness Through Unawareness\n\nHW1: Using tiny sample (\\(N &lt; 10K\\)) of Florida voter registrations… RandomForestClassifier (default settings, no hyperparameter tuning, no cross-validation, no ensembling with other methods) will predict self-reported race with \\(&gt;90\\%\\) accuracy (in balanced sample) from just surname and county of residence\n\nCan reach \\(70\\text{-}75\\%\\) with just surname or just county of residence\n\nAlso in HW1: Facebook ad matching service provides over 1,000 different user attributes for (micro)targeting\n\n\n\n\nFrom Datta et al. (2017)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#to-make-it-even-more-concrete",
    "href": "w03/index.html#to-make-it-even-more-concrete",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "To Make It Even More Concrete…",
    "text": "To Make It Even More Concrete…\n\nBloomberg analysis of neighborhoods with same-day delivery from Amazon:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Figures from Ingold and Soper (2016)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#we-can-do-a-bit-better",
    "href": "w03/index.html#we-can-do-a-bit-better",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "We Can Do (A Bit) Better…",
    "text": "We Can Do (A Bit) Better…\n\nUse random variables to model inferences made by an algorithm (or a human!)\n\\(\\implies\\) fairness by statistically equalizing loan rejections, error rate, etc. between groups\nObvious societal drawback: equality does not ameliorate the effects of past injustices (see: police contact vs. trust-in-government plot from last week)\n\nThis one we saw coming, given “context-free” nature!\n\nLess obvious mathematical drawback: impossibility results (because algebra 😳)\n\nRoughly: can’t satisfy [more than] two statistical fairness criteria at once; similar to how setting \\(\\Pr(X) = p\\) also determines \\(\\Pr(\\text{not }X) = 1 - p\\), or how plugging \\(x = 3\\) into \\(x + y = 5\\) leaves only one possibility \\(y = 2\\)\n\nBUT, “impossibility” \\(\\neq\\) impossibility: (a) one criteria may be “all you need” in given setting; (b) can derive more robust measures by “relaxing” confusion-matrix measures",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#what-the-fairness-measures-will-feel-like-for-now",
    "href": "w03/index.html#what-the-fairness-measures-will-feel-like-for-now",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "What the Fairness Measures Will Feel Like For Now",
    "text": "What the Fairness Measures Will Feel Like For Now\n\n\n\n\n\n\n(They will get more robust and will incorporate context soon, I promise!)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#who-remembers-confusion-matrices",
    "href": "w03/index.html#who-remembers-confusion-matrices",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Who Remembers… 🎉Confusion Matrices!!!🎉",
    "text": "Who Remembers… 🎉Confusion Matrices!!!🎉\n\nTerrifyingly higher stakes than in DSAN 5000, however!\nNow \\(D = 1\\) could literally mean “shoot this person” or “throw this person in jail for life”\n\n\n\n\nFrom Mitchell et al. (2021)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#our-first-fairness-measure-finally",
    "href": "w03/index.html#our-first-fairness-measure-finally",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Our First Fairness Measure (Finally)!",
    "text": "Our First Fairness Measure (Finally)!\n\nStandard across the literature: Random Variable \\(A_i\\) “encoding” membership in protected/sensitive group. In HW1, for example:\n\n\\[\nA_i = \\begin{cases}\n0 &\\text{if }i\\text{ self-reported ``white''} \\\\\n1 &\\text{if }i\\text{ self-reported ``black''}\n\\end{cases}\n\\]\n\nNotice: choice of mapping into \\(\\{0, 1\\}\\) here non-arbitrary!\nWe want our models/criteria to be descriptively but also normatively robust; e.g.:\nIf (antecedent I hold, though majority in US do not) one believes that ending (much less repairing) centuries of unrelenting white supremacist violence here might require asymmetric race-based policies,\nThen our model should allow different normative labels and differential weights on\n\\[\n\\begin{align*}\n\\Delta &= (\\text{Fairness} \\mid A = 1) - (\\text{Fairness} \\mid A = 0) \\\\\n\\nabla &= (\\text{Fairness} \\mid A = 0) - (\\text{Fairness} \\mid A = 1)\n\\end{align*}\n\\]\ndespite the descriptive fact that \\(\\Delta = -\\nabla\\).",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#where-descriptive-and-normative-become-intertwined",
    "href": "w03/index.html#where-descriptive-and-normative-become-intertwined",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Where Descriptive and Normative Become Intertwined",
    "text": "Where Descriptive and Normative Become Intertwined\n\nAllowing this asymmetry is precisely what enables bring descriptive facts to bear on normative concerns!\nMathematically we can always “flip” the mapping from racial labels into \\(\\{0, 1\\}\\)…\nBut this (in a precise, mathematical sense: namely, isomorphism) implies that we’re treating racial categorization as the same type of phenomenon as driving on left or right side of road (see: prev slides on why we make the descriptive vs. normative distinction)\n(See also: Sweden’s Dagen H!)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#fairness-through-equalized-positive-rates",
    "href": "w03/index.html#fairness-through-equalized-positive-rates",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "“Fairness” Through Equalized Positive Rates",
    "text": "“Fairness” Through Equalized Positive Rates\n\\[\n\\Pr(D = 1 \\mid A = 0) = \\Pr(D = 1 \\mid A = 1)\n\\]\n\nThis works specifically for discrete, binary-valued categories\nFor general attributes (whether discrete or continuous!), generalizes to:\n\n\\[\nD \\perp A \\iff \\Pr(D = d, A = a) = \\Pr(D = d)\\Pr(A = a)\n\\]",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#fairness-through-equalized-error-rates",
    "href": "w03/index.html#fairness-through-equalized-error-rates",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "“Fairness” Through Equalized Error Rates",
    "text": "“Fairness” Through Equalized Error Rates\n\nEqualized False Positive Rate:\n\n\\[\n\\Pr(D = 1 \\mid Y = 0, A = 0) = \\Pr(D = 1 \\mid Y = 0, A = 1)\n\\]\n\nEqualized False Negative Rate:\n\n\\[\n\\Pr(D = 0 \\mid Y = 1, A = 0) = \\Pr(D = 0 \\mid Y = 1, A = 1)\n\\]\n\nFor general (non-binary) attributes: \\((D \\perp A) \\mid Y\\):\n\n\\[\n\\Pr(D = d, A = a \\mid Y = y) = \\Pr(D = d \\mid Y = y)\\Pr(A = a \\mid Y = y)\n\\]",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#no-more-equations",
    "href": "w03/index.html#no-more-equations",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "NO MORE EQUATIONS! 😤",
    "text": "NO MORE EQUATIONS! 😤\n\nDepending on your background and/or learning style (say, visual vs. auditory), you may be able to look at equations on previous slides and “see” what they’re “saying”\nIf your brain works similarly to mine, however, your eyes glazed over, you began dissociating, planning an escape route, looking for open ventilation ducts, etc.\nIf you’re in the latter group, welcome to the cult of Probabilistic Graphical Models 😈",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#baby-steps-a-real-world-confusion-matrix",
    "href": "w03/index.html#baby-steps-a-real-world-confusion-matrix",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Baby Steps: A Real-World Confusion Matrix",
    "text": "Baby Steps: A Real-World Confusion Matrix\n\n\n\n\n\n\n\n\n\nLabeled Low-Risk\nLabeled High-Risk\n\n\n\n\nDidn’t Do More Crimes\nTrue Negative\nFalse Positive\n\n\nDid More Crimes\nFalse Negative\nTrue Positive\n\n\n\n\nWhat kinds of causal connections and/or feedback loops might there be between our decision variable (low vs. high risk) and our outcome variable (did vs. didn’t do more crimes)\nWhat types of policy implications might this process have, after it “runs” for several “iterations”?\nWhy might some segments of society, with some shared ethical framework(s), weigh the “costs” of false negatives and false positives differently from other segments of society with different shared ethical framework(s)?\n(Non-rhetorical questions!)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#references",
    "href": "w03/index.html#references",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "References",
    "text": "References\n\n\nAwad, Edmond, Sydney Levine, Michael Anderson, Susan Leigh Anderson, Vincent Conitzer, M. J. Crockett, Jim A. C. Everett, et al. 2022. “Computational Ethics.” Trends in Cognitive Sciences 26 (5): 388–405. https://doi.org/10.1016/j.tics.2022.02.009.\n\n\nBourdieu, Pierre. 2010. Sociology Is a Martial Art: Political Writings by Pierre Bourdieu. New Press.\n\n\nChurchill, Ward, and Michael Ryan. 1998. Pacifism as Pathology: Reflections on the Role of Armed Struggle in North America. PM Press.\n\n\nCrawford, Kate, and Trevor Paglen. 2019. “Excavating AI: The Politics of Training Sets for Machine Learning.” AI Now Institute, NYU. https://excavating.ai.\n\n\nDatta, Anupam, Matt Fredrikson, Gihyuk Ko, Piotr Mardziel, and Shayak Sen. 2017. “Proxy Non-Discrimination in Data-Driven Systems.” arXiv. https://doi.org/10.48550/arXiv.1707.08120.\n\n\nDeutscher, Guy. 2010. Through the Language Glass: Why the World Looks Different in Other Languages. Henry Holt and Company.\n\n\nDube, Arindrajit, Jeff Jacobs, Suresh Naidu, and Siddharth Suri. 2020. “Monopsony in Online Labor Markets.” American Economic Review: Insights 2 (1): 33–46. https://doi.org/10.1257/aeri.20180150.\n\n\nDworkin, Ronald. 1977. Taking Rights Seriously. A&C Black.\n\n\nFields, Barbara J., and Karen E. Fields. 2012. Racecraft: The Soul of Inequality in American Life. Verso Books.\n\n\nFrance, Anatole. 1894. Le Lys Rouge (The Red Lily). G. Wells.\n\n\nGould, Stephen Jay. 1980. The Mismeasure of Man (Revised and Expanded). W. W. Norton & Company.\n\n\nGray, Mary L., and Siddharth Suri. 2019. Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass. HarperCollins.\n\n\nHare, R. M. 1952. The Language of Morals. OUP Oxford.\n\n\nHenrich, Joseph, Robert Boyd, Samuel Bowles, Colin Camerer, Ernst Fehr, Herbert Gintis, and Richard McElreath. 2001. “In Search of Homo Economicus: Behavioral Experiments in 15 Small-Scale Societies.” American Economic Review 91 (2): 73–78. https://doi.org/10.1257/aer.91.2.73.\n\n\nHirschman, Albert O. 1970. Exit, Voice, and Loyalty: Responses to Decline in Firms, Organizations, and States. Harvard University Press.\n\n\n———. 1977. The Passions and the Interests: Political Arguments for Capitalism Before Its Triumph. Princeton University Press.\n\n\nHobbes, Thomas. 1668. Leviathan: With Selected Variants from the Latin Edition of 1668. Hackett Publishing.\n\n\nIngold, David, and Spencer Soper. 2016. “Amazon Doesn’t Consider the Race of Its Customers. Should It?” Bloomberg, April. http://www.bloomberg.com/graphics/2016-amazon-same-day/.\n\n\nJames, William. 1891. “The Moral Philosopher and the Moral Life.” International Journal of Ethics 1 (3): 330–54. https://www.jstor.org/stable/2375309.\n\n\nKahneman, Daniel. 2011. Thinking, Fast and Slow. Farrar, Straus and Giroux.\n\n\nLe Guin, Ursula K. 1973. The Ones Who Walk Away from Omelas: A Story. HarperCollins.\n\n\nMcWhorter, John H. 2014. The Language Hoax: Why the World Looks the Same in Any Language. Oxford University Press.\n\n\nMitchell, Shira, Eric Potash, Solon Barocas, Alexander D’Amour, and Kristian Lum. 2021. “Algorithmic Fairness: Choices, Assumptions, and Definitions.” Annual Review of Statistics and Its Application 8 (1): 141–63. https://doi.org/10.1146/annurev-statistics-042720-125902.\n\n\nMorris, Benny. 1987. The Birth of the Palestinian Refugee Problem, 1947-1949. Cambridge University Press.\n\n\nPappe, Ilan. 2006. The Ethnic Cleansing of Palestine. Simon and Schuster.\n\n\nPellicer, Miquel, and Vimal Ranchhod. 2023. “Understanding the Effects of Racial Classification in Apartheid South Africa.” Journal of Development Economics 160 (January): 102998. https://doi.org/10.1016/j.jdeveco.2022.102998.\n\n\nRawls, John. 1951. “Outline of a Decision Procedure for Ethics.” The Philosophical Review 60 (2): 177–97. https://doi.org/10.2307/2181696.\n\n\n———. 1971. A Theory of Justice: Original Edition. Harvard University Press.\n\n\nRoemer, John E. 1988. Free to Lose: An Introduction to Marxist Economic Philosophy. Harvard University Press.\n\n\nRousseau, Jean-Jacques. 1762. The Social Contract. Geneva: J. M. Dent.\n\n\nSkinner, Quentin. 2012. Visions of Politics, Volume 1: Regarding Method. Cambridge: Cambridge University Press.\n\n\nSt. Augustine. 1874. The Works of Aurelius Augustine: Lectures or Tractates on the Gospel According to St. John, v. 2. T. & T. Clark.\n\n\nWeber, Max. 1904. The Protestant Ethic and the Spirit of Capitalism. Courier Corporation.",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#footnotes",
    "href": "w03/index.html#footnotes",
    "title": "Week 3: Ethical Frameworks, Rights, and Discrimination",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFields and Fields (2012), for example, coined “racecraft” to describe reification of blackness in US… much more on this later!↩︎",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html",
    "href": "w04/index.html",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#so-how-should-we-makechoose-conventions",
    "href": "w04/index.html#so-how-should-we-makechoose-conventions",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "So How Should We Make/Choose Conventions?",
    "text": "So How Should We Make/Choose Conventions?\n\nHobbes (1668): Only way out of “war of all against all” is to surrender all power to one sovereign (the Leviathan)\nRousseau (1762): Social contract\n[Big big ~200 year gap here… can you think of why? Hint: French Revolution in 1789]\nRawls (1971): Social contract behind the “veil of ignorance”\n\nIf we didn’t know where we were going to end up in society, how would we set it up?",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#rawls-veil-of-ignorance",
    "href": "w04/index.html#rawls-veil-of-ignorance",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Rawls’ Veil of Ignorance",
    "text": "Rawls’ Veil of Ignorance\n\nProbably the most important tool for policy whitepapers!\n“Justice as fairness” (next week: fairness in AI 😜)\nWe don’t know whether we’ll be \\(A\\) or \\(B\\) in the intersection game, so we’d choose the traffic light!\nMore profoundly: We don’t know what race, gender, class, ethnicity, sexuality, disability status we’ll have; We don’t know whether we’ll be Israeli or Palestinian; we don’t know whether we’ll own means of production or own only our labor power (and thus have to sell it on a market to survive)… 🤔",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#one-final-reminder",
    "href": "w04/index.html#one-final-reminder",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "One Final Reminder",
    "text": "One Final Reminder\n\nIndustry rule #4080: Cannot “prove” \\(q(x) = \\text{``Algorithm }x\\text{ is fair''}\\)! Only \\(p(x) \\implies q(y)\\):\n\n\\[\n\\underbrace{p(x)}_{\\substack{\\text{Accept ethical} \\\\ \\text{framework }x}} \\implies \\underbrace{q(y)}_{\\substack{\\text{Algorithms should} \\\\ \\text{satisfy condition }y}}\n\\]\n\nBefore: possible ethical frameworks (values for \\(x\\))\nNow: possible fairness criteria (values for \\(y\\))",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#categories-of-fairness-criteria",
    "href": "w04/index.html#categories-of-fairness-criteria",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Categories of Fairness Criteria",
    "text": "Categories of Fairness Criteria\n\nRoughly, approaches to fairness/bias in AI can be categorized as follows:\n\n\nFairness\n\n\n\n\n\n\nContext-Free\n\n\nSingle-Threshold Fairness\nEqual Prediction\nEqual Decision\n\n\n\n\n\n\n\n\n\nContext-Sensitive\n\n\nFairness via Similarity Metric(s)\nCausal Definitions\n\n\n\n\n\n\n\n[Today] Context-Free Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of Machine Learning (you already know much of it, given DSAN 5000!)\nBut easy-to-grasp notion \\(\\neq\\) “good” notion!\nYour job: push yourself to (a) consider what is getting left out of the context-free definitions, and (b) the loopholes that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#laws-often-perfectly-technically-fair",
    "href": "w04/index.html#laws-often-perfectly-technically-fair",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Laws: Often Perfectly “Technically Fair”",
    "text": "Laws: Often Perfectly “Technically Fair”\n\nAh, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!\n\n\n(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)\n\nAnatole France, Le Lys Rouge (France 1894)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#the-brogrammers-criterion",
    "href": "w04/index.html#the-brogrammers-criterion",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "The Brogrammer’s Criterion",
    "text": "The Brogrammer’s Criterion\ndf.drop(columns=[\"race\"], inplace=True)\n\nRacism solved, folks! 🥳🎊🎉 End of the course, have a great rest of your data science career ✌️",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#no-fairness-through-unawareness",
    "href": "w04/index.html#no-fairness-through-unawareness",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "(No) Fairness Through Unawareness",
    "text": "(No) Fairness Through Unawareness\n\nHW1: Using tiny sample (\\(N &lt; 10K\\)) of Florida voter registrations… RandomForestClassifier (default settings, no hyperparameter tuning, no cross-validation, no ensembling with other methods) will predict self-reported race with \\(&gt;90\\%\\) accuracy (in balanced sample) from just surname and county of residence\n\nCan reach \\(70\\text{-}75\\%\\) with just surname or just county of residence\n\nEnd-of-HW1 discussion: Facebook ad matching service provides over 1,000 different user attributes for (micro)targeting\n\n\n\n\nFrom Datta et al. (2017)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#we-can-do-a-bit-better",
    "href": "w04/index.html#we-can-do-a-bit-better",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "We Can Do (A Bit) Better…",
    "text": "We Can Do (A Bit) Better…\n\nUse random variables to model inferences made by an algorithm (or a human!)\n\\(\\implies\\) fairness by statistically equalizing loan rejections, error rate, etc. between groups\nObvious societal drawback: equality does not ameliorate the effects of past injustices (see: police contact vs. trust-in-government plot from last week)\n\nThis one we saw coming, given “context-free” nature!\n\nLess obvious mathematical drawback: impossibility results (because algebra 😳)\n\nRoughly: can’t satisfy [more than] two statistical fairness criteria at once; similar to how setting \\(\\Pr(X) = p\\) also determines \\(\\Pr(\\neg X) = 1 - p\\), or how plugging \\(x = 3\\) into \\(x + y = 5\\) leaves only one possibility \\(y = 2\\)\n\nBUT, “impossibility” \\(\\neq\\) impossibility: (a) one criteria may be “all you need” in given setting; (b) can derive more robust measures by “relaxing” confusion-matrix measures",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#what-the-fairness-measures-will-feel-like-for-now",
    "href": "w04/index.html#what-the-fairness-measures-will-feel-like-for-now",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "What the Fairness Measures Will Feel Like For Now",
    "text": "What the Fairness Measures Will Feel Like For Now\n\n\n\n\n\n\n(They will get more robust and will incorporate context soon, I promise!)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#who-remembers-confusion-matrices",
    "href": "w04/index.html#who-remembers-confusion-matrices",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Who Remembers… 🎉Confusion Matrices!!!🎉",
    "text": "Who Remembers… 🎉Confusion Matrices!!!🎉\n\nTerrifyingly higher stakes than in DSAN 5000, however!\nNow \\(D = 1\\) could literally mean “shoot this person” or “throw this person in jail for life”\n\n\n\n\nFrom Mitchell et al. (2021)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#baby-steps-a-real-world-confusion-matrix",
    "href": "w04/index.html#baby-steps-a-real-world-confusion-matrix",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Baby Steps: A Real-World Confusion Matrix",
    "text": "Baby Steps: A Real-World Confusion Matrix\n\n\n\n\n\n\n\n\n\nLabeled Low-Risk\nLabeled High-Risk\n\n\n\n\nDidn’t Do More Crimes\nTrue Negative\nFalse Positive\n\n\nDid More Crimes\nFalse Negative\nTrue Positive\n\n\n\n\nWhat kinds of causal connections and/or feedback loops might there be between our decision variable (low vs. high risk) and our outcome variable (did vs. didn’t do more crimes)\nWhat types of policy implications might this process have, after it “runs” for several “iterations”?\nWhy might some segments of society, with some shared ethical framework(s), weigh the “costs” of false negatives and false positives differently from other segments of society with different shared ethical framework(s)?\n(Non-rhetorical questions!)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#categories-of-fairness-criteria-1",
    "href": "w04/index.html#categories-of-fairness-criteria-1",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Categories of Fairness Criteria",
    "text": "Categories of Fairness Criteria\n\nRoughly, approaches to fairness/bias in AI can be categorized as follows:\n\n\nFairness\n\n\n\n\n\n\nContext-Free\n\n\nSingle-Threshold Fairness\nEqual Prediction\nEqual Decision\n\n\n\n\n\n\n\n\n\nContext-Sensitive\n\n\nFairness via Similarity Metric(s)\nCausal Definitions\n\n\n\n\n\n\n\n[Today] Context-Free Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of Machine Learning (you already know much of it, given DSAN 5000!)\nBut easy-to-grasp notion \\(\\neq\\) “good” notion!\nYour job: push yourself to (a) consider what is getting left out of the context-free definitions, and (b) the loopholes that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#laws-often-perfectly-technically-fair-1",
    "href": "w04/index.html#laws-often-perfectly-technically-fair-1",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Laws: Often Perfectly “Technically Fair”",
    "text": "Laws: Often Perfectly “Technically Fair”\n\nAh, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!\n\n\n(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)\n\nAnatole France, Le Lys Rouge (France 1894)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#no-fairness-through-unawareness-1",
    "href": "w04/index.html#no-fairness-through-unawareness-1",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "(No) Fairness Through Unawareness",
    "text": "(No) Fairness Through Unawareness\n\nHW1: Using tiny sample (\\(N &lt; 10K\\)) of Florida voter registrations… RandomForestClassifier (default settings, no hyperparameter tuning, no cross-validation, no ensembling with other methods) will predict self-reported race with \\(&gt;90\\%\\) accuracy (in balanced sample) from just surname and county of residence\n\nCan reach \\(70\\text{-}75\\%\\) with just surname or just county of residence\n\nAlso in HW1: Facebook ad matching service provides over 1,000 different user attributes for (micro)targeting\n\n\n\n\nFrom Datta et al. (2017)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#last-one-i-promise",
    "href": "w04/index.html#last-one-i-promise",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Last One I Promise",
    "text": "Last One I Promise\n\n\n\nPredicting self-reported whiteness with 70% accuracy",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#last-one-i-promise-1",
    "href": "w04/index.html#last-one-i-promise-1",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Last One I Promise",
    "text": "Last One I Promise\n\n\n\nPredicting self-reported non-whiteness with 90% accuracy",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#we-can-do-a-bit-better-1",
    "href": "w04/index.html#we-can-do-a-bit-better-1",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "We Can Do (A Bit) Better…",
    "text": "We Can Do (A Bit) Better…\n\nUse random variables to model inferences made by an algorithm (or a human!)\n\\(\\implies\\) fairness by statistically equalizing loan rejections, error rate, etc. between groups\nObvious societal drawback: equality does not ameliorate the effects of past injustices (see: police contact vs. trust-in-government plot from last week)\n\nThis one we saw coming, given “context-free” nature!\n\nLess obvious mathematical drawback: impossibility results (because algebra 😳)\n\nRoughly: can’t satisfy [more than] two statistical fairness criteria at once; similar to how setting \\(\\Pr(X) = p\\) also determines \\(\\Pr(\\text{not }X) = 1 - p\\), or how plugging \\(x = 3\\) into \\(x + y = 5\\) leaves only one possibility \\(y = 2\\)\n\nBUT, “impossibility” \\(\\neq\\) impossibility: (a) one criteria may be “all you need” in given setting; (b) can derive more robust measures by “relaxing” confusion-matrix measures",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#protectedsensitive-attributes",
    "href": "w04/index.html#protectedsensitive-attributes",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Protected/Sensitive Attributes",
    "text": "Protected/Sensitive Attributes\n\nStandard across the literature: Random Variable \\(A_i\\) “encoding” membership in protected/sensitive group. In HW1, for example:\n\n\\[\nA_i = \\begin{cases}\n0 &\\text{if }i\\text{ self-reported ``white''} \\\\\n1 &\\text{if }i\\text{ self-reported ``black''}\n\\end{cases}\n\\]\n\nNotice: choice of mapping into \\(\\{0, 1\\}\\) here non-arbitrary!\nWe want our models/criteria to be descriptively but also normatively robust; e.g.:\nIf (antecedent I hold, though majority in US do not) one believes that ending (much less repairing) centuries of unrelenting white supremacist violence here might require asymmetric race-based policies,\nThen our model should allow different normative labels and differential weights on\n\\[\n\\begin{align*}\n\\Delta &= (\\text{Fairness} \\mid A = 1) - (\\text{Fairness} \\mid A = 0) \\\\\n\\nabla &= (\\text{Fairness} \\mid A = 0) - (\\text{Fairness} \\mid A = 1)\n\\end{align*}\n\\]\ndespite the descriptive fact that \\(\\Delta = -\\nabla\\).",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#where-descriptive-and-normative-become-intertwined",
    "href": "w04/index.html#where-descriptive-and-normative-become-intertwined",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Where Descriptive and Normative Become Intertwined",
    "text": "Where Descriptive and Normative Become Intertwined\n\nAllowing this asymmetry is precisely what enables bring descriptive facts to bear on normative concerns!\nMathematically we can always “flip” the mapping from racial labels into \\(\\{0, 1\\}\\)…\nBut this (in a precise, mathematical sense: namely, isomorphism) implies that we’re treating racial categorization as the same type of phenomenon as driving on left or right side of road (see: prev slides on why we make the descriptive vs. normative distinction)\n(See also: Sweden’s Dagen H!)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#fairness-through-equalized-positive-rates-epr",
    "href": "w04/index.html#fairness-through-equalized-positive-rates-epr",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "“Fairness” Through Equalized Positive Rates (EPR)",
    "text": "“Fairness” Through Equalized Positive Rates (EPR)\n\n \n\n\\[\n\\boxed{\\Pr(D = 1 \\mid A = 0) = \\Pr(D = 1 \\mid A = 1)}\n\\]\n\nThis works specifically for discrete, binary-valued categories\nFor general attributes (whether discrete or continuous!), generalizes to:\n\n\\[\n\\boxed{D \\perp A} \\iff \\Pr(D = d, A = a) = \\Pr(D = d)\\Pr(A = a)\n\\]\n\nImagine you learn that a person received a scholarship (\\(D = 1\\)); [with equalized positive rates], this fact would give you no knowledge about the race (or sex, or class, as desired) \\(A\\) of the individual in question. (DeDeo 2016)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#achieving-equalized-positive-rates",
    "href": "w04/index.html#achieving-equalized-positive-rates",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Achieving Equalized Positive Rates",
    "text": "Achieving Equalized Positive Rates\n\nThe good news: if we want this, there is a closed-form solution: take your datapoints \\(X_i\\) and re-weigh each point to obtain \\(\\widetilde{X}_i = w_iX_i\\), where\n\\[\n  w_i = \\frac{\\Pr(Y_i = 1)}{\\Pr(Y_i = 1 \\mid A_i = 1)}\n  \\]\nand use derived dataset \\(\\widetilde{X}_i\\) to learn \\(r(X)\\) (via ML algorithm)… Why does this work?\nLet \\(\\mathcal{X}_{\\text{fair}}\\) be the set of all possible reweighted versions of \\(X_i\\) ensuring \\(Y_i \\perp A_i\\). Then\n\n\\[\n\\widetilde{X}_i = \\min_{X_i' \\in \\mathcal{X}_{\\text{fair}}}\\textsf{distance}(X_i', X_i) = \\min_{X_i' \\in \\mathcal{X}_{\\text{fair}}}\\underbrace{KL(X_i' \\| X_i)}_{\\text{Relative entropy!}}\n\\]\n\nThe bad news: nobody in the fairness in AI community read DeDeo (2016), which proves this using information theory? Idk. It has a total of 22 citations 😐",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#fairness-through-equalized-error-rates",
    "href": "w04/index.html#fairness-through-equalized-error-rates",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "“Fairness” Through Equalized Error Rates",
    "text": "“Fairness” Through Equalized Error Rates\n\nEqualized positive rates didn’t take outcomes \\(Y_i\\) into account…\n\n(Even if \\(A_i = 1 \\Rightarrow Y_i = 1, A_i = 0 \\Rightarrow Y_i = 0\\), we’d have to choose \\(\\widehat{Y}_i = c\\))\n\nThis time, we consider the outcome \\(Y\\) that\nEqualized False Positive Rate (EFPR):\n\n\\[\n\\Pr(D = 1 \\mid Y = 0, A = 0) = \\Pr(D = 1 \\mid Y = 0, A = 1)\n\\]\n\nEqualized False Negative Rate (EFNR):\n\n\\[\n\\Pr(D = 0 \\mid Y = 1, A = 0) = \\Pr(D = 0 \\mid Y = 1, A = 1)\n\\]\n\nFor general (non-binary) attributes: \\((D \\perp A) \\mid Y\\):\n\n\\[\n\\Pr(D = d, A = a \\mid Y = y) = \\Pr(D = d \\mid Y = y)\\Pr(A = a \\mid Y = y)\n\\]",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#less-equations-please",
    "href": "w04/index.html#less-equations-please",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "⚠️ LESS EQUATIONS PLEASE! 😤",
    "text": "⚠️ LESS EQUATIONS PLEASE! 😤\n\nDepending on your background and/or learning style (say, visual vs. auditory), you may be able to look at equations on previous two slides and “see” what they’re “saying”\nIf your brain works similarly to mine, however, your eyes glazed over, you began dissociating, planning an escape route, etc., the moment \\(&gt; 2\\) variables appeared\nIf you’re in the latter group, welcome to the cult of Probabilistic Graphical Models 😈\n\n\n\n\nYour first PGM, illustrating hypothesized causal relationships between three random variables \\(Y\\) (outcome), \\(D\\) (decision), and \\(A\\) (protected attribute). The \\(Y\\) node is shaded to indicate that it is an observed value in our model, rendering the unobserved values \\(D\\) and \\(A\\) independent conditional on it. If I was elected Emperor of Math, equations would be abolished in favor of PGMs.",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#section",
    "href": "w04/index.html#section",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "",
    "text": "Equalized False Negative/Positive Rates\n\n\n\n\nOur first measure that 🥳🎉matches a principle of justice in society!!!🕺🪩\nBlackstone’s Ratio: “It is better that ten guilty persons escape, than that one innocent suffers.” (Blackstone 1769)\n(…break time!)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#back-to-equalized-error-rates",
    "href": "w04/index.html#back-to-equalized-error-rates",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Back to Equalized Error Rates",
    "text": "Back to Equalized Error Rates\n\nBlackstone’s Ratio: “It is better that ten guilty persons escape, than that one innocent suffers.” (Blackstone 1769)\nMathematically \\(\\Rightarrow \\text{Cost}(FPR) = 10\\cdot \\text{Cost}(FNR)\\)\nLegally \\(\\Rightarrow\\) beyond reasonable doubt standard for conviction\nEFPR \\(\\iff\\) rates of false conviction should be the same for everyone, including members of different racial groups.\n\nViolated when black people are disproportionately likely to be incorrectly convicted, as if a lower evidentiary standard were applied to black people.",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#one-final-context-free-criterion-calibration",
    "href": "w04/index.html#one-final-context-free-criterion-calibration",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "One Final Context-Free Criterion: Calibration",
    "text": "One Final Context-Free Criterion: Calibration\n\nA risk function \\(r(X)\\) is calibrated if\n\n\\[\n\\Pr(Y = 1 \\mid r(X) = v_r) = v_r\n\\]\n\n(Sweeping a lot of details under the rug), I see this one as: the risk function “tracks” real-world probabilities\nThen, \\(r(X)\\) is calibrated by group if\n\n\\[\n\\Pr(Y = y \\mid r(X) = v_r, A = a) = v_r\n\\]",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#impossibility-results",
    "href": "w04/index.html#impossibility-results",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Impossibility Results",
    "text": "Impossibility Results\n\ntldr: We cannot possibly achieve all three of equalized positive rates (often also termed “anti-classification”), classification parity, and calibration (regardless of base rates)\nMore alarmingly: We can’t even achieve both classification parity and calibration, except in the special case of equal base rates",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#impossibility-vs.-impossibility",
    "href": "w04/index.html#impossibility-vs.-impossibility",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "“Impossibility” vs. Impossibility",
    "text": "“Impossibility” vs. Impossibility\n\nSometimes “impossibility results” are, for all intents and purposes, mathematical curiosities: often there’s some pragmatic way of getting around them\nExample: “Arrow’s Impossibility Theorem”\n\n[In theory] It is mathematically impossible to aggregate individual preferences into societal preferences\n[The catch] True only if people are restricted to ordinal preferences: “I prefer \\(x\\) to \\(y\\).” No more information allowed\n[The way around it] Allow people to indicate the magnitude of their preferences: “I prefer \\(x\\) 5 times more than \\(y\\)”\n\nIn this case, though, there are direct and (often) unavoidable real-world barriers that fairness impossibility imposes 😕",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#arrows-impossibility-theorem",
    "href": "w04/index.html#arrows-impossibility-theorem",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Arrow’s Impossibility Theorem",
    "text": "Arrow’s Impossibility Theorem\n\nAziza, Bogdan, and Charles are competing in a fitness test with four events. Goal: determine who is most fit overall\n\n\n\n\n\nRun\nJump\nHurdle\nWeights\n\n\n\n\nAziza\n10.1”\n6.0’\n40”\n150 lb\n\n\nBogdan\n9.2”\n5.9’\n42”\n140 lb\n\n\nCharles\n10.0”\n6.1’\n39”\n145 lb\n\n\n\n\nWe can rank unambiguously on individual events: Jump: Charles \\(\\succ_J\\) Aziza \\(\\succ_J\\) Bogdan\nNow, axioms for aggregation:\n\n\\(\\text{WP}\\) (Weak Pareto Optimality): if \\(x \\succ_i y\\) for all events \\(i\\), \\(x \\succ y\\)\n\\(\\text{IIA}\\) (Independence of Irrelevant Alternatives): If a fourth competitor enters, but Aziza and Bogdan still have the same relative standing on all events, their relative standing overall should not change\n\nLong story short: only aggregation that can satisfy these is “dictatorship”: choose one event, give it importance of 100%, the rest have importance 0% 😰",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#propublica-vs.-northpointe",
    "href": "w04/index.html#propublica-vs.-northpointe",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "ProPublica vs. Northpointe",
    "text": "ProPublica vs. Northpointe\n\nThis is… an example with 1000s of books and papers and discussions around it! (A red flag 🚩, since, obsession with one example may conceal much wider range of issues!)\nBut, tldr, Northpointe created a ML algorithm called COMPAS, used by court systems all over the US to predict “risk” of arrestees\nIn 2016, ProPublica published results from an investigative report documenting COMPAS’s racial discrimination, in the form of violating equal error rates between black and white arrestees\nNorthpointe responded that COMPAS does not discriminate, as it satisfies calibration\nPeople have argued about who is “right” for 8 years, with some progress, but… not a lot",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#so-what-do-we-do",
    "href": "w04/index.html#so-what-do-we-do",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "So… What Do We Do?",
    "text": "So… What Do We Do?\n\nOne option: argue about which of the two definitions is “better” for the next 100 years (what is the best way to give food to the poor?)\n\n\nIt appears to reveal an unfortunate but inexorable fact about our world: we must choose between two intuitively appealing ways to understand fairness in ML. Many scholars have done just that, defending either ProPublica’s or Northpointe’s definitions against what they see as the misguided alternative. (Simons 2023)\n\n\nAnother option: study and then work to ameliorate the social conditions which force us into this realm of mathematical impossibility (why do the poor have no food?)\n\n\nThe impossibility result is about much more than math. [It occurs because] the underlying outcome is distributed unevenly in society. This is a fact about society, not mathematics, and requires engaging with a complex, checkered history of systemic racism in the US. Predicting an outcome whose distribution is shaped by this history requires tradeoffs because the inequalities and injustices are encoded in data—in this case, because America has criminalized Blackness for as long as America has existed.",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#why-not-both",
    "href": "w04/index.html#why-not-both",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Why Not Both??",
    "text": "Why Not Both??\n\nOn the one hand: yes, both! On the other hand: fallacy of the “middle ground”\nWe’re back at descriptive vs. normative:\n\nDescriptively, given 100 values \\(v_1, \\ldots, v_{100}\\), their mean may be a good way to summarize, if we have to choose a single number\nBut, normatively, imagine that these are opinions that people hold about fairness.\nNow, if it’s the US South in 1860 and \\(v_i\\) represents person \\(i\\)’s approval of slavery, from a sample of 100 people, then approx. 97 of the \\(v_i\\)’s are “does not disapprove” (Rousey 2001) — in this case, normatively, is the mean \\(0.97\\) the “correct” answer?\n\nWe have another case where, like the “grass is green” vs. “grass ought to be green” example, we cannot just “import” our logical/mathematical tools from the former to solve the latter! (However: this does not mean they are useless! This is the fallacy of the excluded middle, sort of the opposite of the fallacy of the middle ground)\nThis is why we have ethical frameworks in the first place! Going back to Rawls: “97% of Americans think black people shouldn’t have rights”  \\(\\nimplies\\)“black people shouldn’t have rights”, since rights are a primary good",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#references",
    "href": "w04/index.html#references",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "References",
    "text": "References\n\n\nBlackstone, William. 1769. Commentaries on the Laws of England, Volume 2: A Facsimile of the First Edition of 1765-1769. University of Chicago Press.\n\n\nDatta, Anupam, Matt Fredrikson, Gihyuk Ko, Piotr Mardziel, and Shayak Sen. 2017. “Proxy Non-Discrimination in Data-Driven Systems.” arXiv. https://doi.org/10.48550/arXiv.1707.08120.\n\n\nDeDeo, Simon. 2016. “Wrong Side of the Tracks: Big Data and Protected Categories.” arXiv. https://doi.org/10.48550/arXiv.1412.4643.\n\n\nFrance, Anatole. 1894. Le Lys Rouge (The Red Lily). G. Wells.\n\n\nHobbes, Thomas. 1668. Leviathan: With Selected Variants from the Latin Edition of 1668. Hackett Publishing.\n\n\nMitchell, Shira, Eric Potash, Solon Barocas, Alexander D’Amour, and Kristian Lum. 2021. “Algorithmic Fairness: Choices, Assumptions, and Definitions.” Annual Review of Statistics and Its Application 8 (1): 141–63. https://doi.org/10.1146/annurev-statistics-042720-125902.\n\n\nRawls, John. 1971. A Theory of Justice: Original Edition. Harvard University Press.\n\n\nRousey, Dennis C. 2001. “Friends and Foes of Slavery: Foreigners and Northerners in the Old South.” Journal of Social History 35 (2): 373–96. https://www.jstor.org/stable/3790193.\n\n\nRousseau, Jean-Jacques. 1762. The Social Contract. Geneva: J. M. Dent.\n\n\nSimons, Josh. 2023. Algorithms for the People: Democracy in the Age of AI. Princeton University Press.",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/slides.html#so-how-should-we-makechoose-conventions",
    "href": "w04/slides.html#so-how-should-we-makechoose-conventions",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "So How Should We Make/Choose Conventions?",
    "text": "So How Should We Make/Choose Conventions?\n\nHobbes (1668): Only way out of “war of all against all” is to surrender all power to one sovereign (the Leviathan)\nRousseau (1762): Social contract\n[Big big ~200 year gap here… can you think of why? Hint: French Revolution in 1789]\nRawls (1971): Social contract behind the “veil of ignorance”\n\nIf we didn’t know where we were going to end up in society, how would we set it up?"
  },
  {
    "objectID": "w04/slides.html#rawls-veil-of-ignorance",
    "href": "w04/slides.html#rawls-veil-of-ignorance",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Rawls’ Veil of Ignorance",
    "text": "Rawls’ Veil of Ignorance\n\nProbably the most important tool for policy whitepapers!\n“Justice as fairness” (next week: fairness in AI 😜)\nWe don’t know whether we’ll be \\(A\\) or \\(B\\) in the intersection game, so we’d choose the traffic light!\nMore profoundly: We don’t know what race, gender, class, ethnicity, sexuality, disability status we’ll have; We don’t know whether we’ll be Israeli or Palestinian; we don’t know whether we’ll own means of production or own only our labor power (and thus have to sell it on a market to survive)… 🤔"
  },
  {
    "objectID": "w04/slides.html#one-final-reminder",
    "href": "w04/slides.html#one-final-reminder",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "One Final Reminder",
    "text": "One Final Reminder\n\nIndustry rule #4080: Cannot “prove” \\(q(x) = \\text{``Algorithm }x\\text{ is fair''}\\)! Only \\(p(x) \\implies q(y)\\):\n\n\\[\n\\underbrace{p(x)}_{\\substack{\\text{Accept ethical} \\\\ \\text{framework }x}} \\implies \\underbrace{q(y)}_{\\substack{\\text{Algorithms should} \\\\ \\text{satisfy condition }y}}\n\\]\n\nBefore: possible ethical frameworks (values for \\(x\\))\nNow: possible fairness criteria (values for \\(y\\))"
  },
  {
    "objectID": "w04/slides.html#categories-of-fairness-criteria",
    "href": "w04/slides.html#categories-of-fairness-criteria",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Categories of Fairness Criteria",
    "text": "Categories of Fairness Criteria\n\nRoughly, approaches to fairness/bias in AI can be categorized as follows:\n\n\nFairness\n\n\n\n\n\n\nContext-Free\n\n\nSingle-Threshold Fairness\nEqual Prediction\nEqual Decision\n\n\n\n\n\n\n\n\n\nContext-Sensitive\n\n\nFairness via Similarity Metric(s)\nCausal Definitions\n\n\n\n\n\n\n[Today] Context-Free Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of Machine Learning (you already know much of it, given DSAN 5000!)\nBut easy-to-grasp notion \\(\\neq\\) “good” notion!\nYour job: push yourself to (a) consider what is getting left out of the context-free definitions, and (b) the loopholes that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”"
  },
  {
    "objectID": "w04/slides.html#laws-often-perfectly-technically-fair",
    "href": "w04/slides.html#laws-often-perfectly-technically-fair",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Laws: Often Perfectly “Technically Fair”",
    "text": "Laws: Often Perfectly “Technically Fair”\n\nAh, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!\n\n\n(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)\n\nAnatole France, Le Lys Rouge (France 1894)"
  },
  {
    "objectID": "w04/slides.html#the-brogrammers-criterion",
    "href": "w04/slides.html#the-brogrammers-criterion",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "The Brogrammer’s Criterion",
    "text": "The Brogrammer’s Criterion\ndf.drop(columns=[\"race\"], inplace=True)\n\nRacism solved, folks! 🥳🎊🎉 End of the course, have a great rest of your data science career ✌️"
  },
  {
    "objectID": "w04/slides.html#no-fairness-through-unawareness",
    "href": "w04/slides.html#no-fairness-through-unawareness",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "(No) Fairness Through Unawareness",
    "text": "(No) Fairness Through Unawareness\n\nHW1: Using tiny sample (\\(N &lt; 10K\\)) of Florida voter registrations… RandomForestClassifier (default settings, no hyperparameter tuning, no cross-validation, no ensembling with other methods) will predict self-reported race with \\(&gt;90\\%\\) accuracy (in balanced sample) from just surname and county of residence\n\nCan reach \\(70\\text{-}75\\%\\) with just surname or just county of residence\n\nEnd-of-HW1 discussion: Facebook ad matching service provides over 1,000 different user attributes for (micro)targeting\n\n\nFrom Datta et al. (2017)"
  },
  {
    "objectID": "w04/slides.html#we-can-do-a-bit-better",
    "href": "w04/slides.html#we-can-do-a-bit-better",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "We Can Do (A Bit) Better…",
    "text": "We Can Do (A Bit) Better…\n\nUse random variables to model inferences made by an algorithm (or a human!)\n\\(\\implies\\) fairness by statistically equalizing loan rejections, error rate, etc. between groups\nObvious societal drawback: equality does not ameliorate the effects of past injustices (see: police contact vs. trust-in-government plot from last week)\n\nThis one we saw coming, given “context-free” nature!\n\nLess obvious mathematical drawback: impossibility results (because algebra 😳)\n\nRoughly: can’t satisfy [more than] two statistical fairness criteria at once; similar to how setting \\(\\Pr(X) = p\\) also determines \\(\\Pr(\\neg X) = 1 - p\\), or how plugging \\(x = 3\\) into \\(x + y = 5\\) leaves only one possibility \\(y = 2\\)\n\nBUT, “impossibility” \\(\\neq\\) impossibility: (a) one criteria may be “all you need” in given setting; (b) can derive more robust measures by “relaxing” confusion-matrix measures"
  },
  {
    "objectID": "w04/slides.html#what-the-fairness-measures-will-feel-like-for-now",
    "href": "w04/slides.html#what-the-fairness-measures-will-feel-like-for-now",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "What the Fairness Measures Will Feel Like For Now",
    "text": "What the Fairness Measures Will Feel Like For Now\n\n\n(They will get more robust and will incorporate context soon, I promise!)"
  },
  {
    "objectID": "w04/slides.html#who-remembers-confusion-matrices",
    "href": "w04/slides.html#who-remembers-confusion-matrices",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Who Remembers… 🎉Confusion Matrices!!!🎉",
    "text": "Who Remembers… 🎉Confusion Matrices!!!🎉\n\nTerrifyingly higher stakes than in DSAN 5000, however!\nNow \\(D = 1\\) could literally mean “shoot this person” or “throw this person in jail for life”\n\n\nFrom Mitchell et al. (2021)"
  },
  {
    "objectID": "w04/slides.html#baby-steps-a-real-world-confusion-matrix",
    "href": "w04/slides.html#baby-steps-a-real-world-confusion-matrix",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Baby Steps: A Real-World Confusion Matrix",
    "text": "Baby Steps: A Real-World Confusion Matrix\n\n\n\n\n\n\n\n\n\nLabeled Low-Risk\nLabeled High-Risk\n\n\n\n\nDidn’t Do More Crimes\nTrue Negative\nFalse Positive\n\n\nDid More Crimes\nFalse Negative\nTrue Positive\n\n\n\n\nWhat kinds of causal connections and/or feedback loops might there be between our decision variable (low vs. high risk) and our outcome variable (did vs. didn’t do more crimes)\nWhat types of policy implications might this process have, after it “runs” for several “iterations”?\nWhy might some segments of society, with some shared ethical framework(s), weigh the “costs” of false negatives and false positives differently from other segments of society with different shared ethical framework(s)?\n(Non-rhetorical questions!)"
  },
  {
    "objectID": "w04/slides.html#categories-of-fairness-criteria-1",
    "href": "w04/slides.html#categories-of-fairness-criteria-1",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Categories of Fairness Criteria",
    "text": "Categories of Fairness Criteria\n\nRoughly, approaches to fairness/bias in AI can be categorized as follows:\n\n\nFairness\n\n\n\n\n\n\nContext-Free\n\n\nSingle-Threshold Fairness\nEqual Prediction\nEqual Decision\n\n\n\n\n\n\n\n\n\nContext-Sensitive\n\n\nFairness via Similarity Metric(s)\nCausal Definitions\n\n\n\n\n\n\n[Today] Context-Free Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of Machine Learning (you already know much of it, given DSAN 5000!)\nBut easy-to-grasp notion \\(\\neq\\) “good” notion!\nYour job: push yourself to (a) consider what is getting left out of the context-free definitions, and (b) the loopholes that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”"
  },
  {
    "objectID": "w04/slides.html#laws-often-perfectly-technically-fair-1",
    "href": "w04/slides.html#laws-often-perfectly-technically-fair-1",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Laws: Often Perfectly “Technically Fair”",
    "text": "Laws: Often Perfectly “Technically Fair”\n\nAh, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!\n\n\n(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)\n\nAnatole France, Le Lys Rouge (France 1894)"
  },
  {
    "objectID": "w04/slides.html#no-fairness-through-unawareness-1",
    "href": "w04/slides.html#no-fairness-through-unawareness-1",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "(No) Fairness Through Unawareness",
    "text": "(No) Fairness Through Unawareness\n\nHW1: Using tiny sample (\\(N &lt; 10K\\)) of Florida voter registrations… RandomForestClassifier (default settings, no hyperparameter tuning, no cross-validation, no ensembling with other methods) will predict self-reported race with \\(&gt;90\\%\\) accuracy (in balanced sample) from just surname and county of residence\n\nCan reach \\(70\\text{-}75\\%\\) with just surname or just county of residence\n\nAlso in HW1: Facebook ad matching service provides over 1,000 different user attributes for (micro)targeting\n\n\nFrom Datta et al. (2017)"
  },
  {
    "objectID": "w04/slides.html#last-one-i-promise",
    "href": "w04/slides.html#last-one-i-promise",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Last One I Promise",
    "text": "Last One I Promise\n\nPredicting self-reported whiteness with 70% accuracy"
  },
  {
    "objectID": "w04/slides.html#last-one-i-promise-1",
    "href": "w04/slides.html#last-one-i-promise-1",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Last One I Promise",
    "text": "Last One I Promise\n\nPredicting self-reported non-whiteness with 90% accuracy"
  },
  {
    "objectID": "w04/slides.html#we-can-do-a-bit-better-1",
    "href": "w04/slides.html#we-can-do-a-bit-better-1",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "We Can Do (A Bit) Better…",
    "text": "We Can Do (A Bit) Better…\n\nUse random variables to model inferences made by an algorithm (or a human!)\n\\(\\implies\\) fairness by statistically equalizing loan rejections, error rate, etc. between groups\nObvious societal drawback: equality does not ameliorate the effects of past injustices (see: police contact vs. trust-in-government plot from last week)\n\nThis one we saw coming, given “context-free” nature!\n\nLess obvious mathematical drawback: impossibility results (because algebra 😳)\n\nRoughly: can’t satisfy [more than] two statistical fairness criteria at once; similar to how setting \\(\\Pr(X) = p\\) also determines \\(\\Pr(\\text{not }X) = 1 - p\\), or how plugging \\(x = 3\\) into \\(x + y = 5\\) leaves only one possibility \\(y = 2\\)\n\nBUT, “impossibility” \\(\\neq\\) impossibility: (a) one criteria may be “all you need” in given setting; (b) can derive more robust measures by “relaxing” confusion-matrix measures"
  },
  {
    "objectID": "w04/slides.html#protectedsensitive-attributes",
    "href": "w04/slides.html#protectedsensitive-attributes",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Protected/Sensitive Attributes",
    "text": "Protected/Sensitive Attributes\n\nStandard across the literature: Random Variable \\(A_i\\) “encoding” membership in protected/sensitive group. In HW1, for example:\n\n\\[\nA_i = \\begin{cases}\n0 &\\text{if }i\\text{ self-reported ``white''} \\\\\n1 &\\text{if }i\\text{ self-reported ``black''}\n\\end{cases}\n\\]\n\nNotice: choice of mapping into \\(\\{0, 1\\}\\) here non-arbitrary!\nWe want our models/criteria to be descriptively but also normatively robust; e.g.:\nIf (antecedent I hold, though majority in US do not) one believes that ending (much less repairing) centuries of unrelenting white supremacist violence here might require asymmetric race-based policies,\nThen our model should allow different normative labels and differential weights on\n\\[\n\\begin{align*}\n\\Delta &= (\\text{Fairness} \\mid A = 1) - (\\text{Fairness} \\mid A = 0) \\\\\n\\nabla &= (\\text{Fairness} \\mid A = 0) - (\\text{Fairness} \\mid A = 1)\n\\end{align*}\n\\]\ndespite the descriptive fact that \\(\\Delta = -\\nabla\\)."
  },
  {
    "objectID": "w04/slides.html#where-descriptive-and-normative-become-intertwined",
    "href": "w04/slides.html#where-descriptive-and-normative-become-intertwined",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Where Descriptive and Normative Become Intertwined",
    "text": "Where Descriptive and Normative Become Intertwined\n\nAllowing this asymmetry is precisely what enables bring descriptive facts to bear on normative concerns!\nMathematically we can always “flip” the mapping from racial labels into \\(\\{0, 1\\}\\)…\nBut this (in a precise, mathematical sense: namely, isomorphism) implies that we’re treating racial categorization as the same type of phenomenon as driving on left or right side of road (see: prev slides on why we make the descriptive vs. normative distinction)\n(See also: Sweden’s Dagen H!)"
  },
  {
    "objectID": "w04/slides.html#fairness-through-equalized-positive-rates-epr",
    "href": "w04/slides.html#fairness-through-equalized-positive-rates-epr",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "“Fairness” Through Equalized Positive Rates (EPR)",
    "text": "“Fairness” Through Equalized Positive Rates (EPR)\n\n \n\n\\[\n\\boxed{\\Pr(D = 1 \\mid A = 0) = \\Pr(D = 1 \\mid A = 1)}\n\\]\n\nThis works specifically for discrete, binary-valued categories\nFor general attributes (whether discrete or continuous!), generalizes to:\n\n\\[\n\\boxed{D \\perp A} \\iff \\Pr(D = d, A = a) = \\Pr(D = d)\\Pr(A = a)\n\\]\n\nImagine you learn that a person received a scholarship (\\(D = 1\\)); [with equalized positive rates], this fact would give you no knowledge about the race (or sex, or class, as desired) \\(A\\) of the individual in question. (DeDeo 2016)"
  },
  {
    "objectID": "w04/slides.html#achieving-equalized-positive-rates",
    "href": "w04/slides.html#achieving-equalized-positive-rates",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Achieving Equalized Positive Rates",
    "text": "Achieving Equalized Positive Rates\n\nThe good news: if we want this, there is a closed-form solution: take your datapoints \\(X_i\\) and re-weigh each point to obtain \\(\\widetilde{X}_i = w_iX_i\\), where\n\\[\n  w_i = \\frac{\\Pr(Y_i = 1)}{\\Pr(Y_i = 1 \\mid A_i = 1)}\n  \\]\nand use derived dataset \\(\\widetilde{X}_i\\) to learn \\(r(X)\\) (via ML algorithm)… Why does this work?\nLet \\(\\mathcal{X}_{\\text{fair}}\\) be the set of all possible reweighted versions of \\(X_i\\) ensuring \\(Y_i \\perp A_i\\). Then\n\n\\[\n\\widetilde{X}_i = \\min_{X_i' \\in \\mathcal{X}_{\\text{fair}}}\\textsf{distance}(X_i', X_i) = \\min_{X_i' \\in \\mathcal{X}_{\\text{fair}}}\\underbrace{KL(X_i' \\| X_i)}_{\\text{Relative entropy!}}\n\\]\n\nThe bad news: nobody in the fairness in AI community read DeDeo (2016), which proves this using information theory? Idk. It has a total of 22 citations 😐"
  },
  {
    "objectID": "w04/slides.html#fairness-through-equalized-error-rates",
    "href": "w04/slides.html#fairness-through-equalized-error-rates",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "“Fairness” Through Equalized Error Rates",
    "text": "“Fairness” Through Equalized Error Rates\n\nEqualized positive rates didn’t take outcomes \\(Y_i\\) into account…\n\n(Even if \\(A_i = 1 \\Rightarrow Y_i = 1, A_i = 0 \\Rightarrow Y_i = 0\\), we’d have to choose \\(\\widehat{Y}_i = c\\))\n\nThis time, we consider the outcome \\(Y\\) that\nEqualized False Positive Rate (EFPR):\n\n\\[\n\\Pr(D = 1 \\mid Y = 0, A = 0) = \\Pr(D = 1 \\mid Y = 0, A = 1)\n\\]\n\nEqualized False Negative Rate (EFNR):\n\n\\[\n\\Pr(D = 0 \\mid Y = 1, A = 0) = \\Pr(D = 0 \\mid Y = 1, A = 1)\n\\]\n\nFor general (non-binary) attributes: \\((D \\perp A) \\mid Y\\):\n\n\\[\n\\Pr(D = d, A = a \\mid Y = y) = \\Pr(D = d \\mid Y = y)\\Pr(A = a \\mid Y = y)\n\\]"
  },
  {
    "objectID": "w04/slides.html#less-equations-please",
    "href": "w04/slides.html#less-equations-please",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "⚠️ LESS EQUATIONS PLEASE! 😤",
    "text": "⚠️ LESS EQUATIONS PLEASE! 😤\n\nDepending on your background and/or learning style (say, visual vs. auditory), you may be able to look at equations on previous two slides and “see” what they’re “saying”\nIf your brain works similarly to mine, however, your eyes glazed over, you began dissociating, planning an escape route, etc., the moment \\(&gt; 2\\) variables appeared\nIf you’re in the latter group, welcome to the cult of Probabilistic Graphical Models 😈\n\n\nYour first PGM, illustrating hypothesized causal relationships between three random variables \\(Y\\) (outcome), \\(D\\) (decision), and \\(A\\) (protected attribute). The \\(Y\\) node is shaded to indicate that it is an observed value in our model, rendering the unobserved values \\(D\\) and \\(A\\) independent conditional on it. If I was elected Emperor of Math, equations would be abolished in favor of PGMs."
  },
  {
    "objectID": "w04/slides.html#section",
    "href": "w04/slides.html#section",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "",
    "text": "Equalized False Negative/Positive Rates\n\n\n\nOur first measure that 🥳🎉matches a principle of justice in society!!!🕺🪩\nBlackstone’s Ratio: “It is better that ten guilty persons escape, than that one innocent suffers.” (Blackstone 1769)\n(…break time!)"
  },
  {
    "objectID": "w04/slides.html#back-to-equalized-error-rates",
    "href": "w04/slides.html#back-to-equalized-error-rates",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Back to Equalized Error Rates",
    "text": "Back to Equalized Error Rates\n\nBlackstone’s Ratio: “It is better that ten guilty persons escape, than that one innocent suffers.” (Blackstone 1769)\nMathematically \\(\\Rightarrow \\text{Cost}(FPR) = 10\\cdot \\text{Cost}(FNR)\\)\nLegally \\(\\Rightarrow\\) beyond reasonable doubt standard for conviction\nEFPR \\(\\iff\\) rates of false conviction should be the same for everyone, including members of different racial groups.\n\nViolated when black people are disproportionately likely to be incorrectly convicted, as if a lower evidentiary standard were applied to black people."
  },
  {
    "objectID": "w04/slides.html#one-final-context-free-criterion-calibration",
    "href": "w04/slides.html#one-final-context-free-criterion-calibration",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "One Final Context-Free Criterion: Calibration",
    "text": "One Final Context-Free Criterion: Calibration\n\nA risk function \\(r(X)\\) is calibrated if\n\n\\[\n\\Pr(Y = 1 \\mid r(X) = v_r) = v_r\n\\]\n\n(Sweeping a lot of details under the rug), I see this one as: the risk function “tracks” real-world probabilities\nThen, \\(r(X)\\) is calibrated by group if\n\n\\[\n\\Pr(Y = y \\mid r(X) = v_r, A = a) = v_r\n\\]"
  },
  {
    "objectID": "w04/slides.html#impossibility-results",
    "href": "w04/slides.html#impossibility-results",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Impossibility Results",
    "text": "Impossibility Results\n\ntldr: We cannot possibly achieve all three of equalized positive rates (often also termed “anti-classification”), classification parity, and calibration (regardless of base rates)\nMore alarmingly: We can’t even achieve both classification parity and calibration, except in the special case of equal base rates"
  },
  {
    "objectID": "w04/slides.html#impossibility-vs.-impossibility",
    "href": "w04/slides.html#impossibility-vs.-impossibility",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "“Impossibility” vs. Impossibility",
    "text": "“Impossibility” vs. Impossibility\n\nSometimes “impossibility results” are, for all intents and purposes, mathematical curiosities: often there’s some pragmatic way of getting around them\nExample: “Arrow’s Impossibility Theorem”\n\n[In theory] It is mathematically impossible to aggregate individual preferences into societal preferences\n[The catch] True only if people are restricted to ordinal preferences: “I prefer \\(x\\) to \\(y\\).” No more information allowed\n[The way around it] Allow people to indicate the magnitude of their preferences: “I prefer \\(x\\) 5 times more than \\(y\\)”\n\nIn this case, though, there are direct and (often) unavoidable real-world barriers that fairness impossibility imposes 😕"
  },
  {
    "objectID": "w04/slides.html#arrows-impossibility-theorem",
    "href": "w04/slides.html#arrows-impossibility-theorem",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Arrow’s Impossibility Theorem",
    "text": "Arrow’s Impossibility Theorem\n\nAziza, Bogdan, and Charles are competing in a fitness test with four events. Goal: determine who is most fit overall\n\n\n\n\n\nRun\nJump\nHurdle\nWeights\n\n\n\n\nAziza\n10.1”\n6.0’\n40”\n150 lb\n\n\nBogdan\n9.2”\n5.9’\n42”\n140 lb\n\n\nCharles\n10.0”\n6.1’\n39”\n145 lb\n\n\n\n\nWe can rank unambiguously on individual events: Jump: Charles \\(\\succ_J\\) Aziza \\(\\succ_J\\) Bogdan\nNow, axioms for aggregation:\n\n\\(\\text{WP}\\) (Weak Pareto Optimality): if \\(x \\succ_i y\\) for all events \\(i\\), \\(x \\succ y\\)\n\\(\\text{IIA}\\) (Independence of Irrelevant Alternatives): If a fourth competitor enters, but Aziza and Bogdan still have the same relative standing on all events, their relative standing overall should not change\n\nLong story short: only aggregation that can satisfy these is “dictatorship”: choose one event, give it importance of 100%, the rest have importance 0% 😰"
  },
  {
    "objectID": "w04/slides.html#propublica-vs.-northpointe",
    "href": "w04/slides.html#propublica-vs.-northpointe",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "ProPublica vs. Northpointe",
    "text": "ProPublica vs. Northpointe\n\nThis is… an example with 1000s of books and papers and discussions around it! (A red flag 🚩, since, obsession with one example may conceal much wider range of issues!)\nBut, tldr, Northpointe created a ML algorithm called COMPAS, used by court systems all over the US to predict “risk” of arrestees\nIn 2016, ProPublica published results from an investigative report documenting COMPAS’s racial discrimination, in the form of violating equal error rates between black and white arrestees\nNorthpointe responded that COMPAS does not discriminate, as it satisfies calibration\nPeople have argued about who is “right” for 8 years, with some progress, but… not a lot"
  },
  {
    "objectID": "w04/slides.html#so-what-do-we-do",
    "href": "w04/slides.html#so-what-do-we-do",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "So… What Do We Do?",
    "text": "So… What Do We Do?\n\nOne option: argue about which of the two definitions is “better” for the next 100 years (what is the best way to give food to the poor?)\n\n\nIt appears to reveal an unfortunate but inexorable fact about our world: we must choose between two intuitively appealing ways to understand fairness in ML. Many scholars have done just that, defending either ProPublica’s or Northpointe’s definitions against what they see as the misguided alternative. (Simons 2023)\n\n\nAnother option: study and then work to ameliorate the social conditions which force us into this realm of mathematical impossibility (why do the poor have no food?)\n\n\nThe impossibility result is about much more than math. [It occurs because] the underlying outcome is distributed unevenly in society. This is a fact about society, not mathematics, and requires engaging with a complex, checkered history of systemic racism in the US. Predicting an outcome whose distribution is shaped by this history requires tradeoffs because the inequalities and injustices are encoded in data—in this case, because America has criminalized Blackness for as long as America has existed."
  },
  {
    "objectID": "w04/slides.html#why-not-both",
    "href": "w04/slides.html#why-not-both",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "Why Not Both??",
    "text": "Why Not Both??\n\nOn the one hand: yes, both! On the other hand: fallacy of the “middle ground”\nWe’re back at descriptive vs. normative:\n\nDescriptively, given 100 values \\(v_1, \\ldots, v_{100}\\), their mean may be a good way to summarize, if we have to choose a single number\nBut, normatively, imagine that these are opinions that people hold about fairness.\nNow, if it’s the US South in 1860 and \\(v_i\\) represents person \\(i\\)’s approval of slavery, from a sample of 100 people, then approx. 97 of the \\(v_i\\)’s are “does not disapprove” (Rousey 2001) — in this case, normatively, is the mean \\(0.97\\) the “correct” answer?\n\nWe have another case where, like the “grass is green” vs. “grass ought to be green” example, we cannot just “import” our logical/mathematical tools from the former to solve the latter! (However: this does not mean they are useless! This is the fallacy of the excluded middle, sort of the opposite of the fallacy of the middle ground)\nThis is why we have ethical frameworks in the first place! Going back to Rawls: “97% of Americans think black people shouldn’t have rights”  \\(\\nimplies\\)“black people shouldn’t have rights”, since rights are a primary good"
  },
  {
    "objectID": "w04/slides.html#references",
    "href": "w04/slides.html#references",
    "title": "Week 4: (Descriptive) Fairness in AI",
    "section": "References",
    "text": "References\n\n\nBlackstone, William. 1769. Commentaries on the Laws of England, Volume 2: A Facsimile of the First Edition of 1765-1769. University of Chicago Press.\n\n\nDatta, Anupam, Matt Fredrikson, Gihyuk Ko, Piotr Mardziel, and Shayak Sen. 2017. “Proxy Non-Discrimination in Data-Driven Systems.” arXiv. https://doi.org/10.48550/arXiv.1707.08120.\n\n\nDeDeo, Simon. 2016. “Wrong Side of the Tracks: Big Data and Protected Categories.” arXiv. https://doi.org/10.48550/arXiv.1412.4643.\n\n\nFrance, Anatole. 1894. Le Lys Rouge (The Red Lily). G. Wells.\n\n\nHobbes, Thomas. 1668. Leviathan: With Selected Variants from the Latin Edition of 1668. Hackett Publishing.\n\n\nMitchell, Shira, Eric Potash, Solon Barocas, Alexander D’Amour, and Kristian Lum. 2021. “Algorithmic Fairness: Choices, Assumptions, and Definitions.” Annual Review of Statistics and Its Application 8 (1): 141–63. https://doi.org/10.1146/annurev-statistics-042720-125902.\n\n\nRawls, John. 1971. A Theory of Justice: Original Edition. Harvard University Press.\n\n\nRousey, Dennis C. 2001. “Friends and Foes of Slavery: Foreigners and Northerners in the Old South.” Journal of Social History 35 (2): 373–96. https://www.jstor.org/stable/3790193.\n\n\nRousseau, Jean-Jacques. 1762. The Social Contract. Geneva: J. M. Dent.\n\n\nSimons, Josh. 2023. Algorithms for the People: Democracy in the Age of AI. Princeton University Press."
  },
  {
    "objectID": "w05/index.html",
    "href": "w05/index.html",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#table-setting-i-should-have-done-before-hw1-truth-tables",
    "href": "w05/index.html#table-setting-i-should-have-done-before-hw1-truth-tables",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Table-Setting I Should Have Done Before HW1: Truth Tables!",
    "text": "Table-Setting I Should Have Done Before HW1: Truth Tables!\nJust one (❗️) “primary” axiom required for first-order predicate logic!\n\nBut, to make it more digestible, we can define some “helper axioms”:\n\n\n\n\n[Helper Axiom ]\n\n\nA unary operator “\\(\\neg\\)”\nIntersubjective agreement: call it “not”\n\n\n\n\n\n\n\n\n\n\\(p\\)\n\\(\\neg p\\)\n\n\n\n\n0\n1\n\n\n1\n0\n\n\n\n\n\n\n[Helper Axiom ]\n\n\nA binary operator “\\(\\wedge\\)”\nIntersubjective agreement: call it “and”\n\n\n\n\n\n\\(p\\)\n\\(q\\)\n\\(p \\wedge q\\)\n\n\n\n\n0\n0\n0\n\n\n0\n1\n0\n\n\n1\n0\n0\n\n\n1\n1\n1",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-single-axiom",
    "href": "w05/index.html#the-single-axiom",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Single Axiom",
    "text": "The Single Axiom\n[Axiom ] A binary operator “\\(\\barwedge\\)”, defined (for human consumption) s.t. \\(a \\barwedge b \\triangleq \\neg(a \\wedge b)\\), but defined precisely as the binary operator which maps the blue cols into orange col:\n\n\n\n\\(p\\)\n\\(q\\)\n\\(p \\underset{\\small\\text{or}}{\\vee} q\\)\n\\(p \\underset{\\small\\text{xor}}{\\otimes} q\\)\n\\(p \\underset{\\small\\text{and}}{\\wedge} q\\)\n\\(p \\underset{\\small\\text{nand}}{\\barwedge} q\\)\n\n\n\n\n0\n0\n0\n0\n0\n1\n\n\n0\n1\n1\n1\n0\n1\n\n\n1\n0\n1\n1\n0\n1\n\n\n1\n1\n1\n0\n1\n0",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#deriving-not",
    "href": "w05/index.html#deriving-not",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Deriving “Not”",
    "text": "Deriving “Not”\n\nGiven Axiom , we can derive Axiom  as a theorem (meaning, it does not need to be included as an axiom!):\n\\[\n[\\text{Theorem 1}] \\; ~ p \\barwedge p \\text{ satisfies all properties of }\\neg p\n\\]\nTherefore, define \\(\\neg p \\triangleq p \\barwedge p\\)\nGiven Axiom  and Theorem 1, we can derive Axiom  as a theorem:\n\\[\n[\\text{Theorem 2}] ~ \\neg(p \\barwedge q) \\text{ satisfies all properties of }p \\wedge q\n\\]\nTherefore, define \\(p \\wedge q \\triangleq \\neg(p \\barwedge q)\\)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#hw1-clarification-necessary-vs.-sufficient",
    "href": "w05/index.html#hw1-clarification-necessary-vs.-sufficient",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "HW1 Clarification: Necessary vs. Sufficient",
    "text": "HW1 Clarification: Necessary vs. Sufficient\n\nThese are, at root, logical connectors: given “atomic” (non-implicational) logical predicates \\(p\\) and \\(q\\), we can form implicational predicates (here “\\(\\equiv\\)” means “will always have the same logical value (T or F) as”):\n\n\n\n\n\n\n\n\n\n\nEnglish\nLogical Form\n\\(\\equiv\\)\nContrapositive Form\nIf True Then…\n\n\n\n\n“If \\(p\\) then \\(q\\)”\n\\(p \\Rightarrow q\\) or \\(q \\Leftarrow p\\)\n\\(\\equiv\\)\n\\(\\neg q \\Rightarrow \\neg p\\)\n\\(p\\) sufficient for \\(q\\)\n\n\n“If \\(q\\) then \\(p\\)”\n\\(q \\Rightarrow p\\) or \\(p \\Leftarrow q\\)\n\\(\\equiv\\)\n\\(\\neg p \\Rightarrow \\neg q\\)\n\\(p\\) necessary for \\(q\\)\n\n\n\n\n\n\nThe truth table for \\(\\Rightarrow\\) looks like:\n\n\n\n\n\\(p\\)\n\\(q\\)\n\\(p \\Rightarrow q\\)\n\\(\\neg p \\vee q\\)\n\n\n\n\n0\n0\n1\n1\n\n\n0\n1\n1\n1\n\n\n1\n0\n0\n0\n\n\n1\n1\n1\n1\n\n\n\n\n\nWhich means, finally, we can “plug in” English statements for \\(p\\) and \\(q\\):\n\n\\(p\\) = «A law mandating segregation is in force in a polity»\n\\(q\\) = «Segregation emerges in the polity»\n\nAnd evaluate based on \\(p\\) and \\(q\\) (board time!)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#hw2-metadata",
    "href": "w05/index.html#hw2-metadata",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "HW2 Metadata",
    "text": "HW2 Metadata\n\nOn “Context-Sensitive Fairness”\nReleasing tonight!\nDue Friday, February 21, 5:59pm EST\nAutograder \\(\\rightarrow\\) Autohinter!",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#propublica-vs.-northpointe",
    "href": "w05/index.html#propublica-vs.-northpointe",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "ProPublica vs. Northpointe",
    "text": "ProPublica vs. Northpointe\n\nThis is… an example with 1000s of books and papers and discussions around it! (A red flag 🚩, since, obsession with one example may conceal much wider range of issues!)\nBut, tldr, Northpointe created a ML algorithm called COMPAS, used by court systems all over the US to predict “risk” of arrestees\nIn 2016, ProPublica published results from an investigative report documenting COMPAS’s racial discrimination, in the form of violating equal error rates between black and white arrestees\nNorthpointe responded that COMPAS does not discriminate, as it satisfies calibration\nPeople have argued about who is “right” for 8 years, with some progress, but… not a lot",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#compas-overview",
    "href": "w05/index.html#compas-overview",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "COMPAS Overview",
    "text": "COMPAS Overview\n\nWhen defendants are booked into jail in Broward County, Florida, they are asked to respond to a COMPAS questionnaire with 137 questions, including “Was one of your parents ever sent to jail or prison?,” “How many of your friends/acquaintances are taking drugs illegally?,” and “How often did you get into fights at school?” Arrestees are also asked to agree or disagree with the statements “A hungry person has the right to steal” and “If people make me angry or I lose my temper, I can be dangerous.” Answers are fed into the COMPAS model, which generates an individual risk score that is reported in three buckets: “low risk” (1 to 4), “medium risk” (5 to 7), and “high risk” (8 to 10).",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#compas-overview-1",
    "href": "w05/index.html#compas-overview-1",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "COMPAS Overview",
    "text": "COMPAS Overview\n\nProPublica accused COMPAS of racism: “There’s software used across the country to predict future criminals. And it’s biased against blacks,” read the subheading on the article. ProPublica found that COMPAS’s error rates—the rate at which the model got it wrong—were unequal across racial groups. COMPAS’s predictions were more likely to incorrectly label African Americans as high risk and more likely to incorrectly label white Americans as low risk. “In the criminal justice context,” said Julia Angwin, coauthor of the ProPublica article, “false findings can have far-reaching effects on the lives of the people charged with crimes.",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#so-what-do-we-do",
    "href": "w05/index.html#so-what-do-we-do",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "So… What Do We Do?",
    "text": "So… What Do We Do?\n\nOne option: argue about which of the two definitions is “better” for the next 100 years (what is the best way to give food to the poor?)\n\nIt appears to reveal an unfortunate but inexorable fact about our world: we must choose between two intuitively appealing ways to understand fairness in ML. Many scholars have done just that, defending either ProPublica’s or Northpointe’s definitions against what they see as the misguided alternative. (Simons 2023)\n\nAnother option: study and then work to ameliorate the social conditions which force us into this realm of mathematical impossibility (why do the poor have no food?)\n\nThe impossibility result is about much more than math. [It occurs because] the underlying outcome is distributed unevenly in society. This is a fact about society, not mathematics, and requires engaging with a complex, checkered history of systemic racism in the US. Predicting an outcome whose distribution is shaped by this history requires tradeoffs because the inequalities and injustices are encoded in data—in this case, because America has criminalized Blackness for as long as America has existed.",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#why-not-both",
    "href": "w05/index.html#why-not-both",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Why Not Both??",
    "text": "Why Not Both??\n\nOn the one hand: yes, both! On the other hand: fallacy of the “middle ground”\nWe’re back at descriptive vs. normative:\n\nDescriptively, given 100 values \\(v_1, \\ldots, v_{100}\\), their mean may be a good way to summarize, if we have to choose a single number\nBut, normatively, imagine that these are opinions that people hold about fairness.\nNow, if it’s the US South in 1860 and \\(v_i\\) represents person \\(i\\)’s approval of slavery, from a sample of 100 people, then approx. 97 of the \\(v_i\\)’s are “does not disapprove” (Rousey 2001) — in this case, normatively, is the mean \\(0.97\\) the “correct” answer?\n\nWe have another case where, like the “grass is green” vs. “grass ought to be green” example, we cannot just “import” our logical/mathematical tools from the former to solve the latter! (However: this does not mean they are useless! This is the fallacy of the excluded middle, sort of the opposite of the fallacy of the middle ground)\nThis is why we have ethical frameworks in the first place! Going back to Rawls: “97% of Americans think black people shouldn’t have rights”  \\(\\nimplies\\)“black people shouldn’t have rights”, since rights are a primary good",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#motivation-linguistic-meaning",
    "href": "w05/index.html#motivation-linguistic-meaning",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Motivation: Linguistic Meaning",
    "text": "Motivation: Linguistic Meaning\n\n\n\n\n\n\n The Distributional Hypothesis (Firth 1968, 179)\n\n\n\nYou shall know a word by the company it keeps!\n\n\n\nRelated to Chomsky’s context-free vs. context-sensitive distinction!\nBut why is it relevant to DSAN 5450?…",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-meaning-of-fairness",
    "href": "w05/index.html#the-meaning-of-fairness",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The “Meaning” of Fairness",
    "text": "The “Meaning” of Fairness\n\n\n\n\n\n\n The Distributional [Fairness] Hypothesis\n\n\n\nYou shall know “fairness” by the company it keeps [i.e., the context it incorporates].\n\n\n\nContext-free (confusion-matrix-based) fairness: “plug the confusion matrix values into a formula and see if the formula is satisfied”\nContext-sensitive fairness: analyze fairness relative to a set of antecedents regarding how normative concerns should enter into our measurements of fairness",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#group-fairness-rightarrow-individual-fairness",
    "href": "w05/index.html#group-fairness-rightarrow-individual-fairness",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Group Fairness \\(\\rightarrow\\) Individual Fairness",
    "text": "Group Fairness \\(\\rightarrow\\) Individual Fairness\n\nThe crucial insight of Dwork: group-level fairness does not ensure that individuals are treated fairly as individuals\nExactly the issue we’ve seen with utilitarianism: optimizing society-level “happiness” may lead to individuals being brutally mistreated (e.g., having their rights violated)\nSo, at a high level, Dwork’s proposal could provide a Rawls-style ordering: individual fairness lexically prior to group-level fairness (optimize group-level fairness once individual-level is satisfied)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-normative-antecedent",
    "href": "w05/index.html#the-normative-antecedent",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The (Normative!) Antecedent",
    "text": "The (Normative!) Antecedent\n\n\n\n\n\n\nFairness Through Awareness (Dwork et al. 2011)\n\n\n\nIndividuals who are similar with respect to a task should be classified similarly.\n\n\n\n\n\n\n\n\n\nNot well-liked in industry / policy because you can’t just “plug in” results of your classifier and get True/False “we satisfied fairness!” …But this is exactly the point!\n\n\n\n\n\n\nFrom Kiat (2018)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#bringing-in-context-1",
    "href": "w05/index.html#bringing-in-context-1",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Bringing In Context",
    "text": "Bringing In Context\n\nIn itself, the principle of equal treatment is abstract, a formal relationship that lacks substantive content”\nThe principle must be given content by defining which cases are similar and which are different, and by considering what kinds of differences justify differential treatment\nDeciding what differences are relevant, and what kinds of differential treatment are justified by particular differences, requires wrestling with moral and political debates about the responsibilities of different institutions to address persistent injustice (Simons 2023, 51)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#remember-distance-metrics",
    "href": "w05/index.html#remember-distance-metrics",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Remember Distance Metrics?(!)",
    "text": "Remember Distance Metrics?(!)\n\n\n\n\n\n\n\nA core element in both similarity-based and causal fairness!\nAlready difficult to choose a metric on pragmatic grounds (ambulance needs to get to hospital)\nNow people will also have fundamental normative disagreements about what should and should not determine difference\n\n\n\n\n\n\nFrom Shahid et al. (2009)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#satisfying-individual-vs.-group-fairness",
    "href": "w05/index.html#satisfying-individual-vs.-group-fairness",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Satisfying Individual vs. Group Fairness",
    "text": "Satisfying Individual vs. Group Fairness\n\nAn algorithm is individually fair if, for all individuals \\(x\\) and \\(y\\), we have\n\\[\n\\textsf{dist}(r(x), r(y)) \\leq \\textsf{dist}(x, y)\n\\]\n\\(\\implies\\) an advertising system must show similar sets of ads to similar users.\nIt achieves group fairness-through-parity for two groups of users \\(S\\) and \\(T\\) when:\n\\[\n\\textsf{dist}(\\mathbb{E}_{s \\in S}[r(s)], \\mathbb{E}_{t \\in T}[r(t)]) \\leq \\varepsilon\n\\]\nwhere \\(\\mathbb{E}_{s \\in S}\\) and \\(\\mathbb{E}_{t \\in T}\\) denote the expectation of ads seen by an individual chosen uniformly among \\(S\\) and \\(T\\). This definition implies that the difference in probability between two groups of seeing a particular ad will be bounded by \\(\\varepsilon\\).\nGiven these definitions: Individual fairness  \\(\\nimplies\\) group fairness, and vice versa! (Riederer and Chaintreau 2017)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-importance-of-not-excluding-race",
    "href": "w05/index.html#the-importance-of-not-excluding-race",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Importance of Not Excluding Race!",
    "text": "The Importance of Not Excluding Race!\n\nOn HW2 you will see how, on the one hand: excluding race from the similarity metric ensures race-blind fairness\nBut, on the other hand: race-blind fairness can not only maintain but also amplify preexisting inequalities\nBy including race in our similarity metric, we can explicitly take this into account!\nEx: someone with a (morally irrelevant) disadvantage due to birth lottery who achieves an SAT score of 1400 is similar to someone with a (morally irrelevant) advantage due to birth lottery who achieves an SAT score of 1500",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#equality-of-opportunity",
    "href": "w05/index.html#equality-of-opportunity",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Equality of Opportunity",
    "text": "Equality of Opportunity\n\n\n\n\n\n\n\nThis notion (last bullet of the previous slide) is contentious, to say the least\nBut also, crucially: our job is not to decide the similarity metric unilaterally!\nThe equality of opportunity approach is not itself a similarity metric!\nIt is a “meta-algorithm” for translating normative positions (consequents of an ethical framework) into concrete fairness constraints that you can then impose on ML algorithms\n\n\n\n\n\n\nRoemer (1998)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#roemers-algorithm",
    "href": "w05/index.html#roemers-algorithm",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Roemer’s Algorithm",
    "text": "Roemer’s Algorithm\n\nEquality of Opportunity algorithm boils down to (Input 0 = data on individuals \\(X_i\\)):\nInput 1 (!): Attributes \\(J_{\\text{advantage}} \\subseteq X_i\\) that a society (real or hypothetical) considers normatively relevant for an outcome, but that people are not individually responsible for (e.g., race or nationality via birth lottery)\nInput 2: Attributes \\(J_{\\text{merit}} \\subseteq X_i\\) that a society considers people individually responsible for (effort, sacrificing short-term pleasure for longer-term benefits, etc.)\n: Set of individuals in society \\(S\\) is partitioned into subsets \\(S_i\\), where \\(i\\) is some combination of particular values for the attributes in \\(X_{\\text{advantage}}\\)\n: Individuals’ context-sensitive scores are computed relative to their group \\(S_i\\), as percentile of their \\(X_{\\text{merit}}\\) value relative to distribution of \\(X_{\\text{merit}}\\) values across \\(S_i\\)\nOutcome: Now that we have incorporated social context, by converting the original context-free units (e.g., numeric SAT score) into context-sensitive units (percentile of numeric SAT score within distribution of comparable individuals), we can compare people across groups on the basis of context-sensitive scores!",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#an-overly-simplistic-example-more-on-hw2",
    "href": "w05/index.html#an-overly-simplistic-example-more-on-hw2",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "An Overly-Simplistic Example (More on HW2!)",
    "text": "An Overly-Simplistic Example (More on HW2!)\n\n\\(\\mathbf{x}_i = (x_{i,1}, x_{i,2}, x_{i,3}) = (\\texttt{wealth}_i, \\texttt{study\\_hrs}_i, \\texttt{SAT}_i)\\)\n\\(J_{\\text{advantage}} = (1) = (\\texttt{wealth})\\), \\(J_{\\text{merit}} = (2) = (\\texttt{study\\_hrs})\\)\n\\(\\Rightarrow \\texttt{study\\_hrs} \\rightarrow \\texttt{SAT}\\) a “fair” pathway\n\\(\\Rightarrow \\texttt{wealth} \\rightarrow \\texttt{SAT}\\) an “unfair” pathway\n\\(\\Rightarrow\\) School admission decisions “fair” to the extent that they capture the direct effect \\(\\texttt{study\\_hrs} \\rightarrow \\texttt{SAT} \\rightarrow \\texttt{admit}\\), but aren’t affected by indirect effect \\(\\texttt{wealth} \\rightarrow \\texttt{SAT} \\rightarrow \\texttt{admit}\\)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#at-a-macro-level",
    "href": "w05/index.html#at-a-macro-level",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "At a Macro Level!",
    "text": "At a Macro Level!",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-state-of-the-art",
    "href": "w05/index.html#the-state-of-the-art",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The State of the Art!",
    "text": "The State of the Art!\n\nCurrent state of fairness in AI: measures which explicitly model causal connections between variables of interest are most promising for robust notions of fairness\nRobust in the sense of:\n\nBeing normatively desirable (as in, matching the key tenets of our ethical frameworks) while also being\nDescriptively tractable (as in, concretely implementable in math/code, and transparent enough to allow us to evaluate and update these implementations, using a process like reflective equilibrium).",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-antecedent",
    "href": "w05/index.html#the-antecedent",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Antecedent",
    "text": "The Antecedent\n\nSince it’s impossible to eliminate information about sensitive attributes like race/gender/etc. from our ML algorithms…\nFairness should instead be defined on the basis of how this sensitive information “flows” through the causal chain of decisions which lead to an given (observed) outcome",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-new-object-of-analysis-causal-pathways",
    "href": "w05/index.html#the-new-object-of-analysis-causal-pathways",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The New Object of Analysis: Causal Pathways",
    "text": "The New Object of Analysis: Causal Pathways\n\nOnce we have a model of the causal connections among:\n\nVariables that we care about socially/normatively, and\nVariables used by a Machine Learning algorithm,\n\nWe can then use techniques developed by statisticians who study causal inference to\nBlock certain “causal pathways” that we deem normatively unjustifiable while allowing other pathways that we deem to be normatively justifiable.",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#causal-fairness-in-hw2",
    "href": "w05/index.html#causal-fairness-in-hw2",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Causal Fairness in HW2",
    "text": "Causal Fairness in HW2\n\nIntuition required to make the jump from correlational approach (from statistics and probability generally, and DSAN 5100 specifically!) to causal approach!\nCausal approach builds on correlational, but…\nStricter, directional standard for \\(X \\rightarrow Y\\)\nEasy cases: find high correlation \\(|\\text{corr}(X,Y)|\\), embed in a causal diagram, evaluate \\(\\Pr(Y \\mid \\text{do}(X)) \\overset{?}{&gt;} \\Pr(Y \\mid \\neg\\text{do}(X))\\)\nHard cases: can have \\(\\Pr(Y \\mid \\text{do}(X)) \\overset{?}{&gt;} \\Pr(Y \\mid \\neg\\text{do}(X))\\) even when \\(\\text{corr}(X,Y) = 0\\) 😰 (dw, we’ll get there!)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#causal-building-blocks",
    "href": "w05/index.html#causal-building-blocks",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Causal Building Blocks",
    "text": "Causal Building Blocks\n\nDSAN 5100 precedent: nodes in the network \\(X\\), \\(Y\\) are Random Variables, connections \\(X \\leftrightarrow Y\\) are joint distributions \\(\\Pr(X, Y)\\)\nDirectional edges \\(X \\rightarrow Y\\), then, just represent conditional distributions: \\(X \\rightarrow Y\\) is \\(\\Pr(Y \\mid X)\\)\nWhere we’re going: connections \\(X \\leftrightarrow Y\\) represent unknown but extant causal connections between \\(X\\) and \\(Y\\), while \\(X \\rightarrow Y\\) represents a causal relationship between \\(X\\) and \\(Y\\)\nSpecifically, \\(X \\rightarrow Y\\) now means: an intervention that changes the value of \\(X\\) by \\(\\varepsilon\\) causes a change in the value of \\(Y\\) by \\(f(\\varepsilon)\\)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-intuitive-problem-of-causal-inference",
    "href": "w05/index.html#the-intuitive-problem-of-causal-inference",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Intuitive Problem of Causal Inference",
    "text": "The Intuitive Problem of Causal Inference\n\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nga_lawyers &lt;- c(21362, 22254, 23134, 23698, 24367, 24930, 25632, 26459, 27227, 27457)\nski_df &lt;- tibble::tribble(\n  ~year, ~varname, ~value,\n  2000, \"ski_revenue\", 1551,\n  2001, \"ski_revenue\", 1635,\n  2002, \"ski_revenue\", 1801,\n  2003, \"ski_revenue\", 1827,\n  2004, \"ski_revenue\", 1956,\n  2005, \"ski_revenue\", 1989,\n  2006, \"ski_revenue\", 2178,\n  2007, \"ski_revenue\", 2257,\n  2008, \"ski_revenue\", 2476,\n  2009, \"ski_revenue\", 2438,\n)\nski_mean &lt;- mean(ski_df$value)\nski_sd &lt;- sd(ski_df$value)\nski_df &lt;- ski_df %&gt;% mutate(val_scaled = 12*value, val_norm = (value - ski_mean)/ski_sd)\nlaw_df &lt;- tibble::tibble(year=2000:2009, varname=\"ga_lawyers\", value=ga_lawyers)\nlaw_mean &lt;- mean(law_df$value)\nlaw_sd &lt;- sd(law_df$value)\nlaw_df &lt;- law_df %&gt;% mutate(val_norm = (value - law_mean)/law_sd)\nspur_df &lt;- dplyr::bind_rows(ski_df, law_df)\nggplot(spur_df, aes(x=year, y=val_norm, color=factor(varname, labels = c(\"Ski Revenue\",\"Lawyers in Georgia\")))) +\n  stat_smooth(method=\"loess\", se=FALSE) +\n  geom_point(size=g_pointsize/1.5) +\n  labs(\n    fill=\"\",\n    title=\"Ski Revenue vs. Georgia Lawyers\",\n    x=\"Year\",\n    color=\"Correlation: 99.2%\",\n    linetype=NULL\n  ) +\n  theme_dsan() +\n  scale_x_continuous(\n    breaks=seq(from=2000, to=2014, by=2)\n  ) +\n  #scale_y_continuous(\n  #  name=\"Total Revenue, Ski Facilities (Million USD)\",\n  #  sec.axis = sec_axis(~ . * law_sd + law_mean, name = \"Number of Lawyers in Georgia\")\n  #) +\n  scale_y_continuous(breaks = -1:1,\n    labels = ~ . * round(ski_sd,1) + round(ski_mean,1),\n    name=\"Total Revenue, Ski Facilities (Million USD)\",\n    sec.axis = sec_axis(~ . * law_sd + law_mean, name = \"Number of Lawyers in Georgia\")) +\n  expand_limits(x=2010) +\n  #geom_hline(aes(yintercept=x, color=\"Mean Values\"), as.data.frame(list(x=0)), linewidth=0.75, alpha=1.0, show.legend = TRUE) +\n  scale_color_manual(\n    breaks=c('Ski Revenue', 'Lawyers in Georgia'),\n    values=c('Ski Revenue'=cbPalette[1], 'Lawyers in Georgia'=cbPalette[2])\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\ncor(ski_df$value, law_df$value)\n\n[1] 0.9921178\n\n\n\n(Data from Spurious Correlations, Tyler Vigen)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-fundamental-problem-of-causal-inference",
    "href": "w05/index.html#the-fundamental-problem-of-causal-inference",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Fundamental Problem of Causal Inference",
    "text": "The Fundamental Problem of Causal Inference\nThe only workable definition of “\\(X\\) causes \\(Y\\)”:\n\n\n\n\n\n\n Defining Causality\n\n\n\n\\(X\\) causes \\(Y\\) if and only if:\n\nX temporally precedes \\(Y\\) and\nIn two worlds \\(W_0\\) and \\(W_1\\) where everything is exactly the same except that \\(X = 0\\) in \\(W_0\\) and \\(X = 1\\) in \\(W_1\\), \\(Y = 0\\) in \\(W_0\\) and \\(Y = 1\\) in \\(W_1\\) (hume_treatise_1739?)\n\n\n\n\nThe problem? We live in one world, not two simultaneous worlds 😭",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#what-is-to-be-done",
    "href": "w05/index.html#what-is-to-be-done",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "What Is To Be Done?",
    "text": "What Is To Be Done?",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "href": "w05/index.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm",
    "text": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm\n\nFind good comparison cases: Treatment and Control\nWithout a control group, you cannot make inferences!\nSelecting on the dependent variable…",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#selecting-on-the-dependent-variable",
    "href": "w05/index.html#selecting-on-the-dependent-variable",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Selecting on the Dependent Variable",
    "text": "Selecting on the Dependent Variable\n\n\n\nWhat “““research”“” “““says”“” about identifying people who might commit mass shootings\n\n\n\nJeff’s rant: If you care about actually solving social issues, this should infuriate you",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#complications-selection",
    "href": "w05/index.html#complications-selection",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Complications: Selection",
    "text": "Complications: Selection\n\nTldr: Why did this person (unit) end up in the treatment group? Why did this other person (unit) end up in the control group?\nAre there systematic differences?\nVietnam/Indochina Draft: Why can’t we just study [men who join the military] versus [men who don’t], and take the difference as a causal estimate?",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#complications-compliance",
    "href": "w05/index.html#complications-compliance",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Complications: Compliance",
    "text": "Complications: Compliance\n\nWe want people assigned to treatment to take the treatment, and people assigned to control to take the control\n“Compliance”: degree to which this is true in experiment\n\nHigh compliance = most people actually took what they were assigned\nLow compliance = lots of people who were assigned to treatment actually took control, and vice-versa\n\nWhat problems might exist w.r.t compliance in the Draft?",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#next-week-and-hw2-experimental-rightarrow-observational-data",
    "href": "w05/index.html#next-week-and-hw2-experimental-rightarrow-observational-data",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Next Week and HW2: Experimental \\(\\rightarrow\\) Observational Data",
    "text": "Next Week and HW2: Experimental \\(\\rightarrow\\) Observational Data\n\nIn observational studies, researchers have no control over assignment to treatment/control 😨\nOn the one hand… Forget Everything And Run [to randomized, controlled experiments], if you can.\nOn the other hand… statisticians over the last 4 centuries have developed fancy causal inference tools/techniques to help us Face Everything And Rise 🧐",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#for-now-matching",
    "href": "w05/index.html#for-now-matching",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "For Now: Matching",
    "text": "For Now: Matching\n\nIn a randomized, controlled experiment, we can ensure (since we have control over the assignment mechanism) that the only systematic difference between \\(C\\) and \\(T\\) is that \\(T\\) received the treatment and \\(C\\) did not\nIn an observational study, we “show up too late”!\nThus, we no longer refer to assignment but to selection\nAnd, our job is to figure out (reverse engineer!) the selection mechanism, then correct for its non-randomness: basically, we “transform” from observational to experimental setting through weighting (👀 W02)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#references",
    "href": "w05/index.html#references",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "References",
    "text": "References\n\n\nDwork, Cynthia, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Rich Zemel. 2011. “Fairness Through Awareness.” arXiv. https://doi.org/10.48550/arXiv.1104.3913.\n\n\nFirth, John Rupert. 1968. Selected Papers of J.R. Firth, 1952-59. Longmans.\n\n\nKiat, Lim Swee. 2018. “Machines Gone Wrong.” PhD thesis, Singapore University of Technology; Design. https://machinesgonewrong.com/about/.\n\n\nRiederer, Christopher, and Augustin Chaintreau. 2017. “The Price of Fairness in Location Based Advertising.” Fairness, Accountability, and Transparency Workshop on Responsible Recommendation. https://doi.org/10.18122/B2MD8C.\n\n\nRoemer, John E. 1998. Equality of Opportunity. Harvard University Press.\n\n\nRousey, Dennis C. 2001. “Friends and Foes of Slavery: Foreigners and Northerners in the Old South.” Journal of Social History 35 (2): 373–96. https://www.jstor.org/stable/3790193.\n\n\nShahid, Rizwan, Stefania Bertazzon, Merril L. Knudtson, and William A. Ghali. 2009. “Comparison of Distance Measures in Spatial Analytical Modeling for Health Service Planning.” BMC Health Services Research 9 (1): 200. https://doi.org/10.1186/1472-6963-9-200.\n\n\nSimons, Josh. 2023. Algorithms for the People: Democracy in the Age of AI. Princeton University Press.",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/slides.html#table-setting-i-should-have-done-before-hw1-truth-tables",
    "href": "w05/slides.html#table-setting-i-should-have-done-before-hw1-truth-tables",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Table-Setting I Should Have Done Before HW1: Truth Tables!",
    "text": "Table-Setting I Should Have Done Before HW1: Truth Tables!\nJust one (❗️) “primary” axiom required for first-order predicate logic!\n\nBut, to make it more digestible, we can define some “helper axioms”:\n\n\n\n\n[Helper Axiom ]\n\n\nA unary operator “\\(\\neg\\)”\nIntersubjective agreement: call it “not”\n\n\n\n\n\n\n\n\n\n\\(p\\)\n\\(\\neg p\\)\n\n\n\n\n0\n1\n\n\n1\n0\n\n\n\n\n\n\n[Helper Axiom ]\n\n\nA binary operator “\\(\\wedge\\)”\nIntersubjective agreement: call it “and”\n\n\n\n\n\n\\(p\\)\n\\(q\\)\n\\(p \\wedge q\\)\n\n\n\n\n0\n0\n0\n\n\n0\n1\n0\n\n\n1\n0\n0\n\n\n1\n1\n1"
  },
  {
    "objectID": "w05/slides.html#the-single-axiom",
    "href": "w05/slides.html#the-single-axiom",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Single Axiom",
    "text": "The Single Axiom\n[Axiom ] A binary operator “\\(\\barwedge\\)”, defined (for human consumption) s.t. \\(a \\barwedge b \\triangleq \\neg(a \\wedge b)\\), but defined precisely as the binary operator which maps the blue cols into orange col:\n\n\n\n\\(p\\)\n\\(q\\)\n\\(p \\underset{\\small\\text{or}}{\\vee} q\\)\n\\(p \\underset{\\small\\text{xor}}{\\otimes} q\\)\n\\(p \\underset{\\small\\text{and}}{\\wedge} q\\)\n\\(p \\underset{\\small\\text{nand}}{\\barwedge} q\\)\n\n\n\n\n0\n0\n0\n0\n0\n1\n\n\n0\n1\n1\n1\n0\n1\n\n\n1\n0\n1\n1\n0\n1\n\n\n1\n1\n1\n0\n1\n0"
  },
  {
    "objectID": "w05/slides.html#deriving-not",
    "href": "w05/slides.html#deriving-not",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Deriving “Not”",
    "text": "Deriving “Not”\n\nGiven Axiom , we can derive Axiom  as a theorem (meaning, it does not need to be included as an axiom!):\n\\[\n[\\text{Theorem 1}] \\; ~ p \\barwedge p \\text{ satisfies all properties of }\\neg p\n\\]\nTherefore, define \\(\\neg p \\triangleq p \\barwedge p\\)\nGiven Axiom  and Theorem 1, we can derive Axiom  as a theorem:\n\\[\n[\\text{Theorem 2}] ~ \\neg(p \\barwedge q) \\text{ satisfies all properties of }p \\wedge q\n\\]\nTherefore, define \\(p \\wedge q \\triangleq \\neg(p \\barwedge q)\\)"
  },
  {
    "objectID": "w05/slides.html#hw1-clarification-necessary-vs.-sufficient",
    "href": "w05/slides.html#hw1-clarification-necessary-vs.-sufficient",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "HW1 Clarification: Necessary vs. Sufficient",
    "text": "HW1 Clarification: Necessary vs. Sufficient\n\nThese are, at root, logical connectors: given “atomic” (non-implicational) logical predicates \\(p\\) and \\(q\\), we can form implicational predicates (here “\\(\\equiv\\)” means “will always have the same logical value (T or F) as”):\n\n\n\n\n\n\n\n\n\n\nEnglish\nLogical Form\n\\(\\equiv\\)\nContrapositive Form\nIf True Then…\n\n\n\n\n“If \\(p\\) then \\(q\\)”\n\\(p \\Rightarrow q\\) or \\(q \\Leftarrow p\\)\n\\(\\equiv\\)\n\\(\\neg q \\Rightarrow \\neg p\\)\n\\(p\\) sufficient for \\(q\\)\n\n\n“If \\(q\\) then \\(p\\)”\n\\(q \\Rightarrow p\\) or \\(p \\Leftarrow q\\)\n\\(\\equiv\\)\n\\(\\neg p \\Rightarrow \\neg q\\)\n\\(p\\) necessary for \\(q\\)\n\n\n\n\n\n\nThe truth table for \\(\\Rightarrow\\) looks like:\n\n\n\n\n\\(p\\)\n\\(q\\)\n\\(p \\Rightarrow q\\)\n\\(\\neg p \\vee q\\)\n\n\n\n\n0\n0\n1\n1\n\n\n0\n1\n1\n1\n\n\n1\n0\n0\n0\n\n\n1\n1\n1\n1\n\n\n\n\n\nWhich means, finally, we can “plug in” English statements for \\(p\\) and \\(q\\):\n\n\\(p\\) = «A law mandating segregation is in force in a polity»\n\\(q\\) = «Segregation emerges in the polity»\n\nAnd evaluate based on \\(p\\) and \\(q\\) (board time!)"
  },
  {
    "objectID": "w05/slides.html#hw2-metadata",
    "href": "w05/slides.html#hw2-metadata",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "HW2 Metadata",
    "text": "HW2 Metadata\n\nOn “Context-Sensitive Fairness”\nReleasing tonight!\nDue Friday, February 21, 5:59pm EST\nAutograder \\(\\rightarrow\\) Autohinter!"
  },
  {
    "objectID": "w05/slides.html#propublica-vs.-northpointe",
    "href": "w05/slides.html#propublica-vs.-northpointe",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "ProPublica vs. Northpointe",
    "text": "ProPublica vs. Northpointe\n\nThis is… an example with 1000s of books and papers and discussions around it! (A red flag 🚩, since, obsession with one example may conceal much wider range of issues!)\nBut, tldr, Northpointe created a ML algorithm called COMPAS, used by court systems all over the US to predict “risk” of arrestees\nIn 2016, ProPublica published results from an investigative report documenting COMPAS’s racial discrimination, in the form of violating equal error rates between black and white arrestees\nNorthpointe responded that COMPAS does not discriminate, as it satisfies calibration\nPeople have argued about who is “right” for 8 years, with some progress, but… not a lot"
  },
  {
    "objectID": "w05/slides.html#compas-overview",
    "href": "w05/slides.html#compas-overview",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "COMPAS Overview",
    "text": "COMPAS Overview\n\nWhen defendants are booked into jail in Broward County, Florida, they are asked to respond to a COMPAS questionnaire with 137 questions, including “Was one of your parents ever sent to jail or prison?,” “How many of your friends/acquaintances are taking drugs illegally?,” and “How often did you get into fights at school?” Arrestees are also asked to agree or disagree with the statements “A hungry person has the right to steal” and “If people make me angry or I lose my temper, I can be dangerous.” Answers are fed into the COMPAS model, which generates an individual risk score that is reported in three buckets: “low risk” (1 to 4), “medium risk” (5 to 7), and “high risk” (8 to 10)."
  },
  {
    "objectID": "w05/slides.html#compas-overview-1",
    "href": "w05/slides.html#compas-overview-1",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "COMPAS Overview",
    "text": "COMPAS Overview\n\nProPublica accused COMPAS of racism: “There’s software used across the country to predict future criminals. And it’s biased against blacks,” read the subheading on the article. ProPublica found that COMPAS’s error rates—the rate at which the model got it wrong—were unequal across racial groups. COMPAS’s predictions were more likely to incorrectly label African Americans as high risk and more likely to incorrectly label white Americans as low risk. “In the criminal justice context,” said Julia Angwin, coauthor of the ProPublica article, “false findings can have far-reaching effects on the lives of the people charged with crimes."
  },
  {
    "objectID": "w05/slides.html#so-what-do-we-do",
    "href": "w05/slides.html#so-what-do-we-do",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "So… What Do We Do?",
    "text": "So… What Do We Do?\n\nOne option: argue about which of the two definitions is “better” for the next 100 years (what is the best way to give food to the poor?)\n\nIt appears to reveal an unfortunate but inexorable fact about our world: we must choose between two intuitively appealing ways to understand fairness in ML. Many scholars have done just that, defending either ProPublica’s or Northpointe’s definitions against what they see as the misguided alternative. (Simons 2023)\n\nAnother option: study and then work to ameliorate the social conditions which force us into this realm of mathematical impossibility (why do the poor have no food?)\n\nThe impossibility result is about much more than math. [It occurs because] the underlying outcome is distributed unevenly in society. This is a fact about society, not mathematics, and requires engaging with a complex, checkered history of systemic racism in the US. Predicting an outcome whose distribution is shaped by this history requires tradeoffs because the inequalities and injustices are encoded in data—in this case, because America has criminalized Blackness for as long as America has existed."
  },
  {
    "objectID": "w05/slides.html#why-not-both",
    "href": "w05/slides.html#why-not-both",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Why Not Both??",
    "text": "Why Not Both??\n\nOn the one hand: yes, both! On the other hand: fallacy of the “middle ground”\nWe’re back at descriptive vs. normative:\n\nDescriptively, given 100 values \\(v_1, \\ldots, v_{100}\\), their mean may be a good way to summarize, if we have to choose a single number\nBut, normatively, imagine that these are opinions that people hold about fairness.\nNow, if it’s the US South in 1860 and \\(v_i\\) represents person \\(i\\)’s approval of slavery, from a sample of 100 people, then approx. 97 of the \\(v_i\\)’s are “does not disapprove” (Rousey 2001) — in this case, normatively, is the mean \\(0.97\\) the “correct” answer?\n\nWe have another case where, like the “grass is green” vs. “grass ought to be green” example, we cannot just “import” our logical/mathematical tools from the former to solve the latter! (However: this does not mean they are useless! This is the fallacy of the excluded middle, sort of the opposite of the fallacy of the middle ground)\nThis is why we have ethical frameworks in the first place! Going back to Rawls: “97% of Americans think black people shouldn’t have rights”  \\(\\nimplies\\)“black people shouldn’t have rights”, since rights are a primary good"
  },
  {
    "objectID": "w05/slides.html#motivation-linguistic-meaning",
    "href": "w05/slides.html#motivation-linguistic-meaning",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Motivation: Linguistic Meaning",
    "text": "Motivation: Linguistic Meaning\n\n\n\n\n The Distributional Hypothesis (Firth 1968, 179)\n\n\nYou shall know a word by the company it keeps!\n\n\n\n\n\nRelated to Chomsky’s context-free vs. context-sensitive distinction!\nBut why is it relevant to DSAN 5450?…"
  },
  {
    "objectID": "w05/slides.html#the-meaning-of-fairness",
    "href": "w05/slides.html#the-meaning-of-fairness",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The “Meaning” of Fairness",
    "text": "The “Meaning” of Fairness\n\n\n\n\n The Distributional [Fairness] Hypothesis\n\n\nYou shall know “fairness” by the company it keeps [i.e., the context it incorporates].\n\n\n\n\n\nContext-free (confusion-matrix-based) fairness: “plug the confusion matrix values into a formula and see if the formula is satisfied”\nContext-sensitive fairness: analyze fairness relative to a set of antecedents regarding how normative concerns should enter into our measurements of fairness"
  },
  {
    "objectID": "w05/slides.html#group-fairness-rightarrow-individual-fairness",
    "href": "w05/slides.html#group-fairness-rightarrow-individual-fairness",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Group Fairness \\(\\rightarrow\\) Individual Fairness",
    "text": "Group Fairness \\(\\rightarrow\\) Individual Fairness\n\nThe crucial insight of Dwork: group-level fairness does not ensure that individuals are treated fairly as individuals\nExactly the issue we’ve seen with utilitarianism: optimizing society-level “happiness” may lead to individuals being brutally mistreated (e.g., having their rights violated)\nSo, at a high level, Dwork’s proposal could provide a Rawls-style ordering: individual fairness lexically prior to group-level fairness (optimize group-level fairness once individual-level is satisfied)"
  },
  {
    "objectID": "w05/slides.html#the-normative-antecedent",
    "href": "w05/slides.html#the-normative-antecedent",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The (Normative!) Antecedent",
    "text": "The (Normative!) Antecedent\n\n\n\n\nFairness Through Awareness (Dwork et al. 2011)\n\n\nIndividuals who are similar with respect to a task should be classified similarly.\n\n\n\n\n\n\n\n\n\n\n\nNot well-liked in industry / policy because you can’t just “plug in” results of your classifier and get True/False “we satisfied fairness!” …But this is exactly the point!\n\n\n\n\n\n\nFrom Kiat (2018)"
  },
  {
    "objectID": "w05/slides.html#bringing-in-context-1",
    "href": "w05/slides.html#bringing-in-context-1",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Bringing In Context",
    "text": "Bringing In Context\n\nIn itself, the principle of equal treatment is abstract, a formal relationship that lacks substantive content”\nThe principle must be given content by defining which cases are similar and which are different, and by considering what kinds of differences justify differential treatment\nDeciding what differences are relevant, and what kinds of differential treatment are justified by particular differences, requires wrestling with moral and political debates about the responsibilities of different institutions to address persistent injustice (Simons 2023, 51)"
  },
  {
    "objectID": "w05/slides.html#remember-distance-metrics",
    "href": "w05/slides.html#remember-distance-metrics",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Remember Distance Metrics?(!)",
    "text": "Remember Distance Metrics?(!)\n\n\n\n\n\n\n\nA core element in both similarity-based and causal fairness!\nAlready difficult to choose a metric on pragmatic grounds (ambulance needs to get to hospital)\nNow people will also have fundamental normative disagreements about what should and should not determine difference\n\n\n\n\n\n\nFrom Shahid et al. (2009)"
  },
  {
    "objectID": "w05/slides.html#satisfying-individual-vs.-group-fairness",
    "href": "w05/slides.html#satisfying-individual-vs.-group-fairness",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Satisfying Individual vs. Group Fairness",
    "text": "Satisfying Individual vs. Group Fairness\n\nAn algorithm is individually fair if, for all individuals \\(x\\) and \\(y\\), we have\n\\[\n\\textsf{dist}(r(x), r(y)) \\leq \\textsf{dist}(x, y)\n\\]\n\\(\\implies\\) an advertising system must show similar sets of ads to similar users.\nIt achieves group fairness-through-parity for two groups of users \\(S\\) and \\(T\\) when:\n\\[\n\\textsf{dist}(\\mathbb{E}_{s \\in S}[r(s)], \\mathbb{E}_{t \\in T}[r(t)]) \\leq \\varepsilon\n\\]\nwhere \\(\\mathbb{E}_{s \\in S}\\) and \\(\\mathbb{E}_{t \\in T}\\) denote the expectation of ads seen by an individual chosen uniformly among \\(S\\) and \\(T\\). This definition implies that the difference in probability between two groups of seeing a particular ad will be bounded by \\(\\varepsilon\\).\nGiven these definitions: Individual fairness  \\(\\nimplies\\) group fairness, and vice versa! (Riederer and Chaintreau 2017)"
  },
  {
    "objectID": "w05/slides.html#the-importance-of-not-excluding-race",
    "href": "w05/slides.html#the-importance-of-not-excluding-race",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Importance of Not Excluding Race!",
    "text": "The Importance of Not Excluding Race!\n\nOn HW2 you will see how, on the one hand: excluding race from the similarity metric ensures race-blind fairness\nBut, on the other hand: race-blind fairness can not only maintain but also amplify preexisting inequalities\nBy including race in our similarity metric, we can explicitly take this into account!\nEx: someone with a (morally irrelevant) disadvantage due to birth lottery who achieves an SAT score of 1400 is similar to someone with a (morally irrelevant) advantage due to birth lottery who achieves an SAT score of 1500"
  },
  {
    "objectID": "w05/slides.html#equality-of-opportunity",
    "href": "w05/slides.html#equality-of-opportunity",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Equality of Opportunity",
    "text": "Equality of Opportunity\n\n\n\n\n\n\n\nThis notion (last bullet of the previous slide) is contentious, to say the least\nBut also, crucially: our job is not to decide the similarity metric unilaterally!\nThe equality of opportunity approach is not itself a similarity metric!\nIt is a “meta-algorithm” for translating normative positions (consequents of an ethical framework) into concrete fairness constraints that you can then impose on ML algorithms\n\n\n\n\n\n\nRoemer (1998)"
  },
  {
    "objectID": "w05/slides.html#roemers-algorithm",
    "href": "w05/slides.html#roemers-algorithm",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Roemer’s Algorithm",
    "text": "Roemer’s Algorithm\n\nEquality of Opportunity algorithm boils down to (Input 0 = data on individuals \\(X_i\\)):\nInput 1 (!): Attributes \\(J_{\\text{advantage}} \\subseteq X_i\\) that a society (real or hypothetical) considers normatively relevant for an outcome, but that people are not individually responsible for (e.g., race or nationality via birth lottery)\nInput 2: Attributes \\(J_{\\text{merit}} \\subseteq X_i\\) that a society considers people individually responsible for (effort, sacrificing short-term pleasure for longer-term benefits, etc.)\n: Set of individuals in society \\(S\\) is partitioned into subsets \\(S_i\\), where \\(i\\) is some combination of particular values for the attributes in \\(X_{\\text{advantage}}\\)\n: Individuals’ context-sensitive scores are computed relative to their group \\(S_i\\), as percentile of their \\(X_{\\text{merit}}\\) value relative to distribution of \\(X_{\\text{merit}}\\) values across \\(S_i\\)\nOutcome: Now that we have incorporated social context, by converting the original context-free units (e.g., numeric SAT score) into context-sensitive units (percentile of numeric SAT score within distribution of comparable individuals), we can compare people across groups on the basis of context-sensitive scores!"
  },
  {
    "objectID": "w05/slides.html#an-overly-simplistic-example-more-on-hw2",
    "href": "w05/slides.html#an-overly-simplistic-example-more-on-hw2",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "An Overly-Simplistic Example (More on HW2!)",
    "text": "An Overly-Simplistic Example (More on HW2!)\n\n\\(\\mathbf{x}_i = (x_{i,1}, x_{i,2}, x_{i,3}) = (\\texttt{wealth}_i, \\texttt{study\\_hrs}_i, \\texttt{SAT}_i)\\)\n\\(J_{\\text{advantage}} = (1) = (\\texttt{wealth})\\), \\(J_{\\text{merit}} = (2) = (\\texttt{study\\_hrs})\\)\n\\(\\Rightarrow \\texttt{study\\_hrs} \\rightarrow \\texttt{SAT}\\) a “fair” pathway\n\\(\\Rightarrow \\texttt{wealth} \\rightarrow \\texttt{SAT}\\) an “unfair” pathway\n\\(\\Rightarrow\\) School admission decisions “fair” to the extent that they capture the direct effect \\(\\texttt{study\\_hrs} \\rightarrow \\texttt{SAT} \\rightarrow \\texttt{admit}\\), but aren’t affected by indirect effect \\(\\texttt{wealth} \\rightarrow \\texttt{SAT} \\rightarrow \\texttt{admit}\\)"
  },
  {
    "objectID": "w05/slides.html#at-a-macro-level",
    "href": "w05/slides.html#at-a-macro-level",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "At a Macro Level!",
    "text": "At a Macro Level!"
  },
  {
    "objectID": "w05/slides.html#the-state-of-the-art",
    "href": "w05/slides.html#the-state-of-the-art",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The State of the Art!",
    "text": "The State of the Art!\n\nCurrent state of fairness in AI: measures which explicitly model causal connections between variables of interest are most promising for robust notions of fairness\nRobust in the sense of:\n\nBeing normatively desirable (as in, matching the key tenets of our ethical frameworks) while also being\nDescriptively tractable (as in, concretely implementable in math/code, and transparent enough to allow us to evaluate and update these implementations, using a process like reflective equilibrium)."
  },
  {
    "objectID": "w05/slides.html#the-antecedent",
    "href": "w05/slides.html#the-antecedent",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Antecedent",
    "text": "The Antecedent\n\nSince it’s impossible to eliminate information about sensitive attributes like race/gender/etc. from our ML algorithms…\nFairness should instead be defined on the basis of how this sensitive information “flows” through the causal chain of decisions which lead to an given (observed) outcome"
  },
  {
    "objectID": "w05/slides.html#the-new-object-of-analysis-causal-pathways",
    "href": "w05/slides.html#the-new-object-of-analysis-causal-pathways",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The New Object of Analysis: Causal Pathways",
    "text": "The New Object of Analysis: Causal Pathways\n\nOnce we have a model of the causal connections among:\n\nVariables that we care about socially/normatively, and\nVariables used by a Machine Learning algorithm,\n\nWe can then use techniques developed by statisticians who study causal inference to\nBlock certain “causal pathways” that we deem normatively unjustifiable while allowing other pathways that we deem to be normatively justifiable."
  },
  {
    "objectID": "w05/slides.html#causal-fairness-in-hw2",
    "href": "w05/slides.html#causal-fairness-in-hw2",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Causal Fairness in HW2",
    "text": "Causal Fairness in HW2\n\nIntuition required to make the jump from correlational approach (from statistics and probability generally, and DSAN 5100 specifically!) to causal approach!\nCausal approach builds on correlational, but…\nStricter, directional standard for \\(X \\rightarrow Y\\)\nEasy cases: find high correlation \\(|\\text{corr}(X,Y)|\\), embed in a causal diagram, evaluate \\(\\Pr(Y \\mid \\text{do}(X)) \\overset{?}{&gt;} \\Pr(Y \\mid \\neg\\text{do}(X))\\)\nHard cases: can have \\(\\Pr(Y \\mid \\text{do}(X)) \\overset{?}{&gt;} \\Pr(Y \\mid \\neg\\text{do}(X))\\) even when \\(\\text{corr}(X,Y) = 0\\) 😰 (dw, we’ll get there!)"
  },
  {
    "objectID": "w05/slides.html#causal-building-blocks",
    "href": "w05/slides.html#causal-building-blocks",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Causal Building Blocks",
    "text": "Causal Building Blocks\n\nDSAN 5100 precedent: nodes in the network \\(X\\), \\(Y\\) are Random Variables, connections \\(X \\leftrightarrow Y\\) are joint distributions \\(\\Pr(X, Y)\\)\nDirectional edges \\(X \\rightarrow Y\\), then, just represent conditional distributions: \\(X \\rightarrow Y\\) is \\(\\Pr(Y \\mid X)\\)\nWhere we’re going: connections \\(X \\leftrightarrow Y\\) represent unknown but extant causal connections between \\(X\\) and \\(Y\\), while \\(X \\rightarrow Y\\) represents a causal relationship between \\(X\\) and \\(Y\\)\nSpecifically, \\(X \\rightarrow Y\\) now means: an intervention that changes the value of \\(X\\) by \\(\\varepsilon\\) causes a change in the value of \\(Y\\) by \\(f(\\varepsilon)\\)"
  },
  {
    "objectID": "w05/slides.html#the-intuitive-problem-of-causal-inference",
    "href": "w05/slides.html#the-intuitive-problem-of-causal-inference",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Intuitive Problem of Causal Inference",
    "text": "The Intuitive Problem of Causal Inference\n\n\n\n\n\n\n\n\n\n\n\n\n\ncor(ski_df$value, law_df$value)\n\n[1] 0.9921178\n\n\n\n(Data from Spurious Correlations, Tyler Vigen)"
  },
  {
    "objectID": "w05/slides.html#the-fundamental-problem-of-causal-inference",
    "href": "w05/slides.html#the-fundamental-problem-of-causal-inference",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Fundamental Problem of Causal Inference",
    "text": "The Fundamental Problem of Causal Inference\nThe only workable definition of “\\(X\\) causes \\(Y\\)”:\n\n\n\n\n Defining Causality\n\n\n\\(X\\) causes \\(Y\\) if and only if:\n\nX temporally precedes \\(Y\\) and\nIn two worlds \\(W_0\\) and \\(W_1\\) where everything is exactly the same except that \\(X = 0\\) in \\(W_0\\) and \\(X = 1\\) in \\(W_1\\), \\(Y = 0\\) in \\(W_0\\) and \\(Y = 1\\) in \\(W_1\\) (hume_treatise_1739?)\n\n\n\n\n\n\nThe problem? We live in one world, not two simultaneous worlds 😭"
  },
  {
    "objectID": "w05/slides.html#what-is-to-be-done",
    "href": "w05/slides.html#what-is-to-be-done",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "What Is To Be Done?",
    "text": "What Is To Be Done?"
  },
  {
    "objectID": "w05/slides.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "href": "w05/slides.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm",
    "text": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm\n\nFind good comparison cases: Treatment and Control\nWithout a control group, you cannot make inferences!\nSelecting on the dependent variable…"
  },
  {
    "objectID": "w05/slides.html#selecting-on-the-dependent-variable",
    "href": "w05/slides.html#selecting-on-the-dependent-variable",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Selecting on the Dependent Variable",
    "text": "Selecting on the Dependent Variable\n\nWhat “““research”“” “““says”“” about identifying people who might commit mass shootings\nJeff’s rant: If you care about actually solving social issues, this should infuriate you"
  },
  {
    "objectID": "w05/slides.html#complications-selection",
    "href": "w05/slides.html#complications-selection",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Complications: Selection",
    "text": "Complications: Selection\n\nTldr: Why did this person (unit) end up in the treatment group? Why did this other person (unit) end up in the control group?\nAre there systematic differences?\nVietnam/Indochina Draft: Why can’t we just study [men who join the military] versus [men who don’t], and take the difference as a causal estimate?"
  },
  {
    "objectID": "w05/slides.html#complications-compliance",
    "href": "w05/slides.html#complications-compliance",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Complications: Compliance",
    "text": "Complications: Compliance\n\nWe want people assigned to treatment to take the treatment, and people assigned to control to take the control\n“Compliance”: degree to which this is true in experiment\n\nHigh compliance = most people actually took what they were assigned\nLow compliance = lots of people who were assigned to treatment actually took control, and vice-versa\n\nWhat problems might exist w.r.t compliance in the Draft?"
  },
  {
    "objectID": "w05/slides.html#next-week-and-hw2-experimental-rightarrow-observational-data",
    "href": "w05/slides.html#next-week-and-hw2-experimental-rightarrow-observational-data",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Next Week and HW2: Experimental \\(\\rightarrow\\) Observational Data",
    "text": "Next Week and HW2: Experimental \\(\\rightarrow\\) Observational Data\n\nIn observational studies, researchers have no control over assignment to treatment/control 😨\nOn the one hand… Forget Everything And Run [to randomized, controlled experiments], if you can.\nOn the other hand… statisticians over the last 4 centuries have developed fancy causal inference tools/techniques to help us Face Everything And Rise 🧐"
  },
  {
    "objectID": "w05/slides.html#for-now-matching",
    "href": "w05/slides.html#for-now-matching",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "For Now: Matching",
    "text": "For Now: Matching\n\nIn a randomized, controlled experiment, we can ensure (since we have control over the assignment mechanism) that the only systematic difference between \\(C\\) and \\(T\\) is that \\(T\\) received the treatment and \\(C\\) did not\nIn an observational study, we “show up too late”!\nThus, we no longer refer to assignment but to selection\nAnd, our job is to figure out (reverse engineer!) the selection mechanism, then correct for its non-randomness: basically, we “transform” from observational to experimental setting through weighting (👀 W02)"
  },
  {
    "objectID": "w05/slides.html#references",
    "href": "w05/slides.html#references",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "References",
    "text": "References\n\n\nDwork, Cynthia, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Rich Zemel. 2011. “Fairness Through Awareness.” arXiv. https://doi.org/10.48550/arXiv.1104.3913.\n\n\nFirth, John Rupert. 1968. Selected Papers of J.R. Firth, 1952-59. Longmans.\n\n\nKiat, Lim Swee. 2018. “Machines Gone Wrong.” PhD thesis, Singapore University of Technology; Design. https://machinesgonewrong.com/about/.\n\n\nRiederer, Christopher, and Augustin Chaintreau. 2017. “The Price of Fairness in Location Based Advertising.” Fairness, Accountability, and Transparency Workshop on Responsible Recommendation. https://doi.org/10.18122/B2MD8C.\n\n\nRoemer, John E. 1998. Equality of Opportunity. Harvard University Press.\n\n\nRousey, Dennis C. 2001. “Friends and Foes of Slavery: Foreigners and Northerners in the Old South.” Journal of Social History 35 (2): 373–96. https://www.jstor.org/stable/3790193.\n\n\nShahid, Rizwan, Stefania Bertazzon, Merril L. Knudtson, and William A. Ghali. 2009. “Comparison of Distance Measures in Spatial Analytical Modeling for Health Service Planning.” BMC Health Services Research 9 (1): 200. https://doi.org/10.1186/1472-6963-9-200.\n\n\nSimons, Josh. 2023. Algorithms for the People: Democracy in the Age of AI. Princeton University Press."
  },
  {
    "objectID": "writeups/intuitions-vs-antecedents/index.html",
    "href": "writeups/intuitions-vs-antecedents/index.html",
    "title": "From Intuitions to Antecedents",
    "section": "",
    "text": "If I’ve lived up to my teaching principles over the first seven weeks of the course, then my hope is that you’ve experienced it as more of a “choose your own adventure” course than, for example (to make a fair comparison with a different course I’m teaching this semester) DSAN 5300, where there is essentially a single “pathway” from the beginning to the end of the course1\nAs a part of that, I try my best to utilize assignments/grades/exams mainly as a “feedback mechanism” for learning, to foster a growth mindset in all of you: to encourage you in your own adventure-choosing, rather than to shove a particular vision of “Data Ethics and Policy” on you and then punish you if you don’t internalize it.\n“Growth mindset” is a new-ish term, but the idea itself goes back longer, and to me the core of it was really captured by an educational philosopher/reformer named Maria Montessori—to cut off this rant here and get to the main content, I will just include the “Pedagogical Principles” slide from when I taught PPOL 6805 (the GIS class), a slide that I also should have included in W01 of this class!\n\n\n\n\n\n\nPedagogical Principles\n\n\n\n\nThere’s literally no such thing as “intelligence”\nAnyone is capable of learning anything (neural plasticity)\nGrowth mindset: “I can’t do this” \\(\\leadsto\\) “I can’t do this yet!”\nThe point of a class is learning: understanding something about the world, either (a) For its own sake (an end in itself) or (b) Because it’s relevant to something you care about (a means to an end)\n\n\nOur teaching should be governed, not by a desire to make students learn things, but by the endeavor to keep burning within them that light which is called curiosity. (Montessori 1916)\n\n\n\nSo, given all that, here I want to take the most common deduction from HW1—the question about Rawls’ theory of rights as lexically prior to utility—and write out why it is so important for us going forward into the policy “half” of the course. Rather than bonking you all on the head with a big stick and saying “No! Wrong! Option (c) was correct! Go memorize it!”, I hope instead that this writeup can help in terms of explicitly laying out the steps of reasoning that would lead to option (c)!"
  },
  {
    "objectID": "writeups/intuitions-vs-antecedents/index.html#spring-break-intermission-pedagogical-principles",
    "href": "writeups/intuitions-vs-antecedents/index.html#spring-break-intermission-pedagogical-principles",
    "title": "From Intuitions to Antecedents",
    "section": "",
    "text": "If I’ve lived up to my teaching principles over the first seven weeks of the course, then my hope is that you’ve experienced it as more of a “choose your own adventure” course than, for example (to make a fair comparison with a different course I’m teaching this semester) DSAN 5300, where there is essentially a single “pathway” from the beginning to the end of the course1\nAs a part of that, I try my best to utilize assignments/grades/exams mainly as a “feedback mechanism” for learning, to foster a growth mindset in all of you: to encourage you in your own adventure-choosing, rather than to shove a particular vision of “Data Ethics and Policy” on you and then punish you if you don’t internalize it.\n“Growth mindset” is a new-ish term, but the idea itself goes back longer, and to me the core of it was really captured by an educational philosopher/reformer named Maria Montessori—to cut off this rant here and get to the main content, I will just include the “Pedagogical Principles” slide from when I taught PPOL 6805 (the GIS class), a slide that I also should have included in W01 of this class!\n\n\n\n\n\n\nPedagogical Principles\n\n\n\n\nThere’s literally no such thing as “intelligence”\nAnyone is capable of learning anything (neural plasticity)\nGrowth mindset: “I can’t do this” \\(\\leadsto\\) “I can’t do this yet!”\nThe point of a class is learning: understanding something about the world, either (a) For its own sake (an end in itself) or (b) Because it’s relevant to something you care about (a means to an end)\n\n\nOur teaching should be governed, not by a desire to make students learn things, but by the endeavor to keep burning within them that light which is called curiosity. (Montessori 1916)\n\n\n\nSo, given all that, here I want to take the most common deduction from HW1—the question about Rawls’ theory of rights as lexically prior to utility—and write out why it is so important for us going forward into the policy “half” of the course. Rather than bonking you all on the head with a big stick and saying “No! Wrong! Option (c) was correct! Go memorize it!”, I hope instead that this writeup can help in terms of explicitly laying out the steps of reasoning that would lead to option (c)!"
  },
  {
    "objectID": "writeups/intuitions-vs-antecedents/index.html#the-hw1-question",
    "href": "writeups/intuitions-vs-antecedents/index.html#the-hw1-question",
    "title": "From Intuitions to Antecedents",
    "section": "The HW1 Question",
    "text": "The HW1 Question\nThe question I’m most concerned about was as follows:\n\n\n\n\n\n\nHW1 Q3.2: Rights and Distributive Justice\n\n\n\nA group of people is behind the veil of ignorance, debating what rights should be enshrined in a constitution:\n\nThey have decided to enshrine a right to private property in their constitution, implying that all individuals in the society have a duty to avoid trespassing on an individual’s property without their permission. However…\nThey also want to enshrine the right to urgent medical care, implying that the society has a duty to provide life-saving resuscitation if an individual has a heart attack, for example.\n\nThe debate centers around what ought to happen, if both rights are indeed written into the constitution, in the following scenario:\n\nA person \\(i\\) is walking down the (public) sidewalk and suddenly has a heart attack, falling over into person \\(j\\)’s (private) front yard. Paramedics arrive quickly on the scene, but \\(j\\) isn’t home to grant or deny permission for the paramedics to enter their front yard to provide medical care to \\(i\\).\n\nThus the society is deliberating about a third constitutional provision to cover this case, which means choosing an ethical preference ordering over the following two possible worlds:\n\n\\(W_1\\): \\(j\\)’s right to private property is given higher priority, so that the paramedics must not violate this right to provide the medical care to \\(i\\)\n\\(W_2\\): \\(i\\)’s right to urgent medical care is given higher priority, so that the paramedics must violate \\(j\\)’s right to private property and enter the yard to provide the medical care\n\nUnder a Rawlsian ethical framework, is this a prioritization that the society could determine a priori (behind the “veil of ignorance”)? Or is Rawls’ ethical framework indeterminate with regard to this ethical decision? If it is not indeterminate, which of the two possible worlds does the Rawlsian system imply should be preferred by a normatively “good” society?\n\n\\(W_1\\) should be preferred\n\\(W_2\\) should be preferred\nIndeterminate\n\n\n\nThe correct answer here (in an important way!) was (c) Indeterminate. However, a good number of folks put (b) \\(W_2\\) should be preferred. I spent a while trying to dig into this outlier, and I think even the most basic explanation—that many of yall are extremely busy and just chose the one that sounded intuitively best—gives us a nice and super-relevant “learning moment”!\nThe reason I hyper-fixate on this one commonly-missed question here is because, starting with this slide from Week 1, a key thread running throughout the entire course is the importance of looking at/figuring out antecedents, as the only way to “cross the boundary” between your own beliefs and those of others."
  },
  {
    "objectID": "writeups/intuitions-vs-antecedents/index.html#why-cant-we-just-use-our-intuition",
    "href": "writeups/intuitions-vs-antecedents/index.html#why-cant-we-just-use-our-intuition",
    "title": "From Intuitions to Antecedents",
    "section": "Why Can’t We Just Use Our Intuition?",
    "text": "Why Can’t We Just Use Our Intuition?\nAnswering this question is… somewhat difficult in terms of how “meta” it is, so, I genuinely apologize (like I did for the Kant writeup) since I don’t know any way to explain it without using some philosophical jargony things 😭\nThe meta-ness comes from the fact that, if a person \\(i\\) says “I believe \\(p\\) because \\(p\\) is obviously true”, and if that predicate \\(p\\) itself is “I can use my intuitions to derive (moral) truths”, then… essentially an infinite-loop of self-reinforcing certainty is created. At best, an interlocutor \\(j\\) can only “chip away at” \\(i\\)’s’ belief-loop, perhaps by e.g. pointing out cases to \\(i\\) where their intuition has failed.2\nBut, with enough “chipping”, \\(i\\) may be convinced to shift their belief towards something more like a predicate \\(q\\), “I can use my intuitions, along with my understanding of other people’s antecedents, to derive moral truths”, which may then reverberate back to “I believe \\(q\\) because \\(q\\) ‘fits with’ the synthesis I’ve formed between my own intuition and the intuitions of others”3\nNonetheless, my implicit antecedent in writing this is that this shift is possible… To inject myself into it one last time, for example, one reason why I included that “My Biases” slide in W01 is because childhood Jeff absolutely would say things like “I believe \\(p\\) because \\(p\\) is obviously true”, where \\(p\\) would be things like “Israel has a right to ‘defend itself’”.4\nSo, with all that said, the reason why I emphasize “antecedent-tracing” so much (and why (c) being the correct answer is important) is precisely because we need somewhere to “go”, data-ethics-and-policy-wise, when the types of conflicts outlined in that question arise in our lives as data scientists!\nOn the one hand, the scenarios in “new employee ethics training” slides, that I called silly in class (bc they are), usually look something like:\n\nBillyBob (Boss): Hey, Alice, you should falsify some data so we can get published and make millions of dollars!!! I will give you a big ‘Employee of the Month’ trophy if you do!!!\nAlice (You): Select a proper response in this scenario\n\nAnd then you’re supposed to click something like “Report BillyBob to [institutional ethics board]”, producing the green check and unlocking the “certified ethics master” achievement.\nOn the other hand, the data-science-career scenarios that I’ve tried to center in class—which can be more pernicious because they are absent from new-employee ethics seminars and thus don’t necessarily have obvious answers—look more like:\n\nBillyBob (Boss): Hey, Alice, we need to include “““crime”“” as a variable in our model, can you go collect data for that?\nAlice (You): Decide (a) how to operationalize “““crime”““, or (b) push back on BillyBob’s command on grounds that perhaps we might not want to reify”““crime”“” in statistical models given ethical issues with how it is measured in available datasets in our current society\n\nAnd in these kinds of cases, whether you choose (a), (b), or some other option, the data-ethical choice you make (the purpose of this class, hence the name) will be rooted in some notion of why it’s a “good” choice to make under those circumstances. And the answer to that why question is precisely the antecedent:\n\nIf you choose (a), for example, perhaps the option is…\n\n“Good” implicitly in terms of reducing your own cognitive dissonance (antecedent = reduction of cognitive dissonance should play a role in ethical decisionmaking), or\n“Good” explicitly because your boss asks you why you chose some particular operationalization and you are able to respond with your reasoning (antecedent = justifiability and/or satisfying your boss should play a role in ethical decisionmaking)\n\nIf you choose (b), for example, your boss may ask you to elaborate/explain why you’re not carrying out the command, which would bring in the same justifiability/boss-satisfaction antecedent as in the previous bullet point.\n\nThen, under the antecedent that the resolution of conflicts like this in a given workplace is a function of the involved agents’ relative power5, your ability to frame your answer to the “why” question in terms of antecedents that will “click” with those of your boss will be directly proportional to your “success” in making the “right” decision here!"
  },
  {
    "objectID": "writeups/intuitions-vs-antecedents/index.html#how-does-the-specifying-antecedents-approach-resolve-this-issue",
    "href": "writeups/intuitions-vs-antecedents/index.html#how-does-the-specifying-antecedents-approach-resolve-this-issue",
    "title": "From Intuitions to Antecedents",
    "section": "How Does the Specifying-Antecedents Approach “Resolve” This Issue?",
    "text": "How Does the Specifying-Antecedents Approach “Resolve” This Issue?\nThe increase in likelihood of “success” isn’t exactly the end of the story here, though. A more holistic way to summarize the answer to the previous section’s question (the question in the title) is:\nAlthough the approach of “we should operationalize crime as \\(\\underline{\\hspace{60px}}\\) because my intuition says that’s best” or “because it’s obvious” is pretty much exactly how we carry out our day-to-day data-scientific work subconsciously (e.g., during long R/Python sessions!), the goal of the (Geertz 1973) slide from W01 was to point out how:\n\nBeing conscious of our antecedents will be helpful descriptively when we’re working with others who may ask for justification or may not be convinced by “because it’s obvious”, and\nBeing conscious of our antecedents will be helpful normatively in terms of helping us evaluate the alignment between our day-to-day subconscious choices and our conscious ethical values\n\nSo, to finally get to the takeaway in terms of Q3.2: it’s important to know that Rawls’ framework, on its own, does not serve as an antecedent for deciding between different rights that a society has decided to establish!\nRawls’ contribution to ethics, in the broadly-construed way we’ve talked about ethics in the first half of the course, was primarily to give a “middle-ground solution” to the Problem of Utilitarianism that we discussed (torturing one person to make everyone else happy):\n\n\n\n\n\n\nRawls as Solution to Utilitarian Torture-One-Person Problem\n\n\n\nSociety adopts Utilitarianism, except for a set of Kant-style (deontological) rules regarding the rights of individuals, which thus serve as “vetos” that individuals can use to override Utilitarian decisions.\n\n\nRawls, however (importantly!) does not provide a framework for (a) which specific rules should be adopted as rights, or (b) the prioritization of certain rights \\(x\\) as “more important than” other rights \\(y\\).\nThis “hedging” by Rawls is, ultimately, not specific to Rawls but just one example of the “Paradox of Liberalism”: if we want a full-on, concrete ethical framework—one which actually specifies the content of what a person/group/organization should do in a particular case… then we need to add on our own antecedents. For example, an antecedent that would make (a) \\(W_1\\) should be preferred correct would be:\n\nRawls’ theory + “The right to private property is more important than the right to medical care”\n\nWhereas an antecedent that would make (b) \\(W_2\\) should be preferred correct would be:\n\nRawls’ theory + “The right to medical care is more important than the right to private property”\n\nAnd thus, one of those two additional antecedents would need to be added, as a third clause to the constitution being debated, for the question to not be indeterminate!\nThat’s… the best I can do in terms of explaining why Q3.2 is so important, and why we shouldn’t answer it based on our intuitions, but should think about the antecedents that would lead to each of the three answer choices! For anyone still reading, who wants the full-on deeper philosophical/cultural reasons that I can’t really do justice to (the more general “crossing the boundary between your own and others’ beliefs” from the W01 slide), check out:\n\nGeertz (1973), The Interpretation of Cultures (the book pictured in that W01 slide),\nSkorupski (1978), “The Meaning of Another Culture’s Beliefs” [Pages 83-106 in this PDF], and\nSkinner (2012), “Interpretation, Rationality, and Truth” [Pages 27-56 in this PDF]"
  },
  {
    "objectID": "writeups/intuitions-vs-antecedents/index.html#appendix-extremely-cool-modern-neuroscience-based-cultural-studies",
    "href": "writeups/intuitions-vs-antecedents/index.html#appendix-extremely-cool-modern-neuroscience-based-cultural-studies",
    "title": "From Intuitions to Antecedents",
    "section": "Appendix: Extremely Cool Modern Neuroscience-Based Cultural Studies",
    "text": "Appendix: Extremely Cool Modern Neuroscience-Based Cultural Studies\nIf you’ve read to this point (beyond even the point at the end of the last section where I tossed a bunch of books at you?!?): You’ll notice that the readings in the last section are kind of old and dry and philosophical. But, there is (imo) also really exciting research being done in cognitive science/neuroscience labs to test the kinds of theories talked about in those philosophy papers:\nBasically, they use behavioral experiments and EEG/EKG/MRI data to probe into what exactly is going on in people’s heads when they make [logical or ethical] decisions? Those studies usually cite Sperber (1996) as a key “spark” that gave rise to this research program, and it is definitely a mind-blowingly cool book and fun place to start. Then, for an example of a more recent study on this front, see Miton and DeDeo (2022) (and then check out both of those authors’ Google Scholar pages for more!)"
  },
  {
    "objectID": "writeups/intuitions-vs-antecedents/index.html#references",
    "href": "writeups/intuitions-vs-antecedents/index.html#references",
    "title": "From Intuitions to Antecedents",
    "section": "References",
    "text": "References\n\n\nGeertz, Clifford. 1973. The Interpretation Of Cultures. Basic Books.\n\n\nMiton, Helena, and Simon DeDeo. 2022. “The Cultural Transmission of Tacit Knowledge.” Journal of The Royal Society Interface 19 (195): 20220238. https://doi.org/10.1098/rsif.2022.0238.\n\n\nMontessori, Maria. 1916. Spontaneous Activity in Education: A Basic Guide to the Montessori Methods of Learning in the Classroom. Lulu Press.\n\n\nSkinner, Quentin. 2012. Visions of Politics, Volume 1: Regarding Method. Cambridge: Cambridge University Press.\n\n\nSkorupski, John. 1978. “The Meaning of Another Culture’s Beliefs.” In Action and Interpretation: Studies in the Philosophy of the Social Sciences, edited by Christopher Hookway and Philip Pettit, 83–106. CUP Archive.\n\n\nSperber, Dan. 1996. Explaining Culture: A Naturalistic Approach. Cambridge: Blackwell."
  },
  {
    "objectID": "writeups/intuitions-vs-antecedents/index.html#footnotes",
    "href": "writeups/intuitions-vs-antecedents/index.html#footnotes",
    "title": "From Intuitions to Antecedents",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn that case, that pathway is determined by the structure of the chapters in ISLR!↩︎\nAs a tldr: this “meta-difficulty” is also behind my rant in class about why you should adopt \\(0.99999\\) rather than \\(1\\) as the probability you ascribe to things you think are “certain”! It turns out that this shift-to-\\(0.99999\\) can simultaneously resolve both technical-mathematical issues (like trying to use Bayes’ Rule to derive posterior distributions from evidence if your prior is \\(\\Pr(E) = 0\\)) and philosophical-epistemological issues like the one just described 😎↩︎\n(I wouldn’t mention this except for the fact that I got to mention it in a recently-peer-reviewed and soon-to-be-released book chapter, woohoo) Since I come from a Computer Science background, I think of this “chipping away” approach as directly analogous to the EM Algorithm for deriving Maximum Likelihood estimates: we can obtain better estimates of model parameters through a series of “chipping” steps, shuffling back-and-forth from the Expectation-computation step to the likelihood-Maximization step. If that makes no sense, please don’t worry, and just ignore all that until the chapter comes out :P↩︎\n“The IDF is the most moral army in the world” was another favorite of 13-year-old Jeff—I absolutely would have characterized this as obviously-true “common sense” at that time.↩︎\nIf this seems like a fuzzy concept right now, we will be going over a formal legal-theory-based definition of “relative power in a workplace” next week!↩︎"
  },
  {
    "objectID": "writeups/w02.html",
    "href": "writeups/w02.html",
    "title": "Week 2 Resources / Priming Your Brain for HW1",
    "section": "",
    "text": "Hi all :) It’s in my nature or something to kvetch about “loose ends” that haven’t been tied up once class ends (plus, there are fun studies about so-called spaced repetition and how it massively increases retention and understanding, if u wanna be science about it), so I’ll try to get into the habit of sending these after class, so you have some stuff to pursue in the intervening week, if you’d like! (Update: I accidentally wrote way too much for an email, so, I’ll also add these to the course webpage in the “Writeups” section, linked in the sidebar)"
  },
  {
    "objectID": "writeups/w02.html#things-i-googled-opened-during-class",
    "href": "writeups/w02.html#things-i-googled-opened-during-class",
    "title": "Week 2 Resources / Priming Your Brain for HW1",
    "section": "1. Things I Googled / Opened During Class",
    "text": "1. Things I Googled / Opened During Class\n\n(a) Eugenia Cheng talk at Google, “The Art of Logic” (YouTube)\nIt’s the part from 14 minutes onwards where she starts drawing the diagrams relevant to us: “tracing back” an ethically-charged scenario from observed consequents (e.g., person gets beaten up and taken off the plane) to the massive collection of hypothesized antecedents (e.g., flight delays, policies of overbooking, capitalism, efficiency of the airline, and the incentives thereof). To map it back into something from the slides for this class: this “tracing back” corresponds (in my view) to the term I mentioned in the slides from last week: “unraveling history”.\nHopefully the Eugenia Cheng talk, in combination with this notion of “unraveling history” or “tracing consequents to antecedents”, can help you in seeing how difficult it is to answer the question of when to stop doing this “tracing back” and start intervening. If I was to keep ranting, I would mention how my “solution” here, to the extent that “solutions” are possible, is (i) humans aren’t fully rational, but we can incorporate the limits of our own rationality into our models of humans in some sense, e.g. as is done in models of boundedly rational; then, with a bounded-rationality-based model in hand, (ii) Bayes rule literally gives us a mathematically “optimal” rule, given an objective function of “choosing the best course of action given all information available to us at a given moment”, for which course of action to choose. This essay by Simon DeDeo from Carnegie Mellon University does a better job than I ever could at explaining and justifying why this might be a good model for decision-making under uncertainty (and why it makes sense to call it “Bayesian Reasoning”), despite its horribly pretentious/condescending title :P\n\n\n(b) Walter Thabit, How East New York Became A Ghetto (2003): PDF\nThis one is a bit more peripheral to the main topics in this class, but yeah I wanted to bring it up in class and then also send the PDF here because: if data science in urban policy is your jam, it’s a perfect example of how the data we have nowadays about differential health outcomes and correlates of crime and etc. for different neighborhoods in NYC didn’t magically “appear” in nice .csv format – it exists because of some combination of political organizing and agitation and etc. (which Walter Thabit himself very much took part in), in conjunction with the discrepancies that were pointed out in a more “qualitative” way by works in urban sociology like this one and its precursors…"
  },
  {
    "objectID": "writeups/w02.html#exploitation-as-descriptive-vs.-normative-term-in-economics",
    "href": "writeups/w02.html#exploitation-as-descriptive-vs.-normative-term-in-economics",
    "title": "Week 2 Resources / Priming Your Brain for HW1",
    "section": "2. “Exploitation” as Descriptive vs. Normative Term in Economics",
    "text": "2. “Exploitation” as Descriptive vs. Normative Term in Economics\nI basically completely stammered my way through answering this question in-class, which I’m mad at myself for since imo “exploitation” is a 100% perfect example for looking at how words can have entirely different meanings, and how people can make diametrically opposed judgements of their validity, both within and between the “descriptive” and “normative” realms.\nIn this case, analysis/discussion in the descriptive realm could look like: should we attach the label [“exploitation” (as descriptive term)] to [equation \\(A\\)] or [equation \\(B\\)]? Then, in the normative realm, analysis/discussion could look like: is [“exploitation” (as descriptive term, labeling equation \\(X \\in \\{A, B\\}\\))] morally objectionable? Is it something an institution could feasibly reduce, in theory? And if so, should they use the scarce resources available to them to try and reduce it?\nThe reason I stammered and felt so embarrassed that I couldn’t give a good succinct answer is because… I have no idea how to explain it without sounding like I’m doing a cringey flex/humblebrag type of thing but here goes:\nPrinceton University Press literally commissioned me to write a book chapter answering exactly that question back in 2018 lol, as basically part of a little companion book to a new edition of Das Kapital coming out in September this year (as part of my role on the editorial board for that), woohoo! But then, 10% because of covid and 90% because of my inability to finish anything, the chapter still isn’t finished and isn’t coming out anytime soon. Worse, it’s not even helpful to link the pdf draft in its current state (since there are literally like, half-finished equations in it, section headers without text, etc.). But if the question of different ethical perspectives on economically-defined exploitation is interesting to you, I am happy to send you a sloppy-but-finished pdf of the next draft in ~a week or two!\nSo yeah, embarrassed because I couldn’t just say “read my book!” given its current disheveled state, SO the resolution to all this is that I’m just going to link PDFs for two finished and published book! One by a person I mentioned in week 1, John Roemer:\n\n(a) Roemer, Free to Lose: An Introduction to Marxist Economic Philosophy (1988) [PDF], Chs. 2 and 4\nThis book gives an “intuitive” model of exploitation in plain English in Chapter 2, then a mathematical model with a semi-formal microeconomic definition of exploitation in Chapter 4.1\n\n\n(b) Morishima, Marx’s Economics (1973) [PDF], Ch. 5: “Surplus Value and Exploitation”\nIf you were an econ major, and especially if you feel good about econometrics stuff that uses linear algebra and matrix equations, you might instead prefer [chapter 5 of this book] by Michio Morishima, which (a) is better in the sense that it uses more standard econ terms, but then (b) is worse in the sense that it is all building to the argument it became famous for (in chapter 14), that Marxian exploitation can be defined without assuming the so-called Labor Theory of Value. Which was interesting in the 70s when it came out, but by 1988 Roemer could mostly just get to the point of defining and discussing exploitation without having to call it Exploitation-but-not-the-kind-thats-defined-using-Labor-Theory-of-Value.\nMoving back on-topic to DSAN 5450, though, the Morishima book does have a nice feature in that Chapter 2 is called “Hidden Assumptions”! Where he goes more into what antecedents might be hiding behind the term “exploitation” when it is used by neoclassical economists vs. Marxian economists."
  },
  {
    "objectID": "writeups/w02.html#hw1-nuts-and-bolts-for-fairness-in-ai",
    "href": "writeups/w02.html#hw1-nuts-and-bolts-for-fairness-in-ai",
    "title": "Week 2 Resources / Priming Your Brain for HW1",
    "section": "3. HW1: Nuts and Bolts for Fairness in AI",
    "text": "3. HW1: Nuts and Bolts for Fairness in AI\nI’ve already written way too much and included way too many PDFs here, but I’d rather have you overly rather than under-ly prepared for HW1, so I just wanted to give a quick preview of what will be on it, with pointers towards stuff where, if you skim them for example, you’ll know what to do when the homework comes along.\nTo be clear: most of the contents of these readings will be scary and confusing, since (a) we haven’t discussed them yet, but also (b) they’re entire papers/books devoted solely to a single topic that is just one among several topics in this class. And so the idea is just: you can look at these, maybe read the ones that you find sufficiently interesting and ignore the ones you don’t, and then your brain will be “primed” for the full-on understanding we’ll develop through slides + homework!\n\n(a) Recovering “Race” from Proxy Variables\nThere are a million bazillion books and articles and essays from humanities and the social sciences which I am forcing myself not to list here, because I want to just give yall a short-and-sweet primer you can use to understand the issue with “Step 1: remove the variable called ‘race’ -&gt; Step 2: problem solved 🥳💯” from a straightforward, data-science-rooted standpoint. So, for that, I’d go with this one:\n\nMichael Carl Tschantz, “What is Proxy Discrimination?” (2022)\n\n\n\n(b) Discrimination in Advertising\n\nAli et al. (2019). “Discrimination through optimization: How Facebook’s ad delivery can lead to skewed outcomes”, arXiv Preprint\n\nThis topic purposefully comes after (a) though (a) and (b) form a connected pair, since the results in this paper will seem very confusing/suspicious without knowledge about more and less valid ways of “recovering” race despite absence of a variable called “race” in the dataset. In the study, they employ an absolutely brilliant method (imo) for discovering discrimination in Facebook’s ads, but then they do a bit of a “sleight of hand” in just saying “we’ve found that the discrimination is based on race”, when in fact it’s “we’ve found that the discrimination is based on [estimated race inferred from proxy variables in a way that you might think is valid but you also might think is invalid]”.\n\n\n(c) Confusion matrix fairness\nAs you might see on the slides we haven’t gotten to yet, the two main resources I’m drawing on for this part are:\n\nChapter 3 of Barocas, Hardt, and Narayanan’s Fairness in Machine Learning (2023) (the full book is online for free, legally!), titled “Classification”\nMitchell et al. “Algorithmic Fairness: Choices, Assumptions, and Definitions”. Annual Review of Statistics and its Applications (2021)\n\nBut then, really, an approach to the confusion matrix-based definitions (among others!) that probably fits even better with the class is this presentation from Narayanan (the third author on the above Fairness in ML book), which is refreshing in that it explicitly links fairness definitions with political considerations, rather than trying to “hide” them behind… math/science/greek letters\n\nArvind Narayanan, “Tutorial: 21 Fairness Definitions and Their Politics”, from FAT-ML Conference, 2018 (YouTube)\n\n\n\n(d) Causal-path fairness\n\nChapter 5 of the Fairness in Machine Learning book mentioned above is all about causality-based approaches.\n\nIt’s not my favorite starting point tbh, but since I already linked that book, if you find that you like its approach, you can read Ch 6 as well…\nTo me, a central work in this sphere is:\n\nLily Hu, “What is ‘Race’ in Algorithmic Discrimination on the Basis of Race?”, Journal of Moral Philosophy (2024, forthcoming)\n\nThis is the distillation of Lily’s “thick constructivist” theory of race that I mentioned today. But the intuition behind it is broken down into maybe more digestible chunks with pictures and stuff in her blog posts on the Phenomenal World blog. There are 5 things listed there, but the last 2 are interviews so just skip those, I’m referring to “Disparate Causes Pt. I”, “Disparate Causes Pt. II”, and “Direct Effects”\nThe thing I’m scared of with this part, though, is that Lily’s work is a critique of causal-path fairness definitions, meaning that it can be hard to start there if you don’t know the thing she’s critiquing in the first place… the issue is that the literature on causal pathways is really brutally tough to “break into”, honestly. But, probably the book with the fewest barriers to entry—basically, a book that you have all the necessary background for, as DSAN students—is:\n\nMorgan and Winship (2014). Counterfactuals and Causal Inference [PDF]\n\nAnd then I’ll just say that: a book with the full-on details of everything you’d ever want to know about causal pathways is:\n\nJudea Pearl (2000). Causality: Models, Reasoning, and Inference [PDF, EPUB]\n\n\n\n(e) Reverse fairness\nThis one was rough tbh, in terms of trying to intro it in Week 2 without the details you’ll have by Week ~7 to 9 when we’ll get into this. Because, it’s actually completely rooted in a topic that maybe sounds… either miserably boring or miserably presumptuous at first: “Optimal Tax Rate Theory” (Optimal labor income taxation / Optimal capital income taxation)\nBut, if you are willing to see what they mean when they say that a tax rate is quote-unquote “optimal”, it will get you most of the way to understanding inverse fairness. As you’re hopefully getting used to, descriptively it means something like:\n\n“[set of criteria \\(C\\) and objective function \\(f\\)] =&gt; [tax rate \\(z^*\\) = maximum of \\(f\\) subject to constraints \\(C\\)]”,\n\nand then normatively it means something like:\n\n“[if \\((C,f)\\) characterize your policy goal(s)] \\(\\implies\\) [you ought to set tax rate to be \\(z\\)]”.\n\nThat’s not as fun or conclusive/satisfying as they way some economists present it (“this is the best most GOATed tax rate and if you don’t choose this tax rate you’re dumb and don’t understand economics!!”), but it allows us to understand the word “optimal” as the \\(q\\) in \\(p \\implies q\\) and move on 😜\nBecause then, we can use Bayes’ rule to go back and forth: from \\(p\\) to \\(q\\), or (!) from \\(q\\) backwards to \\(p\\). And in this case that means: given a set of distributional concerns (\\(p\\)), we can derive an optimal tax rate (\\(q\\)), OR (!) given an existing tax rate \\(q\\), we can infer the distributional concerns \\(p\\) that such a tax rate is implicitly implementing, in the sense of which groups in society are “weighted” higher and lower in the aggregation of individual preferences that manifests in the form of the tax policy.\nSince this is so much later in the class, and the HW1 problem will just be tiiny baby steps in that direction, I’m not too worried about specific articles or anything here – instead, I think actually a really helpful thing to read (though it may seem totally out of nowhere) is:\n\nJean-Paul Sartre (1946) Existentialism is a Humanism [PDF, EPUB], pgs. 30-34\n\nIf you use the EPUB: it’s the series of paragraphs starting with “To give you an example that will help you to better understand what we mean by abandonment”; it’s a section where he talks about a student coming to him for help with “ethically deciding” whether to join the anti-Nazi resistance or stay home and care for his sick mother.\nThe reason I cite that here is because it highlights how, once we’ve set up all these fancy definitions of fairness and causality and social welfare and etc., there is still always going to be an indeterminacy in ethical decision-making: Sartre’s point in giving this anecdote, in my reading of it at least, was to drive home the fact that he could teach this student 20 years of seminars on ethics, and the student could know 500 ethical frameworks in minute detail, and he would still have to do the hard, agonizing emotional work of making the decision. I think that can be a pretty good lesson to help us “zoom out” a bit, if we find ourselves lost in the sauce of “algorithms are gonna make all our decisions and fix everything!!”\nK I’m done,\nJeff"
  },
  {
    "objectID": "writeups/w02.html#footnotes",
    "href": "writeups/w02.html#footnotes",
    "title": "Week 2 Resources / Priming Your Brain for HW1",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you want the full set of gruesome axioms/antecedents which give rise to this definition, that’s in the more-intense-math but fully-axiomatized “version” of the book: Analytical Foundations of Marxian Economic Theory↩︎"
  },
  {
    "objectID": "writeups/ai_fairness.html",
    "href": "writeups/ai_fairness.html",
    "title": "Is It Fair? The Issue of Operationalization and “Fairness” in AI",
    "section": "",
    "text": "Colab Link\n\n\n\n\nClick here to open in Colab"
  },
  {
    "objectID": "writeups/ai_fairness.html#is-it-fair-the-issue-of-operationalization-and-fairness-in-ai",
    "href": "writeups/ai_fairness.html#is-it-fair-the-issue-of-operationalization-and-fairness-in-ai",
    "title": "Is It Fair? The Issue of Operationalization and “Fairness” in AI",
    "section": "Is It Fair? The Issue of Operationalization and “Fairness” in AI",
    "text": "Is It Fair? The Issue of Operationalization and “Fairness” in AI"
  },
  {
    "objectID": "writeups/ai_fairness.html#true-and-inferred-population-parameters",
    "href": "writeups/ai_fairness.html#true-and-inferred-population-parameters",
    "title": "Is It Fair? The Issue of Operationalization and “Fairness” in AI",
    "section": "(1) (True and Inferred) Population Parameters",
    "text": "(1) (True and Inferred) Population Parameters\nAs an opening disclaimer: recall that we know from statistical theory (e.g., the material that forms the basis of DSAN5100) that, given a population of size \\(\\nu\\) (“nu”, the Greek version of \\(n\\)), even if we conduct smaller samples of size \\(n \\ll \\nu\\), we can infer fairly accurate estimates of some property of the population, especially as \\(n \\rightarrow \\nu\\).\nSo, given that framework, and our goal of laying out operationalization as clearly as possible, you can keep in mind here that:\n\nThe parts of our analysis which look at drug usage by race will utilize this antecedent, but that\nThe parts of our analysis which utilize base rates of self-reported race will in fact be slightly different: they will be “true” population parameter values, given their provenance from the US Census itself.\n\n\n(1.1) Setting the Table: Inferences from Empirical Survey Data\nStudies of drug usage, drawing on a range of anonymized surveys, have slowly started to come up with estimates of population drug usage by self-reported race, which tend to find that the rate of narcotics usage is slightly higher for the white population than for the black population in the US (left panel):\n\nImage Source\n\n\n(1.2) Axioms and Antecedents: Race\nMathematically, then, let’s start laying out our axioms or antecedents, that we’ll work with in building up descriptive definitions of fairness.\nLet \\(\\overline{\\Pi}\\) represent the entire population of the US, so that e.g. \\(\\Pr_{\\overline{\\Pi}}(E)\\) represents the probability that a randomly-chosen person from the population satisfies event \\(E\\). Let \\(\\overline{\\mathcal{W}}\\) and \\(\\overline{\\mathcal{B}}\\) represent the white and black populations of the US respectively (recall from e.g. DSAN5100 the use of Greek letters, or at least curly capitalized Latin letters, to represent population parameters! And, as for why they have \\(\\overline{\\text{overlines}}\\) above them, read onwards).\nLet’s first attempt (and fail) to define a Random Variable \\(\\widetilde{A}\\) (short for “Protected Attribute” in this case) representing the race self-reported to the US Census for a randomly-chosen person from the population of the US (\\(\\overline{\\Pi}\\)), such that\n\\[\n\\widetilde{A} = \\begin{cases}\n0 &\\text{if Self-Reported White} \\\\\n1 &\\text{if Self-Reported Black}\n\\end{cases}\n\\]\nWhy is there a tilde (~) above the \\(A\\) there (and why does this fail to serve as a valid Random Variable as defined in probability theory)? Because, before we can even get off the ground, we have to have the background knowledge that individuals responding to the Census’ questions can list more than one race: there are many individuals in the US for whom the event \\(\\widetilde{A} = 0\\) and \\(\\widetilde{A} = 1\\) both occur if they happen to be the randomly-chosen person. Thus, since Random Variables are by definition:\n\nFunctions which map\nOutcomes from a sample space (which are by definition mutually-exclusive, since the set of possible outcomes forms a partition of the sample space \\(\\Omega\\)) to\nValues in \\(\\mathbb{R}\\),\n\n\\(\\widetilde{A}\\) is straightforwardly not a valid Random Variable—the conditions of the Kolmogorov axioms, which enable expressions in probability theory to be “true” in the same way that the ZFC axioms enable \\(1 + 1 = 2\\) to be “true”, do not permit non-mutually-exclusive outcomes.\nSo, if we simply ignore this fact and “jump” directly to white vs. black in the way that this is usually done—a jump that, admittedly, we made ourselves in Question 4 of HW1—this should trigger a “red flag” in your mind, with respect to the question from the Operationalization slides about, “is this variable really measuring what it says it is measuring?”\nTo address this issue, at minimum, we’ll need to define two Random Variables \\(B\\) and \\(W\\), such that\n\\[\n\\begin{align*}\nB &= \\begin{cases}\n0 &\\text{if Did Not Self-Report Black} \\\\\n1 &\\text{if Self-Reported Black}\n\\end{cases} \\\\\nW &= \\begin{cases}\n0 &\\text{if Did Not Self-Report White} \\\\\n1 &\\text{if Self-Reported White}\n\\end{cases}\n\\end{align*}\n\\]\nSo that now \\(B = 1\\) and \\(W = 1\\) can both be true for an individual, which does not violate any Kolmogorov axioms!\nThen, we can read more into the methodology that the Hamilton Project/Brookings study cited above uses, to find that they\n\n\nSplit individuals in the dataset into several racial groups on the basis of one-reported-race only responses, and then\n\n\nOnly computed rates of drug use for the one-reported-race respondents who reported either black or white.\n\n\nSo, solely for the (descriptive) purpose of matching their provided data on drug usage with base rate information from the Census (see below), we’ll now define a non-tilde version of \\(A\\) which is what the two bars in the above plots really represent. Letting\n\\[\nS = \\begin{cases}\n0 &\\text{if Multiple Self-Reported Races} \\\\\n1 &\\text{if Single Self-Reported Race}\n\\end{cases}\n\\]\nwe can now handle the first bullet point by defining a new sub-population \\(\\Sigma \\subset \\overline{\\Pi}\\) consisting of all Census respondents who self-reported only one race, i.e., all Census respondents in \\(\\overline{\\Pi}\\) for whom \\(S = 1\\).\nBut, to handle the second bullet point, we need to define a second sub-population \\(\\Pi \\subset \\Sigma \\subset \\overline{\\Pi}\\), of those individuals in \\(\\Sigma\\) for whom \\(W = 1\\) or \\(B = 1\\).\nIt is with respect to this second sub-population \\(\\Pi\\) that we can now finally define a valid binary Random Variable \\(A\\) as\n\\[\nA = \\begin{cases}\n0 &\\text{if }W = 1 \\\\\n1 &\\text{if }B = 1\n\\end{cases}\n\\]\nwhere we need to keep in mind that \\(A\\) is only well-defined with respect to \\(\\Pi \\subset \\Sigma \\subset \\overline{\\Pi}\\).\nNow, as the Hamilton Institute/Brookings study (and many many, probably most, studies of race in the US) defines it implicitly, we can therefore be more explicit here that we are:\n\nMapping \\(A = 0\\) to the term “White” and\nMapping \\(A = 1\\) to the term “Black”.\n\nCorrespondingly, we can map:\n\nThe set of individuals in \\(\\Sigma\\) for whom \\(A = 0\\) to the term “white population” and the symbol \\(\\mathcal{W}\\) (mirroring the \\(\\overline{\\mathcal{W}}\\) from earlier) and\nThe set of individuals in \\(\\Sigma\\) for whom \\(A = 1\\) to the term “black population” and the symbol \\(\\mathcal{B}\\) (mirroring the \\(\\overline{\\mathcal{B}}\\) from earlier)\n\nI will drop the scare-quotes on “Black” and “White” in a lot of places going forward, so your job is to insert them in your mind when you read the two non-scare-quoted words! I understand if that strikes you as pedantic at first, but please keep in mind the goal of transparency and reproducibility in science (those aren’t even from this class, they’re from the core DSAN5000 class, week 1!): the point is to enable people who are (rightfully) skeptical about data scientists studying race to at least be able to scroll up here and uncover some of the layers of assumptions undergirding our operationalization of “race” here.\n\n\n(1.3) Axioms and Antecedents: Drug Usage\nNow, to characterize the height of the bar plotted in the figure’s left panel (as opposed to the split of the population into two separate bars), we need to define \\(D\\) as a Random Variable (short for “Drugs” in this case) representing the drug use of a randomly-chosen person from \\(\\Pi\\), such that\n\\[\nD = \\begin{cases}\n0 &\\text{if Doesn't Use Drugs} \\\\\n1 &\\text{if Uses Drugs}\n\\end{cases}\n\\]\nAnd now we can represent the two bar heights, the two population-level parameters, as:\n\\[\n\\begin{align*}\n\\mathbb{E}[D \\mid A = 0] = \\Pr(D = 1 \\mid A = 0) &\\approx 0.18 \\\\\n\\mathbb{E}[D \\mid A = 1] = \\Pr(D = 1 \\mid A = 1) &\\approx 0.16\n\\end{align*}\n\\]\nWhere the expectation and probability measures are equal in this case because the Random Variable \\(D\\) is binary (0/1)[1].\nNotice how, there are implementation factors coming into play in moving from this information towards the Fairness in AI material below, since we have a somewhat weird case of something (drug use) that we can infer at the population level despite not being able to easily observe it at the individual level. In other words, to move to the next “step” from this one, we’re already pushing a lot of stuff-from-weeks-1-and-2 (for example, the ethics of elicitation of sensitive data—an individual is not going to be as forthcoming in their illegal drug usage as they would be their eye color).\n\n\nThis is a straightforward probability-using-binary-RVs theorem, not something specific to 5450, but I think it can help to re-state it early on here: that if \\(X\\) is a binary 0/1 Random Variable, then the definition of expectation of a RV gives us:\n\n\\[\n\\mathbb{E}[X] \\overset{\\text{def}}{=} \\sum_{v_X \\in \\mathcal{R}_X}v_X \\cdot \\Pr(X = v_X) = 0 \\cdot \\Pr(X = 0) + 1 \\cdot \\Pr(X = 1) = \\Pr(X = 1)\n\\]\n\n\n(1.4) Population Base Rates\nAlthough the population-level data above is technically available for use by researchers, on its own it doesn’t help very much for researchers working with ML-based classifiers for example, since it basically represents a dataset with \\(N = 2\\) observations:\n\nimport pandas as pd\npop_df = pd.DataFrame({'quote_unquote_race': [0, 1], 'prop_uses_drugs': [0.16, 0.18]})\npop_df\n\n\n  \n    \n\n\n\n\n\n\nquote_unquote_race\nprop_uses_drugs\n\n\n\n\n0\n0\n0.16\n\n\n1\n1\n0.18\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\nTo even get started in terms of being able to use this data to evaluate fairness, we need to also know the base rates of the two subgroups \\(\\mathcal{B}\\) and \\(\\mathcal{W}\\) with respect to their combined population \\(\\Sigma\\). For example, Chapter 3 of Barocas et al. (2024) builds its description of fairness in AI around classification as the problem of determining (predicting) values of \\(y\\) for given values of \\(x\\), rooted in jointly distributed Random Variables \\(X\\) and \\(Y\\), with a particular collected dataset viewed as samples from\n\na probability distribution over pairs of values \\((x,y)\\) that the random variables \\((X,Y)\\) might take on.\n\nIn our case, notice how we currently only have the two conditional expectations written above, not a full joint distribution of \\(D\\) and \\(A\\). So, we should be able to identify the missing piece by writing out the joint distribution as a function of conditional and marginal distributions (in prob/stats textbooks, this is usually introduced as the definition of conditional probability):\n\\[\n\\Pr(D \\mid A) = \\frac{\\Pr(D, A)}{\\Pr(A)} \\implies \\Pr(D, A) = \\underbrace{\\Pr(D \\mid A)}_{\\text{We have this}}\\underbrace{\\Pr(A)}_{\\text{We don't have this}}\n\\]\nSo, we have to go out and find the missing term \\(\\Pr(A)\\). Thankfully for this case, the US Census Bureau’s job is to take censuses of the self-reported race of the US population. Less thankfully, these are reported with respect to \\(\\overline{\\Pi}\\), not \\(\\Pi\\), so we’ll need to re-normalize.\nYou can find the Census population percentages here, which tell us that:\n\nThe “White alone” percentage \\(\\Pr_{\\overline{\\Pi}}(W = 1, S = 1)\\) is 0.753,\nThe “Black alone” percentage \\(\\Pr_{\\overline{\\Pi}}(B = 1, S = 1)\\) is 0.137, and\nThe percentage reporting two or more races \\(\\Pr_{\\overline{\\Pi}}(S = 0)\\) is 0.031\n\nFirst, since the Census provides \\(\\Pr_{\\overline{\\Pi}}(S = 0)\\), but the Hamilton/Brookings study’s population is those for whom \\(S = 1\\), we’ll need to use the Kolmogorov axioms to derive\n\\[\n\\textstyle\n\\Pr_{\\overline{\\Pi}}(S = 1) = 1 - \\Pr_{\\overline{\\Pi}}(S = 0) = 0.969.\n\\]\nFrom this quantity we can derive\n\\[\n\\begin{align*}\n\\textstyle \\Pr_{\\overline{\\Pi}}(W = 1 \\mid S = 1) &= \\frac{\\Pr_{\\overline{\\Pi}}(W = 1, S = 1)}{\\Pr_{\\overline{\\Pi}}(S = 1)} = \\frac{0.753}{0.969} \\approx 0.777 \\\\\n\\textstyle \\Pr_{\\overline{\\Pi}}(B = 1 \\mid S = 1) &= \\frac{\\Pr_{\\overline{\\Pi}}(B = 1, S = 1)}{\\Pr_{\\overline{\\Pi}}(S = 1)} = \\frac{0.137}{0.969} \\approx 0.141 \\\\\n\\end{align*}\n\\]\ntherefore giving us (by the way we defined \\(\\Sigma\\) above):\n\\[\n\\begin{align*}\n\\textstyle \\Pr_{\\Sigma}(W = 1) &= 0.777 \\\\\n\\textstyle \\Pr_{\\Sigma}(B = 1) &= 0.141\n\\end{align*}\n\\]\nand finally, by the way we defined \\(\\Pi\\) (where, since this is our target population, the one we’d like to use for the remainder of the demo, we define \\(\\Pr_{\\Pi}(E) \\equiv \\Pr(E)\\)),\n\\[\n\\begin{align*}\n\\Pr(A = 0) &= \\frac{\\Pr_{\\Sigma}(W = 1)}{\\Pr_{\\Sigma}(W = 1 \\vee B = 1)} = \\frac{0.777}{0.777 + 0.141} \\approx 0.846 \\\\\n\\Pr(A = 1) &= \\frac{\\Pr_{\\Sigma}(B = 1)}{\\Pr_{\\Sigma}(W = 1 \\vee B = 1)} = \\frac{0.141}{0.777 + 0.141} \\approx 0.154\n\\end{align*}\n\\]\n\n\n(1.5) Working with the Joint Distribution\nNow that we have the missing piece allowing us to fully characterize the joint distribution, we can (finally) start deriving a few of the non-immediately-obvious implications from the data we have. For example:\nThe probability of being a drug user\n\\[\n\\begin{align*}\n\\Pr(D = 1) &= \\Pr(D = 1, A = 0) + \\Pr(D = 1, A = 1) \\\\\n&= \\Pr(D = 1 \\mid A = 0)\\Pr(A = 0) + \\Pr(D = 1 \\mid A = 1)\\Pr(A = 1) \\\\\n&= (0.18)(0.846) + (0.16)(0.154) \\approx 0.177\n\\end{align*}\n\\]\nThe probability of being a non-drug user (a sanity check to make sure our probabilities satisfy Kolmogorov axioms)\n\\[\n\\begin{align*}\n\\Pr(D = 0) &= \\Pr(D = 0, A = 0) + \\Pr(D = 0, A = 1) \\\\\n&= \\Pr(D = 0 \\mid A = 0)\\Pr(A = 0) + \\Pr(D = 0 \\mid A = 1)\\Pr(A = 1) \\\\\n&= (0.82)(0.846) + (0.84)(0.154) \\approx 0.823\n\\end{align*}\n\\]\nThe probability that someone is black given that they are a drug user\n\\[\n\\begin{align*}\n\\Pr(A = 1 \\mid D = 1) &\\overset{\\text{Bayes}}{\\underset{\\text{Thm}}{=}} \\frac{\\Pr(D = 1 \\mid A = 1)\\Pr(A = 1)}{\\Pr(D = 1)} = \\frac{(0.16)(0.154)}{0.177} \\\\\n&\\approx 0.139\n\\end{align*}\n\\]\nThe probability that someone is white given that they are a drug user\n\\[\n\\begin{align*}\n\\Pr(A = 0 \\mid D = 1) &\\overset{\\text{Bayes}}{\\underset{\\text{Thm}}{=}} \\frac{\\Pr(D = 1 \\mid A = 0)\\Pr(A = 0)}{\\Pr(D = 1)} = \\frac{(0.18)(0.846)}{0.177} \\\\\n&\\approx 0.860\n\\end{align*}\n\\]\nAnd, more generally, we can write out the entire joint distribution in a table like\n\n\n\n\n\\(D = 0\\)\n\\(D = 1\\)\n\n\n\n\n\\(A = 0\\)\n\\(\\Pr(A = 0, D = 0)\\)\n\\(\\Pr(A = 0, D = 1)\\)\n\n\n\\(A = 1\\)\n\\(\\Pr(A = 1, D = 0)\\)\n\\(\\Pr(A = 1, D = 1)\\)\n\n\n\nWhich we compute using Python here to save time (though in general the types of calculations above are fair game for assignments / exams!)\n\nimport numpy as np\npA0 = 0.846\npA1 = 1 - pA0 # Hooray for mantissas (...mantissae? mantissi?)\npD1_given_A0 = 0.18\npD0_given_A0 = 1 - pD1_given_A0\npD1_given_A1 = 0.16\npD0_given_A1 = 1 - pD1_given_A1\n\n# Joint probabilities\npD1_A0 = pD1_given_A0 * pA0\nprint(pD1_A0)\npD1_A1 = pD1_given_A1 * pA1\nprint(pD1_A1)\npD0_A0 = pD0_given_A0 * pA0\nprint(pD0_A0)\npD0_A1 = pD0_given_A1 * pA1\nprint(pD0_A1)\n\njoint_dist = np.array([\n    [pD0_A0, pD1_A0],\n    [pD0_A1, pD1_A1]\n])\nprint(joint_dist)\n\nprint(np.sum(joint_dist))\nprint(pD0_A0 + pD0_A1 + pD1_A0 + pD1_A1) # Coolio\n\n0.15228\n0.024640000000000006\n0.69372\n0.12936000000000003\n[[0.69372 0.15228]\n [0.12936 0.02464]]\n1.0\n1.0"
  },
  {
    "objectID": "writeups/ai_fairness.html#making-predictions-related-to-this-data",
    "href": "writeups/ai_fairness.html#making-predictions-related-to-this-data",
    "title": "Is It Fair? The Issue of Operationalization and “Fairness” in AI",
    "section": "(2) Making Predictions Related to This Data",
    "text": "(2) Making Predictions Related to This Data\nNow, moving from 5100-esque to 5450-specific topics, let’s think about a decision-making system which utilizes surveillance cameras installed around a given neighborhood. This system aims to identify people’s faces using these cameras and then, on the basis of a given person \\(i\\)’s facial image features \\(X_i\\), classify them into one of two classes:\n\\[\n\\widehat{D}_i = \\begin{cases}\n0 &\\text{if }i\\textbf{ Not}\\text{ a Predicted Drug User} \\\\\n1 &\\text{if }i\\textbf{ Is}\\text{ a Predicted Drug User}\n\\end{cases}\n\\]\nIt turns out that, given the descriptive (and context-free) definitions of fairness at the core of the Fairness in AI literature, we have almost everything that we need, besides a loss function.\nUsing a slightly different notation than the one we use in e.g. DSAN 5300 (we can convert between the two notations if need be!), in a fairness context the loss is often parameterized with respect to a given true label value \\(y\\) and a given prediction for that label \\(\\widehat{y}\\): \\(L(\\widehat{y}, y)\\) tells us the “badness” of predicting a value \\(\\widehat{y}\\) when the true value that we were trying to predict is \\(y\\).\nOne standard loss function, used by pretty much any binary classifier (say, those in scikit-learn) unless the default settings are modified, is the misclassification loss:\n\\[\nL(0, 0) = 0, L(0, 1) = 1, L(1, 0) = 1, L(1, 1) = 0\n\\]\nThis loss function assigns a “badness” of 1 when the prediction was incorrect, and a “badness” of 0 when the prediction was correct, so that it can be condensed even more using the indicator function \\(\\mathbb{1}\\) into just:\n\\[\nL(\\widehat{y}, y) = \\mathbb{1}[\\widehat{y} \\neq y].\n\\]\nWe can also represent this loss function in a form that resembles a confusion matrix (which we’ll use a lot from now on!), keeping in mind that it’s just the same form as a confusion matrix, not a confusion matrix itself:\n\n\n\n\n\\(\\widehat{D}_i = 0\\)\n\\(\\widehat{D}_i = 1\\)\n\n\n\n\n\\(D = 0\\)\n0\n1\n\n\n\\(D = 1\\)\n1\n0\n\n\n\n\n(2.1) Fairness Definition 1: Statistical Parity\nStatistical Independence is satisfied if\n\\[\n\\Pr(\\widehat{D} = 1 \\mid A = 0) = \\Pr(\\widehat{D} = 1 \\mid A = 1)\n\\]\nSo, let’s see how/whether this fairness definition “matches up with” our intuitions around fairness!\nFirst, let’s construct a “population” of size \\(\\nu = 1000\\) (since our estimates only go to 3 decimal places max), using the joint distribution derived above, that we can sample from (though, for our purposes here, our “sample” will in fact be the entire population, so that \\(N = \\nu = 1000\\)):\n\n\n(2.2) Constructing a Simulated Population\n\nimport pandas as pd\nnu = 1000\npop_df = pd.DataFrame({'A': [0]*nu, 'D': [0]*nu})\npop_df.head()\n\n\n  \n    \n\n\n\n\n\n\nA\nD\n\n\n\n\n0\n0\n0\n\n\n1\n0\n0\n\n\n2\n0\n0\n\n\n3\n0\n0\n\n\n4\n0\n0\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\nprint(nu * joint_dist)\n\n[[693.72 152.28]\n [129.36  24.64]]\n\n\n\nD0_A0_df = pd.DataFrame([{'D': 0, 'A': 0}] * 694) # dist[0,0]\nD0_A1_df = pd.DataFrame([{'D': 0, 'A': 1}] * 129) # dist[1,0]\nD1_A0_df = pd.DataFrame([{'D': 1, 'A': 0}] * 152) # dist[0,1]\nD1_A1_df = pd.DataFrame([{'D': 1, 'A': 1}] * 25) # dist[1,1]\npop_df = pd.concat([D0_A0_df, D0_A1_df, D1_A0_df, D1_A1_df], axis=0, ignore_index=True)\npop_df\n\n\n  \n    \n\n\n\n\n\n\nD\nA\n\n\n\n\n0\n0\n0\n\n\n1\n0\n0\n\n\n2\n0\n0\n\n\n3\n0\n0\n\n\n4\n0\n0\n\n\n...\n...\n...\n\n\n995\n1\n1\n\n\n996\n1\n1\n\n\n997\n1\n1\n\n\n998\n1\n1\n\n\n999\n1\n1\n\n\n\n\n1000 rows × 2 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nlen(pop_df[pop_df['D'] == 1])\n\n177\n\n\n\n\n(2.3) Adding a Noisy Feature and a Random Feature\nNow let’s pretend \\(X_i\\) is some noisy measurement of \\(A_i\\), train a classifier to predict \\(D_i\\) from \\(X_i\\), and see if we get “fairness”!\n\nimport numpy as np\nrng = np.random.default_rng(seed=5450)\npop_df['X_bin'] = pop_df['A'].apply(lambda x: 1 if x == 1 else -1)\n# Random (low chance) flip\npop_df['X_mult'] = rng.choice([1,-1], size=len(pop_df), p=[0.95,0.05])\npop_df['X_result'] = pop_df['X_bin'] * pop_df['X_mult']\npop_df['X_noise'] = rng.normal(0, 0.1, size=len(pop_df))\npop_df['X'] = pop_df['X_result'] + pop_df['X_noise']\npop_df['X_rand'] = rng.normal(0, 0.1, size=len(pop_df))\npop_df\n\n\n  \n    \n\n\n\n\n\n\nD\nA\nX_bin\nX_mult\nX_result\nX_noise\nX\nX_rand\n\n\n\n\n0\n0\n0\n-1\n1\n-1\n-0.054224\n-1.054224\n-0.050844\n\n\n1\n0\n0\n-1\n1\n-1\n-0.239642\n-1.239642\n0.047055\n\n\n2\n0\n0\n-1\n1\n-1\n0.067170\n-0.932830\n-0.010561\n\n\n3\n0\n0\n-1\n-1\n1\n0.120252\n1.120252\n-0.092252\n\n\n4\n0\n0\n-1\n1\n-1\n0.026217\n-0.973783\n-0.163111\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n995\n1\n1\n1\n1\n1\n0.072730\n1.072730\n-0.120465\n\n\n996\n1\n1\n1\n1\n1\n-0.032165\n0.967835\n0.013276\n\n\n997\n1\n1\n1\n1\n1\n-0.070791\n0.929209\n0.006057\n\n\n998\n1\n1\n1\n1\n1\n0.060893\n1.060893\n0.092034\n\n\n999\n1\n1\n1\n1\n1\n-0.043217\n0.956783\n0.110954\n\n\n\n\n1000 rows × 8 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nblack_df = pop_df[pop_df['A'] == 1].copy()\nblack_df['X'].mean()\n\n0.9368364928954515\n\n\n\nblack_df['X'].std()\n\n0.37793852152251584\n\n\n\nwhite_df = pop_df[pop_df['A'] == 0].copy()\nwhite_df['X'].mean()\n\n-0.8899012951427693\n\n\n\nwhite_df['X'].std()\n\n0.46257415929089934\n\n\n\npd.crosstab(pop_df['A'], pop_df['D'], margins=True, normalize=True)\n\n\n  \n    \n\n\n\n\n\nD\n0\n1\nAll\n\n\nA\n\n\n\n\n\n\n\n0\n0.694\n0.152\n0.846\n\n\n1\n0.129\n0.025\n0.154\n\n\nAll\n0.823\n0.177\n1.000\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\npd.crosstab(pop_df['A'], pop_df['D'], margins=True, normalize='columns')\n\n\n  \n    \n\n\n\n\n\nD\n0\n1\nAll\n\n\nA\n\n\n\n\n\n\n\n0\n0.843256\n0.858757\n0.846\n\n\n1\n0.156744\n0.141243\n0.154\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\npd.crosstab(pop_df['A'], pop_df['D'], margins=True, normalize='index')\n\n\n  \n    \n\n\n\n\n\nD\n0\n1\n\n\nA\n\n\n\n\n\n\n0\n0.820331\n0.179669\n\n\n1\n0.837662\n0.162338\n\n\nAll\n0.823000\n0.177000\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\npop_df[['A','D','X']].corr()\n\n\n  \n    \n\n\n\n\n\n\nA\nD\nX\n\n\n\n\nA\n1.000000\n-0.016390\n0.825867\n\n\nD\n-0.016390\n1.000000\n-0.037118\n\n\nX\n0.825867\n-0.037118\n1.000000\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\nimport seaborn as sns\nsns.boxplot(x='A', y='X', data=pop_df)\n\n\n\n\n\n\n\n\n\nsns.boxplot(x='X', y='D', orient='h', data=pop_df)\n\n\n\n\n\n\n\n\n\n\n(2.4) Classify with Scikit-Learn\n\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nfrom sklearn.metrics import confusion_matrix, roc_curve, RocCurveDisplay, ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\n\n\n#clf = LinearSVC()\n#clf = MLPClassifier(hidden_layer_sizes=(10,10), activation='logistic')\nclf = LogisticRegression()\n#clf = DecisionTreeClassifier(max_depth=1)\n\n\nX_df = pop_df[['X','X_rand']].copy()\nX_scaled = scaler.fit_transform(X_df)\nd_df = pop_df['D'].copy()\nX_train, X_test, d_train, d_test = train_test_split(X_scaled, d_df)\nclf = clf.fit(X_train, d_train)\n\n\nX_train\n\narray([[ 2.01620819, -1.32996031],\n       [ 2.2518996 , -0.75840806],\n       [ 2.14098014,  0.31504902],\n       ...,\n       [-0.28251252,  1.00551134],\n       [-0.57882442, -0.15290433],\n       [ 1.99170214,  0.46089925]])\n\n\n\nX_df.shape, d_df.shape\n\n((1000, 2), (1000,))\n\n\n\nd_test_hat = clf.predict(X_test)\n\n\nconfusion_matrix(d_test, d_test_hat)\n\narray([[207,   0],\n       [ 43,   0]])\n\n\n\npop_df['D_hat'] = clf.predict(pop_df[['X','X_rand']])\npop_df\n\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n  warnings.warn(\n\n\n\n  \n    \n\n\n\n\n\n\nD\nA\nX_bin\nX_mult\nX_result\nX_noise\nX\nX_rand\nD_hat\n\n\n\n\n0\n0\n0\n-1\n1\n-1\n-0.054224\n-1.054224\n-0.050844\n0\n\n\n1\n0\n0\n-1\n1\n-1\n-0.239642\n-1.239642\n0.047055\n0\n\n\n2\n0\n0\n-1\n1\n-1\n0.067170\n-0.932830\n-0.010561\n0\n\n\n3\n0\n0\n-1\n-1\n1\n0.120252\n1.120252\n-0.092252\n0\n\n\n4\n0\n0\n-1\n1\n-1\n0.026217\n-0.973783\n-0.163111\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n995\n1\n1\n1\n1\n1\n0.072730\n1.072730\n-0.120465\n0\n\n\n996\n1\n1\n1\n1\n1\n-0.032165\n0.967835\n0.013276\n0\n\n\n997\n1\n1\n1\n1\n1\n-0.070791\n0.929209\n0.006057\n0\n\n\n998\n1\n1\n1\n1\n1\n0.060893\n1.060893\n0.092034\n0\n\n\n999\n1\n1\n1\n1\n1\n-0.043217\n0.956783\n0.110954\n0\n\n\n\n\n1000 rows × 9 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nif isinstance(clf, DecisionTreeClassifier):\n  plot_tree(clf)\n\n\ntest_X0 = np.arange(-1, 1, 0.1)\ntest_Xrand = rng.normal(0, 0.1, size=len(test_X0))\ntest_Xmat = np.column_stack([test_X0, test_Xrand])\ntest_Xmat\n\narray([[-1.00000000e+00, -8.21496502e-02],\n       [-9.00000000e-01, -1.18804351e-01],\n       [-8.00000000e-01, -9.71993639e-02],\n       [-7.00000000e-01,  1.79121572e-01],\n       [-6.00000000e-01,  7.54615529e-02],\n       [-5.00000000e-01, -7.55314281e-02],\n       [-4.00000000e-01, -2.14828193e-02],\n       [-3.00000000e-01, -5.39771961e-02],\n       [-2.00000000e-01, -1.24518105e-01],\n       [-1.00000000e-01,  1.15651561e-01],\n       [-2.22044605e-16, -1.11209055e-01],\n       [ 1.00000000e-01, -1.63469797e-01],\n       [ 2.00000000e-01, -4.00110245e-02],\n       [ 3.00000000e-01, -8.82016598e-02],\n       [ 4.00000000e-01, -2.74525280e-02],\n       [ 5.00000000e-01, -5.04958858e-02],\n       [ 6.00000000e-01, -3.54260686e-02],\n       [ 7.00000000e-01,  4.46857290e-03],\n       [ 8.00000000e-01, -1.21658993e-01],\n       [ 9.00000000e-01, -3.37236460e-02]])\n\n\n\nclf.predict(test_Xmat)\n\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\n\n\ntest_Xmat_pred = clf.predict_proba(test_Xmat)\ntest_Xmat_pred\n\narray([[0.811287  , 0.188713  ],\n       [0.81442558, 0.18557442],\n       [0.81643575, 0.18356425],\n       [0.81365365, 0.18634635],\n       [0.81801088, 0.18198912],\n       [0.82315069, 0.17684931],\n       [0.82450109, 0.17549891],\n       [0.82739245, 0.17260755],\n       [0.83091462, 0.16908538],\n       [0.82894698, 0.17105302],\n       [0.83514931, 0.16485069],\n       [0.83823475, 0.16176525],\n       [0.83832092, 0.16167908],\n       [0.84129042, 0.15870958],\n       [0.84241775, 0.15758225],\n       [0.84491479, 0.15508521],\n       [0.84676281, 0.15323719],\n       [0.84819397, 0.15180603],\n       [0.85224427, 0.14775573],\n       [0.85288184, 0.14711816]])\n\n\n\ntest_d_prob = test_Xmat_pred[:,1]\ntest_d_prob\n\narray([0.188713  , 0.18557442, 0.18356425, 0.18634635, 0.18198912,\n       0.17684931, 0.17549891, 0.17260755, 0.16908538, 0.17105302,\n       0.16485069, 0.16176525, 0.16167908, 0.15870958, 0.15758225,\n       0.15508521, 0.15323719, 0.15180603, 0.14775573, 0.14711816])\n\n\n\ndef classify(cur_clf, test_Xmat, d_prob_thresh = 0.17):\n  test_Xmat_pred = cur_clf.predict_proba(test_Xmat)\n  test_d_prob = test_Xmat_pred[:,1]\n  test_d_class = np.where(test_d_prob &gt; d_prob_thresh, 1, 0)\n  return test_d_class\n\n\ntest_d_pred = classify(test_Xmat)\ntest_d_pred\n\narray([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\n\n\ntest_d_true = np.where(test_Xmat[:,0] &lt; 0, 1, 0)\ntest_d_true\n\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\n\n\n#RocCurveDisplay.from_estimator(clf, X_test, d_test, plot_chance_level=True)\n\n\nRocCurveDisplay.from_predictions(test_d_true, test_d_pred, plot_chance_level=True)\n\n\n\n\n\n\n\n\n\nnew_samp_df = pop_df.sample(100, random_state=5450)\n\n\nnew_samp_df\n\n\n  \n    \n\n\n\n\n\n\nD\nA\nX_bin\nX_mult\nX_result\nX_noise\nX\nX_rand\n\n\n\n\n899\n1\n0\n-1\n1\n-1\n-0.033770\n-1.033770\n-0.026273\n\n\n699\n0\n1\n1\n1\n1\n-0.181455\n0.818545\n-0.023939\n\n\n481\n0\n0\n-1\n1\n-1\n-0.200307\n-1.200307\n0.113340\n\n\n503\n0\n0\n-1\n1\n-1\n0.034218\n-0.965782\n-0.048357\n\n\n856\n1\n0\n-1\n1\n-1\n0.103965\n-0.896035\n0.015975\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n896\n1\n0\n-1\n1\n-1\n-0.018532\n-1.018532\n-0.049717\n\n\n500\n0\n0\n-1\n1\n-1\n0.010933\n-0.989067\n0.030974\n\n\n558\n0\n0\n-1\n1\n-1\n-0.001991\n-1.001991\n-0.110632\n\n\n414\n0\n0\n-1\n1\n-1\n0.067946\n-0.932054\n-0.124212\n\n\n279\n0\n0\n-1\n1\n-1\n-0.120680\n-1.120680\n-0.015748\n\n\n\n\n100 rows × 8 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nnew_test_Xmat = new_samp_df[['X','X_rand']].copy()\n\n\nnew_test_preds = classify(new_test_Xmat)\n\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n  warnings.warn(\n\n\n\nconfusion_matrix(new_test_preds, new_samp_df['D'])\n\narray([[14,  5],\n       [63, 18]])\n\n\nFairness comes from the confusion matrix using A instead of D!\n\nconfusion_matrix(new_test_preds, new_samp_df['A'])\n\narray([[ 8, 11],\n       [79,  2]])\n\n\n\nConfusionMatrixDisplay.from_predictions(new_samp_df['A'], new_test_preds) #, display_labels=['not_drug_user','drug_user'])\n\n\n\n\n\n\n\n\n\nconfusion_matrix(new_samp_df['A'], new_test_preds, normalize='true')\n\narray([[0.09195402, 0.90804598],\n       [0.84615385, 0.15384615]])"
  },
  {
    "objectID": "writeups/ai_fairness.html#same-thing-but-with-arrest-rates",
    "href": "writeups/ai_fairness.html#same-thing-but-with-arrest-rates",
    "title": "Is It Fair? The Issue of Operationalization and “Fairness” in AI",
    "section": "(3) Same Thing But With Arrest Rates…",
    "text": "(3) Same Thing But With Arrest Rates…\nNow, if we re-do everything above but with drug usage rates operationalized using arrest rates, we instead have\n\\[\n\\begin{align*}\n\\Pr(D = 1 \\mid A = 0) &= 0.0040 \\\\\n\\Pr(D = 1 \\mid A = 1) &= 0.0105\n\\end{align*}\n\\]\n\ndef gen_noisy_feature(pop_race_vec):\n  X_bin = pop_df['A'].apply(lambda x: 1 if x == 1 else -1)\n  # Random (low chance) flip\n  X_mult = rng.choice([1,-1], size=len(pop_race_vec), p=[0.95,0.05])\n  X_result = X_bin * X_mult\n  X_noise = rng.normal(0, 0.1, size=len(pop_df))\n  X_final = X_result + X_noise\n  return X_final\n\ndef gen_random_feature(pop_race_vec):\n  X_rand = rng.normal(0, 0.1, size=len(pop_race_vec))\n  return X_rand\n\ndef classify(test_Xmat, d_prob_thresh = 0.17):\n  test_Xmat_pred = clf.predict_proba(test_Xmat)\n  test_d_prob = test_Xmat_pred[:,1]\n  test_d_class = np.where(test_d_prob &gt; d_prob_thresh, 1, 0)\n  return test_d_class\n\ndef construct_population(pD1_given_A0, pD1_given_A1, nu=1000):\n  pA0 = 0.846\n  pA1 = 1 - pA0\n  pD0_given_A0 = 1 - pD1_given_A0\n  pD0_given_A1 = 1 - pD1_given_A1\n  # Joint probabilities\n  pD1_A0 = pD1_given_A0 * pA0\n  #print(pD1_A0)\n  pD1_A1 = pD1_given_A1 * pA1\n  #print(pD1_A1)\n  pD0_A0 = pD0_given_A0 * pA0\n  #print(pD0_A0)\n  pD0_A1 = pD0_given_A1 * pA1\n  #print(pD0_A1)\n  joint_dist = np.array([\n      [pD0_A0, pD1_A0],\n      [pD0_A1, pD1_A1]\n  ])\n  print(joint_dist)\n  nu = 1000\n  pop_df = pd.DataFrame({'A': [0]*nu, 'D': [0]*nu})\n  joint_freqs = nu * joint_dist\n  D0_A0_df = pd.DataFrame([{'D': 0, 'A': 0}] * round(joint_freqs[0,0]))\n  D0_A1_df = pd.DataFrame([{'D': 0, 'A': 1}] * round(joint_freqs[1,0]))\n  D1_A0_df = pd.DataFrame([{'D': 1, 'A': 0}] * round(joint_freqs[0,1]))\n  D1_A1_df = pd.DataFrame([{'D': 1, 'A': 1}] * round(joint_freqs[1,1]))\n  pop_df = pd.concat([D0_A0_df, D0_A1_df, D1_A0_df, D1_A1_df], axis=0, ignore_index=True)\n  #display(pop_df)\n  pop_df['X0'] = gen_noisy_feature(pop_df['A'])\n  pop_df['X1'] = gen_random_feature(pop_df['A'])\n  return pop_df\n\narrest_df = construct_population(0.0040, 0.0105)\ndisplay(arrest_df)\n\n[[0.842616 0.003384]\n [0.152383 0.001617]]\n\n\n\n  \n    \n\n\n\n\n\n\nD\nA\nX0\nX1\n\n\n\n\n0\n0\n0\n-0.971645\n-0.024211\n\n\n1\n0\n0\n-1.176896\n0.039959\n\n\n2\n0\n0\n-1.008070\n-0.026912\n\n\n3\n0\n0\n-0.999462\n0.021601\n\n\n4\n0\n0\n-0.944086\n-0.149199\n\n\n...\n...\n...\n...\n...\n\n\n995\n1\n0\n0.925104\n-0.033928\n\n\n996\n1\n0\n1.013372\n-0.130119\n\n\n997\n1\n0\n0.898179\n0.108746\n\n\n998\n1\n1\n0.887125\n-0.123374\n\n\n999\n1\n1\n0.848386\n-0.082399\n\n\n\n\n1000 rows × 4 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\n# Classify\ndef thresh_classify(cur_clf, test_Xmat, d_prob_thresh = 0.17):\n  test_Xmat_pred = cur_clf.predict_proba(test_Xmat)\n  test_d_prob = test_Xmat_pred[:,1]\n  test_d_class = np.where(test_d_prob &gt; d_prob_thresh, 1, 0)\n  return test_d_class\n\npop_clf = LogisticRegression()\nX_pop = arrest_df[['X0','X1']].copy()\nd_pop = arrest_df['D'].copy()\npop_clf.fit(X_pop, d_pop)\noptimal_pr_d_hat = thresh_classify(pop_clf, X_pop, 0.5)\nfair_pr_d_hat = thresh_classify(pop_clf, X_pop, 0.03)\nunfair_pr_d_hat = thresh_classify(pop_clf, X_pop, 0.025)\n\n\ndef display_confusion(race_vec, classification_vec):\n  return ConfusionMatrixDisplay.from_predictions(race_vec, classification_vec) #, display_labels=['not_drug_user','drug_user'])\n\ndef display_confusion_normalized(race_vec, classification_vec):\n  return ConfusionMatrixDisplay.from_predictions(race_vec, classification_vec, normalize='true') #, display_labels=['not_drug_user','drug_user'])\n\nFor optimal classifier:\n\ndisplay_confusion(arrest_df['A'], optimal_pr_d_hat)\ndisplay_confusion_normalized(arrest_df['A'], optimal_pr_d_hat)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor effective threshold classifier:\n\ndisplay_confusion(arrest_df['A'], fair_pr_d_hat)\ndisplay_confusion_normalized(arrest_df['A'], fair_pr_d_hat)\n\ndef compute_unfairness(race_vec, d_hat):\n  cmat = confusion_matrix(race_vec, d_hat, normalize='true')\n  pr_DH1_A0 = cmat[0,1]\n  pr_DH1_A1 = cmat[1,1]\n  return abs(pr_DH1_A1 - pr_DH1_A0)\n\ndef compute_accuracy(d_vec, d_hat):\n  cmat = confusion_matrix(d_vec, d_hat, normalize='all')\n  pr_DH0_H0 = cmat[0,0]\n  pr_DH1_H1 = cmat[1,1]\n  return pr_DH0_H0 + pr_DH1_H1\n\nprint(compute_unfairness(arrest_df['A'], fair_pr_d_hat))\nprint(compute_accuracy(arrest_df['D'], fair_pr_d_hat))\n\n0.002364066193853428\n0.993\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nthresh_vals_macro = np.arange(0, 0.04, 0.0001)\ndef gen_unfairness_curve(thresh_vals):\n  unfairness_data = []\n\n  for cur_thresh in thresh_vals:\n    cur_pr_d_hat = thresh_classify(pop_clf, X_pop, cur_thresh)\n    cur_unfairness = compute_unfairness(arrest_df['A'], cur_pr_d_hat)\n    cur_accuracy = compute_accuracy(arrest_df['D'], cur_pr_d_hat)\n    cur_data = {\n        'thresh': cur_thresh,\n        'unfairness': 10*cur_unfairness,\n        'accuracy': cur_accuracy,\n    }\n    unfairness_data.append(cur_data)\n  unfairness_df = pd.DataFrame(unfairness_data)\n  return unfairness_df\n\nunfairness_macro_df = gen_unfairness_curve(thresh_vals_macro)\n\n\nunfairness_macro_df\n\n\n  \n    \n\n\n\n\n\n\nthresh\nunfairness\naccuracy\n\n\n\n\n0\n0.0000\n0.0\n0.005\n\n\n1\n0.0001\n0.0\n0.005\n\n\n2\n0.0002\n0.0\n0.005\n\n\n3\n0.0003\n0.0\n0.005\n\n\n4\n0.0004\n0.0\n0.005\n\n\n...\n...\n...\n...\n\n\n395\n0.0395\n0.0\n0.995\n\n\n396\n0.0396\n0.0\n0.995\n\n\n397\n0.0397\n0.0\n0.995\n\n\n398\n0.0398\n0.0\n0.995\n\n\n399\n0.0399\n0.0\n0.995\n\n\n\n\n400 rows × 3 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nunfairness_macro_df.plot(x='thresh', y=['unfairness','accuracy'])\n\n\n\n\n\n\n\n\n\nthresh_vals_micro = np.arange(0, 0.005, 0.00001)\nunfairness_micro_df = gen_unfairness_curve(thresh_vals_micro)\nunfairness_micro_df.plot(x='thresh', y=['unfairness','accuracy'])"
  },
  {
    "objectID": "writeups/ai_fairness.html#predictive-parity-a-slightly-less-arbitrary-but-slightly-more-problematic-fairness-definition",
    "href": "writeups/ai_fairness.html#predictive-parity-a-slightly-less-arbitrary-but-slightly-more-problematic-fairness-definition",
    "title": "Is It Fair? The Issue of Operationalization and “Fairness” in AI",
    "section": "(4) Predictive Parity: A Slightly Less Arbitrary, But Slightly More Problematic(?) Fairness Definition",
    "text": "(4) Predictive Parity: A Slightly Less Arbitrary, But Slightly More Problematic(?) Fairness Definition\nBuilding on Statistical Parity, Predictive Parity incorporates the actual accuracy of the predictions, requiring only that the rate of correct predictions is equal for \\(A = 0\\) and \\(A = 1\\):\n\\[\n\\Pr(D = 1 \\mid \\widehat{D} = 1, A = 0) = \\Pr(D = 1 \\mid \\widehat{D} = 1, A = 1)\n\\]"
  },
  {
    "objectID": "writeups/ai_fairness.html#calibration-the-least-bamboozling-of-the-context-free-fairness-measures",
    "href": "writeups/ai_fairness.html#calibration-the-least-bamboozling-of-the-context-free-fairness-measures",
    "title": "Is It Fair? The Issue of Operationalization and “Fairness” in AI",
    "section": "(5) Calibration: The Least Bamboozling of the Context-Free Fairness Measures",
    "text": "(5) Calibration: The Least Bamboozling of the Context-Free Fairness Measures\nFor any given estimation “score” \\(s(X)\\) used by the algorithm as a proxy for estimating \\(\\widehat{\\Pr}(D = 1)\\)[2], which in turns gets used (e.g., via thresholding) to generate a final prediction \\(\\widehat{D}\\), the probability of using drugs \\(\\Pr(D = 1)\\) is equal for \\(A = 0\\) and \\(A = 1\\):\n\\[\n\\Pr(D = 1 \\mid s(X) = s, A = 0) = \\Pr(D = 1 \\mid s(X) = s, A = 1), \\; \\forall s \\in [0, 1]\n\\]\nThis measure is the least bamboozling in the sense that it directly addresses the underlying “risk scores” which, if a given machine learning algorithm does not directly compute itself, can at least be inferred by treating the algorithm like a “black box”.\n\n\nThis notation is used mainly just to emphasize how \\(s(X) \\in [0, 1]\\) is used by the algorithm to generate estimates of the true probability \\(\\Pr(D = 1)\\)/"
  },
  {
    "objectID": "writeups/do-calculus/index.html",
    "href": "writeups/do-calculus/index.html",
    "title": "Do-Calculus: Choose Your Own Pace",
    "section": "",
    "text": "\\[\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\newcommand{\\bigexp}[1]{\\exp\\mkern-4mu\\left[ #1 \\right]}\n\\newcommand{\\bigexpect}[1]{\\mathbb{E}\\mkern-4mu \\left[ #1 \\right]}\n\\newcommand{\\definedas}{\\overset{\\small\\text{def}}{=}}\n\\newcommand{\\definedalign}{\\overset{\\phantom{\\text{defn}}}{=}}\n\\newcommand{\\eqeventual}{\\overset{\\text{eventually}}{=}}\n\\newcommand{\\Err}{\\text{Err}}\n\\newcommand{\\expect}[1]{\\mathbb{E}[#1]}\n\\newcommand{\\expectsq}[1]{\\mathbb{E}^2[#1]}\n\\newcommand{\\fw}[1]{\\texttt{#1}}\n\\newcommand{\\given}{\\mid}\n\\newcommand{\\green}[1]{\\color{green}{#1}}\n\\newcommand{\\heads}{\\outcome{heads}}\n\\newcommand{\\iid}{\\overset{\\text{\\small{iid}}}{\\sim}}\n\\newcommand{\\lik}{\\mathcal{L}}\n\\newcommand{\\loglik}{\\ell}\n\\DeclareMathOperator*{\\maximize}{maximize}\n\\DeclareMathOperator*{\\minimize}{minimize}\n\\newcommand{\\mle}{\\textsf{ML}}\n\\newcommand{\\nimplies}{\\;\\not\\!\\!\\!\\!\\implies}\n\\newcommand{\\orange}[1]{\\color{orange}{#1}}\n\\newcommand{\\outcome}[1]{\\textsf{#1}}\n\\newcommand{\\param}[1]{{\\color{purple} #1}}\n\\newcommand{\\pgsamplespace}{\\{\\green{1},\\green{2},\\green{3},\\purp{4},\\purp{5},\\purp{6}\\}}\n\\newcommand{\\prob}[1]{P\\left( #1 \\right)}\n\\newcommand{\\purp}[1]{\\color{purple}{#1}}\n\\newcommand{\\sign}{\\text{Sign}}\n\\newcommand{\\spacecap}{\\; \\cap \\;}\n\\newcommand{\\spacewedge}{\\; \\wedge \\;}\n\\newcommand{\\tails}{\\outcome{tails}}\n\\newcommand{\\Var}[1]{\\text{Var}[#1]}\n\\newcommand{\\bigVar}[1]{\\text{Var}\\mkern-4mu \\left[ #1 \\right]}\n\\]\nIn class during Week 6, I spent too long covering the “base” DGP which generates Random Variables \\(Y\\) and \\(E\\), such that \\(Y\\) and \\(E\\) are statistically correlated despite “truly” being independently-generated random values in \\(\\{0, 1\\}\\). Spent too long, meaning, we didn’t get to cover the case of the do-Calculus modified DGP, where we force \\(E \\leftarrow 1\\) within the DGP itself, so that we could see how this ability to intervene in the DGP is what allows us to infer causation from correlation!\nSo, in this writeup, I’d like to write it out, so that rather than me trying to sprint through it on the board in the classroom, you can process it at your own pace 💆"
  },
  {
    "objectID": "writeups/do-calculus/index.html#the-custom-cooked-dgp",
    "href": "writeups/do-calculus/index.html#the-custom-cooked-dgp",
    "title": "Do-Calculus: Choose Your Own Pace",
    "section": "The “Custom-Cooked” DGP",
    "text": "The “Custom-Cooked” DGP\nI call it “custom-cooked” because, like the case I mentioned in class where we have to generate clustered data in order to see whether our unsupervised clustering algorithms “work” (whether they successfully recover the latent clusters), here we create a DGP which is “cooked up” in such a way that it will generate a pair of statistically-correlated RVs which are in fact (under the surface) generated by entirely separate, non-interrelated random number generations.\nSo, for the part I did get to in class, we have the following “base” DGP."
  },
  {
    "objectID": "writeups/do-calculus/index.html#our-data-generating-process",
    "href": "writeups/do-calculus/index.html#our-data-generating-process",
    "title": "Do-Calculus: Choose Your Own Pace",
    "section": "Our Data-Generating Process",
    "text": "Our Data-Generating Process\n\n\n\n\n\n\n\\(\\text{DGP}[(V,E,Y)]\\): The Private School \\(\\leadsto\\) Success Pipeline 🤑\n\n\n\nGiven the following three Random Variables:\n\n\\(Y\\): Future success, \\(\\mathcal{R}_Y = \\{0, 1\\}\\)\n\\(E\\): Private school education, \\(\\mathcal{R}_E = \\{0, 1\\}\\)\n\\(V\\): Born into poverty, \\(\\mathcal{R}_V = \\{0, 1\\}\\)\n\nRealized values \\((y_i, e_i, v_i)\\) of the joint distribution of \\((Y,E,V)\\) are generated via the following steps:\n\nSample independent RVs \\(U_1 \\sim \\mathcal{B}(1/2)\\), \\(U_2 \\sim \\mathcal{B}(1/3)\\), \\(U_3 \\sim \\mathcal{B}(1/3)\\)\n\\(V \\leftarrow U_1\\)\n\\(E \\leftarrow \\textsf{if }(V = 1)\\textsf{ then } 0\\textsf{ else }U_2\\)\n\\(Y \\leftarrow \\textsf{if }(V = 1)\\textsf{ then }0\\textsf{ else }U_3\\)\n\n\n\nHere, rather than immediately jumping to the chalkboard (which is maybe helpful for e.g. “pure” prob/stats classes, but less helpful for data science classes!), it may have helped if I instead showed what it would look like to write code implementing this DGP, then running it to generate datapoints, and using tools from 5100 to estimate correlations between variables. So, let’s do that here! The following code literally just implements the DGP as closely as possible, where we make it clear that each row is one individual person by also generating a name each time the DGP is run:\n\n\nCode\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(Rlab) |&gt; suppressPackageStartupMessages()\nlibrary(randomNames) |&gt; suppressPackageStartupMessages()\nset.seed(5450)\nrun_dgp &lt;- function(p1, p2, p3) {\n    u1 &lt;- rbern(n=1, prob=p1)\n    u2 &lt;- rbern(n=1, prob=p2)\n    u3 &lt;- rbern(n=1, prob=p3)\n    v_val &lt;- u1\n    e_val &lt;- ifelse(v_val == 1, 0, u2)\n    y_val &lt;- ifelse(v_val == 1, 0, u3)\n    rand_name &lt;- randomNames(1, which.names=\"first\")\n    return(tibble_row(name=rand_name, v=v_val, e=e_val, y=y_val))\n}\n# Generate one person's data using DGP\nrun_dgp(p1=1/2, p2=1/3, p3=1/3)\n\n\n\n\n\n\nname\nv\ne\ny\n\n\n\n\nAlexander\n1\n0\n0\n\n\n\n\n\n\nSo, what this means is, we could generate a population using this DGP, and then use our tools from 5100 to analyze its properties. Here we generate a population of \\(N = 5000\\) people:\n\n\nCode\nset.seed(5450)\nN &lt;- 10000\nprivate_school_df &lt;- tibble(name=character(), v=numeric(), e=numeric(), y=numeric())\n# Run DGP N times, to generate size-N population\nfor (i in 1:N) {\n    cur_draw &lt;- run_dgp(1/2, 1/3, 1/3)\n    private_school_df &lt;- bind_rows(private_school_df, cur_draw)\n}\nprivate_school_df |&gt; head()\n\n\n\n\n\n\nname\nv\ne\ny\n\n\n\n\nAlexander\n1\n0\n0\n\n\nGabriel\n1\n0\n0\n\n\nSaabiqa\n1\n0\n0\n\n\nSafar\n1\n0\n0\n\n\nHafsa\n1\n0\n0\n\n\nChris\n1\n0\n0\n\n\n\n\n\n\nThe (seemingly minor but nonetheless important) point of doing all that stuff on the board rather than R, in this case, was to show how even if we have an infinite population we still get this problem—in other words, it’s not a problem that can be solved by just taking more and more samples.\nBut, we can start to see the problem even with our finite R-generated population. So, please keep in mind how the above code is what you don’t see—what you do see is, you show up to work one day with the above-generated dataset saved as private_school_data.csv, ready for you to analyze (but, again, you don’t get to see the code that generated it!)\nTo make the point in an even more emphatic, over-the-top way, here we save the dataset as private_school_data.csv, then in the next section you’ll put your data scientist hat on and reload it:\n\n\nCode\nprivate_school_df |&gt; write_csv(\"private_school_data.csv\")"
  },
  {
    "objectID": "writeups/do-calculus/index.html#using-probability-theory-to-study-v-e-y",
    "href": "writeups/do-calculus/index.html#using-probability-theory-to-study-v-e-y",
    "title": "Do-Calculus: Choose Your Own Pace",
    "section": "Using Probability Theory to Study \\((V, E, Y)\\)",
    "text": "Using Probability Theory to Study \\((V, E, Y)\\)\nAnd now, without access to any of the previous code, we show up at our data science job and load the dataset someone sent us:\n\n\nCode\nprivate_school_df &lt;- read_csv(\"private_school_data.csv\")\n\n\nRows: 10000 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): name\ndbl (3): v, e, y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nFirst, what is the overall likelihood of success that we can infer from our dataset?\n\n\nCode\n(mean_y &lt;- mean(private_school_df$y))\n\n\n[1] 0.1674\n\n\nwhich, if we round to three decimal places, is exactly the same as the population-wide expected value we derived on the board, \\(\\Pr(Y = 1) = \\frac{1}{6}\\), rounded to three decimal places:\n\n\nCode\nprint(round(mean_y, 3))\n\n\n[1] 0.167\n\n\nCode\nprint(round(1/6, 3))\n\n\n[1] 0.167\n\n\nWhere we have an issue, however, is when we start to try and interpret the correlations between the columns of this dataset! Here we compute the correlation between \\(Y\\) and \\(E\\):\n\n\nCode\ncor(private_school_df$y, private_school_df$e)\n\n\n[1] 0.1997943\n\n\n\n\n\n\n\n\nSymPy Sidebar\n\n\n\n\n\nWho remembers when I randomly wrote “SymPy” on the board today? If you do, here’s one reason why I thought that was important enough to write up there: it’s (the start of) a symbolic computation system, which is different from the numeric computation system used by default in R and Python. While in general one of the benefits of symbolic computation is that we avoid rounding errors, specifically in this case another nice benefit is the ability to use code to reason about populations rather than just samples.\nHere is an even-more-simplified version of some example code from SymPy’s website, showing how we can calculate the probability that the outcome of a single dice roll:\n\n\nCode\nfrom sympy import S\nfrom sympy.stats import E, P, Die\nX_sym = Die('X', 6) # Define a six sided die\nP(X_sym &gt; 3) # Probability X is greater than 3\n\n\n1/2\n\n\nSo now, using this system, we can get the exact probabilities that we simulated using large-\\(N\\) simulations above:\n\n\nCode\nfrom sympy.stats import Bernoulli\nhalf_sym = S(1) / S(2)\nthird_sym = S(1) / S(3)\nU1_sym = Bernoulli(name='U1', p=half_sym)\nU2_sym = Bernoulli(name='U2', p=third_sym)\nU3_sym = Bernoulli(name='U3', p=third_sym)\nV_sym = U1_sym\nE_sym = V_sym * U2_sym\nY_sym = V_sym * U3_sym\nE(Y_sym)\n\n\n1/6"
  },
  {
    "objectID": "writeups/do-calculus/index.html#change-in-probability-after-conditioning-on-e-1-neq-causal-effect-of-e-1",
    "href": "writeups/do-calculus/index.html#change-in-probability-after-conditioning-on-e-1-neq-causal-effect-of-e-1",
    "title": "Do-Calculus: Choose Your Own Pace",
    "section": "Change in Probability After Conditioning on \\(E = 1\\) \\(\\neq\\) Causal Effect of \\(E = 1\\)!",
    "text": "Change in Probability After Conditioning on \\(E = 1\\) \\(\\neq\\) Causal Effect of \\(E = 1\\)!\nSo, on the chalkboard, we worked (painfully) through a DAG that looked like the following:\n\n\n\n\n\nWhere we asked: given the above unobserved DGP which gives rise to the joint distribution of \\((V, E, Y)\\), can we assess whether or not that arrow \\(E \\rightarrow Y\\) should be there? Or in other words, can we assess whether \\(E\\) has a causal effect on \\(Y\\)?\nUsing only the tools of probability theory, the best approach we have for trying to answer this is to compute the following two quantities:\n\n\\(s_{\\text{overall}} \\definedas \\Pr(Y = 1)\\)\n\\(s_{\\text{private}} \\definedas \\Pr(Y = 1 \\mid E = 1)\\)\n\nAnd then, our intuition is that if \\(s_{\\text{private}} &gt; s_{\\text{overall}}\\), then receiving a private school education increases our chances of success—due to the slipperyness of language when it comes to association vs. causation, it is easy to then interpret this as saying, “Private school education causes an increase in likelihood of success”. But, that’s exactly why statistics professors hit students on the head with the “correlation does not imply causation” stick! Is because, we can’t say that!\nUsually, therefore, in those types of classes even in the best case you usually just compute these two quantities, see how \\(s_{\\text{private}}\\) is in fact greater than \\(s_{\\text{public}}\\) despite the lack of “true” causation, and leave it at that. So, let’s start with that step now, using our simulated population we loaded earlier.\nWe already found, by computing mean(private_school_df$y), that \\(\\Pr(Y = 1) \\approx \\frac{1}{6}\\). So, now let’s also use what we know from 5100 to compute the conditional probability we want, \\(\\Pr(Y = 1 \\mid E = 1)\\), by subsetting our sample to include only people for whom \\(E = 1\\), and then re-computing \\(\\Pr(Y = 1)\\) within this subset. First, the subset itself (giving us a df with only those individuals in the simulated population who went to private school):\n\n\nCode\nprivate_only_df &lt;- private_school_df[private_school_df$e == 1,]\nprint(nrow(private_only_df))\n\n\n[1] 1603\n\n\nCode\nprivate_only_df |&gt; tail()\n\n\n\n\n\n\nname\nv\ne\ny\n\n\n\n\nRazeena\n0\n1\n0\n\n\nJordan\n0\n1\n0\n\n\nDeirdre\n0\n1\n1\n\n\nGaelen\n0\n1\n0\n\n\nMonaye\n0\n1\n0\n\n\nWajdi\n0\n1\n0\n\n\n\n\n\n\nNow, within this subgroup, we recompute \\(\\Pr(Y = 1)\\) to obtain our conditional probability:\n\n\nCode\nmean(private_only_df$y)\n\n\n[1] 0.338116\n\n\nThus giving us a value which is approximately equal to the population-level value we computed out on the board: that the conditional probability of success given private school education here is\n\\[\n\\Pr(Y = 1 \\mid E = 1) = \\frac{\\Pr(Y = 1, E = 1)}{\\Pr(E = 1)} = \\frac{\\frac{1}{18}}{\\frac{1}{6}} = \\frac{1}{3}\n\\]\nTherefore, what we’ve found is that:\n\nAcross everyone in the population, the likelihood of success is \\(s_{\\text{overall}} = \\frac{1}{6}\\), but\nAmong individuals who went to private school, the likelihood of success is \\(s_{\\text{private}} = \\frac{1}{3}\\)\n\nSo, private schools can justifiably claim, in this (hypothetical) case, that attending their school doubles one’s likelihood of success! The question that remains is, should we interpret this “doubling” as essentially denoting…\n\nA verb attached to “attending private school” (a thing that “attending private school” does is “doubles success chance”); or\nA property of the emergent distribution, i.e., the less strong claim that \\(Y = 1\\) occurs within the population with \\(E = 1\\) at twice the rate that \\(Y = 1\\) occurs within the overall population"
  },
  {
    "objectID": "writeups/do-calculus/index.html#the-textsfdo-operator",
    "href": "writeups/do-calculus/index.html#the-textsfdo-operator",
    "title": "Do-Calculus: Choose Your Own Pace",
    "section": "The \\(\\textsf{do}\\) Operator",
    "text": "The \\(\\textsf{do}\\) Operator\nNow, let’s see why having the operator \\(\\textsf{do}(\\cdot)\\) launches us beyond this fallacy, a fallacy that we invetiably fall into no matter how carefully/thoughfully we use the tools given to us by probability theory, since (given an antecedent argued for in, e.g., Elster (2015)) “associations” are pretty much never what we actually care about! The “point” of science (again, under antecedents argued for in that book) is to hypothesize and then evaluate causal claims! So, let’s see how the \\(\\textsf{do}\\) operator helps us here. Now, we’ll add a third value to our collection of things we can compute to try and evaluate the \\(E \\rightarrow Y\\) relationship:\n\n\\(s_{\\text{overall}} = \\Pr(Y = 1) = \\frac{1}{6}\\) ✅\n\\(s_{\\text{private}} = \\Pr(Y = 1 \\mid E = 1) = \\frac{1}{3}\\) ✅\n\\(s_{\\textsf{do}(\\text{private})} = \\Pr(Y = 1 \\mid \\textsf{do}(E = 1)) = \\; ?\\)\n\nHere, \\(\\textsf{do}(E = 1)\\) means diving into the DGP below the surface and changing it so \\(E = 1\\)… Setting \\(E\\) to be 1 in the DGP itself, producing a new DGP, which in this case looks as follows:\n\n\n\n\n\n\n\\(\\text{DGP}[(V, E, Y) \\mid \\textsf{do}(E = 1)]\\): Intervening to Set \\(E \\leftarrow 1\\)\n\n\n\n\nSample independent RVs \\(U_1 \\sim \\mathcal{B}(1/2)\\), \\(U_2 \\sim \\mathcal{B}(1/3)\\), \\(U_3 \\sim \\mathcal{B}(1/3)\\)\n\\(V \\leftarrow U_1\\)\n\\(E \\leftarrow 1\\)\n\\(Y \\leftarrow \\textsf{if }(V = 1)\\textsf{ then }0\\textsf{ else }U_3\\)\n\n\n\nNow, if we simulate a new population using this new DGP, rather than just subsetting the population we created earlier, we’ll be able to see how this change within the DGP is what lets us infer the causal effect of \\(E\\) on \\(Y\\)!\n\n\nCode\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(Rlab) |&gt; suppressPackageStartupMessages()\nlibrary(randomNames) |&gt; suppressPackageStartupMessages()\nset.seed(5450)\ndgp_do_e1 &lt;- function(p1, p2, p3) {\n    u1 &lt;- rbern(n=1, prob=p1)\n    u2 &lt;- rbern(n=1, prob=p2)\n    u3 &lt;- rbern(n=1, prob=p3)\n    v_val &lt;- u1\n    e_val &lt;- 1 # do(E = 1)\n    y_val &lt;- ifelse(v_val == 1, 0, u3)\n    rand_name &lt;- randomNames(1, which.names=\"first\")\n    return(tibble_row(name=rand_name, v=v_val, e=e_val, y=y_val))\n}\n# Generate one person's data using DGP\ndgp_do_e1(p1=1/2, p2=1/3, p3=1/3)\n\n\n\n\n\n\nname\nv\ne\ny\n\n\n\n\nAlexander\n1\n1\n0\n\n\n\n\n\n\nAnd now we can simulate a population as before, re-computing the probabilities in this new counterfactual world:\n\n\nCode\nset.seed(5450)\ne1_df &lt;- tibble(name=character(), v=numeric(), e=numeric(), y=numeric())\n# Run DGP N times, to generate size-N population\nfor (i in 1:N) {\n    cur_draw &lt;- dgp_do_e1(1/2, 1/3, 1/3)\n    e1_df &lt;- bind_rows(e1_df, cur_draw)\n}\nmean(e1_df$y)\n\n\n[1] 0.1674\n\n\nWhich is approximately equal to the value we would’ve gotten if I planned time better to let us do a second board exercise: under this new DGP,\n\\[\n\\begin{align*}\n\\textstyle \\Pr_{\\textsf{do}(E = 1)}(Y = 1) &= 0 \\cdot \\Pr(V = 1) + \\Pr(U_3 = 1) \\cdot \\Pr(V = 0) \\\\\n&= 0 \\cdot \\frac{1}{2} + \\frac{1}{3}\\cdot \\frac{1}{2} = \\frac{1}{6}.\n\\end{align*}\n\\]\n\n\n\n\n\n\nSymPy Again\n\n\n\nTo get the exact value of \\(\\Pr(Y = 1 \\mid \\textsf{do}(E = 1))\\), in place of the above approximation, we can use SymPy like we did earlier, changing one line:\n\n\nCode\nfrom sympy.stats import Bernoulli\nhalf_sym = S(1) / S(2)\nthird_sym = S(1) / S(3)\nU1_sym = Bernoulli(name='U1', p=half_sym)\nU2_sym = Bernoulli(name='U2', p=third_sym)\nU3_sym = Bernoulli(name='U3', p=third_sym)\nV_sym = U1_sym\nE_sym = S(1) # do(E = 1)\nY_sym = V_sym * U3_sym\nE(Y_sym)\n\n\n1/6\n\n\n\n\nAnd now we can answer our question! In the counterfactual world where everything is the same as before but now we intervene to assign the value \\(1\\) to \\(E\\) (and let the DGP operate as it did before, other than that change), the probability of success remains the same as the probability of success in the overall population:\n\n\\(\\Pr(Y = 1) = \\frac{1}{6}\\)\n\\(\\Pr(Y = 1 \\mid \\textsf{do}(E = 1)) = \\frac{1}{6}\\),\n\nwhich tells us that (within our custom-cooked world!) getting a private school education does not cause an increase in the likelihood of success.\n…So yeah, that is where we would have ended up if I had planned out my timing for the Chalkboard Lab a little better, so, I just hope that reading through this can better highlight the usefulness of the \\(\\textsf{do}\\) operator for distinguishing which associations are “just associations” and which actually correspond to causal relationships!"
  },
  {
    "objectID": "writeups/berkson/index.html",
    "href": "writeups/berkson/index.html",
    "title": "Berkson’s Paradox Example",
    "section": "",
    "text": "To see Berkson’s paradox in action, consider a simplified model of hospital admissions:\nThe Data-Generating Process, in this case, looks as follows:\nSo that we can represent the connections between the variables using the following PGM:\nFrom this DGP (or just from the earlier fact that the diseases occur independently), we immedately have the two facts:"
  },
  {
    "objectID": "writeups/berkson/index.html#analyzing-hospital-admissions-data",
    "href": "writeups/berkson/index.html#analyzing-hospital-admissions-data",
    "title": "Berkson’s Paradox Example",
    "section": "Analyzing Hospital Admissions Data",
    "text": "Analyzing Hospital Admissions Data\nNow, let’s say we are analyzing data from the hospital, so that all of the data in our dataset has \\(Z = 1\\).\nThe first step, which is not yet an example of Berkson’s paradox (just an application of Bayes’ theorem), is to compute the new disease probabilities given the observation that \\(Z = 1\\):\n\\[\n\\begin{align*}\n&\\Pr(Y = 1 \\mid Z = 1) \\\\\n&= \\frac{\\Pr(Z = 1 \\mid Y = 1)\\Pr(Y = 1)}{\\Pr(Z = 1 \\mid Y = 1)\\Pr(Y = 1) + \\Pr(Z = 1 \\mid Y = 0)\\Pr(Y = 0)} \\\\\n&= \\frac{1 \\cdot 1/3}{1 \\cdot 1/3 + \\Pr(X = 1)\\Pr(Y = 0)} = \\frac{1/3}{1/3 + (1/3)(2/3)} = \\frac{1/3}{1/3 + 2/9} \\\\\n&= \\frac{1/3}{5/9} = \\frac{1}{3} \\cdot \\frac{9}{5} = \\frac{3}{5}\n\\end{align*}\n\\]\nand by symmetry we also have \\(\\Pr(X = 1 \\mid Z = 1) = \\frac{3}{5}\\).\nThese two quantities do fit our intuition, generally, since we can reason that we’re more likely to encounter a person with disease \\(X\\) in a hospital which specializes in treating \\(X\\) than we are to encounter this person in general."
  },
  {
    "objectID": "writeups/berkson/index.html#computing-the-joint-pdf",
    "href": "writeups/berkson/index.html#computing-the-joint-pdf",
    "title": "Berkson’s Paradox Example",
    "section": "Computing the Joint pdf",
    "text": "Computing the Joint pdf\nThere are many ways we could proceed to “build up to” having the full joint pdf of \\((X, Y, Z)\\), but for me a key missing piece is the overall marginal probability of being in the hospital, \\(\\Pr(Z = 1)\\). For this step, what clicks in my brain is to use the definition of how we translate the logical “or” into a statement involving probabilistic events (here we use the independence of \\(X\\) and \\(Y\\) in the last step):\n\\[\n\\begin{align*}\n\\Pr(Z = 1) &= \\Pr(X = 1 \\vee Y = 1) \\\\\n&= \\Pr(X = 1) + \\Pr(Y = 1) - \\Pr(X = 1 \\wedge Y = 1) \\\\\n&= 1/3 + 1/3 - (1/3)(1/3) = 2/3 - 1/9 = \\frac{5}{9}\n\\end{align*}\n\\]\nAs a reminder here, in looking for the joint pdf, we’re looking for the missing values in the following table. I’ve started by placing a 0 in the logically-impossible rows:\n\nSince having \\(X\\) or \\(Y\\) guarantees admission into the hospital, any row where \\(X = 1\\) or \\(Y = 1\\) but \\(Z = 0\\) is not possible\nSince the hospital only treats diseases \\(X\\) and \\(Y\\), admission \\(Z = 1\\) is not possible when \\(X = 0\\) and \\(Y = 0\\)\n\n\n\n\n\\(X\\)\n\\(Y\\)\n\\(Z\\)\n\\(\\Pr(X, Y, Z)\\)\n\n\n\n\n0\n0\n0\n\n\n\n0\n0\n1\n0\n\n\n0\n1\n0\n0\n\n\n0\n1\n1\n\n\n\n1\n0\n0\n0\n\n\n1\n0\n1\n\n\n\n1\n1\n0\n0\n\n\n1\n1\n1\n\n\n\n\nFrom this table, we see that there are only four quantities we need to compute:\n\n\\(\\Pr(X = 0, Y = 0, Z = 0)\\)\n\\(\\Pr(X = 0, Y = 1, Z = 1)\\)\n\\(\\Pr(X = 1, Y = 0, Z = 1)\\)\n\\(\\Pr(X = 1, Y = 1, Z = 1)\\)\n\nLet’s try tackling these one-by-one. First:\n\\[\n\\begin{align*}\n\\Pr(X = 0, Y = 0, Z = 0) &= \\Pr(Z = 0 \\mid X = 0, Y = 0)\\Pr(X = 0, Y = 0) \\\\\n&= 1 \\cdot \\Pr(X = 0, Y = 0) = \\Pr(X = 0)\\Pr(Y = 0) \\\\\n&= \\frac{2}{3} \\cdot \\frac{2}{3} = \\frac{4}{9}\n\\end{align*}\n\\]\nNext:\n\\[\n\\begin{align*}\n\\Pr(X = 0, Y = 1, Z = 1) &= \\Pr(Z = 1 \\mid X = 0, Y = 1)\\Pr(X = 0, Y = 1) \\\\\n&= 1 \\cdot \\Pr(X = 0, Y = 1) = \\frac{2}{3} \\cdot \\frac{1}{3} = \\frac{2}{9}\n\\end{align*}\n\\]\nBy symmetry, we also have \\(\\Pr(X = 1, Y = 0, Z = 1) = \\frac{2}{9}\\), leaving only one probability left in the joint pdf table above! Since the first three calculated probabilities sum to \\(4/9 + 2/9 + 2/9 = 8/9\\), we can conclude that the final slot is \\(\\Pr(X = 1, Y = 1, Z = 1) = \\frac{1}{9}\\)!\nOr, if we want to compute it directly for sanity:\n\\[\n\\begin{align*}\n\\Pr(X = 1, Y = 1, Z = 1) &= \\Pr(Z = 1 \\mid X = 1, Y = 1)\\Pr(X = 1, Y = 1) \\\\\n&= 1 \\cdot \\Pr(X = 1, Y = 1) = \\Pr(X = 1)\\Pr(Y = 1) \\\\\n&= \\frac{1}{3}\\cdot \\frac{1}{3} = \\frac{1}{9}.\n\\end{align*}\n\\]\nThus our final pdf table is:\n\n\n\n\\(X\\)\n\\(Y\\)\n\\(Z\\)\n\\(\\Pr(X, Y, Z)\\)\n\n\n\n\n0\n0\n0\n\\(4/9\\)\n\n\n0\n0\n1\n0\n\n\n0\n1\n0\n0\n\n\n0\n1\n1\n\\(2/9\\)\n\n\n1\n0\n0\n0\n\n\n1\n0\n1\n\\(2/9\\)\n\n\n1\n1\n0\n0\n\n\n1\n1\n1\n\\(1/9\\)"
  },
  {
    "objectID": "writeups/berkson/index.html#berksons-paradox",
    "href": "writeups/berkson/index.html#berksons-paradox",
    "title": "Berkson’s Paradox Example",
    "section": "Berkson’s Paradox",
    "text": "Berkson’s Paradox\nNow, the point where Berkson’s Paradox enters the picture is when we try to evaluate the independence of the two diseases, solely on the basis of the hospital admissions data!\nTo see this, let’s now look at whether observing \\(X = 1\\) in the hospital’s dataset (the observation that someone in the dataset has disease \\(X\\)) changes the probability of having \\(Y\\). Recalling that \\(\\Pr(Y = 1 \\mid Z = 1) = \\frac{3}{5}\\), let’s now compute the change in this quantity when \\(X = 1\\) is observed. Since we’ve computed the full joint pdf above, our task becomes fairly easy!\n\\[\n\\Pr(Y = 1 \\mid X = 1, Z = 1) = \\frac{\\Pr(Y = 1, X = 1, Z = 1)}{\\Pr(X = 1, Z = 1)}.\n\\]\nThe numerator value of \\(1/9\\) we can read directly off the table above.\nFor the denominator, we can sum the probabilities across every row where \\(X = 1\\) and \\(Z = 1\\):\n\\[\n\\begin{align*}\n\\Pr(X = 1, Z = 1) &= \\Pr(X = 1, Y = 0, Z = 1) + \\Pr(X = 1, Y = 1, Z = 1) \\\\\n&= 2/9 + 1/9 = 3/9\n\\end{align*}\n\\]\nThis means that the full result, dividing the numerator by the denominator, is\n\\[\n\\Pr(Y = 1 \\mid X = 1, Z = 1) = \\frac{1/9}{3/9} = \\frac{1}{9}\\cdot \\frac{9}{3} = \\frac{1}{3}\n\\]\nThis reveals the issue: that if we only ever observe data on hospital patients, i.e., data where \\(\\Pr(E)\\) is actually \\(\\Pr(E \\mid Z = 1)\\), then we will get the impression that having \\(X\\) makes \\(Y\\) less likely, and vice-versa! To see this, let \\(\\Pr_{Z = 1}(E)\\) denote the probability of an event \\(E\\) that we would infer if we only had data with \\(Z = 1\\). Using this notation, we get that\n\\[\n\\Pr_{Z = 1}(Y = 1) = \\frac{3}{5},\n\\Pr_{Z = 1}(Y = 1 \\mid X = 1) = \\frac{1}{3},\n\\]\nin other words, we may easily be “tricked” into concluding that observing \\(X = 1\\) decreases the probability of \\(Y = 1\\), despite the fact that we know these diseases occur independently, given our knowledge of the full underlying DGP."
  },
  {
    "objectID": "writeups/berkson/index.html#the-do-operator",
    "href": "writeups/berkson/index.html#the-do-operator",
    "title": "Berkson’s Paradox Example",
    "section": "The do-Operator",
    "text": "The do-Operator\nNow, let’s re-compute these probabilities, using \\(\\textsf{do}\\) to intervene directly in the DGP rather than using the conditional operator to simply “subset” the data:\n\n\n\n\n\n\n\\(\\text{DGP}[(X, Y, Z \\mid \\textsf{do}(X = 1)]\\)\n\n\n\n\n Generate exogenous noise variables \\(U_1 \\sim \\mathcal{B}(1/3)\\) and \\(U_2 \\sim \\mathcal{B}(1/3)\\)\n Set \\(X = 1\\) ()\n Set \\(Y = U_2\\)\n Set \\(Z = 1\\) if \\((X = 1 \\vee Y = 1)\\), 0 otherwise\n\n\n\nBy applying this \\(\\textsf{do}\\) operation, we see that in fact step  can be simplified to just: [Set \\(Z = 1\\)], since \\(X = 1 \\vee Y = 1\\) is always true if \\(X = 1\\), thus producing the following simplified form:\n\n\n\n\n\n\n\\(\\text{DGP}[(X, Y, Z \\mid \\textsf{do}(X = 1)]\\) Simplified\n\n\n\n\n Generate exogenous noise variables \\(U_1 \\sim \\mathcal{B}(1/3)\\) and \\(U_2 \\sim \\mathcal{B}(1/3)\\)\n Set \\(X = 1\\)\n Set \\(Y = U_2\\)\n Set \\(Z = 1\\)\n\n\n\nAnd from this post-\\(\\textsf{do}(X = 1)\\) DGP, we see how straightforwardly we recover the true causal effect of \\(X\\) on \\(Y\\) and vice-versa:\n\\[\n\\begin{align*}\n\\Pr(Y = 1 \\mid \\textsf{do}(X = 1)) &= \\Pr(U_2 = 1) = \\frac{1}{3} = \\Pr(Y = 1) \\\\\n\\Pr(X = 1 \\mid \\textsf{do}(Y = 1)) &= \\Pr(U_1 = 1) = \\frac{1}{3} = \\Pr(X = 1),\n\\end{align*}\n\\]\nand thus we have causal independence: \\(\\Pr(Y = 1 \\mid \\textsf{do}(X = 1)) = \\Pr(Y = 1)\\) and \\(\\Pr(X = 1 \\mid \\textsf{do}(Y = 1)) = \\Pr(X = 1)\\)!"
  },
  {
    "objectID": "final.html",
    "href": "final.html",
    "title": "Final Project Specifications",
    "section": "",
    "text": "Our goal is to make the final project as open-ended as possible, to give you the space to explore any particular topic that may have piqued your interest throughout the semester! At the same time, we hope to provide you with guidance and mentorship so that you don’t feel lost as to how to start, how to proceed, and/or what to submit for the final deliverable!1\nSo, given this, we have randomly assigned each of you to a mentor, who will help you select a topic and pursue it in such a way that it fits within the scope of the remaining weeks in the semester. You will receive an email letting you know who your mentor is, by the end of the weekend (Sunday, March 24th). The mentor assignments can always be re-arranged, however! For example, if you decide to pursue a project that another mentor has particular experience with, we can re-assign you to that mentor!\n\n\n\n\n\n\nThe Goal: Research \\(\\rightarrow\\) Policy Recommendation\n\n\n\nAlthough the structure can be mostly similar to projects you’ve done for e.g. DSAN 5000 and 5100, the new element for the DSAN 5450 project is that we want you to develop and argue for a particular policy recommendation that you’d make, for example if you were asked to speak in Congress as a data science expert!\nThis means, for example, that your deliverable can have the following structure in terms of section headings, which should be familiar from DSAN 5000 and 5100 except for the final section:\n\nIntroduction\nLiterature Review\nData and Methods\nResults\nPolicy Recommendation\n\nThe policy recommendation portion will look different depending on the particular topic you decide to explore, but the idea is that it should be somewhat like a policy whitepaper, where you would move away from the details of your study and towards its implications for a (real or imagined) policymaker who is hoping for information about a given topic.\nOne recent example that you can look at as a rough template would be Chris Callison-Burch’s Congressional testimony, given last year as part of a Congressional hearing around issues that LLMs might present for intellectual property and copyright law. Prof. Callison-Burch discusses the process in this podcast episode, so you can listen to that for details about the approach he took towards the invitation from Congress, but the tldr is: he needed to communicate just enough detail to allow the policymakers to understand what he was talking about, but not so much detail that they would need to have a PhD in Computer Science to understand his recommendations.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#overview",
    "href": "final.html#overview",
    "title": "Final Project Specifications",
    "section": "",
    "text": "Our goal is to make the final project as open-ended as possible, to give you the space to explore any particular topic that may have piqued your interest throughout the semester! At the same time, we hope to provide you with guidance and mentorship so that you don’t feel lost as to how to start, how to proceed, and/or what to submit for the final deliverable!1\nSo, given this, we have randomly assigned each of you to a mentor, who will help you select a topic and pursue it in such a way that it fits within the scope of the remaining weeks in the semester. You will receive an email letting you know who your mentor is, by the end of the weekend (Sunday, March 24th). The mentor assignments can always be re-arranged, however! For example, if you decide to pursue a project that another mentor has particular experience with, we can re-assign you to that mentor!\n\n\n\n\n\n\nThe Goal: Research \\(\\rightarrow\\) Policy Recommendation\n\n\n\nAlthough the structure can be mostly similar to projects you’ve done for e.g. DSAN 5000 and 5100, the new element for the DSAN 5450 project is that we want you to develop and argue for a particular policy recommendation that you’d make, for example if you were asked to speak in Congress as a data science expert!\nThis means, for example, that your deliverable can have the following structure in terms of section headings, which should be familiar from DSAN 5000 and 5100 except for the final section:\n\nIntroduction\nLiterature Review\nData and Methods\nResults\nPolicy Recommendation\n\nThe policy recommendation portion will look different depending on the particular topic you decide to explore, but the idea is that it should be somewhat like a policy whitepaper, where you would move away from the details of your study and towards its implications for a (real or imagined) policymaker who is hoping for information about a given topic.\nOne recent example that you can look at as a rough template would be Chris Callison-Burch’s Congressional testimony, given last year as part of a Congressional hearing around issues that LLMs might present for intellectual property and copyright law. Prof. Callison-Burch discusses the process in this podcast episode, so you can listen to that for details about the approach he took towards the invitation from Congress, but the tldr is: he needed to communicate just enough detail to allow the policymakers to understand what he was talking about, but not so much detail that they would need to have a PhD in Computer Science to understand his recommendations.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#timeline",
    "href": "final.html#timeline",
    "title": "Final Project Specifications",
    "section": "Timeline",
    "text": "Timeline\nThese are rough estimates, but the project will go most smoothly if you are able to hold yourself to the following schedule:\n\nProposal: Approved by mentor by Wednesday, April 3rd\nFinal Draft: Sent to mentor for review by Wednesday, April 24th\nSubmission: Completed project submitted to course staff by Friday, May 10th, 5:59pm EDT",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#submission-format",
    "href": "final.html#submission-format",
    "title": "Final Project Specifications",
    "section": "Submission Format",
    "text": "Submission Format\nThere is now an assignment page for the final project (within the Google Classroom site for the course), where you will upload your final submission for grading. The following is a rough sketch of what we’re looking for in terms of the structure of your submission:\n\nHTML format, as a rendered Quarto manuscript, would be optimal, but can be PDF if there are issues with Quarto. If PDF, LaTeX would be preferred, but also can be a Word doc or Google doc\nIf PDF format, 8-20 pages double-spaced, and then the Quarto HTML length can be the equivalent of this (for example, you can print-preview the Quarto doc to see how many pages it would print as)\nIt should have an abstract, a 250-500 word summary at the top, of (a) what you did and (b) the policy recommendation you’re making\nCitations should be set up so that they’re handled automatically, by Quarto’s citation manager for example, or by Bibtex if you use LaTeX to generate a PDF, or by Word/GDocs otherwise.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#the-proposal-stage",
    "href": "final.html#the-proposal-stage",
    "title": "Final Project Specifications",
    "section": "The Proposal Stage",
    "text": "The Proposal Stage\nOur goal here is for you to have enough time to think through the details in advance, to determine the scope, of the project, before you actually start working on it. This is often (like, almost always) the most difficult part of any project: it’s not a matter of whether you’re capable of doing the project at all—you’re all capable of doing it!—but how feasible it is to do it within the given timeframe.\nSo, this is exactly why there’s a course staff here to help you! We’ve all wrestled with this issue of “scope creep” throughout our own previous projects, which means that our goal in providing feedback on your proposals will be solely to help you brainstorm and then focus in on what you can accomplish by the beginning of May. Thus, to reiterate, you should not view the proposal feedback as some sort of judgement of your innate ability or anything like that! And, to this end, it will not be graded, which we hope will further cement the idea that it is not a judgement process, but a working-together process to arrive at a plan for getting the project done.\nTo conclude, concretely: you’ll be “done” with the proposal stage once you and your mentor are on the same page in terms of\n\nWhat topic you’re going to pursue,\nWhat your final deliverable will look like, and\nA set of milestones you will use from now until the beginning of May to track your progress.\n\nAt that point, you’ll be ready for the implementation stage, described in the next section.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#the-implementation-stage",
    "href": "final.html#the-implementation-stage",
    "title": "Final Project Specifications",
    "section": "The Implementation Stage",
    "text": "The Implementation Stage\nThis stage is more difficult to describe in advance, since it depends on the specific topic you’ll pursue. But, the main goal is for you to have a draft version of the project ready by Wednesday, April 24th. We choose this date specifically because it corresponds to the final lecture in the course, so that as part of that lecture Jeff can make sure to touch on any remaining issues that might still need to be tackled in order to move from the draft to the submission on the last day of the semester.\nHowever, given this explanation, hopefully it makes sense that the earlier you have a draft, the better, since an earlier draft means that Jeff can also use the lectures before the final lecture to cover any topics which might be relevant to your projects! In other words: the whole reason why the last few lectures of the course are set aside as “Selected Topics” is so that these lectures can adapt to cover whatever might be relevant and important for the range of topics yall choose for your final projects! So, please take advantage of this aspect of the class if you can.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#example-project-ideas",
    "href": "final.html#example-project-ideas",
    "title": "Final Project Specifications",
    "section": "Example Project Ideas",
    "text": "Example Project Ideas\nNow that you have all of the above info, we wanted to make it clear that it’s okay if you don’t have any idea of what topic you’d like to pursue for the project! Some people come into the course with a very particular interest, whereas others come in for the sake of learning a broad overview of a bunch of topics, and we’re here to accommodate both cases 😁 So, if you don’t have a preexisting idea of what you’d like to pursue, in this section we provide you with a few examples—one example per course topic—that you can choose as-is or modify to suit your interests.\nAs you’ll quickly see if you start reading through the examples, there are tons and tons of details and tons and tons of variations/modifications that could be made, that I’m unable to state in detail without making this a 1000-page document 😜 so, just keep in mind that if anything at all pops into your head while reading through them, even if the thing that pops into your head doesn’t “match” the specific details of one of the projects here, that’s a good thing! You can take that and run with it, turning it from an idea into a full-blown project by talking through it with your mentor.\n\nHigh-Level Data Science Questions\n\nExample 1: Archive of Missing Datasets\nHere there are tons of possibilities for each “sub-topic” that we covered during the broad overview of data science issues given in Week 1 and Week 2. But, one that I think could be interesting and relevant to the policy-focused goal of the final project would be to pursue the idea of the Archive of Missing Datasets:\nYou may have found, when working on your own projects or the DSAN 5000/5100 projects, that there are lots of datasets that you assume must exist somewhere, but you then find to your horror that they actually don’t exist, at least not in a form that would allow for a useful/informative data analysis.\nSo, if you have experienced this, or if you haven’t but you’re interested in discovering what might be egregious/socially-important cases of missing datasets, your final project could revolve around recommending to policymakers that they invest in (as in, allocate resources towards in general, not just money!) the creation of a currently non-existent dataset.\nThis is precisely what has motivated one of the biggest society-wide DSAN 5450-related developments in the US of recent years: in the aftermath of the sudden publicity that rampant police murder of black people across the country received because of cases like the murders of\n\nTrayvon Martin in Florida,\nFreddie Gray in Baltimore, Maryland,\nMichael Brown in Ferguson, Missouri,\nEric Garner in Staten Island, New York,\nGeorge Floyd in Minneapolis, Minnesota, and\nPhilando Castile in St. Paul, Minnesota,\n\nmany people were shocked to learn that the US government doesn’t care enough to keep track of these killings in any systematic way, which led to data-journalistic endeavors like the Washington Post’s “Fatal Force” police killings database.\nOnce these endeavors were established, however, the next “phase” of policy debates on this issue have revolved around whether and/or how data on these types of socially-important phenomena should in fact be collected by publicly-funded government institutions, given that (in this case) the police officers doing the killings are themselves publicly-funded government employees.\nSo, as an example final project on this issue of missing datasets, you could:\n\nIdentify another such socially-important phenomenon for which there is a dearth of available data that would be helpful for some social goal,\nDocument the details around what data already exists regarding this phenomenon (descriptively), and why it is insufficient from a social perspective (normatively), and then\nArgue that the policymaking audience of your project should in fact allocate resources towards the collection of this data (note the shift from descriptive to normative here!): for example, you would need to argue for the feasibility of this collection—providing concrete details about precisely how it could be implemented, in a cost-effective manner, given some budget—as well as its effectiveness with respect to some explicitly-stated social goal (like, in the above example, the goal could simply be to reduce the frequency of police killings).\n\n\n\nExample 2: Operationalization\nIn the Week 1 slides I included a brief discussion of operationalization in terms of a book by \"\"\"Nobel Prize\"\"\"-winning economists2 Joseph Stiglitz and Amartya Sen called Mismeasuring our Lives: Why GDP Doesn’t Add Up (Stiglitz, Sen, and Fitoussi 2010). This example project outline is sort of a “variation” of Example 1, since basically what I would recommend if you’re interested in this topic would be very similar:\nWhereas the goal of the Archive of Missing Datasets is to point out how there is lots of socially-important information that is not measured at all, Stiglitz and Sen are pointing to equally-urgent and equally-deleterious (often way more urgent/deleterious!) cases where the information is measured, but where the way that it is measured is harmful with respect to the social goal which motivated the measurement in the first place.\nSo, we can take the description of Example 1 above, and basically just replace “missing” with “badly measured”, to see how a project studying operationalization could work:\n\nIdentify a socially-important phenomenon for data does exist but is measured in a way that is relatively unhelpful/non-useful with respect to some social goal (that is, relative to another way of measuring it which could be mroe helpful/useful),\nDocument the details around what data already exists regarding this phenomenon (descriptively), and why it is unhelpful for measuring the social phenomena of interest (normatively), and then\nArgue that the policymaking audience of your project should in fact allocate resources towards the better operationalization that you are proposing (note the shift from descriptive to normative here!): for example, you would need to argue for the feasibility of this new measure—providing concrete details about precisely how it could be implemented, in a cost-effective manner, given some budget—as well as its greater effectiveness than previous ways of measuring, with respect to some explicitly-stated social goal (like, in the earlier example, reducing the frequency of police killings).\n\nAs you can maybe tell by now, the “boundary” between missing data and badly-measured data is sometimes fuzzy: for example, often data-policy debates will say that a certain dataset is missing as shorthand for something more like “it’s measured so badly that, for all intents and purposes it may as well be missing”.\nFor example, technically (until 2019) the FBI used to issue what were called Uniform Crime Reports, but these were based on a “voluntary-reporting” model, meaning that individual police departments could submit whatever data they wanted, and withhold whatever data they wanted, without explanation or documentation, so… from what I can tell, after 2019 they just gave up, since a voluntary-reporting dataset of crime certainly falls under the rubric of may-as-well-be-missing. But, alas, these reports are still used widely in various academic studies of crime, books, journalistic investigations, etc., so if that’s at all interesting to you, it could be studied for a final project that would treat it as a mixture of the missing data and badly-operationalized data issues.\n\n\n\nFairness\nAs we discussed in Week 4 (specifically, I wrote it on the chalkboard and talked through it as an example, on the basis of stuff in those W04 slides), one of the most high-profile cases of algorithmic discrimination in the 21st century emerged out of the ProPublica vs. Northpointe Scandal.\nThe rough summary is that:\n\nAlthough ProPublica meticulously documented anti-black racial discrimination in Northpointe’s COMPAS algorithm in terms of the classification parity fairness measure,\nNorthepointe then responded by meticulously documenting the absence of anti-black racial discrimination in COMPAS in terms of the predictive parity fairness measure\n\nSo, since this is one of the most-often-analyzed datasets in the Fairness in AI literature, your final project could be to pursue this case in a more in-depth way than we were able to cover it in class. This would involve writing a policy paper with two main parts:\n\nExplaining the ProPublica-Northpointe controversy descriptively, by demonstrating how the data simultaneously violates classification parity fairness while satisfying predictive parity fairness. Specifically, this would mean:\n\nExplaining the two fairness definitions to an audience of policymakers and then\nWriting Python or R code which downloads the data and evluates it programmatically on these two different fairness criteria\n\nEvaluating the ProPublic-Northpointe controversy normatively, by providing recommendations for policymakers in terms of how they ought to adjudicate this case. There are several ways you could approach this, but the first two example approaches that come to mind are:\n\nArguing that one of these two fairness criteria better “aligns” with an ethical framework that you think the policymakers should adopt—for example, you could adopt utilitarianism as your ethical “axiom”, and then argue that one of these criteria is more appropriate for evaluating outcomes than the other, and therefore better suited to resolving the dispute in a utilitarian manner\nArguing that neither of the two fairness criteria are sufficient for policymaking, and arguing that policymakers should instead use a framework like \\(\\varepsilon\\)-based fairness or causal fairness to resolve the dispute.\n\n\n\n\nCausality\nAn example project on this topic could pursue the type of approach that appeared on your Homework 2, in Part 3.3, which presented two different hypotheses regarding the causal mechanism by which women experience worse mental health outcomes. You don’t need to pursue this particular question, or use these particular variables in your causal model! But, I am copying some of the key parts of that problem here, along with explanations of how you could pursue this type of analysis in a more in-depth way for a final project.\nThe homework problem presented a simplified version of a causal system studied using causal diagrams in Chapter 16 of Kaufman and Oakes (2006): Glymour (2006), “Using Causal Diagrams to Understand Common Problems in Social Epidemiology”. The idea was to consider an imaginary debate (though one that happens between real people all the time, when taking about this issue!) between:\n\nPerson \\(i\\), who hypothesizes that women have greater rates of depression because they are “‘biologically programmed’ to be depressed” (ibid., pg. 408), and\nPerson \\(j\\), who hypothesizes that women have greater rates of depression because\n\n\n“People get depressed whenever they are sexually harassed” (ibid.), and\n\n\n“Women are more frequently sexually harassed than men” (ibid.)\n\n\n\nIt then took this debate and tried to “zero in” on the particular variables that came into play in the respective arguments:\n\n\\(A\\): The gender of an individual (as before, conceptualized as their self-reported and/or socially-expressed gender), where \\(A = 1\\) for self-reported females and \\(A = 0\\) for those who do not self-report as female\n\\(B\\): An indicator variable representing some biological property of the individual (in these debates, this would most commonly be e.g. \\(B = 1\\) for the presence of at least one Y-chromosome and \\(B = 0\\) otherwise)\n\\(H\\): Whether or not someone experiences sexual harassment, where \\(H = 1\\) represents that the individual has experienced such harassment and \\(H = 0\\) represents that they have not experienced it\n\\(Y\\): The “outcome” of whether or not someone has developed depression, where \\(Y = 1\\) represents an individual with depression and \\(Y = 0\\) represents an individual without depression\n\nAnd, once these variables were established, we were able to “encode” the two hypothesized causal pathways within the same causal diagram:\n\n\n\nWe then looked at two subgraphs of the full causal diagram, with the following subgraph representing person \\(i\\)’s hypothesis:\n\n\n\nAnd this alternative subgraph representing person \\(j\\)’s hypothesis:\n\n\n\nSo, for your final project, you could take a debate around a social issue that is particularly important or particularly interesting to you and perform a causal analysis of it using this general framework.\nThe idea would be to choose a topic where you think that detailing the causal connections between variables in this manner could aid policymakers in addressing the underlying problem.\nLots of examples immediately come to mind (though they are Jeff-style examples so you don’t need to choose any of them, I promise! 😜), but throughout the semester many of the examples in class revolved around the causal pathways linking race with policing, incarceration, and the criminal justice system. From the perspective of a policymaker—the perspective you should have in mind for the final project!—some of the key issues that could be analyzed using frameworks from DSAN 5450 would be:\n\nHow do variables related to social conditions (e.g., poverty, quality of schools) causally interact with variables related to individual choices (e.g., searching for a job, pursuing additional years of school, allocating income between saving and spending) to produce outcomes like career “success” (say, moving into a higher or lower income bracket relative to the bracket one is born into), crime, and/or trust in government?\nHow might it help policymakers to think causally, in terms of how different interventions might counterfactually help or harm some goal that they have?\n\nHere you could choose an existing but vague policy debate like “do police and metal detectors in school help or harm students’ educations?”, and make it more concrete by describing a causally-robust study that could be performed to slightly move this debate away from people-yelling-opinions-at-each-other and towards people-studying-the-causal-impacts-of-interventions… If you were actually able to go out and collect data relevant to these debates, and perform a causal analysis using this data, that would be the holy grail! But, I promise, given the timespan you have, a careful and well-thought-out description of what this type of study would look like and how it could be carried out would be sufficient for the project.\n\n\n\n\nPrivacy and Data Protection Policies\nHere there were a couple of points during Week 8 and Week 9 where I mentioned possible final project ideas, but the first two that come to mind are:\n\nIn this slide during Week 8, I pointed out how there are far too many different data-protection policy frameworks, spanning across too many different countries and states, for me to be able to cover them all. So, your project could be to pursue this further than we were able to in class! But, that’s a bit general, so to make it more specific, the types of projects I briefly outlined in Week 8 were along the lines of:\n\nChoose a country/state that you think is a “policy innovator”, and then see how the data-protection policies from this country/state “diffuse outwards” and get adopted over time by other countries/states. Although one way to do this would be to find a manually-curated dataset which contains (e.g.) 0/1 variables representing whether a given state has adopted a given data-protection policy at a given time (and these datasets definitely exist, and we can help you find them!), to me another cool way to study this would be to use NLP text-reuse detection algorithms like Passim, to “automatically” detect policy adoption by just seeing when text from country \\(A\\)’s data-protection laws appears in another country \\(B\\)’s data-protection laws.\nRather than a diffusion study like this, you could instead carry out what’s called a cross-sectional analysis of countries/states and their data-protection policies: to me, one interesting cross-sectional study could be to see how a country’s form of government relates to the data-protection laws it adopts: are there systematic differences between the data-protection policies adopted by hereditary monarchies in the Middle East like Saudi Arabia or Bahrain and those adopted by comparable (as in, in this case, historically-culturally similar—remember our idea of fair comparison!) Middle Eastern countries with democratic institutions like Yemen or Lebanon?3\n\nOne other potential project I mentioned in both Week 8 and Week 9 would be a project studying how ambiguity is used instrumentally in privacy policies to shift power from users to companies, since these companies possess greater residual rights of control—the right to determine “what happens” when there is ambiguity in a contract—relative to users. The slides for both weeks contained the plot from Wagner (2023) showing the growth in “obfuscatory words” in privacy policies over time, but I also mentioned how the goal of Wagner (2023) was to point out how NLP could be used to try and “combat” the power imbalances induced by this ambiguity.\nSo, one example of a final project pursuing this thread could be a policy paper wherein you code and demonstrate a proof of concept of how a “privacy policy badness detector” could work: it’s the thing I talked about near the beginning of Week 9, where, you could have a user specify their privacy “boundaries”, and then you could have code that uses NLP tools to parse privacy policies to identify statements which might enable the company to violate these boundaries, highlighting them for the user so that they don’t have to read the entire thing manually!\nScope-wise, that would be pretty ambitious, so to me a very reasonable final project could just be a more “naïve” version of this, where users could just specify key terms of interest to them (say, “medical data”), and then maybe the app could be a browser extension which removes all of the parts of the privacy policy besides the parts which may be relevant to the user’s key terms. Then, in your paper, you would want to make an argument to policymakers on the basis of what you “found” in making the app—for example, if you found that there were clauses that were relevant to medical data but where this relevance was “hidden” because of the ambiguity of the language used, then perhaps you could recommend that they pass a law requiring companies to tag each paragraph of their privacy policies with what aspects of privacy they relate to, as a concrete way to ameliorate the “ambiguity problem”!\n\n\n\nPolicy Evaluation / Recommendation\nSince we haven’t covered this yet, I will just provide an example of a policy-evaluation final project in class this week (Week 10), and then I will copy it into this section.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#references",
    "href": "final.html#references",
    "title": "Final Project Specifications",
    "section": "References",
    "text": "References\n\n\nStiglitz, Joseph E., Amartya Sen, and Jean-Paul Fitoussi. 2010. Mismeasuring Our Lives: Why GDP Doesn’t Add Up. The New Press.\n\n\nWagner, Isabel. 2023. “Privacy Policies Across the Ages: Content of Privacy Policies 1996–2021.” ACM Transactions on Privacy and Security 26 (3): 32:1–32. https://doi.org/10.1145/3590152.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#footnotes",
    "href": "final.html#footnotes",
    "title": "Final Project Specifications",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you can’t tell, my whole educational philosophy here is just the Montessori system—this approach was originally developed for younger (primary school) children, but lots and lots of recent educational research indicates that it’s an actually an extremely effective way to learn, and to motivate self-learning, for people of any age 😎↩︎\nEven though I’m biased in the opposite direction of belittling them—since Joseph Stiglitz and Amartya Sen are two of my heroes, and Stiglitz even gave me nice comments on my dissertation and stuff since I was at Columbia with him—it’s honestly important to put \"\"\"Nobel Prize in Economics\"\"\" in triple-quotes, since unlike the “real” (non-triple-quoted) Nobel Prizes, the \"\"\"Nobel Prize\"\"\" in economics was actually created about 80 years after the real ones established by Alfred Nobel, and were explicitly part of the movement by the so-called “Chicago School” of economics to legitimize their particular brand of economics as a “““science”““, and thus delegitimze any other approach to economics as”non-scientific”… For a quick overview with a link to a great interview with Philip Mirowski, here’s a FiveThirtyEight article: “The Economics Nobel Isn’t Really A Nobel”. But the full-on, in-depth essay I’d truly recommend is Yasha Levine’s “It’s all a big lie. There is no ‘Nobel Prize’ in Economics.” &lt;/rant&gt;↩︎\nObviously there are tons of details and particular considerations that you might have to take into account for these types of studies, but that’s exactly the type of thing that the TAs and I can help you with! If you go with this particular choice, for example, you’d have to make sure to control for considerations like the fact that these countries vary in terms of ethnic and/or religious “homogeneity”: About 85% of Saudi Arabian citizens are Sunni Muslim Arabs, for example, whereas Lebanon is basically a patchwork of dozens of different salient religious/cultural/ethnic identities, which would be relevant in the sense that different identity groups within a country might have vastly different dispositions towards how their data should be collected and used!↩︎",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "w10/index.html",
    "href": "w10/index.html",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#thucydides-and-the-kindly-slavemaster",
    "href": "w10/index.html#thucydides-and-the-kindly-slavemaster",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Thucydides and the Kindly Slavemaster",
    "text": "Thucydides and the Kindly Slavemaster\n\n\n[What is] right, as the world goes, is only in question between equals in power; otherwise, the strong do as they please and the weak suffer what they must. (Thucydides 2013 c. 411 BC) (Think of necessary vs. sufficient conditions!)\n\n\n\n\n\nliberalism\nrepublicanism\n\n\n\n\n\nDefinition of Injustice\nStrong do bad things (Berlin 1959)\nStrong can do bad things (Skinner 1998; Pettit 1997; Lovett 2022)\n\n\n\nThucydides Question\nStrong do as they please \\(\\overset{?}{\\Rightarrow}\\) Strong do bad things\nStrong do as they please \\(\\overset{?}{\\Rightarrow}\\) Strong can do bad things\n\n\n\nAnswer\nNo, not necessarily!\nYes, necessarily!\n\n\n\nFrederick Douglass\nMy feelings [towards slave masters] were not the result of any marked cruelty in the treatment I received…\n…they sprung from the consideration of my being a slave in the first place. It was slavery—not its mere incidents—that I despised. (Douglass 1855)\n\n\n\nA Doll’s House\nOur home is nothing but a playroom. I have been your doll-wife, just as at home I was papa’s doll-child; and here the children have been my dolls. (Ibsen 1879)\n\n\n\n\n\n(Plz notice the lowercase “l”, lowercase “r”!)",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#relevance-for-this-week-where-we-left-off",
    "href": "w10/index.html#relevance-for-this-week-where-we-left-off",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Relevance for This Week (Where We Left Off)",
    "text": "Relevance for This Week (Where We Left Off)\n\nCan we develop policy interventions that equalize power, so that world looks like normative ethics from W03-W08 (“what is right”)?\n(Hidden antecedent: non-Nietzschean ethical framework e.g. Utilitarianism/Kant)\nPoint of prev slide: From now til W14, keep in mind how definition of power (and hence “effectiveness” of policy intervention) depends on antecedent\n\nliberal definition \\(\\Rightarrow\\) focus on equilibria (no injustice if bad thing doesn’t happen in equilibrium)\nrepublican definition \\(\\Rightarrow\\) also take off-equilibrium possibilities into account (no injustice if bad thing doesn’t happen in equilibrium and doesn’t happen if one player deviates “on a whim”) (Jacobs and Naidu 2025 😉)\n\nPrisoners’ Dilemma 😫 \\(\\prec\\) Assurance Game 🤨 \\(\\prec\\) Invisible Hand Game 🥳",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#prisoners-dilemma-fishers-dilemma",
    "href": "w10/index.html#prisoners-dilemma-fishers-dilemma",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Prisoners’ Dilemma (Fishers’ Dilemma)",
    "text": "Prisoners’ Dilemma (Fishers’ Dilemma)\n\nSingle, unique Nash equilibrium, and it’s Pareto inferior\n\n\n\n\nThe Game\n\n\n\n\n\n\n\\(j\\)\n\n\n\n\nFish 6 Hours\nFish 8 Hours\n\n\n\\(i\\)\nFish 6 Hours\n\\(1.0,1.0\\)\n\\(0.0,\\boxed{1.2}\\)\n\n\nFish 8 Hours\n\\(\\boxed{1.2}, 0.0\\)\n\\(\\boxed{0.4},\\boxed{0.4}\\)\n\n\n\n\nBoxes = Best Responses:\n\\(\\text{BR}_i(6\\textrm{ hr}) = 8\\textrm{ hr}\\), \\(\\text{BR}_i(8\\textrm{ hr}) = 8\\textrm{ hr}\\)\n\\(\\text{BR}_j(6\\textrm{ hr}) = 8\\textrm{ hr}\\), \\(\\text{BR}_j(8\\textrm{ hr}) = 8\\textrm{ hr}\\)\n\n\n\nPareto Dominance",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#operationalizing-power",
    "href": "w10/index.html#operationalizing-power",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Operationalizing Power",
    "text": "Operationalizing Power\n\nEqually good outside options \\(\\implies\\) can contract to Pareto-optimal point \\(o^P\\)\n\\(i\\) has better outside options \\(\\implies\\) can make take it or leave it offer to \\(j\\):\n\n“You (\\(j\\)) fish 6 hrs all the time. I (\\(i\\)) fish 6 hrs 41% of time, 8 hrs otherwise”\n\n\n\n\n\nEver so slightly better for \\(j\\) \\(\\implies\\) \\(j\\) accepts (Behavioral econ: \\(j\\) accepts if 41% meets subjective fairness threshold; observed across many many cultures!)\nLater / next week: observe policy with outcome \\(o^{C}_{i \\rightarrow j} \\iff\\) policy values \\(i\\)’s welfare more than \\(j\\)’s welfare (inferred social welfare weights \\(\\omega_i &gt; \\omega_j\\))",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#policy-interventions-fish-dilemmas-mapsto-assurance-games",
    "href": "w10/index.html#policy-interventions-fish-dilemmas-mapsto-assurance-games",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Policy Interventions: Fish Dilemmas \\(\\mapsto\\) Assurance Games",
    "text": "Policy Interventions: Fish Dilemmas \\(\\mapsto\\) Assurance Games\n\nNotice: To “escape” prisoners’ dilemma, we had to literally change the rules of the game (permanent intervention)\nFishers’ Dilemma:\n\nNo institutions: \\(a_i, a_j \\in \\{6\\text{ hr}, 8\\text{ hr}\\}\\)\nInstitutions (courts or social norms): \\(\\{\\text{Accept}, \\text{Reject}\\}\\)\n\nDriving “game”:\n\nNo institutions: \\(a_i, a_j \\in \\{\\text{Stop}, \\text{Drive}\\}\\)\nInstitutions (stoplights installed by govt or community agreement): \\(a_i, a_j \\in \\{\\text{Obey Light}, \\text{Run Light}\\}\\)\n\nWithin assurance games, only need to nudge (one-time intervention) \\(\\leadsto\\) new equilibrium (self-enforcing by definition)",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#assurance-game",
    "href": "w10/index.html#assurance-game",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Assurance Game",
    "text": "Assurance Game\n\nMultiple equilibria; the particular outcome we observe is a function of history (path dependency)\nDrive-on-left vs. drive-on-right: Assurance game where neither equilibrium Pareto-dominates other option\n\nSwedish Dagen H: Nudge from \\(a^*_{\\textsf{L}} = (\\textsf{L},\\textsf{L})\\) to \\(a^*_{\\textsf{R}} = (\\textsf{R},\\textsf{R})\\)\nEither eq is self-reinforcing! (Unless you want to crash out)\n\n\n\n\n\nQWERTY vs. DVORAK / Palanpur farmers: Assurance game where observed equilibrium Pareto inferior\n\n\n\n\n\n\n\n\n\\(j\\)\n\n\n\n\nEarly\nLate\n\n\n\\(i\\)\nEarly\n\\(\\boxed{4},\\boxed{4}\\)\n\\(0, \\, 3\\)\n\n\nLate\n\\(3, \\, 0\\)\n\\(\\boxed{2},\\boxed{2}\\)",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#invisible-hand-game",
    "href": "w10/index.html#invisible-hand-game",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Invisible Hand Game",
    "text": "Invisible Hand Game\n\nSingle, unique Nash equilibrium, and it’s Pareto efficient\n\\(\\Rightarrow\\) Acting in self interest \\(\\leadsto\\) best possible outcome\n\n\n\n\nIt is not from the benevolence of the butcher, the brewer, or the baker that we expect our meal, but from their regard to their own interest (Smith 1776)\n\n\n\n\n\n\n\n\\(j\\)\n\n\n\n\nCorn\nTomato\n\n\n\\(i\\)\nCorn\n\\(2, \\, 4\\)\n\\(4, \\, 3\\)\n\n\nTomato\n\\(\\boxed{5}, \\boxed{5}\\)\n\\(3, \\, 2\\)\n\n\n\n\n\n\nWealth of Nations SPOILER: The wealth comes from division of laborand also dumbleydore dies. semperus snake too. and even poor ron the weasel, who never deserved such a fate\n\n\nAn economic transaction is a solved political problem. Economics has gained the title “Queen of the Social Sciences” by choosing solved political problems as its domain. (Lerner 1972)",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#first-fundamental-theorem-of-welfare-economics",
    "href": "w10/index.html#first-fundamental-theorem-of-welfare-economics",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "First Fundamental Theorem of Welfare Economics",
    "text": "First Fundamental Theorem of Welfare Economics\nThm: [Antecedents (Coase Conditions)] \\(\\Rightarrow\\) markets produce Pareto-optimal outcomes\n\nEven Jeff finds proof (and corollaries) compelling / convincing / empirically-supported\n\n(It’s a full-on proof, in the mathematical sense, so doesn’t rly matter what I think; I just mean, imo, important and helpful to think through for class on policy!)\nEx: Conditional on antecedents [(Coase) minus (perfect competition) plus (thing must be allocated via markets)], \\(\\uparrow\\) Competition \\(\\leadsto\\) More efficient allocations\n\nLike how Gauss-Markov Assumptions \\(\\Rightarrow\\) OLS is BLUE, yet our whole field (at least, a whole class, DSAN 5300) built on what to do when GM Assumptions don’t hold\nFor policy development, helpful to think through\n\n which cases “break” FFT (more honored in the breach)\n How each violation might be “fixed” through policy\n\nOur violation: No externalities assumption\n\nPossible policy “fixes”: property rights, market-socialist nationalization",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#part-2-suddenly-collides-with-part-1-property-rights",
    "href": "w10/index.html#part-2-suddenly-collides-with-part-1-property-rights",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Part 2 Suddenly Collides with Part 1: Property Rights",
    "text": "Part 2 Suddenly Collides with Part 1: Property Rights\n\nRawlsian Rights: Vetos on societal decisions; Constitution can make some inalienable (can’t sell self into slavery), some alienable\nProperty rights: alienable. You can gift or sell the rights if you want (veto is over society just, like, taking your property if someone else would be happier with it)\n\n\n\nCase : Society decides Right to Clean Air \\(\\prec\\) Right to Smoke \\(\\Rightarrow\\) Start at \\(E\\)\n\n\\(A\\) can pay \\(B\\) to alienate right (Pay $50/month, can smoke 5 ciggies) \\(\\leadsto\\) \\(X\\)\nMovement along light blue curve: giving up \\(x\\) money for \\(y\\) smoke, equally happy. \\(u_A(p)\\) identical for \\(p\\) on curve\nMovement to higher light blue curve () \\(\\Rightarrow\\) greater utility \\(u_A' &gt; u_A\\)\n\nCase  Society decides Smoke \\(\\prec\\) Clean Air \\(\\Rightarrow\\) Repeat for \\(E' \\leadsto X'\\)\n\n\n\n\n“Edgeworth Box” for Right to Smoke vs. Right to Clean Air: \\(A\\), \\(B\\) are roommates; \\(A\\) loves smokin, \\(B\\) loves clean air",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#externalities-leftrightarrow-costs-of-actions-paid-by-someone-else",
    "href": "w10/index.html#externalities-leftrightarrow-costs-of-actions-paid-by-someone-else",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Externalities \\(\\Leftrightarrow\\) Costs of Actions Paid by Someone Else!",
    "text": "Externalities \\(\\Leftrightarrow\\) Costs of Actions Paid by Someone Else!\n\nFirm \\(S\\) produces amount of steel \\(s\\), pollution \\(x\\)\nFirm \\(F\\) “produces” amount of fish \\(f\\)\n\\(S\\) optimizes\n\n\\[\ns^*_{\\text{Priv}}, x^*_{\\text{Priv}} = \\argmax_{s,x}\\left[ p_s s - c_s(s, x) \\right]\n\\]\n\nWhile \\(F\\) optimizes\n\n\\[\nf^*_{\\text{Priv}} = \\argmax_{f}\\left[ p_f f - c_f(f, x) \\right]\n\\]\n\nIf [Yugoslavia-style] nationalized, new optimization of joint steel-fish venture is\n\n\\[\ns^*_{\\text{Yugo}}, f^*_{\\text{Yugo}}, x^*_{\\text{Yugo}} = \\argmax_{s, f, x}\\left[ p_s s + p_f f - c_s(s, x) - c_f(f, x) \\right]\n\\]\n\nCan prove/“prove” that \\(o(s^*_{\\text{Yugo}}, f^*_{\\text{Yugo}}, x^*_{\\text{Yugo}})\\) Pareto-dominates \\(o(s^*_{\\text{Priv}}, x^*_{\\text{Priv}}, f^*_{\\text{Priv}})\\)",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#functionals",
    "href": "w10/index.html#functionals",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Functionals?",
    "text": "Functionals?\n\nYou probably know what a function \\(f(x)\\) is; a functional is a function of functions: \\(\\mathscr{G}(f)\\)\nIt’s from math, which is scary, but it’s just notation to remind us that we’re analyzing functions of functions\nIn our case, they “work the same way” as regular functions, e.g., \\(\\mathscr{G}(f,g) = f^2 + g^2\\), so \\(f(x) = x, g(x) = 2x \\Rightarrow \\mathscr{G}(f,g)(x) = x^2 + 4x^2 = 5x^2\\)",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#we-live-in-a-society-part-2",
    "href": "w10/index.html#we-live-in-a-society-part-2",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "We Live In A Society, Part 2",
    "text": "We Live In A Society, Part 2\n\nUtilitarianism, Kantian Ethics, and Rawls can all be modeled as Social Welfare Functionals\n\n\\[\nW(\\mathbf{u}) = W(u_1, \\ldots, u_n) \\Rightarrow W(\\mathbf{u})(x) = W(u_1(x), \\ldots, u_n(x))\n\\]\n\n\\(u_i(x)\\): Given bundle of resources \\(x\\), how much utility does \\(i\\) experience? \\(u_i: \\mathcal{X} \\rightarrow \\mathbb{R}\\)\n\\(W(\\mathbf{u})\\): Aggregates \\(u_i(x)\\) over all \\(i\\), to produce measure of overall welfare of society. \\(W: (\\mathcal{X} \\rightarrow \\mathbb{R})^N \\rightarrow \\mathbb{R}\\).\n\\(W(\\mathbf{u}) = \\sum_{i=1}^n \\omega_iu_i(x)\\). \\(\\omega_i\\) is \\(i\\)’s welfare weight\n(Preview) Decomposition: evaluate policies by estimating marginal utility \\(u'_i(x)\\) compared to \\(\\omega_i\\))",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#alternative-swf-specifications",
    "href": "w10/index.html#alternative-swf-specifications",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Alternative SWF Specifications",
    "text": "Alternative SWF Specifications\n\nSocial values\n\n\\[\nW(\\underbrace{v_1, \\ldots, v_n}_{\\text{Values}})(x) \\overset{\\text{e.g.}}{=} \\omega_1\\underbrace{v_1(x)}_{\\text{Privacy}} + \\omega_2\\underbrace{v_2(x)}_{\\mathclap{\\text{Public Health}}}\n\\]\n\nStakeholder Analysis\n\n\\[\nW(\\underbrace{s_1, \\ldots, s_n}_{\\text{Stakeholders}})(x) = \\omega_1\\underbrace{u_{s_1}(x)}_{\\text{Teachers}} + \\omega_2\\underbrace{u_{s_2}(x)}_{\\text{Parents}} + \\omega_3\\underbrace{u_{s_3}(x)}_{\\text{Students}} + \\omega_4\\underbrace{u_{s_4}(x)}_{\\mathclap{\\text{Community}}}\n\\]\n\n(Adapted from this great intro video!)",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#utilitarian-swf",
    "href": "w10/index.html#utilitarian-swf",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Utilitarian SWF",
    "text": "Utilitarian SWF\n\nEasy mode (possibly/probably your intuition?): Everyone’s welfare weight should be equal, \\(\\omega_i = \\frac{1}{n}\\)\n\n\\[\nW(u_1, \\ldots, u_n)(x) = \\frac{1}{n}u_1(x) + \\cdots + \\frac{1}{n}u_n(x)\n\\]\n\n\\(\\implies\\) Utilitarian Social Welfare Functional!\nThe Silly Problem of Utilitarian SWF: What if everyone is made happy by \\(u_{\\text{Jeef}} = -\\infty\\)?",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#the-hard-problem-of-utilitarian-swf",
    "href": "w10/index.html#the-hard-problem-of-utilitarian-swf",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "The Hard Problem of Utilitarian SWF",
    "text": "The Hard Problem of Utilitarian SWF\n\nWhile the rhetoric of “all men [sic] are born equal” is typically taken to be part and parcel of egalitarianism, the effect of ignoring the interpersonal variations can, in fact, be deeply inegalitarian, in hiding the fact that equal consideration for all may demand very unequal treatment in favour of the disadvantaged (Sen 1992)\n\n\n\\(\\implies\\) “Equality of What?”\nWhat is the “thing” that egalitarianism obligates us to equalize (the equilisandum/equilisanda): Utility? Opportunity? Resources? Money? Freedom?",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#we-can-finally-understand-this-image-from-week-1",
    "href": "w10/index.html#we-can-finally-understand-this-image-from-week-1",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "We Can Finally Understand This Image from Week 1!",
    "text": "We Can Finally Understand This Image from Week 1!",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/index.html#references",
    "href": "w10/index.html#references",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "References",
    "text": "References\n\n\nBerlin, Isaiah. 1959. Two Concepts of Liberty: An Inaugural Lecture Delivered Before the University of Oxford on 31 October 1958. Clarendon Press.\n\n\nDouglass, Frederick. 1855. My Bondage and My Freedom. Yale University Press.\n\n\nIbsen, Henrik. 1879. The Doll’s House: A Play. D. Appleton & Company.\n\n\nJacobs, Jeff, and Suresh Naidu. 2025. “Operationalizing Freedom as Non-Domination in the Labor Market.” In Perspectives on Labor Republicanism, edited by Philip Pettit. Cambridge: Cambridge University Press.\n\n\nLerner, Abba P. 1972. “The Economics and Politics of Consumer Sovereignty.” The American Economic Review 62 (1/2): 258–66. https://www.jstor.org/stable/1821551.\n\n\nLovett, Frank. 2022. The Well-Ordered Republic. Oxford University Press.\n\n\nPettit, Philip. 1997. Republicanism: A Theory of Freedom and Government. Oxford University Press.\n\n\nSen, Amartya. 1992. Inequality Reexamined. Clarendon Press.\n\n\nSkinner, Quentin. 1998. Liberty Before Liberalism. Cambridge University Press.\n\n\nSmith, Adam. 1776. The Wealth of Nations. Random House Publishing Group.\n\n\nThucydides. 2013. The War of the Peloponnesians and the Athenians. Cambridge University Press.",
    "crumbs": [
      "Week 10: {{< var w10.date-md >}}"
    ]
  },
  {
    "objectID": "w10/slides.html#thucydides-and-the-kindly-slavemaster",
    "href": "w10/slides.html#thucydides-and-the-kindly-slavemaster",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Thucydides and the Kindly Slavemaster",
    "text": "Thucydides and the Kindly Slavemaster\n\n\n[What is] right, as the world goes, is only in question between equals in power; otherwise, the strong do as they please and the weak suffer what they must. (Thucydides 2013 c. 411 BC) (Think of necessary vs. sufficient conditions!)\n\n\n\n\n\nliberalism\nrepublicanism\n\n\n\n\n\nDefinition of Injustice\nStrong do bad things (Berlin 1959)\nStrong can do bad things (Skinner 1998; Pettit 1997; Lovett 2022)\n\n\n\nThucydides Question\nStrong do as they please \\(\\overset{?}{\\Rightarrow}\\) Strong do bad things\nStrong do as they please \\(\\overset{?}{\\Rightarrow}\\) Strong can do bad things\n\n\n\nAnswer\nNo, not necessarily!\nYes, necessarily!\n\n\n\nFrederick Douglass\nMy feelings [towards slave masters] were not the result of any marked cruelty in the treatment I received…\n…they sprung from the consideration of my being a slave in the first place. It was slavery—not its mere incidents—that I despised. (Douglass 1855)\n\n\n\nA Doll’s House\nOur home is nothing but a playroom. I have been your doll-wife, just as at home I was papa’s doll-child; and here the children have been my dolls. (Ibsen 1879)\n\n\n\n\n\n(Plz notice the lowercase “l”, lowercase “r”!)"
  },
  {
    "objectID": "w10/slides.html#relevance-for-this-week-where-we-left-off",
    "href": "w10/slides.html#relevance-for-this-week-where-we-left-off",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Relevance for This Week (Where We Left Off)",
    "text": "Relevance for This Week (Where We Left Off)\n\nCan we develop policy interventions that equalize power, so that world looks like normative ethics from W03-W08 (“what is right”)?\n(Hidden antecedent: non-Nietzschean ethical framework e.g. Utilitarianism/Kant)\nPoint of prev slide: From now til W14, keep in mind how definition of power (and hence “effectiveness” of policy intervention) depends on antecedent\n\nliberal definition \\(\\Rightarrow\\) focus on equilibria (no injustice if bad thing doesn’t happen in equilibrium)\nrepublican definition \\(\\Rightarrow\\) also take off-equilibrium possibilities into account (no injustice if bad thing doesn’t happen in equilibrium and doesn’t happen if one player deviates “on a whim”) (Jacobs and Naidu 2025 😉)\n\nPrisoners’ Dilemma 😫 \\(\\prec\\) Assurance Game 🤨 \\(\\prec\\) Invisible Hand Game 🥳"
  },
  {
    "objectID": "w10/slides.html#prisoners-dilemma-fishers-dilemma",
    "href": "w10/slides.html#prisoners-dilemma-fishers-dilemma",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Prisoners’ Dilemma (Fishers’ Dilemma)",
    "text": "Prisoners’ Dilemma (Fishers’ Dilemma)\n\nSingle, unique Nash equilibrium, and it’s Pareto inferior\n\n\n\n\nThe Game\n\n\n\n\n\n\n\\(j\\)\n\n\n\n\nFish 6 Hours\nFish 8 Hours\n\n\n\\(i\\)\nFish 6 Hours\n\\(1.0,1.0\\)\n\\(0.0,\\boxed{1.2}\\)\n\n\nFish 8 Hours\n\\(\\boxed{1.2}, 0.0\\)\n\\(\\boxed{0.4},\\boxed{0.4}\\)\n\n\n\n\nBoxes = Best Responses:\n\\(\\text{BR}_i(6\\textrm{ hr}) = 8\\textrm{ hr}\\), \\(\\text{BR}_i(8\\textrm{ hr}) = 8\\textrm{ hr}\\)\n\\(\\text{BR}_j(6\\textrm{ hr}) = 8\\textrm{ hr}\\), \\(\\text{BR}_j(8\\textrm{ hr}) = 8\\textrm{ hr}\\)\n\n\n\nPareto Dominance"
  },
  {
    "objectID": "w10/slides.html#operationalizing-power",
    "href": "w10/slides.html#operationalizing-power",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Operationalizing Power",
    "text": "Operationalizing Power\n\nEqually good outside options \\(\\implies\\) can contract to Pareto-optimal point \\(o^P\\)\n\\(i\\) has better outside options \\(\\implies\\) can make take it or leave it offer to \\(j\\):\n\n“You (\\(j\\)) fish 6 hrs all the time. I (\\(i\\)) fish 6 hrs 41% of time, 8 hrs otherwise”\n\n\n\n\n\nEver so slightly better for \\(j\\) \\(\\implies\\) \\(j\\) accepts (Behavioral econ: \\(j\\) accepts if 41% meets subjective fairness threshold; observed across many many cultures!)\nLater / next week: observe policy with outcome \\(o^{C}_{i \\rightarrow j} \\iff\\) policy values \\(i\\)’s welfare more than \\(j\\)’s welfare (inferred social welfare weights \\(\\omega_i &gt; \\omega_j\\))"
  },
  {
    "objectID": "w10/slides.html#policy-interventions-fish-dilemmas-mapsto-assurance-games",
    "href": "w10/slides.html#policy-interventions-fish-dilemmas-mapsto-assurance-games",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Policy Interventions: Fish Dilemmas \\(\\mapsto\\) Assurance Games",
    "text": "Policy Interventions: Fish Dilemmas \\(\\mapsto\\) Assurance Games\n\nNotice: To “escape” prisoners’ dilemma, we had to literally change the rules of the game (permanent intervention)\nFishers’ Dilemma:\n\nNo institutions: \\(a_i, a_j \\in \\{6\\text{ hr}, 8\\text{ hr}\\}\\)\nInstitutions (courts or social norms): \\(\\{\\text{Accept}, \\text{Reject}\\}\\)\n\nDriving “game”:\n\nNo institutions: \\(a_i, a_j \\in \\{\\text{Stop}, \\text{Drive}\\}\\)\nInstitutions (stoplights installed by govt or community agreement): \\(a_i, a_j \\in \\{\\text{Obey Light}, \\text{Run Light}\\}\\)\n\nWithin assurance games, only need to nudge (one-time intervention) \\(\\leadsto\\) new equilibrium (self-enforcing by definition)"
  },
  {
    "objectID": "w10/slides.html#assurance-game",
    "href": "w10/slides.html#assurance-game",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Assurance Game",
    "text": "Assurance Game\n\nMultiple equilibria; the particular outcome we observe is a function of history (path dependency)\nDrive-on-left vs. drive-on-right: Assurance game where neither equilibrium Pareto-dominates other option\n\nSwedish Dagen H: Nudge from \\(a^*_{\\textsf{L}} = (\\textsf{L},\\textsf{L})\\) to \\(a^*_{\\textsf{R}} = (\\textsf{R},\\textsf{R})\\)\nEither eq is self-reinforcing! (Unless you want to crash out)\n\n\n\n\n\nQWERTY vs. DVORAK / Palanpur farmers: Assurance game where observed equilibrium Pareto inferior\n\n\n\n\n\n\n\n\n\\(j\\)\n\n\n\n\nEarly\nLate\n\n\n\\(i\\)\nEarly\n\\(\\boxed{4},\\boxed{4}\\)\n\\(0, \\, 3\\)\n\n\nLate\n\\(3, \\, 0\\)\n\\(\\boxed{2},\\boxed{2}\\)"
  },
  {
    "objectID": "w10/slides.html#invisible-hand-game",
    "href": "w10/slides.html#invisible-hand-game",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Invisible Hand Game",
    "text": "Invisible Hand Game\n\nSingle, unique Nash equilibrium, and it’s Pareto efficient\n\\(\\Rightarrow\\) Acting in self interest \\(\\leadsto\\) best possible outcome\n\n\n\n\nIt is not from the benevolence of the butcher, the brewer, or the baker that we expect our meal, but from their regard to their own interest (Smith 1776)\n\n\n\n\n\n\n\n\\(j\\)\n\n\n\n\nCorn\nTomato\n\n\n\\(i\\)\nCorn\n\\(2, \\, 4\\)\n\\(4, \\, 3\\)\n\n\nTomato\n\\(\\boxed{5}, \\boxed{5}\\)\n\\(3, \\, 2\\)\n\n\n\n\n\nWealth of Nations SPOILER: The wealth comes from division of laborand also dumbleydore dies. semperus snake too. and even poor ron the weasel, who never deserved such a fate\n\n\nAn economic transaction is a solved political problem. Economics has gained the title “Queen of the Social Sciences” by choosing solved political problems as its domain. (Lerner 1972)"
  },
  {
    "objectID": "w10/slides.html#first-fundamental-theorem-of-welfare-economics",
    "href": "w10/slides.html#first-fundamental-theorem-of-welfare-economics",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "First Fundamental Theorem of Welfare Economics",
    "text": "First Fundamental Theorem of Welfare Economics\nThm: [Antecedents (Coase Conditions)] \\(\\Rightarrow\\) markets produce Pareto-optimal outcomes\n\nEven Jeff finds proof (and corollaries) compelling / convincing / empirically-supported\n\n(It’s a full-on proof, in the mathematical sense, so doesn’t rly matter what I think; I just mean, imo, important and helpful to think through for class on policy!)\nEx: Conditional on antecedents [(Coase) minus (perfect competition) plus (thing must be allocated via markets)], \\(\\uparrow\\) Competition \\(\\leadsto\\) More efficient allocations\n\nLike how Gauss-Markov Assumptions \\(\\Rightarrow\\) OLS is BLUE, yet our whole field (at least, a whole class, DSAN 5300) built on what to do when GM Assumptions don’t hold\nFor policy development, helpful to think through\n\n which cases “break” FFT (more honored in the breach)\n How each violation might be “fixed” through policy\n\nOur violation: No externalities assumption\n\nPossible policy “fixes”: property rights, market-socialist nationalization"
  },
  {
    "objectID": "w10/slides.html#part-2-suddenly-collides-with-part-1-property-rights",
    "href": "w10/slides.html#part-2-suddenly-collides-with-part-1-property-rights",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Part 2 Suddenly Collides with Part 1: Property Rights",
    "text": "Part 2 Suddenly Collides with Part 1: Property Rights\n\nRawlsian Rights: Vetos on societal decisions; Constitution can make some inalienable (can’t sell self into slavery), some alienable\nProperty rights: alienable. You can gift or sell the rights if you want (veto is over society just, like, taking your property if someone else would be happier with it)\n\n\n\nCase : Society decides Right to Clean Air \\(\\prec\\) Right to Smoke \\(\\Rightarrow\\) Start at \\(E\\)\n\n\\(A\\) can pay \\(B\\) to alienate right (Pay $50/month, can smoke 5 ciggies) \\(\\leadsto\\) \\(X\\)\nMovement along light blue curve: giving up \\(x\\) money for \\(y\\) smoke, equally happy. \\(u_A(p)\\) identical for \\(p\\) on curve\nMovement to higher light blue curve () \\(\\Rightarrow\\) greater utility \\(u_A' &gt; u_A\\)\n\nCase  Society decides Smoke \\(\\prec\\) Clean Air \\(\\Rightarrow\\) Repeat for \\(E' \\leadsto X'\\)\n\n\n\n\n“Edgeworth Box” for Right to Smoke vs. Right to Clean Air: \\(A\\), \\(B\\) are roommates; \\(A\\) loves smokin, \\(B\\) loves clean air"
  },
  {
    "objectID": "w10/slides.html#externalities-leftrightarrow-costs-of-actions-paid-by-someone-else",
    "href": "w10/slides.html#externalities-leftrightarrow-costs-of-actions-paid-by-someone-else",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Externalities \\(\\Leftrightarrow\\) Costs of Actions Paid by Someone Else!",
    "text": "Externalities \\(\\Leftrightarrow\\) Costs of Actions Paid by Someone Else!\n\nFirm \\(S\\) produces amount of steel \\(s\\), pollution \\(x\\)\nFirm \\(F\\) “produces” amount of fish \\(f\\)\n\\(S\\) optimizes\n\n\\[\ns^*_{\\text{Priv}}, x^*_{\\text{Priv}} = \\argmax_{s,x}\\left[ p_s s - c_s(s, x) \\right]\n\\]\n\nWhile \\(F\\) optimizes\n\n\\[\nf^*_{\\text{Priv}} = \\argmax_{f}\\left[ p_f f - c_f(f, x) \\right]\n\\]\n\nIf [Yugoslavia-style] nationalized, new optimization of joint steel-fish venture is\n\n\\[\ns^*_{\\text{Yugo}}, f^*_{\\text{Yugo}}, x^*_{\\text{Yugo}} = \\argmax_{s, f, x}\\left[ p_s s + p_f f - c_s(s, x) - c_f(f, x) \\right]\n\\]\n\nCan prove/“prove” that \\(o(s^*_{\\text{Yugo}}, f^*_{\\text{Yugo}}, x^*_{\\text{Yugo}})\\) Pareto-dominates \\(o(s^*_{\\text{Priv}}, x^*_{\\text{Priv}}, f^*_{\\text{Priv}})\\)"
  },
  {
    "objectID": "w10/slides.html#functionals",
    "href": "w10/slides.html#functionals",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Functionals?",
    "text": "Functionals?\n\nYou probably know what a function \\(f(x)\\) is; a functional is a function of functions: \\(\\mathscr{G}(f)\\)\nIt’s from math, which is scary, but it’s just notation to remind us that we’re analyzing functions of functions\nIn our case, they “work the same way” as regular functions, e.g., \\(\\mathscr{G}(f,g) = f^2 + g^2\\), so \\(f(x) = x, g(x) = 2x \\Rightarrow \\mathscr{G}(f,g)(x) = x^2 + 4x^2 = 5x^2\\)"
  },
  {
    "objectID": "w10/slides.html#we-live-in-a-society-part-2",
    "href": "w10/slides.html#we-live-in-a-society-part-2",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "We Live In A Society, Part 2",
    "text": "We Live In A Society, Part 2\n\nUtilitarianism, Kantian Ethics, and Rawls can all be modeled as Social Welfare Functionals\n\n\\[\nW(\\mathbf{u}) = W(u_1, \\ldots, u_n) \\Rightarrow W(\\mathbf{u})(x) = W(u_1(x), \\ldots, u_n(x))\n\\]\n\n\\(u_i(x)\\): Given bundle of resources \\(x\\), how much utility does \\(i\\) experience? \\(u_i: \\mathcal{X} \\rightarrow \\mathbb{R}\\)\n\\(W(\\mathbf{u})\\): Aggregates \\(u_i(x)\\) over all \\(i\\), to produce measure of overall welfare of society. \\(W: (\\mathcal{X} \\rightarrow \\mathbb{R})^N \\rightarrow \\mathbb{R}\\).\n\\(W(\\mathbf{u}) = \\sum_{i=1}^n \\omega_iu_i(x)\\). \\(\\omega_i\\) is \\(i\\)’s welfare weight\n(Preview) Decomposition: evaluate policies by estimating marginal utility \\(u'_i(x)\\) compared to \\(\\omega_i\\))"
  },
  {
    "objectID": "w10/slides.html#alternative-swf-specifications",
    "href": "w10/slides.html#alternative-swf-specifications",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Alternative SWF Specifications",
    "text": "Alternative SWF Specifications\n\nSocial values\n\n\\[\nW(\\underbrace{v_1, \\ldots, v_n}_{\\text{Values}})(x) \\overset{\\text{e.g.}}{=} \\omega_1\\underbrace{v_1(x)}_{\\text{Privacy}} + \\omega_2\\underbrace{v_2(x)}_{\\mathclap{\\text{Public Health}}}\n\\]\n\nStakeholder Analysis\n\n\\[\nW(\\underbrace{s_1, \\ldots, s_n}_{\\text{Stakeholders}})(x) = \\omega_1\\underbrace{u_{s_1}(x)}_{\\text{Teachers}} + \\omega_2\\underbrace{u_{s_2}(x)}_{\\text{Parents}} + \\omega_3\\underbrace{u_{s_3}(x)}_{\\text{Students}} + \\omega_4\\underbrace{u_{s_4}(x)}_{\\mathclap{\\text{Community}}}\n\\]\n\n(Adapted from this great intro video!)"
  },
  {
    "objectID": "w10/slides.html#utilitarian-swf",
    "href": "w10/slides.html#utilitarian-swf",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "Utilitarian SWF",
    "text": "Utilitarian SWF\n\nEasy mode (possibly/probably your intuition?): Everyone’s welfare weight should be equal, \\(\\omega_i = \\frac{1}{n}\\)\n\n\\[\nW(u_1, \\ldots, u_n)(x) = \\frac{1}{n}u_1(x) + \\cdots + \\frac{1}{n}u_n(x)\n\\]\n\n\\(\\implies\\) Utilitarian Social Welfare Functional!\nThe Silly Problem of Utilitarian SWF: What if everyone is made happy by \\(u_{\\text{Jeef}} = -\\infty\\)?"
  },
  {
    "objectID": "w10/slides.html#the-hard-problem-of-utilitarian-swf",
    "href": "w10/slides.html#the-hard-problem-of-utilitarian-swf",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "The Hard Problem of Utilitarian SWF",
    "text": "The Hard Problem of Utilitarian SWF\n\nWhile the rhetoric of “all men [sic] are born equal” is typically taken to be part and parcel of egalitarianism, the effect of ignoring the interpersonal variations can, in fact, be deeply inegalitarian, in hiding the fact that equal consideration for all may demand very unequal treatment in favour of the disadvantaged (Sen 1992)\n\n\n\\(\\implies\\) “Equality of What?”\nWhat is the “thing” that egalitarianism obligates us to equalize (the equilisandum/equilisanda): Utility? Opportunity? Resources? Money? Freedom?"
  },
  {
    "objectID": "w10/slides.html#we-can-finally-understand-this-image-from-week-1",
    "href": "w10/slides.html#we-can-finally-understand-this-image-from-week-1",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "We Can Finally Understand This Image from Week 1!",
    "text": "We Can Finally Understand This Image from Week 1!"
  },
  {
    "objectID": "w10/slides.html#references",
    "href": "w10/slides.html#references",
    "title": "Week 10: Welfare Economics and Policy Evaluation",
    "section": "References",
    "text": "References\n\n\nBerlin, Isaiah. 1959. Two Concepts of Liberty: An Inaugural Lecture Delivered Before the University of Oxford on 31 October 1958. Clarendon Press.\n\n\nDouglass, Frederick. 1855. My Bondage and My Freedom. Yale University Press.\n\n\nIbsen, Henrik. 1879. The Doll’s House: A Play. D. Appleton & Company.\n\n\nJacobs, Jeff, and Suresh Naidu. 2025. “Operationalizing Freedom as Non-Domination in the Labor Market.” In Perspectives on Labor Republicanism, edited by Philip Pettit. Cambridge: Cambridge University Press.\n\n\nLerner, Abba P. 1972. “The Economics and Politics of Consumer Sovereignty.” The American Economic Review 62 (1/2): 258–66. https://www.jstor.org/stable/1821551.\n\n\nLovett, Frank. 2022. The Well-Ordered Republic. Oxford University Press.\n\n\nPettit, Philip. 1997. Republicanism: A Theory of Freedom and Government. Oxford University Press.\n\n\nSen, Amartya. 1992. Inequality Reexamined. Clarendon Press.\n\n\nSkinner, Quentin. 1998. Liberty Before Liberalism. Cambridge University Press.\n\n\nSmith, Adam. 1776. The Wealth of Nations. Random House Publishing Group.\n\n\nThucydides. 2013. The War of the Peloponnesians and the Athenians. Cambridge University Press."
  },
  {
    "objectID": "w07/index.html",
    "href": "w07/index.html",
    "title": "Week 7: In-Class Midterm",
    "section": "",
    "text": "The midterm will be posted on Google Classroom",
    "crumbs": [
      "Week 7: {{< var w07.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html",
    "href": "w09/index.html",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#final-project-tings",
    "href": "w09/index.html#final-project-tings",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Final Project Tings",
    "text": "Final Project Tings",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#project-management-tings",
    "href": "w09/index.html#project-management-tings",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Project Management Tings",
    "text": "Project Management Tings\n\n\n\nTing\nPros\nCons\nVerdict\n\n\n\n\nTasksBoard\nIntegrated with Google Workspace (@georgetown.edu emails)\nFree version useless (no share)\n❌\n\n\nJira\nMaybe most popular?\n30-day free trial\n❌\n\n\nTrello\nSimpler than Jira (both owned by Atlassian)\n14-day free trial\n❌\n\n\nAirtable\nJeff uses this every day\n.edu plan doesn’t include free users\n❌\n\n\nNotion\nJeff uses this v often, .edu plan has hackish way to include users for free\nForce yall to sign up for new ting\n✅\n\n\n\n\n👉 Notion: Example 5450 Project 👈",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#recap-0-descriptive-vs.-normative",
    "href": "w09/index.html#recap-0-descriptive-vs.-normative",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Recap 0: Descriptive vs. Normative",
    "text": "Recap 0: Descriptive vs. Normative\n\nMuch of Part 1 has been adjusting to weirdness of normative reasoning\nDescriptive reasoning looks like [Rules of math \\(\\implies \\theta^* = 2.5\\)], but [rules of math] part isn’t mentioned bc extraneous\n\n(Even if it was mentioned, intersubjective agreement not so hard, very few people fighting wars over “we should denote repeated addition with \\(\\otimes\\) not \\(\\times\\)!”)\n\nNormative reasoning looks like [Antecedent A \\(\\implies\\) Answer 1 but Antecedent B \\(\\implies\\) Answer 2], and people do fight wars over A vs. B (implicitly or explicitly)\nPart 2: Rapid cycling back and forth between normative and descriptive!\nOne new aspect: “Descriptive Ethics” (How do people act, not how should people act) \\(\\leadsto\\) Study of Power\n\n[What is] right, as the world goes, is only in question between equals in power; otherwise, the strong do as they please and the weak suffer what they must. (Thucydides 2013 c. 411 BC)",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#recap-1-privacy-policies-take-a-long-time-to-read",
    "href": "w09/index.html#recap-1-privacy-policies-take-a-long-time-to-read",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Recap 1: Privacy Policies Take a Long Time to Read!",
    "text": "Recap 1: Privacy Policies Take a Long Time to Read!",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#recap-2-reading-privacy-policies-neq-understanding-privacy-policies",
    "href": "w09/index.html#recap-2-reading-privacy-policies-neq-understanding-privacy-policies",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Recap 2: Reading Privacy Policies \\(\\neq\\) Understanding Privacy Policies!",
    "text": "Recap 2: Reading Privacy Policies \\(\\neq\\) Understanding Privacy Policies!\n\nReading vs. understanding implications / contingencies / ambiguities…\nNLP could (and should!) be helpful (“making privacy policies machine readable […] would help users match privacy preferences against policies offered by web services”), but mostly just reveals how bad the problem is:\n\n\n\n\nFigure 15 from Wagner (2023). “Obfuscatory words” are words like acceptable, significant, mainly, or predominantly, interpretated at the discretion of companies rather than users (see next slide!)",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#the-adversarial-sisyphusian-problem-of-contracts",
    "href": "w09/index.html#the-adversarial-sisyphusian-problem-of-contracts",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "The Adversarial-Sisyphusian Problem of Contracts",
    "text": "The Adversarial-Sisyphusian Problem of Contracts\n\nRecall Intuitive Problem of Causal Inference: Correlation \\(\\nimplies\\) Causation, but can do a bunch of work to overcome\nAdversarial-Sisyphusian Problem is one level worse 😱\n\nIPCI: You vs. discovered correlation (inanimate)\nASPC: You vs. companies investing resources 💰 into making the problem harder and harder for you\n\nThe moment you (\\(N=1\\), $) finally find and “fix” bad thing, company (\\(N \\gg 1\\), $$$) adds more ambiguity to re-enable / sends your data to “new” 3rd-party processor 🥸\nAnalogy would be: someone making causal chains longer and longer as you’re checking causality (map of dancing landscape)",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#no-logo-why-johnny-cant-dissent",
    "href": "w09/index.html#no-logo-why-johnny-cant-dissent",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "No Logo / Why Johnny Can’t Dissent",
    "text": "No Logo / Why Johnny Can’t Dissent\n\nNaomi Klein’s No Logo (1999) sparked a nationwide boycott of companies employing sweatshop labor\nGreat success; all companies responded and (out of the kindness of their hearts) cut ties with all of the sweatshops\nInstead, they established ties with supply chain management companies, who made the profit-maximizing decision to re-establish ties with all of the sweatshops\n\n\n“You can’t outrun them, or even stay ahead of them for very long: it’s their racetrack, and that’s them waiting at the finish line to congratulate you” (Frank 1994)",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#conclusion",
    "href": "w09/index.html#conclusion",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Conclusion",
    "text": "Conclusion",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#real-conclusion",
    "href": "w09/index.html#real-conclusion",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Real Conclusion(?)",
    "text": "Real Conclusion(?)",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#wars-with-one-side",
    "href": "w09/index.html#wars-with-one-side",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Wars with One Side",
    "text": "Wars with One Side\n\n\n\nIt would be ideal except for the Porto Ricans [sic]. They are beyond doubt the dirtiest, laziest, most degenerate and thievish race of men ever inhabiting this sphere. It makes you sick to inhabit the same island with them. They are even lower than Italians. What the island needs is not public health work but a tidal wave or something to totally exterminate the population. It might then be livable. I have done my best to further the process of extermination by killing off 8 and transplanting cancer into several more. (Cornelius Rhoads)\n\n\nBy 1930, the police had files on at least 135,000 individuals (about 3 percent of the island) suspected of favoring independence. (Source)",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#wars-with-one-side-1",
    "href": "w09/index.html#wars-with-one-side-1",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Wars with One Side?",
    "text": "Wars with One Side?\n\n\n\nGeorgetown Law School Center on Privacy and Technology, American Dragnet: Data-Driven Deportation in the 21st Century",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#the-fundamental-problem-of-contracts",
    "href": "w09/index.html#the-fundamental-problem-of-contracts",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "The Fundamental Problem of Contracts",
    "text": "The Fundamental Problem of Contracts\n\nJust as we can’t observe two simultaneous worlds \\(W_{X = 0}\\) and \\(W_{X = 1}\\) which differ only in the value of \\(X\\),\nWe can’t foresee all possible contingencies that need to be included in a contract\n\n(We can try, though! Hence use of obfuscatory words to minimize liability)\n\nSo, when a situation arises which is not covered by a clause in the contract, what happens? What principle determines whose interpretation wins out?\n\n(Hint: It is actually literally my legal middle name…)",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#power",
    "href": "w09/index.html#power",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "…POWER!",
    "text": "…POWER!\n\nExamples from employment contracts (tooting own horn):\nIn a private, cooperatively-owned, democratic firm, outcome determined by conversation, majority vote, unanimity, etc.\n\nThese technically exist in the US! Employing 2,380 workers, \\(\\frac{2380}{127509000} \\approx 0.0019\\%\\) of US workforce\n\nOtherwise, in a non-unionized private firm (94% of total), the outcome is determined by organizational hierarchy\n\nThis is the case for \\(\\frac{125000000}{127509000} \\approx 98.03\\%\\) of US workforce",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#descriptive-and-normative-considerations",
    "href": "w09/index.html#descriptive-and-normative-considerations",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Descriptive and Normative Considerations",
    "text": "Descriptive and Normative Considerations\n\nThe combined effect of incomplete contracts and conflicts of interest is that the determination of outcomes depends on who exercises power in the transaction.\nPower is generally exercised by those who hold the residual rights of control, meaning the right to determine what is not specified contractually (Bowles 2009)\n\n\n[Step 1: Empirically measurable given antecedents] Who has power w.r.t. a given incomplete contract?\n[Step 2: Up to you and your ethical axioms; e.g., efficiency] Who ought to have power w.r.t. incomplete contracts?",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#working-definition-of-power",
    "href": "w09/index.html#working-definition-of-power",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Working Definition of Power",
    "text": "Working Definition of Power\n\n\n\n\n\n\n\n Defining (Dyadic) Power (Bowles and Gintis 1992, 326–27)\n\n\n\nFor agent \\(A\\) to have power over agent \\(B\\) it is sufficient that, by imposing or threatening to impose sanctions on \\(B\\), \\(A\\) is capable of affecting \\(B\\)’s actions in ways that further \\(A\\)’s interests, while \\(B\\) lacks this capacity with respect to \\(A\\).",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#prisoners-dilemma",
    "href": "w09/index.html#prisoners-dilemma",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Prisoners’ Dilemma",
    "text": "Prisoners’ Dilemma\n\n\n\n\n\n\\(B\\)\n\n\n\n\nSilent\nSnitch\n\n\n\\(A\\)\nSilent\n\\(-1,-1\\)\n\\(-3,\\phantom{-}0\\)\n\n\nSnitch\n\\(\\phantom{-}0, -3\\)\n\\(-10,-10\\)",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#assurance-game",
    "href": "w09/index.html#assurance-game",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Assurance Game",
    "text": "Assurance Game\nPalanpur, Gujarat, India\n\nThe farmers do not doubt that earlier planting would give them larger harvests, but no one, the farmer explained, is willing to be the first to plant, as the seeds on any lone plot would be quickly eaten by birds…\n[What if you all organized to plant on the same day, to reap rewards of earlier planting while minimizing bird losses (dividing by \\(N\\) instead of \\(1\\))?]\n“If we knew how to do that”, he said, looking up from his hoe at me, “we would not be poor.” (Bowles 2009)",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#assurance-game-in-normal-form",
    "href": "w09/index.html#assurance-game-in-normal-form",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Assurance Game in Normal Form",
    "text": "Assurance Game in Normal Form\n\n\n\n\n\n\\(B\\)\n\n\n\n\nEarly\nLate\n\n\n\\(A\\)\nEarly\n\\(4, 4\\)\n\\(0, 3\\)\n\n\nLate\n\\(3, 0\\)\n\\(2, 2\\)",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#invisible-hand-game-normal-form",
    "href": "w09/index.html#invisible-hand-game-normal-form",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Invisible Hand Game (Normal Form)",
    "text": "Invisible Hand Game (Normal Form)\n\n\n\n\n\n\\(B\\)\n\n\n\n\nCorn\nTomatoes\n\n\n\\(A\\)\nCorn\n\\(2, 4\\)\n\\(4, 3\\)\n\n\nTomatoes\n\\(5, 5\\)\n\\(3, 2\\)",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/index.html#references",
    "href": "w09/index.html#references",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "References",
    "text": "References\n\n\nBowles, Samuel. 2009. Microeconomics: Behavior, Institutions, and Evolution. Princeton University Press.\n\n\nBowles, Samuel, and Herbert Gintis. 1992. “Power and Wealth in a Competitive Capitalist Economy.” Philosophy & Public Affairs 21 (4): 324–53. https://www.jstor.org/stable/2265369.\n\n\nFrank, Tom. 1994. “DARK AGE: Why Johnny Can’t Dissent.” The Baffler, no. 6: 5–192. https://www.jstor.org/stable/43555671.\n\n\nThucydides. 2013. The War of the Peloponnesians and the Athenians. Cambridge University Press.\n\n\nWagner, Isabel. 2023. “Privacy Policies Across the Ages: Content of Privacy Policies 1996–2021.” ACM Transactions on Privacy and Security 26 (3): 32:1–32. https://doi.org/10.1145/3590152.",
    "crumbs": [
      "Week 9: {{< var w09.date-md >}}"
    ]
  },
  {
    "objectID": "w09/slides.html#final-project-tings",
    "href": "w09/slides.html#final-project-tings",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Final Project Tings",
    "text": "Final Project Tings"
  },
  {
    "objectID": "w09/slides.html#project-management-tings",
    "href": "w09/slides.html#project-management-tings",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Project Management Tings",
    "text": "Project Management Tings\n\n\n\nTing\nPros\nCons\nVerdict\n\n\n\n\nTasksBoard\nIntegrated with Google Workspace (@georgetown.edu emails)\nFree version useless (no share)\n❌\n\n\nJira\nMaybe most popular?\n30-day free trial\n❌\n\n\nTrello\nSimpler than Jira (both owned by Atlassian)\n14-day free trial\n❌\n\n\nAirtable\nJeff uses this every day\n.edu plan doesn’t include free users\n❌\n\n\nNotion\nJeff uses this v often, .edu plan has hackish way to include users for free\nForce yall to sign up for new ting\n✅\n\n\n\n\n👉 Notion: Example 5450 Project 👈"
  },
  {
    "objectID": "w09/slides.html#recap-0-descriptive-vs.-normative",
    "href": "w09/slides.html#recap-0-descriptive-vs.-normative",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Recap 0: Descriptive vs. Normative",
    "text": "Recap 0: Descriptive vs. Normative\n\nMuch of Part 1 has been adjusting to weirdness of normative reasoning\nDescriptive reasoning looks like [Rules of math \\(\\implies \\theta^* = 2.5\\)], but [rules of math] part isn’t mentioned bc extraneous\n\n(Even if it was mentioned, intersubjective agreement not so hard, very few people fighting wars over “we should denote repeated addition with \\(\\otimes\\) not \\(\\times\\)!”)\n\nNormative reasoning looks like [Antecedent A \\(\\implies\\) Answer 1 but Antecedent B \\(\\implies\\) Answer 2], and people do fight wars over A vs. B (implicitly or explicitly)\nPart 2: Rapid cycling back and forth between normative and descriptive!\nOne new aspect: “Descriptive Ethics” (How do people act, not how should people act) \\(\\leadsto\\) Study of Power\n\n[What is] right, as the world goes, is only in question between equals in power; otherwise, the strong do as they please and the weak suffer what they must. (Thucydides 2013 c. 411 BC)"
  },
  {
    "objectID": "w09/slides.html#recap-1-privacy-policies-take-a-long-time-to-read",
    "href": "w09/slides.html#recap-1-privacy-policies-take-a-long-time-to-read",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Recap 1: Privacy Policies Take a Long Time to Read!",
    "text": "Recap 1: Privacy Policies Take a Long Time to Read!"
  },
  {
    "objectID": "w09/slides.html#recap-2-reading-privacy-policies-neq-understanding-privacy-policies",
    "href": "w09/slides.html#recap-2-reading-privacy-policies-neq-understanding-privacy-policies",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Recap 2: Reading Privacy Policies \\(\\neq\\) Understanding Privacy Policies!",
    "text": "Recap 2: Reading Privacy Policies \\(\\neq\\) Understanding Privacy Policies!\n\nReading vs. understanding implications / contingencies / ambiguities…\nNLP could (and should!) be helpful (“making privacy policies machine readable […] would help users match privacy preferences against policies offered by web services”), but mostly just reveals how bad the problem is:\n\n\nFigure 15 from Wagner (2023). “Obfuscatory words” are words like acceptable, significant, mainly, or predominantly, interpretated at the discretion of companies rather than users (see next slide!)"
  },
  {
    "objectID": "w09/slides.html#the-adversarial-sisyphusian-problem-of-contracts",
    "href": "w09/slides.html#the-adversarial-sisyphusian-problem-of-contracts",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "The Adversarial-Sisyphusian Problem of Contracts",
    "text": "The Adversarial-Sisyphusian Problem of Contracts\n\nRecall Intuitive Problem of Causal Inference: Correlation \\(\\nimplies\\) Causation, but can do a bunch of work to overcome\nAdversarial-Sisyphusian Problem is one level worse 😱\n\nIPCI: You vs. discovered correlation (inanimate)\nASPC: You vs. companies investing resources 💰 into making the problem harder and harder for you\n\nThe moment you (\\(N=1\\), $) finally find and “fix” bad thing, company (\\(N \\gg 1\\), $$$) adds more ambiguity to re-enable / sends your data to “new” 3rd-party processor 🥸\nAnalogy would be: someone making causal chains longer and longer as you’re checking causality (map of dancing landscape)"
  },
  {
    "objectID": "w09/slides.html#no-logo-why-johnny-cant-dissent",
    "href": "w09/slides.html#no-logo-why-johnny-cant-dissent",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "No Logo / Why Johnny Can’t Dissent",
    "text": "No Logo / Why Johnny Can’t Dissent\n\nNaomi Klein’s No Logo (1999) sparked a nationwide boycott of companies employing sweatshop labor\nGreat success; all companies responded and (out of the kindness of their hearts) cut ties with all of the sweatshops\nInstead, they established ties with supply chain management companies, who made the profit-maximizing decision to re-establish ties with all of the sweatshops\n\n\n“You can’t outrun them, or even stay ahead of them for very long: it’s their racetrack, and that’s them waiting at the finish line to congratulate you” (Frank 1994)"
  },
  {
    "objectID": "w09/slides.html#conclusion",
    "href": "w09/slides.html#conclusion",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Conclusion",
    "text": "Conclusion"
  },
  {
    "objectID": "w09/slides.html#real-conclusion",
    "href": "w09/slides.html#real-conclusion",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Real Conclusion(?)",
    "text": "Real Conclusion(?)"
  },
  {
    "objectID": "w09/slides.html#wars-with-one-side",
    "href": "w09/slides.html#wars-with-one-side",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Wars with One Side",
    "text": "Wars with One Side\n\n\n\nIt would be ideal except for the Porto Ricans [sic]. They are beyond doubt the dirtiest, laziest, most degenerate and thievish race of men ever inhabiting this sphere. It makes you sick to inhabit the same island with them. They are even lower than Italians. What the island needs is not public health work but a tidal wave or something to totally exterminate the population. It might then be livable. I have done my best to further the process of extermination by killing off 8 and transplanting cancer into several more. (Cornelius Rhoads)\n\n\nBy 1930, the police had files on at least 135,000 individuals (about 3 percent of the island) suspected of favoring independence. (Source)"
  },
  {
    "objectID": "w09/slides.html#wars-with-one-side-1",
    "href": "w09/slides.html#wars-with-one-side-1",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Wars with One Side?",
    "text": "Wars with One Side?\n\nGeorgetown Law School Center on Privacy and Technology, American Dragnet: Data-Driven Deportation in the 21st Century"
  },
  {
    "objectID": "w09/slides.html#the-fundamental-problem-of-contracts",
    "href": "w09/slides.html#the-fundamental-problem-of-contracts",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "The Fundamental Problem of Contracts",
    "text": "The Fundamental Problem of Contracts\n\nJust as we can’t observe two simultaneous worlds \\(W_{X = 0}\\) and \\(W_{X = 1}\\) which differ only in the value of \\(X\\),\nWe can’t foresee all possible contingencies that need to be included in a contract\n\n(We can try, though! Hence use of obfuscatory words to minimize liability)\n\nSo, when a situation arises which is not covered by a clause in the contract, what happens? What principle determines whose interpretation wins out?\n\n(Hint: It is actually literally my legal middle name…)"
  },
  {
    "objectID": "w09/slides.html#power",
    "href": "w09/slides.html#power",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "…POWER!",
    "text": "…POWER!\n\nExamples from employment contracts (tooting own horn):\nIn a private, cooperatively-owned, democratic firm, outcome determined by conversation, majority vote, unanimity, etc.\n\nThese technically exist in the US! Employing 2,380 workers, \\(\\frac{2380}{127509000} \\approx 0.0019\\%\\) of US workforce\n\nOtherwise, in a non-unionized private firm (94% of total), the outcome is determined by organizational hierarchy\n\nThis is the case for \\(\\frac{125000000}{127509000} \\approx 98.03\\%\\) of US workforce"
  },
  {
    "objectID": "w09/slides.html#descriptive-and-normative-considerations",
    "href": "w09/slides.html#descriptive-and-normative-considerations",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Descriptive and Normative Considerations",
    "text": "Descriptive and Normative Considerations\n\nThe combined effect of incomplete contracts and conflicts of interest is that the determination of outcomes depends on who exercises power in the transaction.\nPower is generally exercised by those who hold the residual rights of control, meaning the right to determine what is not specified contractually (Bowles 2009)\n\n\n[Step 1: Empirically measurable given antecedents] Who has power w.r.t. a given incomplete contract?\n[Step 2: Up to you and your ethical axioms; e.g., efficiency] Who ought to have power w.r.t. incomplete contracts?"
  },
  {
    "objectID": "w09/slides.html#working-definition-of-power",
    "href": "w09/slides.html#working-definition-of-power",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Working Definition of Power",
    "text": "Working Definition of Power\n\n\n\n\n\n Defining (Dyadic) Power (Bowles and Gintis 1992, 326–27)\n\n\nFor agent \\(A\\) to have power over agent \\(B\\) it is sufficient that, by imposing or threatening to impose sanctions on \\(B\\), \\(A\\) is capable of affecting \\(B\\)’s actions in ways that further \\(A\\)’s interests, while \\(B\\) lacks this capacity with respect to \\(A\\)."
  },
  {
    "objectID": "w09/slides.html#prisoners-dilemma",
    "href": "w09/slides.html#prisoners-dilemma",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Prisoners’ Dilemma",
    "text": "Prisoners’ Dilemma\n\n\n\n\n\n\\(B\\)\n\n\n\n\nSilent\nSnitch\n\n\n\\(A\\)\nSilent\n\\(-1,-1\\)\n\\(-3,\\phantom{-}0\\)\n\n\nSnitch\n\\(\\phantom{-}0, -3\\)\n\\(-10,-10\\)"
  },
  {
    "objectID": "w09/slides.html#assurance-game",
    "href": "w09/slides.html#assurance-game",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Assurance Game",
    "text": "Assurance Game\nPalanpur, Gujarat, India\n\nThe farmers do not doubt that earlier planting would give them larger harvests, but no one, the farmer explained, is willing to be the first to plant, as the seeds on any lone plot would be quickly eaten by birds…\n[What if you all organized to plant on the same day, to reap rewards of earlier planting while minimizing bird losses (dividing by \\(N\\) instead of \\(1\\))?]\n“If we knew how to do that”, he said, looking up from his hoe at me, “we would not be poor.” (Bowles 2009)"
  },
  {
    "objectID": "w09/slides.html#assurance-game-in-normal-form",
    "href": "w09/slides.html#assurance-game-in-normal-form",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Assurance Game in Normal Form",
    "text": "Assurance Game in Normal Form\n\n\n\n\n\n\\(B\\)\n\n\n\n\nEarly\nLate\n\n\n\\(A\\)\nEarly\n\\(4, 4\\)\n\\(0, 3\\)\n\n\nLate\n\\(3, 0\\)\n\\(2, 2\\)"
  },
  {
    "objectID": "w09/slides.html#invisible-hand-game-normal-form",
    "href": "w09/slides.html#invisible-hand-game-normal-form",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "Invisible Hand Game (Normal Form)",
    "text": "Invisible Hand Game (Normal Form)\n\n\n\n\n\n\\(B\\)\n\n\n\n\nCorn\nTomatoes\n\n\n\\(A\\)\nCorn\n\\(2, 4\\)\n\\(4, 3\\)\n\n\nTomatoes\n\\(5, 5\\)\n\\(3, 2\\)"
  },
  {
    "objectID": "w09/slides.html#references",
    "href": "w09/slides.html#references",
    "title": "Week 9: From Data Ethics to Data Policy",
    "section": "References",
    "text": "References\n\n\nBowles, Samuel. 2009. Microeconomics: Behavior, Institutions, and Evolution. Princeton University Press.\n\n\nBowles, Samuel, and Herbert Gintis. 1992. “Power and Wealth in a Competitive Capitalist Economy.” Philosophy & Public Affairs 21 (4): 324–53. https://www.jstor.org/stable/2265369.\n\n\nFrank, Tom. 1994. “DARK AGE: Why Johnny Can’t Dissent.” The Baffler, no. 6: 5–192. https://www.jstor.org/stable/43555671.\n\n\nThucydides. 2013. The War of the Peloponnesians and the Athenians. Cambridge University Press.\n\n\nWagner, Isabel. 2023. “Privacy Policies Across the Ages: Content of Privacy Policies 1996–2021.” ACM Transactions on Privacy and Security 26 (3): 32:1–32. https://doi.org/10.1145/3590152."
  },
  {
    "objectID": "w01/index.html",
    "href": "w01/index.html",
    "title": "Week 1: Introduction to the Course",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#prof.-jeff-introduction",
    "href": "w01/index.html#prof.-jeff-introduction",
    "title": "Week 1: Introduction to the Course",
    "section": "Prof. Jeff Introduction!",
    "text": "Prof. Jeff Introduction!\n\nBorn and raised in NW DC → high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#grad-school",
    "href": "w01/index.html#grad-school",
    "title": "Week 1: Introduction to the Course",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/北大) → internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\n\nColumbia for PhD[+Postdoc] in Political Science (2015-2023)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#dissertation-political-science-history",
    "href": "w01/index.html#dissertation-political-science-history",
    "title": "Week 1: Introduction to the Course",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n“Our Word is Our Weapon”: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#why-is-georgetown-having-me-teach-this",
    "href": "w01/index.html#why-is-georgetown-having-me-teach-this",
    "title": "Week 1: Introduction to the Course",
    "section": "Why Is Georgetown Having Me Teach This?",
    "text": "Why Is Georgetown Having Me Teach This?\n\n\n\n\n\n\n\nQuanty things, but then PhD major was Political Philosophy (concentration in International Relations)\nWhat most interested me: unraveling history; Easy to get lost in “present-day” details of e.g. debiasing algorithms and fairness in AI, but these questions go back literally thousands of years!\nPol philosophers distinguish “ancients” and “moderns” based on a crucial shift in perspective: ancients sought perfection, while Rousseau (1762) “took men [sic] as they are, and laws as they could be”.\n\n\n\n\n\n\n\n\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"notebook\"\nimport pandas as pd\nyear_df = pd.DataFrame({\n  'field': ['Math&lt;br&gt;(BS)','CS&lt;br&gt;(BS,MS)','Pol Phil&lt;br&gt;(PhD Pt 1)','Econ&lt;br&gt;(BS+Job)','Pol Econ&lt;br&gt;(PhD Pt 2)'],\n  'cat': ['Quant','Quant','Humanities','Social Sci','Social Sci'],\n  'yrs': [4, 6, 3, 6, 5]\n})\nfig = px.sunburst(\n    year_df, path=['cat','field'], values='yrs',\n    width=450, height=400, color='cat',\n    color_discrete_map={'Quant': cb_palette[0], 'Humanities': cb_palette[1], 'Social Sci': cb_palette[2]},\n    hover_data=[]\n)\nfig.update_traces(\n   hovertemplate=None,\n   hoverinfo='skip'\n)\n# Update layout for tight margin\n# See https://plotly.com/python/creating-and-updating-figures/\nfig.update_layout(margin = dict(t=0, l=0, r=0, b=0))\nfig.show()\n\n                                                \n\n\n\n\n\nFigure 1: Years spent questing in various dungeons of academia\n\n\n\n\n\n\n\nBut is separation of ethics from politics possible? (Bowles 2016) Should we accept “human nature” as immutable/eternal? My answer: yes AND no simultaneously…",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#dialectics",
    "href": "w01/index.html#dialectics",
    "title": "Week 1: Introduction to the Course",
    "section": "Dialectics",
    "text": "Dialectics",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#my-biases",
    "href": "w01/index.html#my-biases",
    "title": "Week 1: Introduction to the Course",
    "section": "My Biases",
    "text": "My Biases\n\n\n\n\n\n\n\nUpbringing: religious Jewish, right-wing (Revisionist Zionist) Republican environment\n“Encouraged” to emigrate to Israel for IDF service, but after learning history I renounced citizenship etc., family no longer big fans of me (Traumatic and scary to talk about, tbh 🙈)\n2015-present: Teach CS + design thinking in refugee camps in West Bank and Gaza each summer (Code for Palestine)\nMetaethics: Learn about the world, challenge+update prior beliefs (Bayes’ rule!); I hope to challenge+update them throughout semester, with your help 🙂",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#on-the-one-hand",
    "href": "w01/index.html#on-the-one-hand",
    "title": "Week 1: Introduction to the Course",
    "section": "On the One Hand…",
    "text": "On the One Hand…",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#on-the-other-hand",
    "href": "w01/index.html#on-the-other-hand",
    "title": "Week 1: Introduction to the Course",
    "section": "On the Other Hand…",
    "text": "On the Other Hand…",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#remembering-why-it-matters",
    "href": "w01/index.html#remembering-why-it-matters",
    "title": "Week 1: Introduction to the Course",
    "section": "Remembering Why It Matters",
    "text": "Remembering Why It Matters",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#rules-of-thumb",
    "href": "w01/index.html#rules-of-thumb",
    "title": "Week 1: Introduction to the Course",
    "section": "Rules of Thumb",
    "text": "Rules of Thumb\n\n\n\n\n\n\n\nAsk questions about power \\(\\leadsto\\) inequities, but especially about structures/processes that give rise to them!\n“Philosophers have hitherto only tried to understand the world; the point, however, is to change it.” (Marx 1845)\nDialectical implication: the more we understand it the better we’ll be at changing it\n\n\n\n\n\n\nRicardo Morales Art Studio / My office",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#axiomatics",
    "href": "w01/index.html#axiomatics",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatics",
    "text": "Axiomatics\n\n\n\n\n\n\n\n\nPopular understanding of math: Deals with Facts, statements are true or false\n\nEx: \\(1 + 1 = 2\\) is “true”\n\nReality: No statements in math are absolutely true! Only conditional statements are possible to prove!\nWe cannot prove atomic statements \\(q\\), only implicational statements: \\(p \\implies q\\) for some axiom(s) \\(p\\).\n\n\\(1 + 1 = 2\\) is indeterminate without definitions of \\(1\\), \\(+\\), \\(=\\), and \\(2\\)!\n(Easy counterexample for math/CS majors: \\(1 + 1 = 0\\) in \\(\\mathbb{Z}_2\\))\n\n\n\n\n\n\n\n\nSteingart (2023)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#example-1-1-2",
    "href": "w01/index.html#example-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: \\(1 + 1 = 2\\)",
    "text": "Example: \\(1 + 1 = 2\\)\n\n\n\n\n\n\n\nHow it’s taught: this is a rule, and if you don’t follow it you will be banished to eternal hellfire\nHow it’s proved: \\(ZFC \\implies [1 + 1 = 2]\\), where \\(ZFC\\) stands for the Zermelo-Fraenkel Axioms with the Axiom of Choice!\n\n\n\n\n\n\nWhitehead and Russell (1910), p. 83. See here for page in context",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#proving-1-1-2",
    "href": "w01/index.html#proving-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Proving \\(1 + 1 = 2\\)",
    "text": "Proving \\(1 + 1 = 2\\)\n(A non-formal proof that still captures the gist:)\n\nAxiom 1: There is a type of thing that can hold other things, which we’ll call a set. We’ll represent it like: \\(\\{ \\langle \\text{\\textit{stuff in the set}} \\rangle \\}\\).\nAxiom 2: Start with the set with nothing in it, \\(\\{\\}\\), and call it “\\(0\\)”.\nAxiom 3: If we put this set \\(0\\) inside of an empty set, we get a new set \\(\\{0\\} = \\{\\{\\}\\}\\), which we’ll call “\\(1\\)”.\nAxiom 4: If we put this set \\(1\\) inside of another set, we get another new set \\(\\{1\\} = \\{\\{\\{\\}\\}\\}\\), which we’ll call “\\(2\\)”.\nAxiom 5: This operation (creating a “next number” by placing a given number inside an empty set) we’ll call succession: \\(S(x) = \\{x\\}\\)\nAxiom 6: We’ll define addition, \\(a + b\\), as applying this succession operation \\(S\\) to \\(a\\), \\(b\\) times. Thus \\(a + b = \\underbrace{S(S(\\cdots (S(}_{b\\text{ times}}a))\\cdots ))\\)\nResult: (Axioms 1-6) \\(\\implies 1 + 1 = S(1) = S(\\{\\{\\}\\}) = \\{\\{\\{\\}\\}\\} = 2. \\; \\blacksquare\\)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#how-is-this-relevant-to-ethics",
    "href": "w01/index.html#how-is-this-relevant-to-ethics",
    "title": "Week 1: Introduction to the Course",
    "section": "How Is This Relevant to Ethics?",
    "text": "How Is This Relevant to Ethics?\n(Thank you for bearing with me on that 😅)\n\nJust as mathematicians slowly came to the realization that\n\n\\[\n\\textbf{mathematical results} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nI hope to help you see how\n\n\\[\n\\textbf{ethical conclusions} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nWhen someone says \\(1 + 1 = 2\\), you are allowed to question them, and ask, “On what basis? Please explain…”.\n\nHere the only valid answer is a collection of axioms which entail \\(1 + 1 = 2\\)\n\nWhen someone says Israel has the right to defend itself, you are allowed to question them, and ask, “On what basis? Please explain…”\n\nHere the only valid answer is an ethical framework which entails that Israel has the right to defend itself.",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#axiomatic-systems-statements-can-be-true-and-false",
    "href": "w01/index.html#axiomatic-systems-statements-can-be-true-and-false",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatic Systems: Statements Can Be True And False",
    "text": "Axiomatic Systems: Statements Can Be True And False\n\nLet \\(T\\) be the sum of the interior angles of a triangle. We’re taught \\(T = 180^\\circ\\) is a “rule”\nEuclid’s Fifth Postulate \\(P_5\\): Given a line and a point not on it, exactly one line parallel to the given line can be drawn through the point.\n\n\n\n\n\n\n\n\n\n\\(P_5 \\implies T = 180^\\circ\\)\n\n\n(Euclidean Geometry)\n\n\n\n\n\\(\\neg P_5 \\implies T \\neq 180^\\circ\\)\n\n\n(Non-Euclidean Geometry)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#ethical-systems-promise-keeping",
    "href": "w01/index.html#ethical-systems-promise-keeping",
    "title": "Week 1: Introduction to the Course",
    "section": "Ethical Systems: Promise-Keeping",
    "text": "Ethical Systems: Promise-Keeping\n\nScenario: You just baked a pie, and you promised your friend you’d give them the pie. You’re walking over to the friend’s house to give them the pie.\nSuddenly, you turn the corner to encounter a hostage situation: the hostage-taker is going to kill their hostage unless someone gives them a pie in the next 30 seconds\nDo you give the hostage-taker the pie?\n\n\n\n\n\n\n\n\nConsequentialist Ethics \\(\\implies\\) Yes\n\n\nTo be ethical is to weigh consequences of your actions\nThe positive consequences of giving the pie to the hostage-taker (saving a life) outweigh the negative consequences (breaking your promise to your friend)\n(Ex: Utilitarianism, associated with British philosopher Jeremy Bentham)\n\n\n\n\nDeontological Ethics \\(\\implies\\) No\n\n\nTo be ethical is to live by rules which you would want everyone to follow.\nAs a rule (a “categorical imperative”), you must not break promises. (Breaking this rule \\(\\implies\\) others can also “pick and choose” when to honor promises to you)\n(Ex: Kantian Ethics, associated with German philosopher Immanuel Kant)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#descriptive-vs.-normative",
    "href": "w01/index.html#descriptive-vs.-normative",
    "title": "Week 1: Introduction to the Course",
    "section": "Descriptive vs. Normative",
    "text": "Descriptive vs. Normative\n\n\n\n\n\n\n\n \n  \n \n\n\n\n\n\n\nbin Laden (2005)\n\n\n\n\n\n\n\n\n\n\n\n\nDescriptive Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years”\nNormative Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years, and that is a good justification”\n\n\nDescriptively True (empirically verifiable)\nNormatively True (entailed by axioms + descriptive facts) in some ethical systems, Normatively False (not entailed by axioms + descriptive facts) in others",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#the-is-ought-distinction",
    "href": "w01/index.html#the-is-ought-distinction",
    "title": "Week 1: Introduction to the Course",
    "section": "The Is-Ought Distinction",
    "text": "The Is-Ought Distinction\n\n\n\n\n\n\nHume on Is vs. Ought (hume_treatise_1739?)\n\n\n\n\nthe author proceeds for some time in the ordinary way of reasoning\nsuddenly, instead of the usual copulations of propositions is and is not,\nI meet with no proposition that is not connected with an ought, or an ought not.\nThis change is imperceptible; but is, however, of the last consequence.\n\n\n\n\n\n\nDescriptive (Is)\nNormative (Ought)\n\n\n\n\nGrass is green (true)\nGrass ought to be green (?)\n\n\nGrass is blue (false)\nGrass ought to be blue (?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#what-happens-when-we-confuse-the-two",
    "href": "w01/index.html#what-happens-when-we-confuse-the-two",
    "title": "Week 1: Introduction to the Course",
    "section": "What Happens When We Confuse The Two?",
    "text": "What Happens When We Confuse The Two?\n\n\n\n\n\n\n\nMakes it impossible to “cross the boundary” between your own and others’ beliefs\nCollective welfare: Bad on its own terms (see: wars, racism, etc.)\nSelf-interest: Prevents us from convincing other people of our arguments\n\n\n\n\n\n\nGeertz (1973)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#collective-vs.-self-interest",
    "href": "w01/index.html#collective-vs.-self-interest",
    "title": "Week 1: Introduction to the Course",
    "section": "Collective vs. Self-Interest",
    "text": "Collective vs. Self-Interest\n\n\n\n\n\n\n\nGood for collection of people \\(\\; \\nimplies\\) good for each individual person! (😰)\n\\(p\\) = Unions improve everyone’s workplace conditions, whether or not they pay dues\n\\(q\\) = Union dues are voluntary\n\\(p \\wedge q \\implies\\) I can obtain benefits of unions without paying\n\\(\\implies\\) Individually rational to not pay dues\n(Think also about how this applies to climate change policy) 🤔\n\n\n\n\n\n\nOlson (1965)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#modeling-individual-vs.-societal-outcomes",
    "href": "w01/index.html#modeling-individual-vs.-societal-outcomes",
    "title": "Week 1: Introduction to the Course",
    "section": "Modeling Individual vs. Societal Outcomes",
    "text": "Modeling Individual vs. Societal Outcomes\n\nIndividual Perspective: Individual \\(i\\) chooses whether or not to pay union dues\n\n\n\n\n\n\n\n\n\\(\\implies\\) Social Outcome: No Union\n\n\n\n\n\n\n\\(\\implies\\) Social Outcome: Union Possible\n\n\nKey reading: Schelling (1978), Micromotives and Macrobehavior",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#takeaway-for-policy-whitepapers",
    "href": "w01/index.html#takeaway-for-policy-whitepapers",
    "title": "Week 1: Introduction to the Course",
    "section": "Takeaway for Policy Whitepapers",
    "text": "Takeaway for Policy Whitepapers\n\n\n\n\n\n\n\nYou cannot (just) say, “doing \\(x\\) will be better for society”\nYou must also justify benefits to individuals, or at minimum, the individual organization and its stakeholders!\n(Is this a normative or descriptive claim?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#data-science-for-who",
    "href": "w01/index.html#data-science-for-who",
    "title": "Week 1: Introduction to the Course",
    "section": "Data Science for Who?",
    "text": "Data Science for Who?\n\nWhat are the processes by which data is (or is not) measured, recorded, and distributed?\nWho are the agents doing or not-doing these things?\n\n\n\n\nThe Library of Missing Datasets. From D’Ignazio and Klein (2020)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#example-measuring-freedom-and-human-rights",
    "href": "w01/index.html#example-measuring-freedom-and-human-rights",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: Measuring “Freedom” and “Human Rights”",
    "text": "Example: Measuring “Freedom” and “Human Rights”",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#methodological-individualism",
    "href": "w01/index.html#methodological-individualism",
    "title": "Week 1: Introduction to the Course",
    "section": "Methodological Individualism",
    "text": "Methodological Individualism\n\nAtoms exhibit properties which are fruitful for understanding the physical world: we can study these properties as “building blocks” \\(\\leadsto\\) interactions among atoms with various properties give rise to higher-level physical “things” (molecules, chemicals, cells, organisms)\nIndividuals exhibit properties which are fruitful for understanding the social world: we can study these properties as “building blocks” \\(\\leadsto\\) interactions among individuals with various properties give rise to higher-level social processes (dyads, groups, institutions)\n\n\n\nFor overthinkers: quarks \\(\\leadsto\\) atoms as mental modules \\(\\leadsto\\) individuals 😉 (Fodor 1983)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#structural-domination-the-grapes-of-wrath",
    "href": "w01/index.html#structural-domination-the-grapes-of-wrath",
    "title": "Week 1: Introduction to the Course",
    "section": "Structural Domination: The Grapes of Wrath",
    "text": "Structural Domination: The Grapes of Wrath\n\nBut… I built it with my hands! Straightened old nails to put the sheathing on!\nIt’s not me. There’s nothing I can do. I’ll lose my job if I don’t do it. And look—suppose you kill me? They’ll hang you, and long before you’re hung there’ll be another guy here, he’ll bump the house down. You’re not killing the right guy.\nThat’s so… Who gave you orders? I’ll go after him. He’s the one to kill.\nYou’re wrong. He got his orders from the bank. ‘Clear those people out or it’s your job.’\nWell, there’s a president of the bank. A board of directors. I’ll fill up my rifle, head to the bank.\nThe bank gets orders from the East. ‘Make the land show profit or we’ll close you up.’ We’re sorry. It’s not us. It’s the monster. The bank isn’t like a man.\nYes, but the bank is only made of men!\nNo, you’re wrong there—quite wrong. The bank is something else than men. It happens nowadays that every man in a bank hates what the bank does, and yet the bank does it. The bank is something more than men, I tell you.\nI got to figure… We all got to figure. There’s some way to stop this. There’s got to be some way to stop this. It’s not like lightning or earthquakes. We’ve got a bad thing made by men, and by God, isn’t that something we should be able to change? (Steinbeck 1939)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#ontology-individuals-and-structures",
    "href": "w01/index.html#ontology-individuals-and-structures",
    "title": "Week 1: Introduction to the Course",
    "section": "Ontology: Individuals and Structures",
    "text": "Ontology: Individuals and Structures\nMethodological Individualism and Structural Domination!\n\n\n\nNo longer much preoccupied with such crudities as ‘conspiracy theory’, [progressives] have become quite monolithic in attributing all things negative to handy abstractions like ‘capitalism’, ‘the state’, ‘structural oppression’, and ‘hierarchy’. Hence they have been able to conjure what might be termed the ‘miracle of immaculate genocide’, a form of genocide, that is, in which there are no actual perpetrators and no one who might ‘really’ be deemed culpable […] The parallels between this ‘cutting edge’ conception and the defense mounted by postwar Germans are as eerie as they are obvious. (Churchill 2003)\n\n\n\n\n\nGiddens (1979)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#operationalization",
    "href": "w01/index.html#operationalization",
    "title": "Week 1: Introduction to the Course",
    "section": "Operationalization",
    "text": "Operationalization\n\n\n\nThink of claims commonly made based on “data”:\n\nMarkets create economic prosperity\nA glass of wine in the evening prevents cancer\nPolicing makes communities safer\n\nHow exactly are “prosperity”, “preventing cancer”, “policing”, “community safety” being measured? Who is measuring? Mechanisms for feedback \\(\\leadsto\\) updates?\n\n\n\n\n\n\n\n\nStiglitz, Sen, and Fitoussi (2010)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#what-is-being-compared",
    "href": "w01/index.html#what-is-being-compared",
    "title": "Week 1: Introduction to the Course",
    "section": "What Is Being Compared?",
    "text": "What Is Being Compared?\n\n\n\n\n\n\n\n\nApples\nOranges\nPears\n\n\n\n\nPolities w/250-500M people (US ~335M, UP ~250M, EU ~450M)\nPolities w/11M people in the Caribbean (Cuba, Haiti, Dominican Republic)\nPolities w/over 1 billion people (China ~1.4B, India ~1.4B, Africa ~1.4B, ⬆️+⬇️ America ~1B)\n\n\nDemocracies (US)\nDemocracies til they democratically elected someone US didn’t like (Iran, Guatemala, Chile)\nNon-democracies which brutally repress democratic movements w/US arms (Saudi Arabia)\n\n\nColonizing polities (US)\nPolities colonized by them (Philippines)\nNon-colonized polities (Ethiopia, Thailand)\n\n\nPolities w/infrastructure built up over 250+ yrs via slave labor (US 🇺🇸)\nPolities populated by former slaves (Liberia 🇱🇷)\nPolities that paid reparations to descendants of [certain] enslaved groups (Germany)\n\n\nPolities independent since 1776 (US)\nPolities independent since 1990 (Namibia)\nNon-self-governing polities (Puerto Rico, Palestine, New Caledonia)\n\n\nPolities enforcing a 60 yr embargo on Cuba (US)\nPolities with a 60 yr embargo imposed on them by US (Cuba)\nPolities without a 60 yr embargo imposed on them by US (…)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#how-are-they-being-compared",
    "href": "w01/index.html#how-are-they-being-compared",
    "title": "Week 1: Introduction to the Course",
    "section": "How Are They Being Compared?",
    "text": "How Are They Being Compared?\n\nWhat metric? Over what timespan?\nWhat unit of obs \\(\\leadsto\\) agg function \\(\\leadsto\\) level of aggregation?\n\n\n\n\nDrèze and Sen (1991)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#there-is-still-hope-i-promise",
    "href": "w01/index.html#there-is-still-hope-i-promise",
    "title": "Week 1: Introduction to the Course",
    "section": "…There is Still Hope! I Promise!",
    "text": "…There is Still Hope! I Promise!\n\nFair Comparison through Statistical Matching:\nLyall (2020): “Treating certain ethnic groups as second-class citizens […] leads victimized soldiers to subvert military authorities once war begins. The higher an army’s inequality, the greater its rates of desertion, side-switching, and casualties”\n\n\nMatching constructs pairs of belligerents that are similar across a wide range of traits thought to dictate battlefield performance but that vary in levels of prewar inequality. The more similar the belligerents, the better our estimate of inequality’s effects, as all other traits are shared and thus cannot explain observed differences in performance, helping assess how battlefield performance would have improved (declined) if the belligerent had a lower (higher) level of prewar inequality.\nSince [non-matched] cases are dropped […] selected cases are more representative of average belligerents/wars than outliers with few or no matches, [providing] surer ground for testing generalizability of the book’s claims than focusing solely on canonical but unrepresentative usual suspects (Germany, the United States, Israel)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#does-inequality-cause-poor-military-performance",
    "href": "w01/index.html#does-inequality-cause-poor-military-performance",
    "title": "Week 1: Introduction to the Course",
    "section": "Does Inequality Cause Poor Military Performance?",
    "text": "Does Inequality Cause Poor Military Performance?\n\n\n\n\n\n\n\n\nCovariates\nSultanate of Morocco Spanish-Moroccan War, 1859-60\nKhanate of Kokand War with Russia, 1864-65\n\n\n\n\n\\(X\\): Military Inequality\nLow (0.01)\nExtreme (0.70)\n\n\n\\(\\mathbf{Z}\\): Matched Covariates:\n\n\n\n\nInitial relative power\n66%\n66%\n\n\nTotal fielded force\n55,000\n50,000\n\n\nRegime type\nAbsolutist Monarchy (−6)\nAbsolute Monarchy (−7)\n\n\nDistance from capital\n208km\n265km\n\n\nStanding army\nYes\nYes\n\n\nComposite military\nYes\nYes\n\n\nInitiator\nNo\nNo\n\n\nJoiner\nNo\nNo\n\n\nDemocratic opponent\nNo\nNo\n\n\nGreat Power\nNo\nNo\n\n\nCivil war\nNo\nNo\n\n\nCombined arms\nYes\nYes\n\n\nDoctrine\nOffensive\nOffensive\n\n\nSuperior weapons\nNo\nNo\n\n\nFortifications\nYes\nYes\n\n\nForeign advisors\nYes\nYes\n\n\nTerrain\nSemiarid coastal plain\nSemiarid grassland plain\n\n\nTopography\nRugged\nRugged\n\n\nWar duration\n126 days\n378 days\n\n\nRecent war history w/opp\nYes\nYes\n\n\nFacing colonizer\nYes\nYes\n\n\nIdentity dimension\nSunni Islam/Christian\nSunni Islam/Christian\n\n\nNew leader\nYes\nYes\n\n\nPopulation\n8–8.5 million\n5–6 million\n\n\nEthnoling fractionalization (ELF)\nHigh\nHigh\n\n\nCiv-mil relations\nRuler as commander\nRuler as commander\n\n\n\\(Y\\): Battlefield Performance:\n\n\n\n\nLoss-exchange ratio\n0.43\n0.02\n\n\nMass desertion\nNo\nYes\n\n\nMass defection\nNo\nNo\n\n\nFratricidal violence\nNo\nYes",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#bro-snapped",
    "href": "w01/index.html#bro-snapped",
    "title": "Week 1: Introduction to the Course",
    "section": "Bro Snapped",
    "text": "Bro Snapped\n(I have no dog in this fight, I’m not trying to improve military performance of an army, but got damn)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#implementation",
    "href": "w01/index.html#implementation",
    "title": "Week 1: Introduction to the Course",
    "section": "Implementation",
    "text": "Implementation\n\n\n\n\n\n\n\n\n\nFrom D’Ignazio and Klein (2020), Ch. 6 (see also)\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Lerman and Weaver (2014) (see also)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#fairness",
    "href": "w01/index.html#fairness",
    "title": "Week 1: Introduction to the Course",
    "section": "Fairness… 🧐",
    "text": "Fairness… 🧐\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Lily Hu, Direct Effects: How Should We Measure Racial Discrimination?, Phenomenal World, 25 September 2020\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: From Kasy and Abebe (2021)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#and-inverse-fairness",
    "href": "w01/index.html#and-inverse-fairness",
    "title": "Week 1: Introduction to the Course",
    "section": "…And INVERSE Fairness 🤯",
    "text": "…And INVERSE Fairness 🤯\n\n\n\nFrom Machine Learning What Policymakers Value (bjorkegren_machine_2022?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#facial-recognition-algorithms",
    "href": "w01/index.html#facial-recognition-algorithms",
    "title": "Week 1: Introduction to the Course",
    "section": "Facial Recognition Algorithms",
    "text": "Facial Recognition Algorithms\n\n\n\n\n\n\n\n\n\nFacia.ai (2023)\n\n\n\n\n\n\n\nWellcome Collection (1890)\n\n\n\n\n\n\n\n\n\nOuz (2023)\n\n\n\n\n\n\n\nWang and Kosinski (2018)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#large-language-models",
    "href": "w01/index.html#large-language-models",
    "title": "Week 1: Introduction to the Course",
    "section": "Large Language Models",
    "text": "Large Language Models\n\n\n\nWhen to retain biases…\n\n\n\n…and when to debias\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: From Schiebinger et al. (2020)\n\n\n\n\n\n\n\n\n\n\nFigure 5: From DeepLearning.AI’s Deep Learning course",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#military-and-police-applications-of-ai",
    "href": "w01/index.html#military-and-police-applications-of-ai",
    "title": "Week 1: Introduction to the Course",
    "section": "Military and Police Applications of AI",
    "text": "Military and Police Applications of AI\n\n\n\n\n\n\n\n\n\nAyyub (2019)\n\n\n\n\n\n\n\nMcNeil (2022)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#from-week-7-onwards-you-work-at-a-think-tank",
    "href": "w01/index.html#from-week-7-onwards-you-work-at-a-think-tank",
    "title": "Week 1: Introduction to the Course",
    "section": "From Week 7 Onwards, You Work At A Think Tank",
    "text": "From Week 7 Onwards, You Work At A Think Tank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMorozov (2015)\n\n\n\n\n\n\n\nFrom Ames (2014)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#references",
    "href": "w01/index.html#references",
    "title": "Week 1: Introduction to the Course",
    "section": "References",
    "text": "References\n\n\nAmes, Mark. 2014. “The Techtopus: How Silicon Valley’s Most Celebrated CEOs Conspired to Drive down 100,000 Tech Engineers’ Wages,” January. http://web.archive.org/web/20200920042121/https://pando.com/2014/01/23/the-techtopus-how-silicon-valleys-most-celebrated-ceos-conspired-to-drive-down-100000-tech-engineers-wages/.\n\n\nAyyub, Rami. 2019. “App Aims to Help Palestinian Drivers Find Their Way Around Checkpoints.” The Times of Israel, August. https://www.timesofisrael.com/app-aims-to-help-palestinian-drivers-find-their-way-around-checkpoints/.\n\n\nbin Laden, Osama. 2005. Messages to the World: The Statements of Osama Bin Laden. Verso Books.\n\n\nBowles, Samuel. 2016. The Moral Economy: Why Good Incentives Are No Substitute for Good Citizens. Yale University Press.\n\n\nChurchill, Ward. 2003. On the Justice of Roosting Chickens: Reflections on the Consequences of U.S. Imperial Arrogance and Criminality. AK Press.\n\n\nD’Ignazio, Catherine, and Lauren F. Klein. 2020. Data Feminism. MIT Press.\n\n\nDrèze, Jean, and Amartya Sen. 1991. “China and India.” In Hunger and Public Action, 0. Oxford University Press. https://doi.org/10.1093/0198283652.003.0011.\n\n\nFacia.ai. 2023. “Facial Recognition Helps Vendors in Healthcare.” Facia.ai. https://facia.ai/blog/facial-recognition-healthcare/.\n\n\nFodor, Jerry A. 1983. The Modularity of Mind. MIT Press.\n\n\nGeertz, Clifford. 1973. The Interpretation Of Cultures. Basic Books.\n\n\nGiddens, Anthony. 1979. Central Problems in Social Theory: Action, Structure, and Contradiction in Social Analysis. University of California Press.\n\n\nKasy, Maximilian, and Rediet Abebe. 2021. “Fairness, Equality, and Power in Algorithmic Decision-Making.” In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 576–86. FAccT ’21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445919.\n\n\nLerman, Amy E., and Vesla M. Weaver. 2014. Arresting Citizenship: The Democratic Consequences of American Crime Control. University of Chicago Press.\n\n\nLyall, Jason. 2020. Divided Armies: Inequality and Battlefield Performance in Modern War. Princeton University Press.\n\n\nMarx, Karl. 1845. Thesen über Feuerbach. Stuttgart: J. H. W. Dietz. https://de.wikisource.org/wiki/Thesen_%C3%BCber_Feuerbach.\n\n\nMcNeil, Sam. 2022. “Israel Deploys Remote-Controlled Robotic Guns in West Bank.” AP News, November. https://apnews.com/article/technology-business-israel-robotics-west-bank-cfc889a120cbf59356f5044eb43d5b88.\n\n\nMorozov, Evgeny. 2015. “Socialize the Data Centres!” New Left Review, no. 91 (February): 45–66.\n\n\nOlson, Mancur. 1965. The Logic of Collective Action. Harvard University Press.\n\n\nOuz. 2023. “Google Pixel 8 Face Unlock Vulnerability Discovered, Allowing Others to Unlock Devices.” Gizmochina. https://www.gizmochina.com/2023/10/16/google-pixel-8-face-unlock/.\n\n\nRousseau, Jean-Jacques. 1762. The Social Contract. Geneva: J. M. Dent.\n\n\nSchelling, Thomas C. 1978. Micromotives and Macrobehavior. Norton.\n\n\nSchiebinger, Londa, Ineke Klinga, Hee Young Paik, Inés Sánchez de Madariaga, Martina Schraudner, and Marcia Stefanick. 2020. “Machine Translation: Gendered Innovations.” http://genderedinnovations.stanford.edu/case-studies/nlp.html#tabs-2.\n\n\nSteinbeck, John. 1939. The Grapes of Wrath. Penguin.\n\n\nSteingart, Alma. 2023. Axiomatics: Mathematical Thought and High Modernism. University of Chicago Press.\n\n\nStiglitz, Joseph E., Amartya Sen, and Jean-Paul Fitoussi. 2010. Mismeasuring Our Lives: Why GDP Doesn’t Add Up. The New Press.\n\n\nWang, Yilun, and Michal Kosinski. 2018. “Deep Neural Networks Are More Accurate Than Humans at Detecting Sexual Orientation from Facial Images.” Journal of Personality and Social Psychology 114 (2): 246–57. https://doi.org/10.1037/pspa0000098.\n\n\nWellcome Collection. 1890. “Composite Photographs: \"The Jewish Type\".” https://wellcomecollection.org/works/ngq29vyw.\n\n\nWhitehead, Alfred North, and Bertrand Russell. 1910. Principia Mathematica. Cambridge University Press.",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/slides.html#prof.-jeff-introduction",
    "href": "w01/slides.html#prof.-jeff-introduction",
    "title": "Week 1: Introduction to the Course",
    "section": "Prof. Jeff Introduction!",
    "text": "Prof. Jeff Introduction!\n\nBorn and raised in NW DC → high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)"
  },
  {
    "objectID": "w01/slides.html#grad-school",
    "href": "w01/slides.html#grad-school",
    "title": "Week 1: Introduction to the Course",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/北大) → internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\nColumbia for PhD[+Postdoc] in Political Science (2015-2023)"
  },
  {
    "objectID": "w01/slides.html#dissertation-political-science-history",
    "href": "w01/slides.html#dissertation-political-science-history",
    "title": "Week 1: Introduction to the Course",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n“Our Word is Our Weapon”: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada"
  },
  {
    "objectID": "w01/slides.html#why-is-georgetown-having-me-teach-this",
    "href": "w01/slides.html#why-is-georgetown-having-me-teach-this",
    "title": "Week 1: Introduction to the Course",
    "section": "Why Is Georgetown Having Me Teach This?",
    "text": "Why Is Georgetown Having Me Teach This?\n\n\n\n\n\n\n\nQuanty things, but then PhD major was Political Philosophy (concentration in International Relations)\nWhat most interested me: unraveling history; Easy to get lost in “present-day” details of e.g. debiasing algorithms and fairness in AI, but these questions go back literally thousands of years!\nPol philosophers distinguish “ancients” and “moderns” based on a crucial shift in perspective: ancients sought perfection, while Rousseau (1762) “took men [sic] as they are, and laws as they could be”.\n\n\n\n\n\n\n\n\n\n                                                \n\n\n\n\n\nFigure 1: Years spent questing in various dungeons of academia\n\n\n\n\n\n\n\nBut is separation of ethics from politics possible? (Bowles 2016) Should we accept “human nature” as immutable/eternal? My answer: yes AND no simultaneously…"
  },
  {
    "objectID": "w01/slides.html#dialectics",
    "href": "w01/slides.html#dialectics",
    "title": "Week 1: Introduction to the Course",
    "section": "Dialectics",
    "text": "Dialectics"
  },
  {
    "objectID": "w01/slides.html#my-biases",
    "href": "w01/slides.html#my-biases",
    "title": "Week 1: Introduction to the Course",
    "section": "My Biases",
    "text": "My Biases\n\n\n\n\n\n\n\nUpbringing: religious Jewish, right-wing (Revisionist Zionist) Republican environment\n“Encouraged” to emigrate to Israel for IDF service, but after learning history I renounced citizenship etc., family no longer big fans of me (Traumatic and scary to talk about, tbh 🙈)\n2015-present: Teach CS + design thinking in refugee camps in West Bank and Gaza each summer (Code for Palestine)\nMetaethics: Learn about the world, challenge+update prior beliefs (Bayes’ rule!); I hope to challenge+update them throughout semester, with your help 🙂"
  },
  {
    "objectID": "w01/slides.html#on-the-one-hand",
    "href": "w01/slides.html#on-the-one-hand",
    "title": "Week 1: Introduction to the Course",
    "section": "On the One Hand…",
    "text": "On the One Hand…"
  },
  {
    "objectID": "w01/slides.html#on-the-other-hand",
    "href": "w01/slides.html#on-the-other-hand",
    "title": "Week 1: Introduction to the Course",
    "section": "On the Other Hand…",
    "text": "On the Other Hand…"
  },
  {
    "objectID": "w01/slides.html#remembering-why-it-matters",
    "href": "w01/slides.html#remembering-why-it-matters",
    "title": "Week 1: Introduction to the Course",
    "section": "Remembering Why It Matters",
    "text": "Remembering Why It Matters"
  },
  {
    "objectID": "w01/slides.html#rules-of-thumb",
    "href": "w01/slides.html#rules-of-thumb",
    "title": "Week 1: Introduction to the Course",
    "section": "Rules of Thumb",
    "text": "Rules of Thumb\n\n\n\n\n\n\n\nAsk questions about power \\(\\leadsto\\) inequities, but especially about structures/processes that give rise to them!\n“Philosophers have hitherto only tried to understand the world; the point, however, is to change it.” (Marx 1845)\nDialectical implication: the more we understand it the better we’ll be at changing it\n\n\n\n\n\n\nRicardo Morales Art Studio / My office"
  },
  {
    "objectID": "w01/slides.html#axiomatics",
    "href": "w01/slides.html#axiomatics",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatics",
    "text": "Axiomatics\n\n\n\n\n\n\n\n\nPopular understanding of math: Deals with Facts, statements are true or false\n\nEx: \\(1 + 1 = 2\\) is “true”\n\nReality: No statements in math are absolutely true! Only conditional statements are possible to prove!\nWe cannot prove atomic statements \\(q\\), only implicational statements: \\(p \\implies q\\) for some axiom(s) \\(p\\).\n\n\\(1 + 1 = 2\\) is indeterminate without definitions of \\(1\\), \\(+\\), \\(=\\), and \\(2\\)!\n(Easy counterexample for math/CS majors: \\(1 + 1 = 0\\) in \\(\\mathbb{Z}_2\\))\n\n\n\n\n\n\n\n\nSteingart (2023)"
  },
  {
    "objectID": "w01/slides.html#example-1-1-2",
    "href": "w01/slides.html#example-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: \\(1 + 1 = 2\\)",
    "text": "Example: \\(1 + 1 = 2\\)\n\n\n\n\n\n\n\nHow it’s taught: this is a rule, and if you don’t follow it you will be banished to eternal hellfire\nHow it’s proved: \\(ZFC \\implies [1 + 1 = 2]\\), where \\(ZFC\\) stands for the Zermelo-Fraenkel Axioms with the Axiom of Choice!\n\n\n\n\n\n\nWhitehead and Russell (1910), p. 83. See here for page in context"
  },
  {
    "objectID": "w01/slides.html#proving-1-1-2",
    "href": "w01/slides.html#proving-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Proving \\(1 + 1 = 2\\)",
    "text": "Proving \\(1 + 1 = 2\\)\n(A non-formal proof that still captures the gist:)\n\nAxiom 1: There is a type of thing that can hold other things, which we’ll call a set. We’ll represent it like: \\(\\{ \\langle \\text{\\textit{stuff in the set}} \\rangle \\}\\).\nAxiom 2: Start with the set with nothing in it, \\(\\{\\}\\), and call it “\\(0\\)”.\nAxiom 3: If we put this set \\(0\\) inside of an empty set, we get a new set \\(\\{0\\} = \\{\\{\\}\\}\\), which we’ll call “\\(1\\)”.\nAxiom 4: If we put this set \\(1\\) inside of another set, we get another new set \\(\\{1\\} = \\{\\{\\{\\}\\}\\}\\), which we’ll call “\\(2\\)”.\nAxiom 5: This operation (creating a “next number” by placing a given number inside an empty set) we’ll call succession: \\(S(x) = \\{x\\}\\)\nAxiom 6: We’ll define addition, \\(a + b\\), as applying this succession operation \\(S\\) to \\(a\\), \\(b\\) times. Thus \\(a + b = \\underbrace{S(S(\\cdots (S(}_{b\\text{ times}}a))\\cdots ))\\)\nResult: (Axioms 1-6) \\(\\implies 1 + 1 = S(1) = S(\\{\\{\\}\\}) = \\{\\{\\{\\}\\}\\} = 2. \\; \\blacksquare\\)"
  },
  {
    "objectID": "w01/slides.html#how-is-this-relevant-to-ethics",
    "href": "w01/slides.html#how-is-this-relevant-to-ethics",
    "title": "Week 1: Introduction to the Course",
    "section": "How Is This Relevant to Ethics?",
    "text": "How Is This Relevant to Ethics?\n(Thank you for bearing with me on that 😅)\n\nJust as mathematicians slowly came to the realization that\n\n\\[\n\\textbf{mathematical results} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nI hope to help you see how\n\n\\[\n\\textbf{ethical conclusions} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nWhen someone says \\(1 + 1 = 2\\), you are allowed to question them, and ask, “On what basis? Please explain…”.\n\nHere the only valid answer is a collection of axioms which entail \\(1 + 1 = 2\\)\n\nWhen someone says Israel has the right to defend itself, you are allowed to question them, and ask, “On what basis? Please explain…”\n\nHere the only valid answer is an ethical framework which entails that Israel has the right to defend itself."
  },
  {
    "objectID": "w01/slides.html#axiomatic-systems-statements-can-be-true-and-false",
    "href": "w01/slides.html#axiomatic-systems-statements-can-be-true-and-false",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatic Systems: Statements Can Be True And False",
    "text": "Axiomatic Systems: Statements Can Be True And False\n\nLet \\(T\\) be the sum of the interior angles of a triangle. We’re taught \\(T = 180^\\circ\\) is a “rule”\nEuclid’s Fifth Postulate \\(P_5\\): Given a line and a point not on it, exactly one line parallel to the given line can be drawn through the point.\n\n\n\n\n\n\n\n\n\n\\(P_5 \\implies T = 180^\\circ\\)\n\n\n(Euclidean Geometry)\n\n\n\n\n\\(\\neg P_5 \\implies T \\neq 180^\\circ\\)\n\n\n(Non-Euclidean Geometry)"
  },
  {
    "objectID": "w01/slides.html#ethical-systems-promise-keeping",
    "href": "w01/slides.html#ethical-systems-promise-keeping",
    "title": "Week 1: Introduction to the Course",
    "section": "Ethical Systems: Promise-Keeping",
    "text": "Ethical Systems: Promise-Keeping\n\nScenario: You just baked a pie, and you promised your friend you’d give them the pie. You’re walking over to the friend’s house to give them the pie.\nSuddenly, you turn the corner to encounter a hostage situation: the hostage-taker is going to kill their hostage unless someone gives them a pie in the next 30 seconds\nDo you give the hostage-taker the pie?\n\n\n\n\n\n\n\n\nConsequentialist Ethics \\(\\implies\\) Yes\n\n\nTo be ethical is to weigh consequences of your actions\nThe positive consequences of giving the pie to the hostage-taker (saving a life) outweigh the negative consequences (breaking your promise to your friend)\n(Ex: Utilitarianism, associated with British philosopher Jeremy Bentham)\n\n\n\n\nDeontological Ethics \\(\\implies\\) No\n\n\nTo be ethical is to live by rules which you would want everyone to follow.\nAs a rule (a “categorical imperative”), you must not break promises. (Breaking this rule \\(\\implies\\) others can also “pick and choose” when to honor promises to you)\n(Ex: Kantian Ethics, associated with German philosopher Immanuel Kant)"
  },
  {
    "objectID": "w01/slides.html#descriptive-vs.-normative",
    "href": "w01/slides.html#descriptive-vs.-normative",
    "title": "Week 1: Introduction to the Course",
    "section": "Descriptive vs. Normative",
    "text": "Descriptive vs. Normative\n\n\n\n\n\n\n\n \n  \n \n\n\n\n\n\n\nbin Laden (2005)\n\n\n\n\n\n\n\n\n\n\n\n\nDescriptive Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years”\nNormative Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years, and that is a good justification”\n\n\nDescriptively True (empirically verifiable)\nNormatively True (entailed by axioms + descriptive facts) in some ethical systems, Normatively False (not entailed by axioms + descriptive facts) in others"
  },
  {
    "objectID": "w01/slides.html#the-is-ought-distinction",
    "href": "w01/slides.html#the-is-ought-distinction",
    "title": "Week 1: Introduction to the Course",
    "section": "The Is-Ought Distinction",
    "text": "The Is-Ought Distinction\n\n\n\n\nHume on Is vs. Ought (hume_treatise_1739?)\n\n\n\nthe author proceeds for some time in the ordinary way of reasoning\nsuddenly, instead of the usual copulations of propositions is and is not,\nI meet with no proposition that is not connected with an ought, or an ought not.\nThis change is imperceptible; but is, however, of the last consequence.\n\n\n\n\n\n\n\n\nDescriptive (Is)\nNormative (Ought)\n\n\n\n\nGrass is green (true)\nGrass ought to be green (?)\n\n\nGrass is blue (false)\nGrass ought to be blue (?)"
  },
  {
    "objectID": "w01/slides.html#what-happens-when-we-confuse-the-two",
    "href": "w01/slides.html#what-happens-when-we-confuse-the-two",
    "title": "Week 1: Introduction to the Course",
    "section": "What Happens When We Confuse The Two?",
    "text": "What Happens When We Confuse The Two?\n\n\n\n\n\n\n\nMakes it impossible to “cross the boundary” between your own and others’ beliefs\nCollective welfare: Bad on its own terms (see: wars, racism, etc.)\nSelf-interest: Prevents us from convincing other people of our arguments\n\n\n\n\n\n\nGeertz (1973)"
  },
  {
    "objectID": "w01/slides.html#collective-vs.-self-interest",
    "href": "w01/slides.html#collective-vs.-self-interest",
    "title": "Week 1: Introduction to the Course",
    "section": "Collective vs. Self-Interest",
    "text": "Collective vs. Self-Interest\n\n\n\n\n\n\n\nGood for collection of people \\(\\; \\nimplies\\) good for each individual person! (😰)\n\\(p\\) = Unions improve everyone’s workplace conditions, whether or not they pay dues\n\\(q\\) = Union dues are voluntary\n\\(p \\wedge q \\implies\\) I can obtain benefits of unions without paying\n\\(\\implies\\) Individually rational to not pay dues\n(Think also about how this applies to climate change policy) 🤔\n\n\n\n\n\n\nOlson (1965)"
  },
  {
    "objectID": "w01/slides.html#modeling-individual-vs.-societal-outcomes",
    "href": "w01/slides.html#modeling-individual-vs.-societal-outcomes",
    "title": "Week 1: Introduction to the Course",
    "section": "Modeling Individual vs. Societal Outcomes",
    "text": "Modeling Individual vs. Societal Outcomes\n\nIndividual Perspective: Individual \\(i\\) chooses whether or not to pay union dues\n\n\n\n\n\n\n\n\n\\(\\implies\\) Social Outcome: No Union\n\n\n\n\n\n\n\\(\\implies\\) Social Outcome: Union Possible\n\nKey reading: Schelling (1978), Micromotives and Macrobehavior"
  },
  {
    "objectID": "w01/slides.html#takeaway-for-policy-whitepapers",
    "href": "w01/slides.html#takeaway-for-policy-whitepapers",
    "title": "Week 1: Introduction to the Course",
    "section": "Takeaway for Policy Whitepapers",
    "text": "Takeaway for Policy Whitepapers\n\n\n\n\n\n\n\nYou cannot (just) say, “doing \\(x\\) will be better for society”\nYou must also justify benefits to individuals, or at minimum, the individual organization and its stakeholders!\n(Is this a normative or descriptive claim?)"
  },
  {
    "objectID": "w01/slides.html#data-science-for-who",
    "href": "w01/slides.html#data-science-for-who",
    "title": "Week 1: Introduction to the Course",
    "section": "Data Science for Who?",
    "text": "Data Science for Who?\n\nWhat are the processes by which data is (or is not) measured, recorded, and distributed?\nWho are the agents doing or not-doing these things?\n\n\nThe Library of Missing Datasets. From D’Ignazio and Klein (2020)"
  },
  {
    "objectID": "w01/slides.html#example-measuring-freedom-and-human-rights",
    "href": "w01/slides.html#example-measuring-freedom-and-human-rights",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: Measuring “Freedom” and “Human Rights”",
    "text": "Example: Measuring “Freedom” and “Human Rights”"
  },
  {
    "objectID": "w01/slides.html#methodological-individualism",
    "href": "w01/slides.html#methodological-individualism",
    "title": "Week 1: Introduction to the Course",
    "section": "Methodological Individualism",
    "text": "Methodological Individualism\n\nAtoms exhibit properties which are fruitful for understanding the physical world: we can study these properties as “building blocks” \\(\\leadsto\\) interactions among atoms with various properties give rise to higher-level physical “things” (molecules, chemicals, cells, organisms)\nIndividuals exhibit properties which are fruitful for understanding the social world: we can study these properties as “building blocks” \\(\\leadsto\\) interactions among individuals with various properties give rise to higher-level social processes (dyads, groups, institutions)\n\n\n\nFor overthinkers: quarks \\(\\leadsto\\) atoms as mental modules \\(\\leadsto\\) individuals 😉 (Fodor 1983)"
  },
  {
    "objectID": "w01/slides.html#structural-domination-the-grapes-of-wrath",
    "href": "w01/slides.html#structural-domination-the-grapes-of-wrath",
    "title": "Week 1: Introduction to the Course",
    "section": "Structural Domination: The Grapes of Wrath",
    "text": "Structural Domination: The Grapes of Wrath\n\nBut… I built it with my hands! Straightened old nails to put the sheathing on!\nIt’s not me. There’s nothing I can do. I’ll lose my job if I don’t do it. And look—suppose you kill me? They’ll hang you, and long before you’re hung there’ll be another guy here, he’ll bump the house down. You’re not killing the right guy.\nThat’s so… Who gave you orders? I’ll go after him. He’s the one to kill.\nYou’re wrong. He got his orders from the bank. ‘Clear those people out or it’s your job.’\nWell, there’s a president of the bank. A board of directors. I’ll fill up my rifle, head to the bank.\nThe bank gets orders from the East. ‘Make the land show profit or we’ll close you up.’ We’re sorry. It’s not us. It’s the monster. The bank isn’t like a man.\nYes, but the bank is only made of men!\nNo, you’re wrong there—quite wrong. The bank is something else than men. It happens nowadays that every man in a bank hates what the bank does, and yet the bank does it. The bank is something more than men, I tell you.\nI got to figure… We all got to figure. There’s some way to stop this. There’s got to be some way to stop this. It’s not like lightning or earthquakes. We’ve got a bad thing made by men, and by God, isn’t that something we should be able to change? (Steinbeck 1939)"
  },
  {
    "objectID": "w01/slides.html#ontology-individuals-and-structures",
    "href": "w01/slides.html#ontology-individuals-and-structures",
    "title": "Week 1: Introduction to the Course",
    "section": "Ontology: Individuals and Structures",
    "text": "Ontology: Individuals and Structures\nMethodological Individualism and Structural Domination!\n\n\n\nNo longer much preoccupied with such crudities as ‘conspiracy theory’, [progressives] have become quite monolithic in attributing all things negative to handy abstractions like ‘capitalism’, ‘the state’, ‘structural oppression’, and ‘hierarchy’. Hence they have been able to conjure what might be termed the ‘miracle of immaculate genocide’, a form of genocide, that is, in which there are no actual perpetrators and no one who might ‘really’ be deemed culpable […] The parallels between this ‘cutting edge’ conception and the defense mounted by postwar Germans are as eerie as they are obvious. (Churchill 2003)\n\n\n\n\n\nGiddens (1979)"
  },
  {
    "objectID": "w01/slides.html#operationalization",
    "href": "w01/slides.html#operationalization",
    "title": "Week 1: Introduction to the Course",
    "section": "Operationalization",
    "text": "Operationalization\n\n\n\nThink of claims commonly made based on “data”:\n\nMarkets create economic prosperity\nA glass of wine in the evening prevents cancer\nPolicing makes communities safer\n\nHow exactly are “prosperity”, “preventing cancer”, “policing”, “community safety” being measured? Who is measuring? Mechanisms for feedback \\(\\leadsto\\) updates?\n\n\n\n\n\n\n\n\nStiglitz, Sen, and Fitoussi (2010)"
  },
  {
    "objectID": "w01/slides.html#what-is-being-compared",
    "href": "w01/slides.html#what-is-being-compared",
    "title": "Week 1: Introduction to the Course",
    "section": "What Is Being Compared?",
    "text": "What Is Being Compared?\n\n\n\n\n\n\n\n\nApples\nOranges\nPears\n\n\n\n\nPolities w/250-500M people (US ~335M, UP ~250M, EU ~450M)\nPolities w/11M people in the Caribbean (Cuba, Haiti, Dominican Republic)\nPolities w/over 1 billion people (China ~1.4B, India ~1.4B, Africa ~1.4B, ⬆️+⬇️ America ~1B)\n\n\nDemocracies (US)\nDemocracies til they democratically elected someone US didn’t like (Iran, Guatemala, Chile)\nNon-democracies which brutally repress democratic movements w/US arms (Saudi Arabia)\n\n\nColonizing polities (US)\nPolities colonized by them (Philippines)\nNon-colonized polities (Ethiopia, Thailand)\n\n\nPolities w/infrastructure built up over 250+ yrs via slave labor (US 🇺🇸)\nPolities populated by former slaves (Liberia 🇱🇷)\nPolities that paid reparations to descendants of [certain] enslaved groups (Germany)\n\n\nPolities independent since 1776 (US)\nPolities independent since 1990 (Namibia)\nNon-self-governing polities (Puerto Rico, Palestine, New Caledonia)\n\n\nPolities enforcing a 60 yr embargo on Cuba (US)\nPolities with a 60 yr embargo imposed on them by US (Cuba)\nPolities without a 60 yr embargo imposed on them by US (…)"
  },
  {
    "objectID": "w01/slides.html#how-are-they-being-compared",
    "href": "w01/slides.html#how-are-they-being-compared",
    "title": "Week 1: Introduction to the Course",
    "section": "How Are They Being Compared?",
    "text": "How Are They Being Compared?\n\nWhat metric? Over what timespan?\nWhat unit of obs \\(\\leadsto\\) agg function \\(\\leadsto\\) level of aggregation?\n\n\nDrèze and Sen (1991)"
  },
  {
    "objectID": "w01/slides.html#there-is-still-hope-i-promise",
    "href": "w01/slides.html#there-is-still-hope-i-promise",
    "title": "Week 1: Introduction to the Course",
    "section": "…There is Still Hope! I Promise!",
    "text": "…There is Still Hope! I Promise!\n\nFair Comparison through Statistical Matching:\nLyall (2020): “Treating certain ethnic groups as second-class citizens […] leads victimized soldiers to subvert military authorities once war begins. The higher an army’s inequality, the greater its rates of desertion, side-switching, and casualties”\n\n\nMatching constructs pairs of belligerents that are similar across a wide range of traits thought to dictate battlefield performance but that vary in levels of prewar inequality. The more similar the belligerents, the better our estimate of inequality’s effects, as all other traits are shared and thus cannot explain observed differences in performance, helping assess how battlefield performance would have improved (declined) if the belligerent had a lower (higher) level of prewar inequality.\nSince [non-matched] cases are dropped […] selected cases are more representative of average belligerents/wars than outliers with few or no matches, [providing] surer ground for testing generalizability of the book’s claims than focusing solely on canonical but unrepresentative usual suspects (Germany, the United States, Israel)"
  },
  {
    "objectID": "w01/slides.html#does-inequality-cause-poor-military-performance",
    "href": "w01/slides.html#does-inequality-cause-poor-military-performance",
    "title": "Week 1: Introduction to the Course",
    "section": "Does Inequality Cause Poor Military Performance?",
    "text": "Does Inequality Cause Poor Military Performance?\n\n\n\n\n\n\n\n\nCovariates\nSultanate of Morocco Spanish-Moroccan War, 1859-60\nKhanate of Kokand War with Russia, 1864-65\n\n\n\n\n\\(X\\): Military Inequality\nLow (0.01)\nExtreme (0.70)\n\n\n\\(\\mathbf{Z}\\): Matched Covariates:\n\n\n\n\nInitial relative power\n66%\n66%\n\n\nTotal fielded force\n55,000\n50,000\n\n\nRegime type\nAbsolutist Monarchy (−6)\nAbsolute Monarchy (−7)\n\n\nDistance from capital\n208km\n265km\n\n\nStanding army\nYes\nYes\n\n\nComposite military\nYes\nYes\n\n\nInitiator\nNo\nNo\n\n\nJoiner\nNo\nNo\n\n\nDemocratic opponent\nNo\nNo\n\n\nGreat Power\nNo\nNo\n\n\nCivil war\nNo\nNo\n\n\nCombined arms\nYes\nYes\n\n\nDoctrine\nOffensive\nOffensive\n\n\nSuperior weapons\nNo\nNo\n\n\nFortifications\nYes\nYes\n\n\nForeign advisors\nYes\nYes\n\n\nTerrain\nSemiarid coastal plain\nSemiarid grassland plain\n\n\nTopography\nRugged\nRugged\n\n\nWar duration\n126 days\n378 days\n\n\nRecent war history w/opp\nYes\nYes\n\n\nFacing colonizer\nYes\nYes\n\n\nIdentity dimension\nSunni Islam/Christian\nSunni Islam/Christian\n\n\nNew leader\nYes\nYes\n\n\nPopulation\n8–8.5 million\n5–6 million\n\n\nEthnoling fractionalization (ELF)\nHigh\nHigh\n\n\nCiv-mil relations\nRuler as commander\nRuler as commander\n\n\n\\(Y\\): Battlefield Performance:\n\n\n\n\nLoss-exchange ratio\n0.43\n0.02\n\n\nMass desertion\nNo\nYes\n\n\nMass defection\nNo\nNo\n\n\nFratricidal violence\nNo\nYes"
  },
  {
    "objectID": "w01/slides.html#bro-snapped",
    "href": "w01/slides.html#bro-snapped",
    "title": "Week 1: Introduction to the Course",
    "section": "Bro Snapped",
    "text": "Bro Snapped\n(I have no dog in this fight, I’m not trying to improve military performance of an army, but got damn)"
  },
  {
    "objectID": "w01/slides.html#implementation",
    "href": "w01/slides.html#implementation",
    "title": "Week 1: Introduction to the Course",
    "section": "Implementation",
    "text": "Implementation\n\n\n\n\n\n\n\n\n\nFrom D’Ignazio and Klein (2020), Ch. 6 (see also)\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Lerman and Weaver (2014) (see also)"
  },
  {
    "objectID": "w01/slides.html#fairness",
    "href": "w01/slides.html#fairness",
    "title": "Week 1: Introduction to the Course",
    "section": "Fairness… 🧐",
    "text": "Fairness… 🧐\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Lily Hu, Direct Effects: How Should We Measure Racial Discrimination?, Phenomenal World, 25 September 2020\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: From Kasy and Abebe (2021)"
  },
  {
    "objectID": "w01/slides.html#and-inverse-fairness",
    "href": "w01/slides.html#and-inverse-fairness",
    "title": "Week 1: Introduction to the Course",
    "section": "…And INVERSE Fairness 🤯",
    "text": "…And INVERSE Fairness 🤯\n\nFrom Machine Learning What Policymakers Value (bjorkegren_machine_2022?)"
  },
  {
    "objectID": "w01/slides.html#facial-recognition-algorithms",
    "href": "w01/slides.html#facial-recognition-algorithms",
    "title": "Week 1: Introduction to the Course",
    "section": "Facial Recognition Algorithms",
    "text": "Facial Recognition Algorithms\n\n\n\n\n\n\n\n\n\nFacia.ai (2023)\n\n\n\n\n\n\n\nWellcome Collection (1890)\n\n\n\n\n\n\n\n\n\nOuz (2023)\n\n\n\n\n\n\n\nWang and Kosinski (2018)"
  },
  {
    "objectID": "w01/slides.html#large-language-models",
    "href": "w01/slides.html#large-language-models",
    "title": "Week 1: Introduction to the Course",
    "section": "Large Language Models",
    "text": "Large Language Models\n\n\n\nWhen to retain biases…\n\n\n\n…and when to debias\n\n\n\n\n\n\n\n\n\n\nFigure 4: From Schiebinger et al. (2020)\n\n\n\n\n\n\n\n\n\n\nFigure 5: From DeepLearning.AI’s Deep Learning course"
  },
  {
    "objectID": "w01/slides.html#military-and-police-applications-of-ai",
    "href": "w01/slides.html#military-and-police-applications-of-ai",
    "title": "Week 1: Introduction to the Course",
    "section": "Military and Police Applications of AI",
    "text": "Military and Police Applications of AI\n\n\n\n\n\n\n\n\n\nAyyub (2019)\n\n\n\n\n\n\n\nMcNeil (2022)"
  },
  {
    "objectID": "w01/slides.html#from-week-7-onwards-you-work-at-a-think-tank",
    "href": "w01/slides.html#from-week-7-onwards-you-work-at-a-think-tank",
    "title": "Week 1: Introduction to the Course",
    "section": "From Week 7 Onwards, You Work At A Think Tank",
    "text": "From Week 7 Onwards, You Work At A Think Tank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMorozov (2015)\n\n\n\n\n\n\n\nFrom Ames (2014)"
  },
  {
    "objectID": "w01/slides.html#references",
    "href": "w01/slides.html#references",
    "title": "Week 1: Introduction to the Course",
    "section": "References",
    "text": "References\n\n\nAmes, Mark. 2014. “The Techtopus: How Silicon Valley’s Most Celebrated CEOs Conspired to Drive down 100,000 Tech Engineers’ Wages,” January. http://web.archive.org/web/20200920042121/https://pando.com/2014/01/23/the-techtopus-how-silicon-valleys-most-celebrated-ceos-conspired-to-drive-down-100000-tech-engineers-wages/.\n\n\nAyyub, Rami. 2019. “App Aims to Help Palestinian Drivers Find Their Way Around Checkpoints.” The Times of Israel, August. https://www.timesofisrael.com/app-aims-to-help-palestinian-drivers-find-their-way-around-checkpoints/.\n\n\nbin Laden, Osama. 2005. Messages to the World: The Statements of Osama Bin Laden. Verso Books.\n\n\nBowles, Samuel. 2016. The Moral Economy: Why Good Incentives Are No Substitute for Good Citizens. Yale University Press.\n\n\nChurchill, Ward. 2003. On the Justice of Roosting Chickens: Reflections on the Consequences of U.S. Imperial Arrogance and Criminality. AK Press.\n\n\nD’Ignazio, Catherine, and Lauren F. Klein. 2020. Data Feminism. MIT Press.\n\n\nDrèze, Jean, and Amartya Sen. 1991. “China and India.” In Hunger and Public Action, 0. Oxford University Press. https://doi.org/10.1093/0198283652.003.0011.\n\n\nFacia.ai. 2023. “Facial Recognition Helps Vendors in Healthcare.” Facia.ai. https://facia.ai/blog/facial-recognition-healthcare/.\n\n\nFodor, Jerry A. 1983. The Modularity of Mind. MIT Press.\n\n\nGeertz, Clifford. 1973. The Interpretation Of Cultures. Basic Books.\n\n\nGiddens, Anthony. 1979. Central Problems in Social Theory: Action, Structure, and Contradiction in Social Analysis. University of California Press.\n\n\nKasy, Maximilian, and Rediet Abebe. 2021. “Fairness, Equality, and Power in Algorithmic Decision-Making.” In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 576–86. FAccT ’21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445919.\n\n\nLerman, Amy E., and Vesla M. Weaver. 2014. Arresting Citizenship: The Democratic Consequences of American Crime Control. University of Chicago Press.\n\n\nLyall, Jason. 2020. Divided Armies: Inequality and Battlefield Performance in Modern War. Princeton University Press.\n\n\nMarx, Karl. 1845. Thesen über Feuerbach. Stuttgart: J. H. W. Dietz. https://de.wikisource.org/wiki/Thesen_%C3%BCber_Feuerbach.\n\n\nMcNeil, Sam. 2022. “Israel Deploys Remote-Controlled Robotic Guns in West Bank.” AP News, November. https://apnews.com/article/technology-business-israel-robotics-west-bank-cfc889a120cbf59356f5044eb43d5b88.\n\n\nMorozov, Evgeny. 2015. “Socialize the Data Centres!” New Left Review, no. 91 (February): 45–66.\n\n\nOlson, Mancur. 1965. The Logic of Collective Action. Harvard University Press.\n\n\nOuz. 2023. “Google Pixel 8 Face Unlock Vulnerability Discovered, Allowing Others to Unlock Devices.” Gizmochina. https://www.gizmochina.com/2023/10/16/google-pixel-8-face-unlock/.\n\n\nRousseau, Jean-Jacques. 1762. The Social Contract. Geneva: J. M. Dent.\n\n\nSchelling, Thomas C. 1978. Micromotives and Macrobehavior. Norton.\n\n\nSchiebinger, Londa, Ineke Klinga, Hee Young Paik, Inés Sánchez de Madariaga, Martina Schraudner, and Marcia Stefanick. 2020. “Machine Translation: Gendered Innovations.” http://genderedinnovations.stanford.edu/case-studies/nlp.html#tabs-2.\n\n\nSteinbeck, John. 1939. The Grapes of Wrath. Penguin.\n\n\nSteingart, Alma. 2023. Axiomatics: Mathematical Thought and High Modernism. University of Chicago Press.\n\n\nStiglitz, Joseph E., Amartya Sen, and Jean-Paul Fitoussi. 2010. Mismeasuring Our Lives: Why GDP Doesn’t Add Up. The New Press.\n\n\nWang, Yilun, and Michal Kosinski. 2018. “Deep Neural Networks Are More Accurate Than Humans at Detecting Sexual Orientation from Facial Images.” Journal of Personality and Social Psychology 114 (2): 246–57. https://doi.org/10.1037/pspa0000098.\n\n\nWellcome Collection. 1890. “Composite Photographs: \"The Jewish Type\".” https://wellcomecollection.org/works/ngq29vyw.\n\n\nWhitehead, Alfred North, and Bertrand Russell. 1910. Principia Mathematica. Cambridge University Press."
  },
  {
    "objectID": "midterm.html",
    "href": "midterm.html",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "",
    "text": "The DSAN 5450 in-class midterm will start at 3:30pm on Wednesday, February 26th. It is intended to take only 1.5 hours, but you will have 3 hours to take it just in case, so that it will be due by 6:30pm.\nWe’ve covered a lot of… sometimes-disjointed topics thus far, so our goal for the midterm is to emphasize the most important takeaways from across the first six weeks of the class, by putting them in your brain’s short-term memory one more time before we dive into the second, policy-focused half of the course when you come back from spring break! As a reminder, there is a very good reason to continually try and re-remember the same course topics, coming from studies of long-term memory retention:",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#overview",
    "href": "midterm.html#overview",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "",
    "text": "The DSAN 5450 in-class midterm will start at 3:30pm on Wednesday, February 26th. It is intended to take only 1.5 hours, but you will have 3 hours to take it just in case, so that it will be due by 6:30pm.\nWe’ve covered a lot of… sometimes-disjointed topics thus far, so our goal for the midterm is to emphasize the most important takeaways from across the first six weeks of the class, by putting them in your brain’s short-term memory one more time before we dive into the second, policy-focused half of the course when you come back from spring break! As a reminder, there is a very good reason to continually try and re-remember the same course topics, coming from studies of long-term memory retention:",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#part-1-high-level-data-ethics-considerations",
    "href": "midterm.html#part-1-high-level-data-ethics-considerations",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 1: High-Level Data Ethics Considerations",
    "text": "Part 1: High-Level Data Ethics Considerations\nThis part corresponds roughly to the first two sessions of the course, where we talked about key “high-level” questions in data ethics.\n\n(1.1) The Library of Missing Datasets\nWhy does some information already exist in the form of nicely-formatted, easily-accessible datasets, while other information does not?\n\nHere the specific reference in class was to the Library of Missing Datasets, so you can check out the photos at that link for examples of missing datasets.\nThe midterm question here could, therefore, ask you to think through the process by which a certain dataset came into existence as (e.g.) a clean, easily-available .csv file, and/or why another set of data might not exist in this form.\n\n\n\n(1.2) Operationalization\nWhat types of data-ethical issues arise because of the “gap” between conceptual variables and operationalized variables?\n\nHere the main reference for you is this slide from Week 2\nFor the possible midterm question here, specifically, you should focus on the idea behind the book on the right side of that slide: “Mis-Measuring Our Lives”. That book points out the gap between the conceptual variable [economic well-being] and its operationalization as [GDP].\n\nSo, for the midterm, we might ask you to consider a conceptual variable like “fairness” or “privacy”, and think through different ways they could be operationalized as measurable quantities.",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#part-2-ethical-frameworks",
    "href": "midterm.html#part-2-ethical-frameworks",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 2: Ethical Frameworks",
    "text": "Part 2: Ethical Frameworks\n\n(2.1) Descriptive vs. Normative\nI think you all did a great job of demonstrating that you understand this distinction, through homeworks and discussions (in class and in office hours)! So, on this topic I think you can just review the basic “gist” of how this works:\nTwo types of Descriptive statements:\n\nNon-implicational statements that describe facts, like \\(1 + 1 = 2\\), are descriptive but indeterminate without a set of axioms (definitions for the symbols, in this case)\nImplicational statements that describe facts, like \\(ZFC \\implies 1 + 1 = 2\\), are descriptive and also determinate (in this case, determinately true)\n\nTwo types of Normative statements:\n\nWhen the statements are not descriptions of empirically/observationally (and intersubjectively) verifiable predicates about how things are (“Grass is green”), but are instead prescriptions of how things ought to be (“Grass ought to be green”/“It is good for grass to be green and bad for grass to be blue”), they have additional normative dimensions\nHowever, in the same way that the descriptive statement \\(1 + 1 = 2\\) goes from indeterminate to determine when we provide a set of axioms, normative statements are also transformed from indeterminate to determinate when we provide an ethical framework within which the normative statement can be evaluated.\n\n\n\n(2.2) Consequentialism vs. Deontological Ethics\nThis portion would also very much involve the two most common concrete versions of these two ethical frameworks:\n\nUtilitarianism as the most common consequentialist framework\nKantian Ethics as the most common deontological-ethical framework\n\nOn the latter two points specifically, I didn’t make the distinction as clearly as I should have in class, so I’m making it here!\nQuestion 2.5 from Homework 1 provided the following statement:\n\n«Lying is bad, since you wouldn’t want others to lie to you.»\n\nAnd then, between Consequentialism and Deontological Ethics, the correct answer was that this statement is more straightforwardly implied by Deontological Ethics. I know this one is particularly difficult to think through, but I wanted to highlight it here because this is the question that really reveals the subtle-but-important distinction between these two systems:\n\nA consequentialist approach to “resolving” a dilemma around lying would, crucially, be based on a prediction of the actual consequences that would result from a possible choice, whereas\nA deontological approach differs from this in considering what makes a possible choice good or bad in-and-of-itself, without reference to the predicted consequences.\n\nThe reason I phrase the distinction in this way is because, in the above statement, you can focus on the portion after the word “since” (“since you wouldn’t want others to lie to you”):\n\nWithin a consequentialist framework, this reasoning would not itself constitute a justification for not lying, since it would have to be paired with a statement like “If I lie, then it is likely that others will lie to me”, which is not true in general! The idiom of a “white lie”, for example, comes precisely from the fact that there are often times when we feel like we should lie to people to avoid the consequence of hurting them.\nWithin a deontological framework, on the other hand, this reasoning would constitute a justification for not lying, since it corresponds precisely to the rule that was mentioned in the prior two questions: Kant’s Categorical Imperative.\nThis Categorical Imperative rule is of special interest, relative to the full set of “ethical rules” you could imagine using, because it is a rule for making ethical decisions without reference to the consequences of a particular choice:\n\nInstead of predicting what might happen if I make this choice, and judging whether it is an ethical choice on that basis…\nI now imagine what would happen hypothetically if everyone else in the world made the choice, whether or not my action would in fact make everyone else in the world make the same choice!\n\n\nI hope that explanation, and the reference to “white lies” as an example, can help make it more clear why the answer to Question 2.5 was “Deontological Ethics”. As one final point, to make it super concrete:\n\nThe reason why the answer is not Consequentialism here is because, a Consequentialist might agree that “I wouldn’t want others to lie to me”, and yet also think “But that’s not a good reason to not lie, since I could lie here without it causing others to lie to me.”\nThat is what would enable “white lies” to be acceptable under consequentialism: since you only consider the predicted consequences of your action in the “real world”, rather than in a hypothetical world where everyone does the same action, you are then able to move to a comparison of whether the benefits of lying outweigh the costs of lying, as one way to make the decision (by “calculating” the consequences!).",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#part-3-context-free-fairness-and-proxy-variables",
    "href": "midterm.html#part-3-context-free-fairness-and-proxy-variables",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 3: Context-Free Fairness and Proxy Variables",
    "text": "Part 3: Context-Free Fairness and Proxy Variables\nHere the main idea will be to think through the fairness definitions introduced in this part:\n\nFairness Through Unawareness (Removing “sensitive” variables from the dataset)\nFairness as Equalized Positive Rate\nFairness as Equalized False Positive Rate\nFairness as Equalized False Negative Rate\nFairness as Calibration\n\nAnd especially to be able to understand the “simple” cases when these might work, but also the non-simple cases where these fail to capture what we’d like a robust / actually-usable fairness measure to capture. Some straightforward questions to guide you in this thinking for this part would be, e.g.:\n\nCan we have all of these measures at once?\n\nShort answer: No. But, you should also have some degree of intuition from class about why we can’t (the impossibility results)\n\nThe first four are probably more straightforward, as things we can achieve by dropping variables (Unawarness) or by reading the entries in a confusion matrix. Calibration, however, requires a bit more thought:\n\nHow is calibration defined? The most succinct definition would just be: the requirement that the value of the risk score \\(r(X)\\) that “underlies” the decision-making algorithm (in that it is used to produce our predictions \\(\\widehat{Y}\\)) is itself a probability value—namely, the probability that a person with attributes \\(X\\) has associated outcome \\(Y\\).\nWhy is calibration desirable? Why does it help us in terms of assessing fairness? The definition in the previous bullet point is not very easy-to-understand (to me, at least), so that I interpret it as just a requirement that the risk score “tracks” the relationship between \\(X\\) and \\(Y\\) in a direct way: for example, high values of \\(\\Pr(Y \\mid X)\\) mean high values of the underlying representation \\(r(X)\\) that is used to generate \\(\\widehat{Y}\\) as a prediction of \\(Y\\).\nViewed in this way, then, I hope it makes sense that this property would be desirable in terms of interpretability: it means that, if we wanted to know why our prediction algorithm was producing some specific prediction \\(\\widehat{Y}_i\\) for a person with attributes \\(X_i\\), we could “open up the black box” of the algorithm and look directly at the risk score \\(r(X_i)\\) with respect to the risk score function \\(r(\\cdot)\\) in general, to see why it produced such a high/low value of \\(\\widehat{Y}_i\\).\nI know even that last point can still be confusing, so to me the final “piece” for understanding is to think about how: if we didn’t have calibration, then we would have no natural way of interpreting the risk function \\(r(\\cdot)\\). Since without calibration it is not constrained to represent a probability, it could take on any value—\\(\\pi\\), \\(-1000\\), \\(\\sqrt{2^{100}}\\)—and we would have no way of knowing the relationship between these values and the resulting predictions \\(\\widehat{Y}\\); no way of knowing, for example, why plugging in a person with characteristics \\(X_i\\) produced \\(r(X_i) = \\pi\\) which then led to the prediction \\(\\widehat{Y}_i = 1\\), to detain this person until trial!",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#part-4-context-sensitive-fairness",
    "href": "midterm.html#part-4-context-sensitive-fairness",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 4: Context-Sensitive Fairness",
    "text": "Part 4: Context-Sensitive Fairness\nWe spent some amount of time critiquing the fairness definitions mentioned in the previous section. This was not for the sake of judging whether they’re “good” or “bad” as such, but rather, for the sake of understanding specifically what they’re missing. Two different characterizations of what they’re missing give us our two key context-sensitive approaches to fairness, discussed in the next two sections:\n\n(4.1) Individual-Similarity-Based Fairness\n\nThe Context-Free measures fail to consider how satisfying a criterion (e.g., Equalized False Positive Rate) at a group level could trample over the rights of individuals.\n\nThe illustration of this failure that I mentioned in class boiled down to:\n\nLet \\(A_i\\) represent a sensitive attribute of individuals, such that \\(A_i = 0\\) if person \\(i\\) is white, and \\(A_i = 1\\) if person \\(i\\) is black.\nIf a police department finds itself failing to satisfy a fairness criterion like Equality of Positive Rates, in the sense that their arrest rate \\(r_1\\) for individuals with \\(A_i = 1\\) is higher than their arrest rate \\(r_0\\) for individuals with \\(A_i = 0\\), then…\nThey can quickly “resolve” this failure and satisfy the criterion by running outside and arresting the first \\(N\\) white people they see, where \\(N\\) is the number of additional white arrestees that would be necessary to make \\(r_0 = r_1\\).\n\nHowever, as this illustration hopefully makes clear, this procedure would allow satisfaction of the group-level fairness criterion, but only at the expense of violating our intuitive notions of fairness towards individuals.\nAlthough there are lots and lots of ways that this notion of individual-level fairness could be incorporated into the Context-Free fairness measures to make them Context-Sensitive, one of the most popular and straightforward ways is by constructing an indiviudal-similarity-based fairness measure, and then using it to constrain the space of possible decisions by enforcing the rule that:\n\n\n\n\n\n\nFairness Through Awareness (Dwork et al. 2011)\n\n\n\nIndividuals who are similar with respect to a task should be classified similarly.\n\n\nThe first thing I want you to note about this approach is that it specifically aims to resolve the issue we’ve already seen with utilitarianism, namely, that * Optimizing society-level desiderata (like “overall happiness”) may lead to * individuals being brutally mistreated (e.g., having their rights violated)\nYou can also hopefully see how this notion (Fairness Through Awarness) could provide a Rawls-style ordering: individual fairness lexically prior to group-level fairness (optimize group-level fairness once individual-level is satisfied).\nThen lastly, as you saw on HW2, this general notion of Fairness Through Awareness can be operationalized as a measurable quantity by, for example, implementing what is generally called metric fairness: Given a similarity metric \\(m: \\mathcal{I} \\times \\mathcal{I} \\rightarrow \\mathbb{R}\\), where \\(\\mathcal{I}\\) is the set of all individuals,\n\\[\n|D_i - D_j| \\leq m(i, j)\n\\]\nfor all pairs of individuals \\((i, j)\\). Or in other words, that the difference between the decisions \\(D_i\\) and \\(D_j\\) should be bounded above by the similarity \\(m(i,j)\\) between \\(i\\) and \\(j\\).\nThis, to me, is already slightly more than you need to know for the midterm, but if you want to dive into this Context-Sensitive approach specifically, Section 5.1 of Mitchell et al. (2021) has a really great discussion of Metric Fairness specifically.\n\n\n(4.2) Causal Fairness\nThis is the capital-B capital-D Big Deal approach to fairness, in my view, but you’ve already heard enough about that in class and on HW2!\nSo, for the midterm, instead I will just say that the key thing I want you to be comfortable with for now is drawing and interpreting Causal Diagrams like the ones I’ve shown in the slides and drawn on the board in class.\nFirst and foremost, if you absorb the Quick Intro to Probabilistic Graphical Models writeup, you are most of the way there to understanding Causal Diagrams in general, since (sweeping some details under the rug) these Causal Diagrams are primarily just PGMs where we interpret the edges (the arrows in the PGMs) as hypothesized causal effects.\nThus, for the midterm, my first goal is to test your ability to read these PGMs and understand what they’re positing (“saying”) about the world. For example, if I give you a hypothesis like\n\n\\(H_1\\): Individual \\(i\\) was arrested because they are black\n\nYou should be able to “translate” this into a causal diagram based on:\n\nA random variable \\(Y_i\\) representing whether or not an individual \\(i\\) was arrested (where we use the letter \\(Y\\) here speicifcally because we’re representing an outcome that we’re hoping to explain)\nA random variable \\(A_i\\) representing the race of individual \\(i\\), and\nAn edge \\(A_i \\rightarrow Y_i\\), representing the hypothesis that individual \\(i\\)’s specific \\(A_i\\) value (\\(A_i = a_i\\)) is what caused \\(Y_i\\) to take on individual \\(i\\)’s specific \\(Y_i\\) value (\\(Y_i = y_i = 1\\), in this case).\n\nThen, once you’re comfortable with this process of “implementing” hypotheses by constructing causal diagrams, the only other thing I think will be important for the midterm is your ability to adjudicate between two or more such diagrams on the basis of their plausibility.\nWhat I mean by that is… keep in mind the definition of causality that was given in a slide in class:\n\n\n\n\n\n\nDefining Causality (hume_treatise_1739?)\n\n\n\n\\(X\\) causes \\(Y\\) if and only if:\n\n\\(X\\) temporally precedes \\(Y\\) and\n\nIn two worlds \\(W_0\\) and \\(W_1\\) where\neverything is exactly the same except that \\(X = 0\\) in \\(W_0\\) and \\(X = 1\\) in \\(W_1\\),\n\\(Y = 0\\) in \\(W_0\\) and \\(Y = 1\\) in \\(W_1\\).\n\n\n\n\nYou should be able to use this definition to (for example) eliminate implausible causal diagrams, namely, causal diagrams which violate the basic predicates within this definition. So, for example, say I gave you the following causal diagram as a causal hypothesis regarding how toasters toast a piece of bread \\(i\\):\n\n\\(T_i\\) is a Random Variable which is \\(0\\) if the bread has not yet been placed in the toaster and \\(1\\) if has been placed in the toaster,\n\\(C_i\\) is a Random Variable which is \\(0\\) if the bread is not cooked, and \\(1\\) if the bread is cooked, and\nThere is an arrow \\(C_i \\rightarrow T_i\\)\n\nYou should be able to identify this as an implausible causal diagram—meaning, a causal diagram representing an implausible hypothesis about how toasters work, relative to the Humean notion of causality—since in our observations of how toasters work, the bread being placed in the toaster (\\(\\text{do}(T_i = 1)\\)) occurs before the bread being cooked \\(C_i = 1\\), temporally.",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#part-5-doin-thangs-causality-continued",
    "href": "midterm.html#part-5-doin-thangs-causality-continued",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 5: Doin Thangs (Causality Continued)",
    "text": "Part 5: Doin Thangs (Causality Continued)\nShort story short, the example from the end of our most recent meeting, where we showed how it’s possible to have:\n\n\\(\\Pr(Y = 1) = p_y\\), and\n\\(\\Pr(Y = 1 \\mid X = 1) \\neq p_y\\), and yet\n\\(\\Pr(Y = 1 \\mid \\text{do}(X = 1)) = p_y\\),\n\nThus revealing the fact that \\(\\Pr(Y = 1 \\mid X = 1)\\) does not capture the causal effect of \\(X\\) on \\(Y\\) in this case, which is just one specific instance of the general maxim you already know, that correlation does not imply causation.\nAnd yet, with this \\(\\text{do}(E)\\) operator (where \\(E\\) is some probabilistic event), we have something concrete that we can use to start figuring out when observing a correlation does allow us to infer a causal effect!\nThe actual figuring-out will have to wait until after the midterm. But I want you to have that notion in your head when you see the \\(\\text{do}(\\cdot)\\) operator and/or a causal diagram: that these are the tools that are going to allow us to bridge this gap between correlation and causation, something that probability theory alone (i.e., the stuff you may have learned in DSAN 5100) cannot do!\nAs a preview, which I mentioned at the very very end of the “do-calculus” example I went through on the board: Pearl (2000) is literally a gigantic book that meticulously works through all possible causal diagrams1 and proves a massively important theorem that we’ll see after the midterm, which tells us precisely what conditions need to be met (in a given causal system) for us to be able to infer causal effects from conditional probabilities.",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#references",
    "href": "midterm.html#references",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "References",
    "text": "References\n\n\nDwork, Cynthia, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Rich Zemel. 2011. “Fairness Through Awareness.” arXiv. https://doi.org/10.48550/arXiv.1104.3913.\n\n\nMitchell, Shira, Eric Potash, Solon Barocas, Alexander D’Amour, and Kristian Lum. 2021. “Algorithmic Fairness: Choices, Assumptions, and Definitions.” Annual Review of Statistics and Its Application 8 (1): 141–63. https://doi.org/10.1146/annurev-statistics-042720-125902.\n\n\nPearl, Judea. 2000. Causality: Models, Reasoning, and Inference. Cambridge University Press.",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#footnotes",
    "href": "midterm.html#footnotes",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNot like, one-by-one, but by mathematically characterizing all of the possibilities, like how we can say that «Assuming Euclid’s 5th Postulate, the interior angles of a triangle sum to 180°», despite not having gone one-by-one through every triangle.↩︎",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Hare (1952), The Language of Morals [PDF]\n\nThis is the canonical book that explains, in excruciating but necessary detail, the linguistic “core” of the descriptive-versus-normative distinction. It’s overkill to read from cover-to-cover if you just want the gist of the concepts, but if you’re curious about how we can develop a “logic” of normative statements like we have for descriptive statements, this is the key text imo!\n\nKorsgaard (1996), The Sources of Normativity [PDF]\n\nThis is… definitely up there among my favorite books of all time on this topic (after wading through many of them during the PhD exam gauntlet I mentioned in Week 1): it does what I wish every ethical-philosophy book did, which is, continuing to ask but why?!? to every theory of ethical justification, until it reaches a perspective which (not coincidentally) is quite close to the perspective we adopt early on in this course!\n\nRoemer (1996), Theories of Distributive Justice [PDF]\n\nI won’t lie to you, this book is pretty brutal in terms of being a mathematical “deep dive” into how the ethical frameworks we discuss in this class can be built up from a set of axioms. So, I don’t recommend the whole thing (that’s why there are two more Roemer books in this section, which are more applied looks at particular ethical frameworks!)\nThe two parts we will draw on, which I do therefore recommend, are the explanations of utility functions in Chapter 1 and of Social Welfare Functionals in Chapter 4\n\n\n\n\n\n\nRoemer (1988), Free to Lose: An Introduction to Marxist Economic Philosophy [PDF]\nAnderson (2017), Private Government: How Employers Rule Our Lives (And Why We Don’t Talk About It) [PDF] [EPUB] [MOBI]\nRawls (1971), A Theory of Justice [PDF]\nRoemer (1998), Equality of Opportunity [PDF]",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#normative-vs.-descriptive-ethical-frameworks",
    "href": "resources.html#normative-vs.-descriptive-ethical-frameworks",
    "title": "Resources",
    "section": "",
    "text": "Hare (1952), The Language of Morals [PDF]\n\nThis is the canonical book that explains, in excruciating but necessary detail, the linguistic “core” of the descriptive-versus-normative distinction. It’s overkill to read from cover-to-cover if you just want the gist of the concepts, but if you’re curious about how we can develop a “logic” of normative statements like we have for descriptive statements, this is the key text imo!\n\nKorsgaard (1996), The Sources of Normativity [PDF]\n\nThis is… definitely up there among my favorite books of all time on this topic (after wading through many of them during the PhD exam gauntlet I mentioned in Week 1): it does what I wish every ethical-philosophy book did, which is, continuing to ask but why?!? to every theory of ethical justification, until it reaches a perspective which (not coincidentally) is quite close to the perspective we adopt early on in this course!\n\nRoemer (1996), Theories of Distributive Justice [PDF]\n\nI won’t lie to you, this book is pretty brutal in terms of being a mathematical “deep dive” into how the ethical frameworks we discuss in this class can be built up from a set of axioms. So, I don’t recommend the whole thing (that’s why there are two more Roemer books in this section, which are more applied looks at particular ethical frameworks!)\nThe two parts we will draw on, which I do therefore recommend, are the explanations of utility functions in Chapter 1 and of Social Welfare Functionals in Chapter 4\n\n\n\n\n\n\nRoemer (1988), Free to Lose: An Introduction to Marxist Economic Philosophy [PDF]\nAnderson (2017), Private Government: How Employers Rule Our Lives (And Why We Don’t Talk About It) [PDF] [EPUB] [MOBI]\nRawls (1971), A Theory of Justice [PDF]\nRoemer (1998), Equality of Opportunity [PDF]",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#fairness-in-ai-context-sensitive-fairness",
    "href": "resources.html#fairness-in-ai-context-sensitive-fairness",
    "title": "Resources",
    "section": "Fairness in AI / Context-Sensitive Fairness",
    "text": "Fairness in AI / Context-Sensitive Fairness\n\nBarocas, Hardt, and Narayanan (2023), Fairness and Machine Learning: Limitations and Opportunities [PDF]\n\nThis will be our main reference during this portion of the course, and is available for free (legally!) online!\n\nKasy and Abebe (2021), “Fairness, Equality, and Power in Algorithmic Decision-Making”, FAccT ’21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency [PDF]",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#econometric-policy-evaluation",
    "href": "resources.html#econometric-policy-evaluation",
    "title": "Resources",
    "section": "Econometric Policy Evaluation",
    "text": "Econometric Policy Evaluation\n\n(bjorkegren_machine_2022?), “(Machine) Learning what Policymakers Value”, EAAMO (Equity and Access in Algorithms, Mechanisms, and Optimization) [PDF]",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "w13/index.html",
    "href": "w13/index.html",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#jeffs-laying-out-biases-corner",
    "href": "w13/index.html#jeffs-laying-out-biases-corner",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Jeff’s Laying-Out-Biases Corner",
    "text": "Jeff’s Laying-Out-Biases Corner\n\n(aka 60-second soapbox)\nI… spent most of my teens/20s in meetings, rallies, etc., yelling at capitalism, imperialism, and the like\nEx: Cringe-era Jeff did an interview with an HK newspaper, where I distinctly remember a whole spiel about:\n\n\nI felt it was important to live and work specifically in Beijing, Shenzhen, and Hong Kong, because in the US we’re taught that anything besides American Capitalism is monolithically evil, so I’m hoping to see for myself how both capitalism and its alternatives are experienced by people in all three",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#section",
    "href": "w13/index.html#section",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "",
    "text": "Which they dutifully reported in a very fair paraphrase:",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#the-reason-i-mention-that",
    "href": "w13/index.html#the-reason-i-mention-that",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "The Reason I Mention That!",
    "text": "The Reason I Mention That!\n\n\n\n\n\n\n\nAcknowledging exclusion vs. thinking through of why ppl are excluded and fixing it\nFavorite non-controversial example: land acknowledgement at pro-Israel summer camps\n\n\n\n\n\n\n\n\n\n\n\nFraser and Honneth (2003)",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#the-standpoint-problem-revisited",
    "href": "w13/index.html#the-standpoint-problem-revisited",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "The Standpoint Problem Revisited",
    "text": "The Standpoint Problem Revisited\n\nProblem statement: Jeff can’t possibly “teach” data-ethical issues, w.r.t. how they affect women, in the same manner he can teach e.g. how to take a derivative\nSolution 1: Have a woman teach a guest lecture \\(\\rightarrow\\) (Possibility) Problem solved; (Possibility) Forcing additional labor onto women (see: 3 slides from now)\nSolution 2: Utilize the immense labor women have already put into trying to explain these issues to men with power, and amplify these already-existing products of this already-expended labor",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#specifically-chosen-examples",
    "href": "w13/index.html#specifically-chosen-examples",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Specifically-Chosen Examples",
    "text": "Specifically-Chosen Examples",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#with-great-privilege-comes-great-responsibility",
    "href": "w13/index.html#with-great-privilege-comes-great-responsibility",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "With Great Privilege Comes Great Responsibility",
    "text": "With Great Privilege Comes Great Responsibility\n\nWhat is the most damage I can do, given my biography, abilities, and commitments, to the racial order and rule of capital? (Joel Olson)",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#youre-really-not-gonna-like-this-one-so-ill-just-show-it-real-quick-and-move-on",
    "href": "w13/index.html#youre-really-not-gonna-like-this-one-so-ill-just-show-it-real-quick-and-move-on",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "(You’re Really Not Gonna Like This One, So I’ll Just Show It Real Quick And Move On)",
    "text": "(You’re Really Not Gonna Like This One, So I’ll Just Show It Real Quick And Move On)\n\nDolezal no doubt has her issues and idiosyncrasies, but, especially if the judgment of the NAACP counts for anything in the matter, I’d take her in a trade for Clarence Thomas, Cory Booker, and Condi Rice.\n\n\nOr would Dolezal’s “not even close to being black” mean that she was raised outside of “authentic” black idiom or cultural experience? But whose black idiom or cultural experience would that be? Is there really an irreducible, definitive one? If so, on which Racial Voice blog or Ivy League campus might we find it?\n\n\nIn Blay’s narrow political universe, the NAACP branch presidency is an honorific to be awarded on the basis of ascriptive categories like race and gender, not the result of effective work on behalf of the Association’s mission and goals.\n\n(Adolph Reed, “From Jenner to Dolezal: One Trans Good, the Other Not So Much”)",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#the-diversity-in-tech-industrial-complex",
    "href": "w13/index.html#the-diversity-in-tech-industrial-complex",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "The “Diversity in Tech”-Industrial Complex",
    "text": "The “Diversity in Tech”-Industrial Complex\n\nProblem: Not enough diversity in tech\nSolution 1: Intervene on the causal pathways leading to this outcome (incl. studying/tracing causal pathways)\n\nCosts borne by tech companies; benefits accrue to marginalized ppl ❌🙅‍♂️⏹️\n\nSolution 2: Make marginalized ppl in tech jobs do tech jobs plus also extra job of explaining their marginalization to non-marginalized ppl (Third Shift?), who go home feeling good that they went to the diversity in tech panel (Brecht)\n\nCosts borne by marginalized ppl; benefits accrue to tech companies ✅🎰🤑",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#see-also",
    "href": "w13/index.html#see-also",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "(See Also)",
    "text": "(See Also)",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#diversity-vs.-fairness-justice",
    "href": "w13/index.html#diversity-vs.-fairness-justice",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "“Diversity” vs. Fairness / Justice",
    "text": "“Diversity” vs. Fairness / Justice\n\n(Only single-quoted, bc not as bad as “““terrorism”“” or “““smartness”““, but still p ill-defined!)",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#diversity-vs.-fairness-justice-1",
    "href": "w13/index.html#diversity-vs.-fairness-justice-1",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Diversity vs. Fairness / Justice",
    "text": "Diversity vs. Fairness / Justice",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#epistemological-one-way-mirror-2-electric-boogaloo",
    "href": "w13/index.html#epistemological-one-way-mirror-2-electric-boogaloo",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Epistemological One-Way Mirror 2: Electric Boogaloo",
    "text": "Epistemological One-Way Mirror 2: Electric Boogaloo\n\nRepresentation of the world, like the world itself, is the work of men; they describe it from their own point of view, which they confuse with the absolute truth.\n\n(Beauvoir 1949)",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#it-goes-without-saying",
    "href": "w13/index.html#it-goes-without-saying",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "“It Goes Without Saying”",
    "text": "“It Goes Without Saying”\n\nWhiteness and maleness are implicit. They are unquestioned. They are the default. And this reality is inescapable for anyone whose identity does not go without saying […] For anyone who is used to jarring up against a world that has not been designed around them and their needs.\n\n\nBelief in the objectivity, the rationality, the, as Catherine Mackinnon has it, “point-of-viewlessness” of the white, male perspective. Because this perspective is not articulated as white and male (because it doesn’t need to be), because it is the norm, it is presumed not to be subjective.",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#people-male-animal-male",
    "href": "w13/index.html#people-male-animal-male",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "People = Male, Animal = Male",
    "text": "People = Male, Animal = Male\n\n“When I say ‘he’ I really mean ‘he or she’, obviously”\nExcept… irrespective of what you really mean, or whether it’s ‘obvious’, it goes out into the world and has effects (reification),\nFrom childhood (Vervecken, Hannover, and Wolter 2013)\nTo job-hunting (Bem and Bem 1973)\nAnd beyond (Sczesny, Formanowicz, and Moser 2016)\nA stuffed animal must be “super-feminine” before “even close to half of participants will refer to it as she rather than he”. (Lambdin et al. 2003)",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#the-cowan-paradox",
    "href": "w13/index.html#the-cowan-paradox",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "The Cowan “Paradox”",
    "text": "The Cowan “Paradox”\n\n\n\n\n\n\n\nFor many ages to come the old Adam will be so strong in us that everybody will need to do some work if he [sic] is to be contented […] But beyond this, we shall endeavour to spread the bread thin on the butter—to make what work there is still to be done to be as widely shared as possible. Three-hour shifts or a fifteen-hour week may put off the problem for a great while. For three hours a day is quite enough to satisfy the old Adam in most of us!\n\n(John Maynard Keynes, “Economic Possibilities for our Grandchildren”, 1930)\n\n\n\n\n\nCowan (1983)",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#solutions-via-causal-historical-analysis",
    "href": "w13/index.html#solutions-via-causal-historical-analysis",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Solutions via Causal Historical Analysis",
    "text": "Solutions via Causal Historical Analysis\n\nThe data: historical cases of attempts to end oppression\nDependent variable: Did they succeed or were they successfully repressed?\n(You’re not gonna like this one either…)",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#instances-of-oppression-and-their-termination",
    "href": "w13/index.html#instances-of-oppression-and-their-termination",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Instances of Oppression and their Termination",
    "text": "Instances of Oppression and their Termination\n\nSlavery?\nColonialism?\nApartheid in South Africa / Rhodesia?\nThe Ethnic Cleansing of Palestine?\nThankfully, all of these were ended peacefully, and in ways that were agreeable to everyone involved, especially those who benefitted from them!!! 🥳🕺",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#great-moments-in-peaceful-protest-history",
    "href": "w13/index.html#great-moments-in-peaceful-protest-history",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Great Moments in Peaceful Protest History",
    "text": "Great Moments in Peaceful Protest History\n\n\n\nFrom The Nib (The Revolution WILL Be Given Permission)",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/index.html#references",
    "href": "w13/index.html#references",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "References",
    "text": "References\n\n\nBeauvoir, Simone de. 1949. The Second Sex. Knopf Doubleday Publishing Group.\n\n\nBem, Sandra L, and Daryl J. Bem. 1973. “Does Sex-biased Job Advertising ‘Aid and Abet’ Sex Discrimination?1.” Journal of Applied Social Psychology 3 (1): 6–18. https://doi.org/10.1111/j.1559-1816.1973.tb01290.x.\n\n\nCowan, Ruth Schwartz. 1983. More Work For Mother. Basic Books.\n\n\nFraser, Nancy, and Axel Honneth. 2003. Redistribution Or Recognition?: A Political-Philosophical Exchange. Verso.\n\n\nLambdin, Jennifer R., Kristen M. Greer, Kari Selby Jibotian, Kelly Rice Wood, and Mykol C. Hamilton. 2003. “The Animal = Male Hypothesis: Children’s and Adults’ Beliefs About the Sex of Non–Sex-Specific Stuffed Animals.” Sex Roles 48 (11): 471–82. https://doi.org/10.1023/A:1023567010708.\n\n\nSczesny, Sabine, Magda Formanowicz, and Franziska Moser. 2016. “Can Gender-Fair Language Reduce Gender Stereotyping and Discrimination?” Frontiers in Psychology 7 (February). https://doi.org/10.3389/fpsyg.2016.00025.\n\n\nVervecken, Dries, Bettina Hannover, and Ilka Wolter. 2013. “Changing (S)expectations: How Gender Fair Job Descriptions Impact Children’s Perceptions and Interest Regarding Traditionally Male Occupations.” Journal of Vocational Behavior 82 (3): 208–20. https://doi.org/10.1016/j.jvb.2013.01.008.",
    "crumbs": [
      "Week 13: {{< var w13.date-md >}}"
    ]
  },
  {
    "objectID": "w13/slides.html#jeffs-laying-out-biases-corner",
    "href": "w13/slides.html#jeffs-laying-out-biases-corner",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Jeff’s Laying-Out-Biases Corner",
    "text": "Jeff’s Laying-Out-Biases Corner\n\n(aka 60-second soapbox)\nI… spent most of my teens/20s in meetings, rallies, etc., yelling at capitalism, imperialism, and the like\nEx: Cringe-era Jeff did an interview with an HK newspaper, where I distinctly remember a whole spiel about:\n\n\nI felt it was important to live and work specifically in Beijing, Shenzhen, and Hong Kong, because in the US we’re taught that anything besides American Capitalism is monolithically evil, so I’m hoping to see for myself how both capitalism and its alternatives are experienced by people in all three"
  },
  {
    "objectID": "w13/slides.html#section",
    "href": "w13/slides.html#section",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "",
    "text": "Which they dutifully reported in a very fair paraphrase:"
  },
  {
    "objectID": "w13/slides.html#the-reason-i-mention-that",
    "href": "w13/slides.html#the-reason-i-mention-that",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "The Reason I Mention That!",
    "text": "The Reason I Mention That!\n\n\n\n\n\n\n\nAcknowledging exclusion vs. thinking through of why ppl are excluded and fixing it\nFavorite non-controversial example: land acknowledgement at pro-Israel summer camps\n\n\n\n\n\n\n\n\n\n\n\nFraser and Honneth (2003)"
  },
  {
    "objectID": "w13/slides.html#the-standpoint-problem-revisited",
    "href": "w13/slides.html#the-standpoint-problem-revisited",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "The Standpoint Problem Revisited",
    "text": "The Standpoint Problem Revisited\n\nProblem statement: Jeff can’t possibly “teach” data-ethical issues, w.r.t. how they affect women, in the same manner he can teach e.g. how to take a derivative\nSolution 1: Have a woman teach a guest lecture \\(\\rightarrow\\) (Possibility) Problem solved; (Possibility) Forcing additional labor onto women (see: 3 slides from now)\nSolution 2: Utilize the immense labor women have already put into trying to explain these issues to men with power, and amplify these already-existing products of this already-expended labor"
  },
  {
    "objectID": "w13/slides.html#specifically-chosen-examples",
    "href": "w13/slides.html#specifically-chosen-examples",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Specifically-Chosen Examples",
    "text": "Specifically-Chosen Examples"
  },
  {
    "objectID": "w13/slides.html#with-great-privilege-comes-great-responsibility",
    "href": "w13/slides.html#with-great-privilege-comes-great-responsibility",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "With Great Privilege Comes Great Responsibility",
    "text": "With Great Privilege Comes Great Responsibility\n\nWhat is the most damage I can do, given my biography, abilities, and commitments, to the racial order and rule of capital? (Joel Olson)"
  },
  {
    "objectID": "w13/slides.html#youre-really-not-gonna-like-this-one-so-ill-just-show-it-real-quick-and-move-on",
    "href": "w13/slides.html#youre-really-not-gonna-like-this-one-so-ill-just-show-it-real-quick-and-move-on",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "(You’re Really Not Gonna Like This One, So I’ll Just Show It Real Quick And Move On)",
    "text": "(You’re Really Not Gonna Like This One, So I’ll Just Show It Real Quick And Move On)\n\nDolezal no doubt has her issues and idiosyncrasies, but, especially if the judgment of the NAACP counts for anything in the matter, I’d take her in a trade for Clarence Thomas, Cory Booker, and Condi Rice.\n\n\nOr would Dolezal’s “not even close to being black” mean that she was raised outside of “authentic” black idiom or cultural experience? But whose black idiom or cultural experience would that be? Is there really an irreducible, definitive one? If so, on which Racial Voice blog or Ivy League campus might we find it?\n\n\nIn Blay’s narrow political universe, the NAACP branch presidency is an honorific to be awarded on the basis of ascriptive categories like race and gender, not the result of effective work on behalf of the Association’s mission and goals.\n\n(Adolph Reed, “From Jenner to Dolezal: One Trans Good, the Other Not So Much”)"
  },
  {
    "objectID": "w13/slides.html#the-diversity-in-tech-industrial-complex",
    "href": "w13/slides.html#the-diversity-in-tech-industrial-complex",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "The “Diversity in Tech”-Industrial Complex",
    "text": "The “Diversity in Tech”-Industrial Complex\n\nProblem: Not enough diversity in tech\nSolution 1: Intervene on the causal pathways leading to this outcome (incl. studying/tracing causal pathways)\n\nCosts borne by tech companies; benefits accrue to marginalized ppl ❌🙅‍♂️⏹️\n\nSolution 2: Make marginalized ppl in tech jobs do tech jobs plus also extra job of explaining their marginalization to non-marginalized ppl (Third Shift?), who go home feeling good that they went to the diversity in tech panel (Brecht)\n\nCosts borne by marginalized ppl; benefits accrue to tech companies ✅🎰🤑"
  },
  {
    "objectID": "w13/slides.html#see-also",
    "href": "w13/slides.html#see-also",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "(See Also)",
    "text": "(See Also)"
  },
  {
    "objectID": "w13/slides.html#diversity-vs.-fairness-justice",
    "href": "w13/slides.html#diversity-vs.-fairness-justice",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "“Diversity” vs. Fairness / Justice",
    "text": "“Diversity” vs. Fairness / Justice\n\n(Only single-quoted, bc not as bad as “““terrorism”“” or “““smartness”““, but still p ill-defined!)"
  },
  {
    "objectID": "w13/slides.html#diversity-vs.-fairness-justice-1",
    "href": "w13/slides.html#diversity-vs.-fairness-justice-1",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Diversity vs. Fairness / Justice",
    "text": "Diversity vs. Fairness / Justice"
  },
  {
    "objectID": "w13/slides.html#epistemological-one-way-mirror-2-electric-boogaloo",
    "href": "w13/slides.html#epistemological-one-way-mirror-2-electric-boogaloo",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Epistemological One-Way Mirror 2: Electric Boogaloo",
    "text": "Epistemological One-Way Mirror 2: Electric Boogaloo\n\nRepresentation of the world, like the world itself, is the work of men; they describe it from their own point of view, which they confuse with the absolute truth.\n\n(Beauvoir 1949)"
  },
  {
    "objectID": "w13/slides.html#it-goes-without-saying",
    "href": "w13/slides.html#it-goes-without-saying",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "“It Goes Without Saying”",
    "text": "“It Goes Without Saying”\n\nWhiteness and maleness are implicit. They are unquestioned. They are the default. And this reality is inescapable for anyone whose identity does not go without saying […] For anyone who is used to jarring up against a world that has not been designed around them and their needs.\n\n\nBelief in the objectivity, the rationality, the, as Catherine Mackinnon has it, “point-of-viewlessness” of the white, male perspective. Because this perspective is not articulated as white and male (because it doesn’t need to be), because it is the norm, it is presumed not to be subjective."
  },
  {
    "objectID": "w13/slides.html#people-male-animal-male",
    "href": "w13/slides.html#people-male-animal-male",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "People = Male, Animal = Male",
    "text": "People = Male, Animal = Male\n\n“When I say ‘he’ I really mean ‘he or she’, obviously”\nExcept… irrespective of what you really mean, or whether it’s ‘obvious’, it goes out into the world and has effects (reification),\nFrom childhood (Vervecken, Hannover, and Wolter 2013)\nTo job-hunting (Bem and Bem 1973)\nAnd beyond (Sczesny, Formanowicz, and Moser 2016)\nA stuffed animal must be “super-feminine” before “even close to half of participants will refer to it as she rather than he”. (Lambdin et al. 2003)"
  },
  {
    "objectID": "w13/slides.html#the-cowan-paradox",
    "href": "w13/slides.html#the-cowan-paradox",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "The Cowan “Paradox”",
    "text": "The Cowan “Paradox”\n\n\n\n\n\n\n\nFor many ages to come the old Adam will be so strong in us that everybody will need to do some work if he [sic] is to be contented […] But beyond this, we shall endeavour to spread the bread thin on the butter—to make what work there is still to be done to be as widely shared as possible. Three-hour shifts or a fifteen-hour week may put off the problem for a great while. For three hours a day is quite enough to satisfy the old Adam in most of us!\n\n(John Maynard Keynes, “Economic Possibilities for our Grandchildren”, 1930)\n\n\n\n\n\nCowan (1983)"
  },
  {
    "objectID": "w13/slides.html#solutions-via-causal-historical-analysis",
    "href": "w13/slides.html#solutions-via-causal-historical-analysis",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Solutions via Causal Historical Analysis",
    "text": "Solutions via Causal Historical Analysis\n\nThe data: historical cases of attempts to end oppression\nDependent variable: Did they succeed or were they successfully repressed?\n(You’re not gonna like this one either…)"
  },
  {
    "objectID": "w13/slides.html#instances-of-oppression-and-their-termination",
    "href": "w13/slides.html#instances-of-oppression-and-their-termination",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Instances of Oppression and their Termination",
    "text": "Instances of Oppression and their Termination\n\nSlavery?\nColonialism?\nApartheid in South Africa / Rhodesia?\nThe Ethnic Cleansing of Palestine?\nThankfully, all of these were ended peacefully, and in ways that were agreeable to everyone involved, especially those who benefitted from them!!! 🥳🕺"
  },
  {
    "objectID": "w13/slides.html#great-moments-in-peaceful-protest-history",
    "href": "w13/slides.html#great-moments-in-peaceful-protest-history",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "Great Moments in Peaceful Protest History",
    "text": "Great Moments in Peaceful Protest History\n\nFrom The Nib (The Revolution WILL Be Given Permission)"
  },
  {
    "objectID": "w13/slides.html#references",
    "href": "w13/slides.html#references",
    "title": "Week 13: Standpoint Epistemology, Data Feminism",
    "section": "References",
    "text": "References\n\n\nBeauvoir, Simone de. 1949. The Second Sex. Knopf Doubleday Publishing Group.\n\n\nBem, Sandra L, and Daryl J. Bem. 1973. “Does Sex-biased Job Advertising ‘Aid and Abet’ Sex Discrimination?1.” Journal of Applied Social Psychology 3 (1): 6–18. https://doi.org/10.1111/j.1559-1816.1973.tb01290.x.\n\n\nCowan, Ruth Schwartz. 1983. More Work For Mother. Basic Books.\n\n\nFraser, Nancy, and Axel Honneth. 2003. Redistribution Or Recognition?: A Political-Philosophical Exchange. Verso.\n\n\nLambdin, Jennifer R., Kristen M. Greer, Kari Selby Jibotian, Kelly Rice Wood, and Mykol C. Hamilton. 2003. “The Animal = Male Hypothesis: Children’s and Adults’ Beliefs About the Sex of Non–Sex-Specific Stuffed Animals.” Sex Roles 48 (11): 471–82. https://doi.org/10.1023/A:1023567010708.\n\n\nSczesny, Sabine, Magda Formanowicz, and Franziska Moser. 2016. “Can Gender-Fair Language Reduce Gender Stereotyping and Discrimination?” Frontiers in Psychology 7 (February). https://doi.org/10.3389/fpsyg.2016.00025.\n\n\nVervecken, Dries, Bettina Hannover, and Ilka Wolter. 2013. “Changing (S)expectations: How Gender Fair Job Descriptions Impact Children’s Perceptions and Interest Regarding Traditionally Male Occupations.” Journal of Vocational Behavior 82 (3): 208–20. https://doi.org/10.1016/j.jvb.2013.01.008."
  }
]