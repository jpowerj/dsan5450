[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Welcome to DSAN 5450: Data Ethics and Policy at Georgetown University!\nThe course meets on Wednesdays from 3:30-6pm in the Walsh Building, Room 498"
  },
  {
    "objectID": "syllabus.html#course-staff",
    "href": "syllabus.html#course-staff",
    "title": "Syllabus",
    "section": "Course Staff",
    "text": "Course Staff\n\nProf. Jeff Jacobs, jj1088@georgetown.edu\n\nOffice hours: TBD\n\nTA 1\n\nOffice hours: TBD\n\nTA 2\n\nOffice hours: TBD"
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nThis graduate-level course will train students to navigate the landscape of ethical issues which arise at each step of the data science process, with an eye towards developing policy recommendations for governments and organizations seeking expert advice on how to tackle these issues from a regulatory perspective. Students will explore and critically evaluate a range of data-related issues in contemporary society, such as responsible data collection, algorithmic bias, privacy, transparency, accountability, democratic participation in data usage and data-driven decisions, and the ethical implications of emerging technologies like artificial intelligence and machine learning (self-driving cars, ChatGPT, crowd-sourced training data, etc.).\nBeginning with a set of historical case studies—instances in which scientists, engineers, and policymakers have been forced to re-evaluate their ethical intuitions in light of technological developments (nuclear power, use of social media platforms to organize protests and influence political outcomes, deployment of facial recognition software and predictive AI by police and military forces)—the course then introduces a set of general ethical frameworks (consequentialism, deontological ethics, and virtue ethics), challenging students to consider their relative strengths and weaknesses for addressing modern technological-ethical dilemmas faced by businesses, healthcare organizations, governments, and academic institutions. After a final portion of the course linking these ethical frameworks with practical regulatory and policy considerations, students will write and present a policy whitepaper analyzing a data-ethical issue of particular interest to them, integrating ethical perspectives, regulatory principles, and domain knowledge into a recommendation of best practices for the relevant agency, firm, or institution.\nThe course will thus equip students with a robust ethical “toolbox” for conscientiously gathering, interpreting, and extracting meaning from data throughout their careers as data scientists, while respecting privacy, fairness, transparency, democratic accountability, and other social concerns. Prerequisites: None. 3 credits."
  },
  {
    "objectID": "syllabus.html#course-overview",
    "href": "syllabus.html#course-overview",
    "title": "Syllabus",
    "section": "Course Overview",
    "text": "Course Overview\nThe course revolves around three “pillars”, which we’ll examine individually before bringing them together for your final projects at the end of the class.\n\nData Science\nA portion of the course will focus on introductions to cutting-edge technologies like self-driving cars, ChatGPT, facial detection algorithms, and various applications of AI to police and military technologies. For this portion, we’ll draw fairly often from the contents of the following books:\n\nCatherine D’Ignazio and Lauren F. Klein (2020). Data Feminism. Cambridge, MA: MIT Press. [Free, open-source!]\nCathy O’Neil (2016). Weapons of Math Destruction. New York, NY: Crown Books.\n\nSince there are plenty of in-depth resources available to you (e.g., other Georgetown courses!) for learning the technical details of these technologies, our goal in this course will be to learn just the particular aspects of each technology which are most relevant to the ethical and policy issues they present.\nFor example, we will look at Neural Netwok-based Machine Learning algorithms, but we will focus specifically on how the performance of these algorithms on a given task depends crucially on the existence of effective training data for that task. The breakthroughs in Artificial Intelligence which have had an immense impact on society over the past few decades, for example, have not come about because of new algorithms (neural networks, for example, have been around since the 1950s). Rather, they have come about because of the massive, exponential increase in the amount of data available to train these already-existing algorithms: for example, data scraped from across the entire web, or from millions of scanned books, or from Wikipedia’s massive collection of articles. This means, therefore, that these algorithms simply encode pre-existing human biases into algorithmically-derived “rules”, thus motivating the next pillar of the course: Ethics!\n\n\nEthics\nFor the ethics-focused portion of the course, we’ll be reading selections from the following textbook:\n\nLewis Vaughn and Louis P. Pojman (2021). The Moral Life: An Introductory Reader in Ethics and Literature. Oxford, UK: Oxford University Press. [PDF]\n\nFrom the vast array of readings contained in this collection, we’ll look at both “standard” ethical readings from e.g. Jeremy Bentham and Immanuel Kant plus readings from literary sources like Ursula Le Guin, Ambrose Bierce, Jesus’ Sermon on the Mount, and Buddha’s Four Noble Truths.\n\n\nPublic Policy\nFor the final piece of the course we will take the technological developments discussed the first portion, analyze them using the ethical frameworks discussed in the second portion, and come to conclusions as to what types of things lawmakers, governments, and civil society organizations (NGOs, for example, and Think Tanks) can do in practice to address the ethical issues raised by these technologies. This means that, specifically, the recommended final project for the course will be a Policy Whitepaper, where you will choose a particular institution and make a recommendation to them in terms of how they can use their power (for example, the power to pass laws) to most effectively address an ethical issue that you believe is important.\nFor this portion of the class we’ll have to draw on a wide range of different readings, depending on what particular subdomains of public policy are most interesting to you all, but as a general textbook on ethics in data science which does focus a good amount on policy specifically, we will look at:\n\nAnne L. Washington (2023). Ethical Data Science: Prediction in the Public Interest. New York, NY: Oxford University Press.\n\nNow that you have an overview of the trajectory of the course, the following section contains the particulars of what we’ll be reading and working on each week!"
  },
  {
    "objectID": "syllabus.html#schedule",
    "href": "syllabus.html#schedule",
    "title": "Syllabus",
    "section": "Schedule",
    "text": "Schedule\nThe following is a rough map of what we will work through together throughout the semester; given that everyone learns at a different pace, my aim is to leave us with a good amount of flexibility in terms of how much time we spend on each topic: if I find that it takes me longer than a week to convey a certain topic in sufficient depth, for example, then I view it as a strength rather than a weakness of the course that we can then rearrange the calendar below by adding an extra week on that particular topic! Similarly, if it seems like I am spending too much time on a topic, to the point that students seem bored or impatient to move onto the next topic, we can move a topic intended for the next week to the current week!\n\n\n\nUnit\nWeek\nDate\nTopic\n\n\n\n\nUnit 1: Data-Scientific Issues\n1\nJan 17\nCourse Intro; Machine Learning and Training Data\n\n\n\n2\nJan 24\nCase Studies: Self-Driving Cars, Facial Recognition, and ChatGPT\n\n\n\n3\nJan 31\nCase Studies: Police and Military Applications of AI\n\n\n\n\nFeb 2 (Friday)\nDeliverable: Data Science\n\n\nUnit 2: Ethical Frameworks\n4\nFeb 7\nConsequentialism\n\n\n\n5\nFeb 14\nVirtue Ethics\n\n\n\n6\nFeb 21\nVirtue Ethics\n\n\n\n\nFeb 23 (Friday)\nDeliverable: Ethical Frameworks\n\n\n\n7\nFeb 28\nMidterm (Data Science and Ethics)\n\n\n\n\nMar 6\nNo Class (Spring Break)\n\n\nUnit 3: Applying Ethical Frameworks\n8\nMar 13\nApplying Ethical Frameworks: Self-Driving Cars, Facial Recognition, and ChatGPT\n\n\n\n9\nMar 20\nApplying Ethical Frameworks: Police and Military Applications of AI\n\n\n\n\nMar 22 (Friday)\nDeliverable: Applying Ethical Frameworks\n\n\nUnit 4: Public Policy\n10\nMar 27\nIntro to Public Policy\n\n\n\n11\nApr 3\nAuthoring Policy Whitepapers\n\n\n\n\nApr 5 (Friday)\nDeliverable: Public Policy\n\n\n\n12\nApr 10\nApplications: Public Policy and Climate Justice\n\n\n\n13\nApr 17\nApplications: Race, Class, Gender, Sexuality, and Disability (Data Feminism)\n\n\n\n14\nApril 24\nApplications: Public Policy and International Law\n\n\n\n\nMay 3 (Friday)\nDeliverable: Policy Whitepaper"
  },
  {
    "objectID": "syllabus.html#assignments-and-grading",
    "href": "syllabus.html#assignments-and-grading",
    "title": "Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThe main assignment in the course will be your policy whitepaper, submitted at the end of the semester. However, there will also be a midterm exam and a series of assignments which exist to let you explore each of the modules of the course, in turn.\n\n\n\n\n\n\n\n\nAssignment\nDue Date\n% of Grade\n\n\n\n\nData Science Overview Assignment\nFriday, February 2\n10%\n\n\nEthical Frameworks Assignment\nFriday, February 23\n10%\n\n\nMidterm\nWednesday, February 28\n30%\n\n\nApplying Ethical Frameworks Assignment\nFriday, March 22\n10%\n\n\nPublic Policy Assignment\nFriday, April 5\n10%\n\n\nPolicy Whitepaper\nFriday, May 3\n30%"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSAN 5450: Data Ethics and Policy",
    "section": "",
    "text": "Welcome to the homepage for DSAN 5450: Data Ethics and Policy at Georgetown University, for the Spring 2024 semester!\nThe course meets on Wednesdays from 3:30pm to 6:00pm in the Walsh Building, Room 498.\nCheck out the syllabus (or any other link in the sidebar) for more info!\nCourse Description:\nThis graduate-level course will train students to navigate the landscape of ethical issues which arise at each step of the data science process, with an eye towards developing policy recommendations for governments and organizations seeking expert advice on how to tackle these issues from a regulatory perspective. Students will explore and critically evaluate a range of data-related issues in contemporary society, such as responsible data collection, algorithmic bias, privacy, transparency, accountability, democratic participation in data usage and data-driven decisions, and the ethical implications of emerging technologies like artificial intelligence and machine learning (self-driving cars, ChatGPT, crowd-sourced training data, etc.).\nBeginning with a set of historical case studies—instances in which scientists, engineers, and policymakers have been forced to re-evaluate their ethical intuitions in light of technological developments (nuclear power, use of social media platforms to organize protests and influence political outcomes, deployment of facial recognition software and predictive AI by police and military forces)—the course then introduces a set of general ethical frameworks (consequentialism, deontological ethics, and virtue ethics), challenging students to consider their relative strengths and weaknesses for addressing modern technological-ethical dilemmas faced by businesses, healthcare organizations, governments, and academic institutions. After a final portion of the course linking these ethical frameworks with practical regulatory and policy considerations, students will write and present a policy whitepaper analyzing a data-ethical issue of particular interest to them, integrating ethical perspectives, regulatory principles, and domain knowledge into a recommendation of best practices for the relevant agency, firm, or institution.\nThe course will thus equip students with a robust ethical “toolbox” for conscientiously gathering, interpreting, and extracting meaning from data throughout their careers as data scientists, while respecting privacy, fairness, transparency, democratic accountability, and other social concerns. Prerequisites: None. 3 credits."
  },
  {
    "objectID": "w01/index.html",
    "href": "w01/index.html",
    "title": "Week 1: Introduction to the Course",
    "section": "",
    "text": "Open slides in new window →"
  },
  {
    "objectID": "w01/index.html#axiomatics",
    "href": "w01/index.html#axiomatics",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatics",
    "text": "Axiomatics\n\n\n\n\n\nPopular understanding of math: Deals with Facts, statements are true or false\n\nEx: \\(1 + 1 = 2\\) is “true”\n\nReality: No statements in math are absolutely true! Only conditional statements are possible to prove!\nWe cannot prove atomic statements \\(q\\), only implicational statements: \\(p \\implies q\\) for some axiom(s) \\(p\\).\n\n\\(1 + 1 = 2\\) is indeterminate without definitions of \\(1\\), \\(+\\), \\(=\\), and \\(2\\)!\n(Easy counterexample for math/CS majors: \\(1 + 1 = 0\\) in \\(\\mathbb{Z}_2\\))\n\n\n\n\n\n\n\n\nSteingart (2023)"
  },
  {
    "objectID": "w01/index.html#example-1-1-2",
    "href": "w01/index.html#example-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: \\(1 + 1 = 2\\)",
    "text": "Example: \\(1 + 1 = 2\\)\n\n\n\n\nHow it’s taught: this is a rule, and if you don’t follow it you will be banished to eternal hellfire\nHow it’s proved: \\(ZFC \\implies [1 + 1 = 2]\\), where \\(ZFC\\) stands for the Zermelo-Fraenkel Axioms with the Axiom of Choice!\n\n\n\n\n\n\nWhitehead and Russell (1910), p. 83. See here for page in context"
  },
  {
    "objectID": "w01/index.html#proving-1-1-2",
    "href": "w01/index.html#proving-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Proving \\(1 + 1 = 2\\)",
    "text": "Proving \\(1 + 1 = 2\\)\n(A non-formal proof that still captures the gist:)\n\nAxiom 1: There is a type of thing that can hold other things, which we’ll call a set. We’ll represent it like: \\(\\{ \\langle \\text{\\textit{stuff in the set}} \\rangle \\}\\).\nAxiom 2: Start with the set with nothing in it, \\(\\{\\}\\), and call it “\\(0\\)”.\nAxiom 3: If we put this set \\(0\\) inside of an empty set, we get a new set \\(\\{0\\} = \\{\\{\\}\\}\\), which we’ll call “\\(1\\)”.\nAxiom 4: If we put this set \\(1\\) inside of another set, we get another new set \\(\\{1\\} = \\{\\{\\{\\}\\}\\}\\), which we’ll call “\\(2\\)”.\nAxiom 5: This operation (creating a “next number” by placing a given number inside an empty set) we’ll call succession: \\(S(x) = \\{x\\}\\)\nAxiom 6: We’ll define addition, \\(a + b\\), as applying this succession operation \\(S\\) to \\(a\\), \\(b\\) times. Thus \\(a + b = \\underbrace{S(S(\\cdots (S(}_{b\\text{ times}}a))\\cdots ))\\)\nResult: (Axioms 1-6) \\(\\implies 1 + 1 = S(1) = S(\\{\\{\\}\\}) = \\{\\{\\{\\}\\}\\} = 2. \\; \\blacksquare\\)"
  },
  {
    "objectID": "w01/index.html#how-is-this-relevant-to-ethics",
    "href": "w01/index.html#how-is-this-relevant-to-ethics",
    "title": "Week 1: Introduction to the Course",
    "section": "How Is This Relevant to Ethics?",
    "text": "How Is This Relevant to Ethics?\n(Thank you for bearing with me on that 😅)\n\nJust as mathematicians slowly came to the realization that\n\n\\[\n\\textbf{mathematical results} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nI hope to help you see how\n\n\\[\n\\textbf{ethical conclusions} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nWhen someone says \\(1 + 1 = 2\\), you are allowed to question them, and ask, “On what basis? Please explain…”.\n\nHere the only valid answer is a collection of axioms which entail \\(1 + 1 = 2\\)\n\nWhen someone says Israel has the right to defend itself, you are allowed to question them, and ask, “On what basis? Please explain…”\n\nHere the only valid answer is an ethical framework which entails that Israel has the right to defend itself."
  },
  {
    "objectID": "w01/index.html#axiomatic-systems-statements-can-be-true-and-false",
    "href": "w01/index.html#axiomatic-systems-statements-can-be-true-and-false",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatic Systems: Statements Can Be True And False",
    "text": "Axiomatic Systems: Statements Can Be True And False\n\nLet \\(T\\) be the sum of the interior angles of a triangle. We’re taught \\(T = 180^\\circ\\) is a “rule”\nEuclid’s Fifth Postulate \\(P_5\\): Given a line and a point not on it, exactly one line parallel to the given line can be drawn through the point.\n\n\n\n\n\n\n\\(P_5 \\implies T = 180^\\circ\\)\n\n\n(Euclidean Geometry)\n\n\n\n\n\\(\\neg P_5 \\implies T \\neq 180^\\circ\\)\n\n\n(Non-Euclidean Geometry)"
  },
  {
    "objectID": "w01/index.html#ethical-systems-promise-keeping",
    "href": "w01/index.html#ethical-systems-promise-keeping",
    "title": "Week 1: Introduction to the Course",
    "section": "Ethical Systems: Promise-Keeping",
    "text": "Ethical Systems: Promise-Keeping\n\nScenario: You just baked a pie, and you promised your friend you’d give them the pie. You’re walking over to the friend’s house to give them the pie.\nSuddenly, you turn the corner to encounter a hostage situation: the hostage-taker is going to kill their hostage unless someone gives them a pie in the next 30 seconds\nDo you give the hostage-taker the pie?\n\n\n\n\n\nConsequentialist Ethics \\(\\implies\\) Yes\n\n\nTo be ethical is to weigh consequences of your actions\nThe positive consequences of giving the pie to the hostage-taker (saving a life) outweigh the negative consequences (breaking your promise to your friend)\n(Ex: Utilitarianism, associated with British philosopher Jeremy Bentham)\n\n\n\n\nDeontological Ethics \\(\\implies\\) No\n\n\nTo be ethical is to live by rules which you would want everyone to follow.\nAs a rule (a “categorical imperative”), you must not break promises. (Breaking this rule \\(\\implies\\) others can also “pick and choose” when to honor promises to you)\n(Ex: Kantian Ethics, associated with German philosopher Immanuel Kant)"
  },
  {
    "objectID": "w01/index.html#descriptive-vs.-normative",
    "href": "w01/index.html#descriptive-vs.-normative",
    "title": "Week 1: Introduction to the Course",
    "section": "Descriptive vs. Normative",
    "text": "Descriptive vs. Normative\n\n\n\n\n \n  \n \n\n\n\n\n\n\nbin Laden (2005)\n\n\n\n\n\n\n\n\n\n\n\n\nDescriptive Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years”\nNormative Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years, and that is a good justification”\n\n\nDescriptively True (empirically verifiable)\nNormatively True (entailed by axioms + descriptive facts) in some ethical systems, Normatively False (not entailed by axioms + descriptive facts) in others"
  },
  {
    "objectID": "w01/index.html#what-happens-when-we-confuse-the-two",
    "href": "w01/index.html#what-happens-when-we-confuse-the-two",
    "title": "Week 1: Introduction to the Course",
    "section": "What Happens When We Confuse The Two?",
    "text": "What Happens When We Confuse The Two?\n\n\n\n\nMakes it impossible to “cross the boundary” between your own and others’ beliefs\nCollective welfare: Bad on its own terms (see: wars, racism, etc.)\nSelf-interest: Prevents us from convincing other people of our arguments\n\n\n\n\n\n\nGeertz (1973)"
  },
  {
    "objectID": "w01/index.html#collective-vs.-self-interest",
    "href": "w01/index.html#collective-vs.-self-interest",
    "title": "Week 1: Introduction to the Course",
    "section": "Collective vs. Self-Interest",
    "text": "Collective vs. Self-Interest\n\n\n\n\nGood for collection of people \\(\\; \\nimplies\\) good for each individual person! (😰)\n\\(p\\) = Unions improve everyone’s workplace conditions, whether or not they pay dues\n\\(q\\) = Union dues are voluntary\n\\(p \\wedge q \\implies\\) I can obtain benefits of unions without paying\n\\(\\implies\\) Individually rational to not pay dues\n(Think also about how this applies to climate change policy)\n\n\n\n\n\n\nOlson (1965)"
  },
  {
    "objectID": "w01/index.html#modeling-individual-vs.-societal-outcomes",
    "href": "w01/index.html#modeling-individual-vs.-societal-outcomes",
    "title": "Week 1: Introduction to the Course",
    "section": "Modeling Individual vs. Societal Outcomes",
    "text": "Modeling Individual vs. Societal Outcomes\n\n\n\n\nIndividual Perspective: Individual \\(i\\) chooses whether or not to pay union dues\n\n\n\n\n\n\n\\(\\implies\\) Social Outcome: No Union\n\n\n\n\n\nSchelling (1978)"
  },
  {
    "objectID": "w01/index.html#takeaway-for-policy-whitepapers",
    "href": "w01/index.html#takeaway-for-policy-whitepapers",
    "title": "Week 1: Introduction to the Course",
    "section": "Takeaway for Policy Whitepapers",
    "text": "Takeaway for Policy Whitepapers\n\n\n\n\nYou cannot (just) say, “doing \\(x\\) will be better for society”\nYou must also justify benefits to individuals, or at minimum, the individual organization and its stakeholders!\n(Is this a normative or descriptive claim?)"
  },
  {
    "objectID": "w01/index.html#data-science-for-who",
    "href": "w01/index.html#data-science-for-who",
    "title": "Week 1: Introduction to the Course",
    "section": "Data Science for Who?",
    "text": "Data Science for Who?\n\nWhat are the processes by which data is measured, recorded, and distributed?\n\n\n\n\nThe Library of Missing Datasets. From D’Ignazio and Klein (2020)"
  },
  {
    "objectID": "w01/index.html#example-measuring-freedom-and-human-rights",
    "href": "w01/index.html#example-measuring-freedom-and-human-rights",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: Measuring “Freedom” and “Human Rights”",
    "text": "Example: Measuring “Freedom” and “Human Rights”"
  },
  {
    "objectID": "w01/index.html#operationalization",
    "href": "w01/index.html#operationalization",
    "title": "Week 1: Introduction to the Course",
    "section": "Operationalization",
    "text": "Operationalization\n\n\n\n\nThink about claims commonly made on the basis of “data”:\n\nFree markets cause economic prosperity\nA glass of wine in the evening prevents cancer\nPolicing makes communities safer\n\nHow exactly are “prosperity”, “preventing cancer”, “policing”, “community safety” being measured?\n\n\n\n\n\n\nStiglitz, Sen, and Fitoussi (2010)"
  },
  {
    "objectID": "w01/index.html#what-is-being-compared",
    "href": "w01/index.html#what-is-being-compared",
    "title": "Week 1: Introduction to the Course",
    "section": "What Is Being Compared?",
    "text": "What Is Being Compared?\n\nAre countries with 1 billion people comparable to countries with 10 million people?\nAre countries which were colonized comparable to the colonizing countries?\nWhen did the colonized countries gain independence?\n\n\n\n\nSen, “China and India”"
  },
  {
    "objectID": "w01/index.html#implementation",
    "href": "w01/index.html#implementation",
    "title": "Week 1: Introduction to the Course",
    "section": "Implementation",
    "text": "Implementation\n\n\n\nFrom D’Ignazio and Klein (2020), Ch. 6 (see also)"
  },
  {
    "objectID": "w01/index.html#facial-recognition-algorithms",
    "href": "w01/index.html#facial-recognition-algorithms",
    "title": "Week 1: Introduction to the Course",
    "section": "Facial Recognition Algorithms",
    "text": "Facial Recognition Algorithms\n\n\n\n\n\n\nFacia.ai (2023)\n\n\n\n\n\n\n\nWellcome Collection (1890)\n\n\n\n\n\n\n\n\n\nOuz (2023)\n\n\n\n\n\n\n\nWang and Kosinski (2018)"
  },
  {
    "objectID": "w01/index.html#military-and-police-applications-of-ai",
    "href": "w01/index.html#military-and-police-applications-of-ai",
    "title": "Week 1: Introduction to the Course",
    "section": "Military and Police Applications of AI",
    "text": "Military and Police Applications of AI\n\n\n\n\n\n\nSenor and Singer (2011)\n\n\n\n\n\n\n\nMcNeil (2022)"
  },
  {
    "objectID": "w01/index.html#references",
    "href": "w01/index.html#references",
    "title": "Week 1: Introduction to the Course",
    "section": "References",
    "text": "References\n\n\nbin Laden, Osama. 2005. Messages to the World: The Statements of Osama Bin Laden. Verso Books.\n\n\nD’Ignazio, Catherine, and Lauren F. Klein. 2020. Data Feminism. MIT Press.\n\n\nFacia.ai. 2023. “Facial Recognition Helps Vendors in Healthcare.” Facia.ai. https://facia.ai/blog/facial-recognition-healthcare/.\n\n\nGeertz, Clifford. 1973. The Interpretation Of Cultures. Basic Books.\n\n\nMcNeil, Sam. 2022. “Israel Deploys Remote-Controlled Robotic Guns in West Bank.” AP News, November. https://apnews.com/article/technology-business-israel-robotics-west-bank-cfc889a120cbf59356f5044eb43d5b88.\n\n\nOlson, Mancur. 1965. The Logic of Collective Action. Harvard University Press.\n\n\nOuz. 2023. “Google Pixel 8 Face Unlock Vulnerability Discovered, Allowing Others to Unlock Devices.” Gizmochina. https://www.gizmochina.com/2023/10/16/google-pixel-8-face-unlock/.\n\n\nSchelling, Thomas C. 1978. Micromotives and Macrobehavior. Norton.\n\n\nSenor, Dan, and Saul Singer. 2011. Start-up Nation: The Story of Israel’s Economic Miracle. Grand Central Publishing.\n\n\nSteingart, Alma. 2023. Axiomatics: Mathematical Thought and High Modernism. University of Chicago Press.\n\n\nStiglitz, Joseph E., Amartya Sen, and Jean-Paul Fitoussi. 2010. Mismeasuring Our Lives: Why GDP Doesn’t Add Up. The New Press.\n\n\nWang, Yilun, and Michal Kosinski. 2018. “Deep Neural Networks Are More Accurate Than Humans at Detecting Sexual Orientation from Facial Images.” Journal of Personality and Social Psychology 114 (2): 246–57. https://doi.org/10.1037/pspa0000098.\n\n\nWellcome Collection. 1890. “Composite Photographs: \"The Jewish Type\".” https://wellcomecollection.org/works/ngq29vyw.\n\n\nWhitehead, Alfred North, and Bertrand Russell. 1910. Principia Mathematica. Cambridge University Press."
  },
  {
    "objectID": "w01/slides.html#axiomatics",
    "href": "w01/slides.html#axiomatics",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatics",
    "text": "Axiomatics\n\n\n\n\n\nPopular understanding of math: Deals with Facts, statements are true or false\n\nEx: \\(1 + 1 = 2\\) is “true”\n\nReality: No statements in math are absolutely true! Only conditional statements are possible to prove!\nWe cannot prove atomic statements \\(q\\), only implicational statements: \\(p \\implies q\\) for some axiom(s) \\(p\\).\n\n\\(1 + 1 = 2\\) is indeterminate without definitions of \\(1\\), \\(+\\), \\(=\\), and \\(2\\)!\n(Easy counterexample for math/CS majors: \\(1 + 1 = 0\\) in \\(\\mathbb{Z}_2\\))\n\n\n\n\n\n\n\n\nSteingart (2023)"
  },
  {
    "objectID": "w01/slides.html#example-1-1-2",
    "href": "w01/slides.html#example-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: \\(1 + 1 = 2\\)",
    "text": "Example: \\(1 + 1 = 2\\)\n\n\n\n\nHow it’s taught: this is a rule, and if you don’t follow it you will be banished to eternal hellfire\nHow it’s proved: \\(ZFC \\implies [1 + 1 = 2]\\), where \\(ZFC\\) stands for the Zermelo-Fraenkel Axioms with the Axiom of Choice!\n\n\n\n\n\n\nWhitehead and Russell (1910), p. 83. See here for page in context"
  },
  {
    "objectID": "w01/slides.html#proving-1-1-2",
    "href": "w01/slides.html#proving-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Proving \\(1 + 1 = 2\\)",
    "text": "Proving \\(1 + 1 = 2\\)\n(A non-formal proof that still captures the gist:)\n\nAxiom 1: There is a type of thing that can hold other things, which we’ll call a set. We’ll represent it like: \\(\\{ \\langle \\text{\\textit{stuff in the set}} \\rangle \\}\\).\nAxiom 2: Start with the set with nothing in it, \\(\\{\\}\\), and call it “\\(0\\)”.\nAxiom 3: If we put this set \\(0\\) inside of an empty set, we get a new set \\(\\{0\\} = \\{\\{\\}\\}\\), which we’ll call “\\(1\\)”.\nAxiom 4: If we put this set \\(1\\) inside of another set, we get another new set \\(\\{1\\} = \\{\\{\\{\\}\\}\\}\\), which we’ll call “\\(2\\)”.\nAxiom 5: This operation (creating a “next number” by placing a given number inside an empty set) we’ll call succession: \\(S(x) = \\{x\\}\\)\nAxiom 6: We’ll define addition, \\(a + b\\), as applying this succession operation \\(S\\) to \\(a\\), \\(b\\) times. Thus \\(a + b = \\underbrace{S(S(\\cdots (S(}_{b\\text{ times}}a))\\cdots ))\\)\nResult: (Axioms 1-6) \\(\\implies 1 + 1 = S(1) = S(\\{\\{\\}\\}) = \\{\\{\\{\\}\\}\\} = 2. \\; \\blacksquare\\)"
  },
  {
    "objectID": "w01/slides.html#how-is-this-relevant-to-ethics",
    "href": "w01/slides.html#how-is-this-relevant-to-ethics",
    "title": "Week 1: Introduction to the Course",
    "section": "How Is This Relevant to Ethics?",
    "text": "How Is This Relevant to Ethics?\n(Thank you for bearing with me on that 😅)\n\nJust as mathematicians slowly came to the realization that\n\n\\[\n\\textbf{mathematical results} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nI hope to help you see how\n\n\\[\n\\textbf{ethical conclusions} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nWhen someone says \\(1 + 1 = 2\\), you are allowed to question them, and ask, “On what basis? Please explain…”.\n\nHere the only valid answer is a collection of axioms which entail \\(1 + 1 = 2\\)\n\nWhen someone says Israel has the right to defend itself, you are allowed to question them, and ask, “On what basis? Please explain…”\n\nHere the only valid answer is an ethical framework which entails that Israel has the right to defend itself."
  },
  {
    "objectID": "w01/slides.html#axiomatic-systems-statements-can-be-true-and-false",
    "href": "w01/slides.html#axiomatic-systems-statements-can-be-true-and-false",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatic Systems: Statements Can Be True And False",
    "text": "Axiomatic Systems: Statements Can Be True And False\n\nLet \\(T\\) be the sum of the interior angles of a triangle. We’re taught \\(T = 180^\\circ\\) is a “rule”\nEuclid’s Fifth Postulate \\(P_5\\): Given a line and a point not on it, exactly one line parallel to the given line can be drawn through the point.\n\n\n\n\n\n\n\\(P_5 \\implies T = 180^\\circ\\)\n\n\n(Euclidean Geometry)\n\n\n\n\n\\(\\neg P_5 \\implies T \\neq 180^\\circ\\)\n\n\n(Non-Euclidean Geometry)"
  },
  {
    "objectID": "w01/slides.html#ethical-systems-promise-keeping",
    "href": "w01/slides.html#ethical-systems-promise-keeping",
    "title": "Week 1: Introduction to the Course",
    "section": "Ethical Systems: Promise-Keeping",
    "text": "Ethical Systems: Promise-Keeping\n\nScenario: You just baked a pie, and you promised your friend you’d give them the pie. You’re walking over to the friend’s house to give them the pie.\nSuddenly, you turn the corner to encounter a hostage situation: the hostage-taker is going to kill their hostage unless someone gives them a pie in the next 30 seconds\nDo you give the hostage-taker the pie?\n\n\n\n\n\nConsequentialist Ethics \\(\\implies\\) Yes\n\n\nTo be ethical is to weigh consequences of your actions\nThe positive consequences of giving the pie to the hostage-taker (saving a life) outweigh the negative consequences (breaking your promise to your friend)\n(Ex: Utilitarianism, associated with British philosopher Jeremy Bentham)\n\n\n\n\nDeontological Ethics \\(\\implies\\) No\n\n\nTo be ethical is to live by rules which you would want everyone to follow.\nAs a rule (a “categorical imperative”), you must not break promises. (Breaking this rule \\(\\implies\\) others can also “pick and choose” when to honor promises to you)\n(Ex: Kantian Ethics, associated with German philosopher Immanuel Kant)"
  },
  {
    "objectID": "w01/slides.html#descriptive-vs.-normative",
    "href": "w01/slides.html#descriptive-vs.-normative",
    "title": "Week 1: Introduction to the Course",
    "section": "Descriptive vs. Normative",
    "text": "Descriptive vs. Normative\n\n\n\n\n \n  \n \n\n\n\n\n\n\nbin Laden (2005)\n\n\n\n\n\n\n\n\n\n\n\n\nDescriptive Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years”\nNormative Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years, and that is a good justification”\n\n\nDescriptively True (empirically verifiable)\nNormatively True (entailed by axioms + descriptive facts) in some ethical systems, Normatively False (not entailed by axioms + descriptive facts) in others"
  },
  {
    "objectID": "w01/slides.html#what-happens-when-we-confuse-the-two",
    "href": "w01/slides.html#what-happens-when-we-confuse-the-two",
    "title": "Week 1: Introduction to the Course",
    "section": "What Happens When We Confuse The Two?",
    "text": "What Happens When We Confuse The Two?\n\n\n\n\nMakes it impossible to “cross the boundary” between your own and others’ beliefs\nCollective welfare: Bad on its own terms (see: wars, racism, etc.)\nSelf-interest: Prevents us from convincing other people of our arguments\n\n\n\n\n\n\nGeertz (1973)"
  },
  {
    "objectID": "w01/slides.html#collective-vs.-self-interest",
    "href": "w01/slides.html#collective-vs.-self-interest",
    "title": "Week 1: Introduction to the Course",
    "section": "Collective vs. Self-Interest",
    "text": "Collective vs. Self-Interest\n\n\n\n\nGood for collection of people \\(\\; \\nimplies\\) good for each individual person! (😰)\n\\(p\\) = Unions improve everyone’s workplace conditions, whether or not they pay dues\n\\(q\\) = Union dues are voluntary\n\\(p \\wedge q \\implies\\) I can obtain benefits of unions without paying\n\\(\\implies\\) Individually rational to not pay dues\n(Think also about how this applies to climate change policy)\n\n\n\n\n\n\nOlson (1965)"
  },
  {
    "objectID": "w01/slides.html#modeling-individual-vs.-societal-outcomes",
    "href": "w01/slides.html#modeling-individual-vs.-societal-outcomes",
    "title": "Week 1: Introduction to the Course",
    "section": "Modeling Individual vs. Societal Outcomes",
    "text": "Modeling Individual vs. Societal Outcomes\n\n\n\n\nIndividual Perspective: Individual \\(i\\) chooses whether or not to pay union dues\n\n\n\n\n\n\n\\(\\implies\\) Social Outcome: No Union\n\n\n\n\n\nSchelling (1978)"
  },
  {
    "objectID": "w01/slides.html#takeaway-for-policy-whitepapers",
    "href": "w01/slides.html#takeaway-for-policy-whitepapers",
    "title": "Week 1: Introduction to the Course",
    "section": "Takeaway for Policy Whitepapers",
    "text": "Takeaway for Policy Whitepapers\n\n\n\n\nYou cannot (just) say, “doing \\(x\\) will be better for society”\nYou must also justify benefits to individuals, or at minimum, the individual organization and its stakeholders!\n(Is this a normative or descriptive claim?)"
  },
  {
    "objectID": "w01/slides.html#data-science-for-who",
    "href": "w01/slides.html#data-science-for-who",
    "title": "Week 1: Introduction to the Course",
    "section": "Data Science for Who?",
    "text": "Data Science for Who?\n\nWhat are the processes by which data is measured, recorded, and distributed?\n\n\nThe Library of Missing Datasets. From D’Ignazio and Klein (2020)"
  },
  {
    "objectID": "w01/slides.html#example-measuring-freedom-and-human-rights",
    "href": "w01/slides.html#example-measuring-freedom-and-human-rights",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: Measuring “Freedom” and “Human Rights”",
    "text": "Example: Measuring “Freedom” and “Human Rights”"
  },
  {
    "objectID": "w01/slides.html#operationalization",
    "href": "w01/slides.html#operationalization",
    "title": "Week 1: Introduction to the Course",
    "section": "Operationalization",
    "text": "Operationalization\n\n\n\n\nThink about claims commonly made on the basis of “data”:\n\nFree markets cause economic prosperity\nA glass of wine in the evening prevents cancer\nPolicing makes communities safer\n\nHow exactly are “prosperity”, “preventing cancer”, “policing”, “community safety” being measured?\n\n\n\n\n\n\nStiglitz, Sen, and Fitoussi (2010)"
  },
  {
    "objectID": "w01/slides.html#what-is-being-compared",
    "href": "w01/slides.html#what-is-being-compared",
    "title": "Week 1: Introduction to the Course",
    "section": "What Is Being Compared?",
    "text": "What Is Being Compared?\n\nAre countries with 1 billion people comparable to countries with 10 million people?\nAre countries which were colonized comparable to the colonizing countries?\nWhen did the colonized countries gain independence?\n\n\nSen, “China and India”"
  },
  {
    "objectID": "w01/slides.html#implementation",
    "href": "w01/slides.html#implementation",
    "title": "Week 1: Introduction to the Course",
    "section": "Implementation",
    "text": "Implementation\n\nFrom D’Ignazio and Klein (2020), Ch. 6 (see also)"
  },
  {
    "objectID": "w01/slides.html#facial-recognition-algorithms",
    "href": "w01/slides.html#facial-recognition-algorithms",
    "title": "Week 1: Introduction to the Course",
    "section": "Facial Recognition Algorithms",
    "text": "Facial Recognition Algorithms\n\n\n\n\n\n\nFacia.ai (2023)\n\n\n\n\n\n\n\nWellcome Collection (1890)\n\n\n\n\n\n\n\n\n\nOuz (2023)\n\n\n\n\n\n\n\nWang and Kosinski (2018)"
  },
  {
    "objectID": "w01/slides.html#military-and-police-applications-of-ai",
    "href": "w01/slides.html#military-and-police-applications-of-ai",
    "title": "Week 1: Introduction to the Course",
    "section": "Military and Police Applications of AI",
    "text": "Military and Police Applications of AI\n\n\n\n\n\n\nSenor and Singer (2011)\n\n\n\n\n\n\n\nMcNeil (2022)"
  },
  {
    "objectID": "w01/slides.html#references",
    "href": "w01/slides.html#references",
    "title": "Week 1: Introduction to the Course",
    "section": "References",
    "text": "References\n\n\nbin Laden, Osama. 2005. Messages to the World: The Statements of Osama Bin Laden. Verso Books.\n\n\nD’Ignazio, Catherine, and Lauren F. Klein. 2020. Data Feminism. MIT Press.\n\n\nFacia.ai. 2023. “Facial Recognition Helps Vendors in Healthcare.” Facia.ai. https://facia.ai/blog/facial-recognition-healthcare/.\n\n\nGeertz, Clifford. 1973. The Interpretation Of Cultures. Basic Books.\n\n\nMcNeil, Sam. 2022. “Israel Deploys Remote-Controlled Robotic Guns in West Bank.” AP News, November. https://apnews.com/article/technology-business-israel-robotics-west-bank-cfc889a120cbf59356f5044eb43d5b88.\n\n\nOlson, Mancur. 1965. The Logic of Collective Action. Harvard University Press.\n\n\nOuz. 2023. “Google Pixel 8 Face Unlock Vulnerability Discovered, Allowing Others to Unlock Devices.” Gizmochina. https://www.gizmochina.com/2023/10/16/google-pixel-8-face-unlock/.\n\n\nSchelling, Thomas C. 1978. Micromotives and Macrobehavior. Norton.\n\n\nSenor, Dan, and Saul Singer. 2011. Start-up Nation: The Story of Israel’s Economic Miracle. Grand Central Publishing.\n\n\nSteingart, Alma. 2023. Axiomatics: Mathematical Thought and High Modernism. University of Chicago Press.\n\n\nStiglitz, Joseph E., Amartya Sen, and Jean-Paul Fitoussi. 2010. Mismeasuring Our Lives: Why GDP Doesn’t Add Up. The New Press.\n\n\nWang, Yilun, and Michal Kosinski. 2018. “Deep Neural Networks Are More Accurate Than Humans at Detecting Sexual Orientation from Facial Images.” Journal of Personality and Social Psychology 114 (2): 246–57. https://doi.org/10.1037/pspa0000098.\n\n\nWellcome Collection. 1890. “Composite Photographs: \"The Jewish Type\".” https://wellcomecollection.org/works/ngq29vyw.\n\n\nWhitehead, Alfred North, and Bertrand Russell. 1910. Principia Mathematica. Cambridge University Press.\n\n\n\n\nDSAN 5450 Week 1: Introduction"
  }
]