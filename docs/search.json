[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Welcome to DSAN 5450: Data Ethics and Policy at Georgetown University!\nThe course meets on Wednesdays from 3:30-6pm in the Walsh Building, Room 498",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-staff",
    "href": "syllabus.html#course-staff",
    "title": "Syllabus",
    "section": "Course Staff",
    "text": "Course Staff\n\nProf. Jeff Jacobs, jj1088@georgetown.edu\n\nOffice hours (Click to schedule): Monday, Tuesday, 3:30-6pm\n\nTA Amelia Baier, ab3868@georgetown.edu\n\nOffice hours: By appointment\n\nTA Sonali Dabhi, sd1387@georgetown.edu\n\nOffice hours: By appointment",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nThis graduate-level course will train students to navigate the landscape of ethical issues which arise at each step of the data science process, with an eye towards developing policy recommendations for governments and organizations seeking expert advice on how to tackle these issues from a regulatory perspective. Students will explore and critically evaluate a range of data-related issues in contemporary society, such as responsible data collection, algorithmic bias, privacy, transparency, accountability, democratic participation in data usage and data-driven decisions, and the ethical implications of emerging technologies like artificial intelligence and machine learning (self-driving cars, ChatGPT, crowd-sourced training data, etc.).\nBeginning with a set of historical case studies—instances in which scientists, engineers, and policymakers have been forced to re-evaluate their ethical intuitions in light of technological developments (nuclear power, use of social media platforms to organize protests and influence political outcomes, deployment of facial recognition software and predictive AI by police and military forces)—the course then introduces a set of general ethical frameworks (consequentialism, deontological ethics, and virtue ethics), challenging students to consider their relative strengths and weaknesses for addressing modern technological-ethical dilemmas faced by businesses, healthcare organizations, governments, and academic institutions. After a final portion of the course linking these ethical frameworks with practical regulatory and policy considerations, students will write and present a policy whitepaper analyzing a data-ethical issue of particular interest to them, integrating ethical perspectives, regulatory principles, and domain knowledge into a recommendation of best practices for the relevant agency, firm, or institution.\nThe course will thus equip students with a robust ethical “toolbox” for conscientiously gathering, interpreting, and extracting meaning from data throughout their careers as data scientists, while respecting privacy, fairness, transparency, democratic accountability, and other social concerns. Prerequisites: None. 3 credits.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-overview",
    "href": "syllabus.html#course-overview",
    "title": "Syllabus",
    "section": "Course Overview",
    "text": "Course Overview\nThe course revolves around three “pillars”, which we’ll examine individually before bringing them together for your final projects at the end of the class.\n\nData Science\nA portion of the course will focus on introductions to cutting-edge technologies like self-driving cars, ChatGPT, facial detection algorithms, and various applications of AI to police and military technologies. For this portion, we’ll draw fairly often from the contents of the following books:\n\nCatherine D’Ignazio and Lauren F. Klein (2020). Data Feminism. Cambridge, MA: MIT Press. [Free, open-source!]\nCathy O’Neil (2016). Weapons of Math Destruction. New York, NY: Crown Books.\n\nSince there are plenty of in-depth resources available to you (e.g., other Georgetown courses!) for learning the technical details of these technologies, our goal in this course will be to learn just the particular aspects of each technology which are most relevant to the ethical and policy issues they present.\nFor example, we will look at Neural Netwok-based Machine Learning algorithms, but we will focus specifically on how the performance of these algorithms on a given task depends crucially on the existence of effective training data for that task. The breakthroughs in Artificial Intelligence which have had an immense impact on society over the past few decades, for example, have not come about because of new algorithms (neural networks, for example, have been around since the 1950s). Rather, they have come about because of the massive, exponential increase in the amount of data available to train these already-existing algorithms: for example, data scraped from across the entire web, or from millions of scanned books, or from Wikipedia’s massive collection of articles. This means, therefore, that these algorithms simply encode pre-existing human biases into algorithmically-derived “rules”, thus motivating the next pillar of the course: Ethics!\n\n\nEthics\nFor the ethics-focused portion of the course, we’ll be reading selections from the following textbook:\n\nLewis Vaughn and Louis P. Pojman (2021). The Moral Life: An Introductory Reader in Ethics and Literature. Oxford, UK: Oxford University Press. [PDF]\n\nFrom the vast array of readings contained in this collection, we’ll look at both “standard” ethical readings from e.g. Jeremy Bentham and Immanuel Kant plus readings from literary sources like Ursula Le Guin and Ambrose Bierce.\n\n\nPublic Policy\nFor the final piece of the course we will take the technological developments discussed the first portion, analyze them using the ethical frameworks discussed in the second portion, and come to conclusions as to what types of things lawmakers, governments, and civil society organizations (NGOs, for example, and Think Tanks) can do in practice to address the ethical issues raised by these technologies. This means that, specifically, the recommended final project for the course will be a Policy Whitepaper, where you will choose a particular institution and make a recommendation to them in terms of how they can use their power (for example, the power to pass laws) to most effectively address an ethical issue that you believe is important.\nFor this portion of the class we’ll have to draw on a wide range of different readings, depending on what particular subdomains of public policy are most interesting to you all, but as a general textbook on ethics in data science which does focus a good amount on policy specifically, we will look at:\n\nAnne L. Washington (2023). Ethical Data Science: Prediction in the Public Interest. New York, NY: Oxford University Press.\n\nNow that you have an overview of the trajectory of the course, the following section contains the particulars of what we’ll be reading and working on each week!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#schedule",
    "href": "syllabus.html#schedule",
    "title": "Syllabus",
    "section": "Schedule",
    "text": "Schedule\nThe following is a rough map of what we will work through together throughout the semester; given that everyone learns at a different pace, my aim is to leave us with a good amount of flexibility in terms of how much time we spend on each topic: if I find that it takes me longer than a week to convey a certain topic in sufficient depth, for example, then I view it as a strength rather than a weakness of the course that we can then rearrange the calendar below by adding an extra week on that particular topic! Similarly, if it seems like I am spending too much time on a topic, to the point that students seem bored or impatient to move onto the next topic, we can move a topic intended for the next week to the current week!\n\n\n\n\nUnit\nWeek\nDate\nTopic\n\n\n\n\nUnit 1: Ethical Frameworks\n1\nJan 17\nIntroduction to the Course\n\n\n\n2\nJan 24\nMachine Learning, Training Data, and Bias\n\n\nUnit 2: Fairness\n3\nJan 31\n(Descriptive) Fairness in AI\n\n\n\n4\nFeb 7\nFairness in AI\n\n\n\n\nFeb 9 (Friday), 11:59pm EST\n[Deliverable] HW1: Nuts and Bolts for Fairness in AI\n\n\n\n5\nFeb 14\nContext-Sensitive Fairness\n\n\n\n6\nFeb 21\nCausality in Ethics and Policy\n\n\n\n\nFeb 26 (Monday), 11:59pm EST\n[Deliverable] HW2: Context-Sensitive Fairness\n\n\n\n7\nFeb 28\nIn-Class Midterm: Data Ethics, Fairness, Privacy, Causality\n\n\n\n\nMar 6\nNo Class (Spring Break)\n\n\nUnit 3: Policy Frameworks\n8\nMar 13\nApplying Ethical Frameworks: Self-Driving Cars, Facial Recognition, and ChatGPT\n\n\n\n9\nMar 20\nApplying Ethical Frameworks: Police and Military Applications of AI\n\n\n\n\nMar 22 (Friday)\n[Deliverable] HW3: Policy Frameworks\n\n\nUnit 4: Policy Evaluation\n10\nMar 27\nPolicy Evaluation and Reverse Fairness\n\n\n\n11\nApr 3\nAuthoring Policy Whitepapers\n\n\n\n\nApr 5 (Friday)\n[Deliverable] HW4: Policy Evaluation\n\n\n\n12\nApr 10\nApplications: Public Policy and Climate Justice\n\n\n\n13\nApr 17\nApplications: Race, Class, Gender, Sexuality, and Disability (Data Feminism)\n\n\n\n14\nApril 24\nApplications: Public Policy and International Law\n\n\n\n\nMay 3 (Friday)\n[Deliverable] Policy Whitepaper",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#assignments-and-grading",
    "href": "syllabus.html#assignments-and-grading",
    "title": "Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThe main assignment in the course will be your policy whitepaper, submitted at the end of the semester. However, there will also be a midterm exam and a series of assignments which exist to let you explore each of the modules of the course, in turn.\n\n\n\n\n\n\n\n\nAssignment\nDue Date\n% of Grade\n\n\n\n\nHW1: Nuts and Bolts for Fairness in AI\nFriday, February 9\n10%\n\n\nHW2: Context-Sensitive Fairness\nMonday, February 26\n10%\n\n\nMidterm\nWednesday, February 28\n30%\n\n\nHW3: Policy Frameworks\nFriday, March 22\n10%\n\n\nHW4: Policy Evaluation\nFriday, April 5\n10%\n\n\nPolicy Whitepaper\nFriday, May 3\n30%\n\n\n\n\nHomework Lateness Policy\nAfter the due date, for each homework assignment, you will have a grace period of 24 hours to submit the assignment without a lateness penalty. After this 24-hour grace period, late penalties will be applied based on the following scale (unless you obtain an excused lateness from one of the instructional staff!):\n\n0 to 24 hours late: no penalty\n24 to 30 hours late: 2.5% penalty\n30 to 42 hours late: 5% penalty\n42 to 54 hours late: 10% penalty\n54 to 66 hours late: 20% penalty\nMore than 66 hours late: Assignment submissions no longer accepted (without instructor approval)",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "w01/slides.html#prof.-jeff-introduction",
    "href": "w01/slides.html#prof.-jeff-introduction",
    "title": "Week 1: Introduction to the Course",
    "section": "Prof. Jeff Introduction!",
    "text": "Prof. Jeff Introduction!\n\nBorn and raised in NW DC → high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)"
  },
  {
    "objectID": "w01/slides.html#grad-school",
    "href": "w01/slides.html#grad-school",
    "title": "Week 1: Introduction to the Course",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/北大) → internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\n\nColumbia (NYC) for PhD[+Postdoc] in Political Science (2015-2023)"
  },
  {
    "objectID": "w01/slides.html#dissertation-political-science-history",
    "href": "w01/slides.html#dissertation-political-science-history",
    "title": "Week 1: Introduction to the Course",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n“Our Word is Our Weapon”: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada"
  },
  {
    "objectID": "w01/slides.html#why-is-georgetown-having-me-teach-this",
    "href": "w01/slides.html#why-is-georgetown-having-me-teach-this",
    "title": "Week 1: Introduction to the Course",
    "section": "Why Is Georgetown Having Me Teach This?",
    "text": "Why Is Georgetown Having Me Teach This?\n\n\n\n\nQuanty things, but then PhD major was Political Philosophy (concentration in International Relations)\nWhat most interested me: unraveling history; Easy to get lost in “present-day” details of e.g. debiasing algorithms and fairness in AI, but these questions go back literally thousands of years!\nPol philosophers distinguish “ancients” and “moderns” based on a crucial shift in perspective: ancients sought perfection, while Rousseau (1762) “took men [sic] as they are, and laws as they could be”.\n\n\n\n\n\n\n\n\n\n                                                \n\n\n\n\n\nFigure 1: Years spent questing in various dungeons of academia\n\n\n\n\n\n\n\nBut is separation of ethics from politics possible? (Bowles 2016) Should we accept “human nature” as immutable/eternal? My answer: yes AND no simultaneously…"
  },
  {
    "objectID": "w01/slides.html#dialectics",
    "href": "w01/slides.html#dialectics",
    "title": "Week 1: Introduction to the Course",
    "section": "Dialectics",
    "text": "Dialectics"
  },
  {
    "objectID": "w01/slides.html#my-backgroundbiases",
    "href": "w01/slides.html#my-backgroundbiases",
    "title": "Week 1: Introduction to the Course",
    "section": "My Background/Biases",
    "text": "My Background/Biases\n\n\n\n\nRaised in religious Jewish, right-wing (Revisionist Zionist) Republican environment\n“Encouraged” to emigrate to Israel for IDF service, but after learning history I renounced citizenship etc., family no longer big fans of me (Traumatic and scary to admit, ngl 🙈)\n2015-present: Teach CS + design thinking in refugee camps in West Bank and Gaza each summer (Code for Palestine)\nMetaethics: Learn about the world, challenge+update prior beliefs (Bayes’ rule!); I hope to challenge+update them throughout semester, with your help 🙂"
  },
  {
    "objectID": "w01/slides.html#on-the-one-hand",
    "href": "w01/slides.html#on-the-one-hand",
    "title": "Week 1: Introduction to the Course",
    "section": "On the One Hand…",
    "text": "On the One Hand…"
  },
  {
    "objectID": "w01/slides.html#on-the-other-hand",
    "href": "w01/slides.html#on-the-other-hand",
    "title": "Week 1: Introduction to the Course",
    "section": "On the Other Hand…",
    "text": "On the Other Hand…"
  },
  {
    "objectID": "w01/slides.html#remembering-why-it-matters",
    "href": "w01/slides.html#remembering-why-it-matters",
    "title": "Week 1: Introduction to the Course",
    "section": "Remembering Why It Matters",
    "text": "Remembering Why It Matters"
  },
  {
    "objectID": "w01/slides.html#rules-of-thumb",
    "href": "w01/slides.html#rules-of-thumb",
    "title": "Week 1: Introduction to the Course",
    "section": "Rules of Thumb",
    "text": "Rules of Thumb\n\n\n\n\nAsk questions about power, about inequities and especially about structures that give rise to them!\n“Philosophers have hitherto only tried to understand the world; the point, however, is to change it.” (Marx 1845)\nDialectical implication: the more we understand it the better we’ll be at changing it\n\n\n\n\n\n\nRicardo Levins Morales Art Studio / My office"
  },
  {
    "objectID": "w01/slides.html#axiomatics",
    "href": "w01/slides.html#axiomatics",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatics",
    "text": "Axiomatics\n\n\n\n\n\nPopular understanding of math: Deals with Facts, statements are true or false\n\nEx: \\(1 + 1 = 2\\) is “true”\n\nReality: No statements in math are absolutely true! Only conditional statements are possible to prove!\nWe cannot prove atomic statements \\(q\\), only implicational statements: \\(p \\implies q\\) for some axiom(s) \\(p\\).\n\n\\(1 + 1 = 2\\) is indeterminate without definitions of \\(1\\), \\(+\\), \\(=\\), and \\(2\\)!\n(Easy counterexample for math/CS majors: \\(1 + 1 = 0\\) in \\(\\mathbb{Z}_2\\))\n\n\n\n\n\n\n\n\nSteingart (2023)"
  },
  {
    "objectID": "w01/slides.html#example-1-1-2",
    "href": "w01/slides.html#example-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: \\(1 + 1 = 2\\)",
    "text": "Example: \\(1 + 1 = 2\\)\n\n\n\n\nHow it’s taught: this is a rule, and if you don’t follow it you will be banished to eternal hellfire\nHow it’s proved: \\(ZFC \\implies [1 + 1 = 2]\\), where \\(ZFC\\) stands for the Zermelo-Fraenkel Axioms with the Axiom of Choice!\n\n\n\n\n\n\nWhitehead and Russell (1910), p. 83. See here for page in context"
  },
  {
    "objectID": "w01/slides.html#proving-1-1-2",
    "href": "w01/slides.html#proving-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Proving \\(1 + 1 = 2\\)",
    "text": "Proving \\(1 + 1 = 2\\)\n(A non-formal proof that still captures the gist:)\n\nAxiom 1: There is a type of thing that can hold other things, which we’ll call a set. We’ll represent it like: \\(\\{ \\langle \\text{\\textit{stuff in the set}} \\rangle \\}\\).\nAxiom 2: Start with the set with nothing in it, \\(\\{\\}\\), and call it “\\(0\\)”.\nAxiom 3: If we put this set \\(0\\) inside of an empty set, we get a new set \\(\\{0\\} = \\{\\{\\}\\}\\), which we’ll call “\\(1\\)”.\nAxiom 4: If we put this set \\(1\\) inside of another set, we get another new set \\(\\{1\\} = \\{\\{\\{\\}\\}\\}\\), which we’ll call “\\(2\\)”.\nAxiom 5: This operation (creating a “next number” by placing a given number inside an empty set) we’ll call succession: \\(S(x) = \\{x\\}\\)\nAxiom 6: We’ll define addition, \\(a + b\\), as applying this succession operation \\(S\\) to \\(a\\), \\(b\\) times. Thus \\(a + b = \\underbrace{S(S(\\cdots (S(}_{b\\text{ times}}a))\\cdots ))\\)\nResult: (Axioms 1-6) \\(\\implies 1 + 1 = S(1) = S(\\{\\{\\}\\}) = \\{\\{\\{\\}\\}\\} = 2. \\; \\blacksquare\\)"
  },
  {
    "objectID": "w01/slides.html#how-is-this-relevant-to-ethics",
    "href": "w01/slides.html#how-is-this-relevant-to-ethics",
    "title": "Week 1: Introduction to the Course",
    "section": "How Is This Relevant to Ethics?",
    "text": "How Is This Relevant to Ethics?\n(Thank you for bearing with me on that 😅)\n\nJust as mathematicians slowly came to the realization that\n\n\\[\n\\textbf{mathematical results} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nI hope to help you see how\n\n\\[\n\\textbf{ethical conclusions} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nWhen someone says \\(1 + 1 = 2\\), you are allowed to question them, and ask, “On what basis? Please explain…”.\n\nHere the only valid answer is a collection of axioms which entail \\(1 + 1 = 2\\)\n\nWhen someone says Israel has the right to defend itself, you are allowed to question them, and ask, “On what basis? Please explain…”\n\nHere the only valid answer is an ethical framework which entails that Israel has the right to defend itself."
  },
  {
    "objectID": "w01/slides.html#axiomatic-systems-statements-can-be-true-and-false",
    "href": "w01/slides.html#axiomatic-systems-statements-can-be-true-and-false",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatic Systems: Statements Can Be True And False",
    "text": "Axiomatic Systems: Statements Can Be True And False\n\nLet \\(T\\) be the sum of the interior angles of a triangle. We’re taught \\(T = 180^\\circ\\) is a “rule”\nEuclid’s Fifth Postulate \\(P_5\\): Given a line and a point not on it, exactly one line parallel to the given line can be drawn through the point.\n\n\n\n\n\n\n\\(P_5 \\implies T = 180^\\circ\\)\n\n\n(Euclidean Geometry)\n\n\n\n\n\\(\\neg P_5 \\implies T \\neq 180^\\circ\\)\n\n\n(Non-Euclidean Geometry)"
  },
  {
    "objectID": "w01/slides.html#ethical-systems-promise-keeping",
    "href": "w01/slides.html#ethical-systems-promise-keeping",
    "title": "Week 1: Introduction to the Course",
    "section": "Ethical Systems: Promise-Keeping",
    "text": "Ethical Systems: Promise-Keeping\n\nScenario: You just baked a pie, and you promised your friend you’d give them the pie. You’re walking over to the friend’s house to give them the pie.\nSuddenly, you turn the corner to encounter a hostage situation: the hostage-taker is going to kill their hostage unless someone gives them a pie in the next 30 seconds\nDo you give the hostage-taker the pie?\n\n\n\n\n\nConsequentialist Ethics \\(\\implies\\) Yes\n\n\nTo be ethical is to weigh consequences of your actions\nThe positive consequences of giving the pie to the hostage-taker (saving a life) outweigh the negative consequences (breaking your promise to your friend)\n(Ex: Utilitarianism, associated with British philosopher Jeremy Bentham)\n\n\n\n\nDeontological Ethics \\(\\implies\\) No\n\n\nTo be ethical is to live by rules which you would want everyone to follow.\nAs a rule (a “categorical imperative”), you must not break promises. (Breaking this rule \\(\\implies\\) others can also “pick and choose” when to honor promises to you)\n(Ex: Kantian Ethics, associated with German philosopher Immanuel Kant)"
  },
  {
    "objectID": "w01/slides.html#descriptive-vs.-normative",
    "href": "w01/slides.html#descriptive-vs.-normative",
    "title": "Week 1: Introduction to the Course",
    "section": "Descriptive vs. Normative",
    "text": "Descriptive vs. Normative\n\n\n\n\n \n  \n \n\n\n\n\n\n\nbin Laden (2005)\n\n\n\n\n\n\n\n\n\n\n\n\nDescriptive Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years”\nNormative Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years, and that is a good justification”\n\n\nDescriptively True (empirically verifiable)\nNormatively True (entailed by axioms + descriptive facts) in some ethical systems, Normatively False (not entailed by axioms + descriptive facts) in others"
  },
  {
    "objectID": "w01/slides.html#the-is-ought-distinction",
    "href": "w01/slides.html#the-is-ought-distinction",
    "title": "Week 1: Introduction to the Course",
    "section": "The Is-Ought Distinction",
    "text": "The Is-Ought Distinction\n\n\n\n\nHume on Is vs. Ought (Hume 1739)\n\n\n\nthe author proceeds for some time in the ordinary way of reasoning\nsuddenly, instead of the usual copulations of propositions is and is not,\nI meet with no proposition that is not connected with an ought, or an ought not.\nThis change is imperceptible; but is, however, of the last consequence.\n\n\n\n\n\n\n\n\nDescriptive (Is)\nNormative (Ought)\n\n\n\n\nGrass is green (true)\nGrass ought to be green (?)\n\n\nGrass is blue (false)\nGrass ought to be blue (?)"
  },
  {
    "objectID": "w01/slides.html#what-happens-when-we-confuse-the-two",
    "href": "w01/slides.html#what-happens-when-we-confuse-the-two",
    "title": "Week 1: Introduction to the Course",
    "section": "What Happens When We Confuse The Two?",
    "text": "What Happens When We Confuse The Two?\n\n\n\n\nMakes it impossible to “cross the boundary” between your own and others’ beliefs\nCollective welfare: Bad on its own terms (see: wars, racism, etc.)\nSelf-interest: Prevents us from convincing other people of our arguments\n\n\n\n\n\n\nGeertz (1973)"
  },
  {
    "objectID": "w01/slides.html#collective-vs.-self-interest",
    "href": "w01/slides.html#collective-vs.-self-interest",
    "title": "Week 1: Introduction to the Course",
    "section": "Collective vs. Self-Interest",
    "text": "Collective vs. Self-Interest\n\n\n\n\nGood for collection of people \\(\\; \\nimplies\\) good for each individual person! (😰)\n\\(p\\) = Unions improve everyone’s workplace conditions, whether or not they pay dues\n\\(q\\) = Union dues are voluntary\n\\(p \\wedge q \\implies\\) I can obtain benefits of unions without paying\n\\(\\implies\\) Individually rational to not pay dues\n(Think also about how this applies to climate change policy) 🤔\n\n\n\n\n\n\nOlson (1965)"
  },
  {
    "objectID": "w01/slides.html#modeling-individual-vs.-societal-outcomes",
    "href": "w01/slides.html#modeling-individual-vs.-societal-outcomes",
    "title": "Week 1: Introduction to the Course",
    "section": "Modeling Individual vs. Societal Outcomes",
    "text": "Modeling Individual vs. Societal Outcomes\n\n\n\n\nIndividual Perspective: Individual \\(i\\) chooses whether or not to pay union dues\n\n\n\n\n\n\n\\(\\implies\\) Social Outcome: No Union\n\n\n\n\n\nSchelling (1978)"
  },
  {
    "objectID": "w01/slides.html#takeaway-for-policy-whitepapers",
    "href": "w01/slides.html#takeaway-for-policy-whitepapers",
    "title": "Week 1: Introduction to the Course",
    "section": "Takeaway for Policy Whitepapers",
    "text": "Takeaway for Policy Whitepapers\n\n\n\n\nYou cannot (just) say, “doing \\(x\\) will be better for society”\nYou must also justify benefits to individuals, or at minimum, the individual organization and its stakeholders!\n(Is this a normative or descriptive claim?)"
  },
  {
    "objectID": "w01/slides.html#data-science-for-who",
    "href": "w01/slides.html#data-science-for-who",
    "title": "Week 1: Introduction to the Course",
    "section": "Data Science for Who?",
    "text": "Data Science for Who?\n\nWhat are the processes by which data is measured, recorded, and distributed?\n\n\nThe Library of Missing Datasets. From D’Ignazio and Klein (2020)"
  },
  {
    "objectID": "w01/slides.html#example-measuring-freedom-and-human-rights",
    "href": "w01/slides.html#example-measuring-freedom-and-human-rights",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: Measuring “Freedom” and “Human Rights”",
    "text": "Example: Measuring “Freedom” and “Human Rights”"
  },
  {
    "objectID": "w01/slides.html#operationalization",
    "href": "w01/slides.html#operationalization",
    "title": "Week 1: Introduction to the Course",
    "section": "Operationalization",
    "text": "Operationalization\n\n\n\n\nThink about claims commonly made on the basis of “data”:\n\nMarkets create economic prosperity\nA glass of wine in the evening prevents cancer\nPolicing makes communities safer\n\nHow exactly are “prosperity”, “preventing cancer”, “policing”, “community safety” being measured?\n\n\n\n\n\n\n\n\n\nStiglitz, Sen, and Fitoussi (2010)"
  },
  {
    "objectID": "w01/slides.html#what-is-being-compared",
    "href": "w01/slides.html#what-is-being-compared",
    "title": "Week 1: Introduction to the Course",
    "section": "What Is Being Compared?",
    "text": "What Is Being Compared?\n\nAre countries with 1 billion people comparable to countries with 10 million people?\nAre countries which were colonized comparable to the colonizing countries?\nWhen did the colonized countries gain independence?\n\n\nDrèze and Sen (1991)"
  },
  {
    "objectID": "w01/slides.html#implementation",
    "href": "w01/slides.html#implementation",
    "title": "Week 1: Introduction to the Course",
    "section": "Implementation",
    "text": "Implementation\n\n\n\n\n\n\nFrom D’Ignazio and Klein (2020), Ch. 6 (see also)\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Lerman and Weaver (2014)"
  },
  {
    "objectID": "w01/slides.html#fairness",
    "href": "w01/slides.html#fairness",
    "title": "Week 1: Introduction to the Course",
    "section": "Fairness… 🧐",
    "text": "Fairness… 🧐\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Lily Hu, Direct Effects: How Should We Measure Racial Discrimination?, Phenomenal World, 25 September 2020\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: From Kasy and Abebe (2021)"
  },
  {
    "objectID": "w01/slides.html#and-inverse-fairness",
    "href": "w01/slides.html#and-inverse-fairness",
    "title": "Week 1: Introduction to the Course",
    "section": "…And INVERSE Fairness 🤯",
    "text": "…And INVERSE Fairness 🤯\n\nFrom Machine Learning What Policymakers Value (Björkegren, Blumenstock, and Knight 2022)"
  },
  {
    "objectID": "w01/slides.html#facial-recognition-algorithms",
    "href": "w01/slides.html#facial-recognition-algorithms",
    "title": "Week 1: Introduction to the Course",
    "section": "Facial Recognition Algorithms",
    "text": "Facial Recognition Algorithms\n\n\n\n\n\n\nFacia.ai (2023)\n\n\n\n\n\n\n\nWellcome Collection (1890)\n\n\n\n\n\n\n\n\n\nOuz (2023)\n\n\n\n\n\n\n\nWang and Kosinski (2018)"
  },
  {
    "objectID": "w01/slides.html#large-language-models",
    "href": "w01/slides.html#large-language-models",
    "title": "Week 1: Introduction to the Course",
    "section": "Large Language Models",
    "text": "Large Language Models\n\n\n\n\n\n\n\n\n\nFigure 4: From Schiebinger et al. (2020)\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: From DeepLearning.AI’s Deep Learning course"
  },
  {
    "objectID": "w01/slides.html#military-and-police-applications-of-ai",
    "href": "w01/slides.html#military-and-police-applications-of-ai",
    "title": "Week 1: Introduction to the Course",
    "section": "Military and Police Applications of AI",
    "text": "Military and Police Applications of AI\n\n\n\n\n\n\nAyyub (2019)\n\n\n\n\n\n\n\nMcNeil (2022)"
  },
  {
    "objectID": "w01/slides.html#from-week-7-onwards-you-work-at-a-think-tank",
    "href": "w01/slides.html#from-week-7-onwards-you-work-at-a-think-tank",
    "title": "Week 1: Introduction to the Course",
    "section": "From Week 7 Onwards, You Work At A Think Tank",
    "text": "From Week 7 Onwards, You Work At A Think Tank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMorozov (2015)\n\n\n\n\n\n\n\nFrom Ames (2014)"
  },
  {
    "objectID": "w01/slides.html#references",
    "href": "w01/slides.html#references",
    "title": "Week 1: Introduction to the Course",
    "section": "References",
    "text": "References\n\n\nAmes, Mark. 2014. “The Techtopus: How Silicon Valley’s Most Celebrated CEOs Conspired to Drive down 100,000 Tech Engineers’ Wages,” January. http://web.archive.org/web/20200920042121/https://pando.com/2014/01/23/the-techtopus-how-silicon-valleys-most-celebrated-ceos-conspired-to-drive-down-100000-tech-engineers-wages/.\n\n\nAyyub, Rami. 2019. “App Aims to Help Palestinian Drivers Find Their Way Around Checkpoints.” The Times of Israel, August. https://www.timesofisrael.com/app-aims-to-help-palestinian-drivers-find-their-way-around-checkpoints/.\n\n\nbin Laden, Osama. 2005. Messages to the World: The Statements of Osama Bin Laden. Verso Books.\n\n\nBjörkegren, Daniel, Joshua E. Blumenstock, and Samsun Knight. 2022. “(Machine) Learning What Policies Value.” arXiv. https://doi.org/10.48550/arXiv.2206.00727.\n\n\nBowles, Samuel. 2016. The Moral Economy: Why Good Incentives Are No Substitute for Good Citizens. Yale University Press.\n\n\nD’Ignazio, Catherine, and Lauren F. Klein. 2020. Data Feminism. MIT Press.\n\n\nDrèze, Jean, and Amartya Sen. 1991. “China and India.” In Hunger and Public Action, 0. Oxford University Press. https://doi.org/10.1093/0198283652.003.0011.\n\n\nFacia.ai. 2023. “Facial Recognition Helps Vendors in Healthcare.” Facia.ai. https://facia.ai/blog/facial-recognition-healthcare/.\n\n\nGeertz, Clifford. 1973. The Interpretation Of Cultures. Basic Books.\n\n\nHume, David. 1739. A Treatise of Human Nature: Being an Attempt to Introduce the Experimental Method of Reasoning Into Moral Subjects; and Dialogues Concerning Natural Religion. Longmans, Green.\n\n\nKasy, Maximilian, and Rediet Abebe. 2021. “Fairness, Equality, and Power in Algorithmic Decision-Making.” In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 576–86. FAccT ’21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445919.\n\n\nLerman, Amy E., and Vesla M. Weaver. 2014. Arresting Citizenship: The Democratic Consequences of American Crime Control. University of Chicago Press.\n\n\nMarx, Karl. 1845. Thesen über Feuerbach. Stuttgart: J. H. W. Dietz. https://de.wikisource.org/wiki/Thesen_%C3%BCber_Feuerbach.\n\n\nMcNeil, Sam. 2022. “Israel Deploys Remote-Controlled Robotic Guns in West Bank.” AP News, November. https://apnews.com/article/technology-business-israel-robotics-west-bank-cfc889a120cbf59356f5044eb43d5b88.\n\n\nMorozov, Evgeny. 2015. “Socialize the Data Centres!” New Left Review, no. 91 (February): 45–66.\n\n\nOlson, Mancur. 1965. The Logic of Collective Action. Harvard University Press.\n\n\nOuz. 2023. “Google Pixel 8 Face Unlock Vulnerability Discovered, Allowing Others to Unlock Devices.” Gizmochina. https://www.gizmochina.com/2023/10/16/google-pixel-8-face-unlock/.\n\n\nRousseau, Jean-Jacques. 1762. The Social Contract. Geneva: J. M. Dent.\n\n\nSchelling, Thomas C. 1978. Micromotives and Macrobehavior. Norton.\n\n\nSchiebinger, Londa, Ineke Klinga, Hee Young Paik, Inés Sánchez de Madariaga, Martina Schraudner, and Marcia Stefanick. 2020. “Machine Translation: Gendered Innovations.” http://genderedinnovations.stanford.edu/case-studies/nlp.html#tabs-2.\n\n\nSteingart, Alma. 2023. Axiomatics: Mathematical Thought and High Modernism. University of Chicago Press.\n\n\nStiglitz, Joseph E., Amartya Sen, and Jean-Paul Fitoussi. 2010. Mismeasuring Our Lives: Why GDP Doesn’t Add Up. The New Press.\n\n\nWang, Yilun, and Michal Kosinski. 2018. “Deep Neural Networks Are More Accurate Than Humans at Detecting Sexual Orientation from Facial Images.” Journal of Personality and Social Psychology 114 (2): 246–57. https://doi.org/10.1037/pspa0000098.\n\n\nWellcome Collection. 1890. “Composite Photographs: \"The Jewish Type\".” https://wellcomecollection.org/works/ngq29vyw.\n\n\nWhitehead, Alfred North, and Bertrand Russell. 1910. Principia Mathematica. Cambridge University Press.\n\n\n\n\n\n\nDSAN 5450 Week 1: Introduction to the Course"
  },
  {
    "objectID": "w01/index.html",
    "href": "w01/index.html",
    "title": "Week 1: Introduction to the Course",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#prof.-jeff-introduction",
    "href": "w01/index.html#prof.-jeff-introduction",
    "title": "Week 1: Introduction to the Course",
    "section": "Prof. Jeff Introduction!",
    "text": "Prof. Jeff Introduction!\n\nBorn and raised in NW DC → high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#grad-school",
    "href": "w01/index.html#grad-school",
    "title": "Week 1: Introduction to the Course",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/北大) → internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\n\nColumbia (NYC) for PhD[+Postdoc] in Political Science (2015-2023)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#dissertation-political-science-history",
    "href": "w01/index.html#dissertation-political-science-history",
    "title": "Week 1: Introduction to the Course",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n“Our Word is Our Weapon”: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#why-is-georgetown-having-me-teach-this",
    "href": "w01/index.html#why-is-georgetown-having-me-teach-this",
    "title": "Week 1: Introduction to the Course",
    "section": "Why Is Georgetown Having Me Teach This?",
    "text": "Why Is Georgetown Having Me Teach This?\n\n\n\n\n\n\n\nQuanty things, but then PhD major was Political Philosophy (concentration in International Relations)\nWhat most interested me: unraveling history; Easy to get lost in “present-day” details of e.g. debiasing algorithms and fairness in AI, but these questions go back literally thousands of years!\nPol philosophers distinguish “ancients” and “moderns” based on a crucial shift in perspective: ancients sought perfection, while Rousseau (1762) “took men [sic] as they are, and laws as they could be”.\n\n\n\n\n\n\n\n\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"notebook\"\nimport pandas as pd\nyear_df = pd.DataFrame({\n  'field': ['Math&lt;br&gt;(BS)','CS&lt;br&gt;(BS,MS)','Pol Phil&lt;br&gt;(PhD Pt 1)','Econ&lt;br&gt;(BS+Job)','Pol Econ&lt;br&gt;(PhD Pt 2)'],\n  'cat': ['Quant','Quant','Humanities','Social Sci','Social Sci'],\n  'yrs': [4, 6, 3, 6, 5]\n})\nfig = px.sunburst(\n    year_df, path=['cat','field'], values='yrs',\n    width=450, height=400, color='cat',\n    color_discrete_map={'Quant': cb_palette[0], 'Humanities': cb_palette[1], 'Social Sci': cb_palette[2]},\n    hover_data=[]\n)\nfig.update_traces(\n   hovertemplate=None,\n   hoverinfo='skip'\n)\n# Update layout for tight margin\n# See https://plotly.com/python/creating-and-updating-figures/\nfig.update_layout(margin = dict(t=0, l=0, r=0, b=0))\nfig.show()\n\n                                                \n\n\n\n\n\nFigure 1: Years spent questing in various dungeons of academia\n\n\n\n\n\n\n\nBut is separation of ethics from politics possible? (Bowles 2016) Should we accept “human nature” as immutable/eternal? My answer: yes AND no simultaneously…",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#dialectics",
    "href": "w01/index.html#dialectics",
    "title": "Week 1: Introduction to the Course",
    "section": "Dialectics",
    "text": "Dialectics",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#my-backgroundbiases",
    "href": "w01/index.html#my-backgroundbiases",
    "title": "Week 1: Introduction to the Course",
    "section": "My Background/Biases",
    "text": "My Background/Biases\n\n\n\n\n\n\n\nRaised in religious Jewish, right-wing (Revisionist Zionist) Republican environment\n“Encouraged” to emigrate to Israel for IDF service, but after learning history I renounced citizenship etc., family no longer big fans of me (Traumatic and scary to admit, ngl 🙈)\n2015-present: Teach CS + design thinking in refugee camps in West Bank and Gaza each summer (Code for Palestine)\nMetaethics: Learn about the world, challenge+update prior beliefs (Bayes’ rule!); I hope to challenge+update them throughout semester, with your help 🙂",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#on-the-one-hand",
    "href": "w01/index.html#on-the-one-hand",
    "title": "Week 1: Introduction to the Course",
    "section": "On the One Hand…",
    "text": "On the One Hand…",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#on-the-other-hand",
    "href": "w01/index.html#on-the-other-hand",
    "title": "Week 1: Introduction to the Course",
    "section": "On the Other Hand…",
    "text": "On the Other Hand…",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#remembering-why-it-matters",
    "href": "w01/index.html#remembering-why-it-matters",
    "title": "Week 1: Introduction to the Course",
    "section": "Remembering Why It Matters",
    "text": "Remembering Why It Matters",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#rules-of-thumb",
    "href": "w01/index.html#rules-of-thumb",
    "title": "Week 1: Introduction to the Course",
    "section": "Rules of Thumb",
    "text": "Rules of Thumb\n\n\n\n\n\n\n\nAsk questions about power, about inequities and especially about structures that give rise to them!\n“Philosophers have hitherto only tried to understand the world; the point, however, is to change it.” (Marx 1845)\nDialectical implication: the more we understand it the better we’ll be at changing it\n\n\n\n\n\n\nRicardo Levins Morales Art Studio / My office",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#axiomatics",
    "href": "w01/index.html#axiomatics",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatics",
    "text": "Axiomatics\n\n\n\n\n\n\n\n\nPopular understanding of math: Deals with Facts, statements are true or false\n\nEx: \\(1 + 1 = 2\\) is “true”\n\nReality: No statements in math are absolutely true! Only conditional statements are possible to prove!\nWe cannot prove atomic statements \\(q\\), only implicational statements: \\(p \\implies q\\) for some axiom(s) \\(p\\).\n\n\\(1 + 1 = 2\\) is indeterminate without definitions of \\(1\\), \\(+\\), \\(=\\), and \\(2\\)!\n(Easy counterexample for math/CS majors: \\(1 + 1 = 0\\) in \\(\\mathbb{Z}_2\\))\n\n\n\n\n\n\n\n\nSteingart (2023)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#example-1-1-2",
    "href": "w01/index.html#example-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: \\(1 + 1 = 2\\)",
    "text": "Example: \\(1 + 1 = 2\\)\n\n\n\n\n\n\n\nHow it’s taught: this is a rule, and if you don’t follow it you will be banished to eternal hellfire\nHow it’s proved: \\(ZFC \\implies [1 + 1 = 2]\\), where \\(ZFC\\) stands for the Zermelo-Fraenkel Axioms with the Axiom of Choice!\n\n\n\n\n\n\nWhitehead and Russell (1910), p. 83. See here for page in context",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#proving-1-1-2",
    "href": "w01/index.html#proving-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Proving \\(1 + 1 = 2\\)",
    "text": "Proving \\(1 + 1 = 2\\)\n(A non-formal proof that still captures the gist:)\n\nAxiom 1: There is a type of thing that can hold other things, which we’ll call a set. We’ll represent it like: \\(\\{ \\langle \\text{\\textit{stuff in the set}} \\rangle \\}\\).\nAxiom 2: Start with the set with nothing in it, \\(\\{\\}\\), and call it “\\(0\\)”.\nAxiom 3: If we put this set \\(0\\) inside of an empty set, we get a new set \\(\\{0\\} = \\{\\{\\}\\}\\), which we’ll call “\\(1\\)”.\nAxiom 4: If we put this set \\(1\\) inside of another set, we get another new set \\(\\{1\\} = \\{\\{\\{\\}\\}\\}\\), which we’ll call “\\(2\\)”.\nAxiom 5: This operation (creating a “next number” by placing a given number inside an empty set) we’ll call succession: \\(S(x) = \\{x\\}\\)\nAxiom 6: We’ll define addition, \\(a + b\\), as applying this succession operation \\(S\\) to \\(a\\), \\(b\\) times. Thus \\(a + b = \\underbrace{S(S(\\cdots (S(}_{b\\text{ times}}a))\\cdots ))\\)\nResult: (Axioms 1-6) \\(\\implies 1 + 1 = S(1) = S(\\{\\{\\}\\}) = \\{\\{\\{\\}\\}\\} = 2. \\; \\blacksquare\\)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#how-is-this-relevant-to-ethics",
    "href": "w01/index.html#how-is-this-relevant-to-ethics",
    "title": "Week 1: Introduction to the Course",
    "section": "How Is This Relevant to Ethics?",
    "text": "How Is This Relevant to Ethics?\n(Thank you for bearing with me on that 😅)\n\nJust as mathematicians slowly came to the realization that\n\n\\[\n\\textbf{mathematical results} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nI hope to help you see how\n\n\\[\n\\textbf{ethical conclusions} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nWhen someone says \\(1 + 1 = 2\\), you are allowed to question them, and ask, “On what basis? Please explain…”.\n\nHere the only valid answer is a collection of axioms which entail \\(1 + 1 = 2\\)\n\nWhen someone says Israel has the right to defend itself, you are allowed to question them, and ask, “On what basis? Please explain…”\n\nHere the only valid answer is an ethical framework which entails that Israel has the right to defend itself.",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#axiomatic-systems-statements-can-be-true-and-false",
    "href": "w01/index.html#axiomatic-systems-statements-can-be-true-and-false",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatic Systems: Statements Can Be True And False",
    "text": "Axiomatic Systems: Statements Can Be True And False\n\nLet \\(T\\) be the sum of the interior angles of a triangle. We’re taught \\(T = 180^\\circ\\) is a “rule”\nEuclid’s Fifth Postulate \\(P_5\\): Given a line and a point not on it, exactly one line parallel to the given line can be drawn through the point.\n\n\n\n\n\n\n\n\n\n\\(P_5 \\implies T = 180^\\circ\\)\n\n\n(Euclidean Geometry)\n\n\n\n\n\\(\\neg P_5 \\implies T \\neq 180^\\circ\\)\n\n\n(Non-Euclidean Geometry)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#ethical-systems-promise-keeping",
    "href": "w01/index.html#ethical-systems-promise-keeping",
    "title": "Week 1: Introduction to the Course",
    "section": "Ethical Systems: Promise-Keeping",
    "text": "Ethical Systems: Promise-Keeping\n\nScenario: You just baked a pie, and you promised your friend you’d give them the pie. You’re walking over to the friend’s house to give them the pie.\nSuddenly, you turn the corner to encounter a hostage situation: the hostage-taker is going to kill their hostage unless someone gives them a pie in the next 30 seconds\nDo you give the hostage-taker the pie?\n\n\n\n\n\n\n\n\nConsequentialist Ethics \\(\\implies\\) Yes\n\n\nTo be ethical is to weigh consequences of your actions\nThe positive consequences of giving the pie to the hostage-taker (saving a life) outweigh the negative consequences (breaking your promise to your friend)\n(Ex: Utilitarianism, associated with British philosopher Jeremy Bentham)\n\n\n\n\nDeontological Ethics \\(\\implies\\) No\n\n\nTo be ethical is to live by rules which you would want everyone to follow.\nAs a rule (a “categorical imperative”), you must not break promises. (Breaking this rule \\(\\implies\\) others can also “pick and choose” when to honor promises to you)\n(Ex: Kantian Ethics, associated with German philosopher Immanuel Kant)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#descriptive-vs.-normative",
    "href": "w01/index.html#descriptive-vs.-normative",
    "title": "Week 1: Introduction to the Course",
    "section": "Descriptive vs. Normative",
    "text": "Descriptive vs. Normative\n\n\n\n\n\n\n\n \n  \n \n\n\n\n\n\n\nbin Laden (2005)\n\n\n\n\n\n\n\n\n\n\n\n\nDescriptive Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years”\nNormative Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years, and that is a good justification”\n\n\nDescriptively True (empirically verifiable)\nNormatively True (entailed by axioms + descriptive facts) in some ethical systems, Normatively False (not entailed by axioms + descriptive facts) in others",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#the-is-ought-distinction",
    "href": "w01/index.html#the-is-ought-distinction",
    "title": "Week 1: Introduction to the Course",
    "section": "The Is-Ought Distinction",
    "text": "The Is-Ought Distinction\n\n\n\n\n\n\nHume on Is vs. Ought (Hume 1739)\n\n\n\n\nthe author proceeds for some time in the ordinary way of reasoning\nsuddenly, instead of the usual copulations of propositions is and is not,\nI meet with no proposition that is not connected with an ought, or an ought not.\nThis change is imperceptible; but is, however, of the last consequence.\n\n\n\n\n\n\nDescriptive (Is)\nNormative (Ought)\n\n\n\n\nGrass is green (true)\nGrass ought to be green (?)\n\n\nGrass is blue (false)\nGrass ought to be blue (?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#what-happens-when-we-confuse-the-two",
    "href": "w01/index.html#what-happens-when-we-confuse-the-two",
    "title": "Week 1: Introduction to the Course",
    "section": "What Happens When We Confuse The Two?",
    "text": "What Happens When We Confuse The Two?\n\n\n\n\n\n\n\nMakes it impossible to “cross the boundary” between your own and others’ beliefs\nCollective welfare: Bad on its own terms (see: wars, racism, etc.)\nSelf-interest: Prevents us from convincing other people of our arguments\n\n\n\n\n\n\nGeertz (1973)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#collective-vs.-self-interest",
    "href": "w01/index.html#collective-vs.-self-interest",
    "title": "Week 1: Introduction to the Course",
    "section": "Collective vs. Self-Interest",
    "text": "Collective vs. Self-Interest\n\n\n\n\n\n\n\nGood for collection of people \\(\\; \\nimplies\\) good for each individual person! (😰)\n\\(p\\) = Unions improve everyone’s workplace conditions, whether or not they pay dues\n\\(q\\) = Union dues are voluntary\n\\(p \\wedge q \\implies\\) I can obtain benefits of unions without paying\n\\(\\implies\\) Individually rational to not pay dues\n(Think also about how this applies to climate change policy) 🤔\n\n\n\n\n\n\nOlson (1965)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#modeling-individual-vs.-societal-outcomes",
    "href": "w01/index.html#modeling-individual-vs.-societal-outcomes",
    "title": "Week 1: Introduction to the Course",
    "section": "Modeling Individual vs. Societal Outcomes",
    "text": "Modeling Individual vs. Societal Outcomes\n\n\n\n\n\n\n\nIndividual Perspective: Individual \\(i\\) chooses whether or not to pay union dues\n\n\n\n\n\n\n\\(\\implies\\) Social Outcome: No Union\n\n\n\n\n\nSchelling (1978)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#takeaway-for-policy-whitepapers",
    "href": "w01/index.html#takeaway-for-policy-whitepapers",
    "title": "Week 1: Introduction to the Course",
    "section": "Takeaway for Policy Whitepapers",
    "text": "Takeaway for Policy Whitepapers\n\n\n\n\n\n\n\nYou cannot (just) say, “doing \\(x\\) will be better for society”\nYou must also justify benefits to individuals, or at minimum, the individual organization and its stakeholders!\n(Is this a normative or descriptive claim?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#data-science-for-who",
    "href": "w01/index.html#data-science-for-who",
    "title": "Week 1: Introduction to the Course",
    "section": "Data Science for Who?",
    "text": "Data Science for Who?\n\nWhat are the processes by which data is measured, recorded, and distributed?\n\n\n\n\nThe Library of Missing Datasets. From D’Ignazio and Klein (2020)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#example-measuring-freedom-and-human-rights",
    "href": "w01/index.html#example-measuring-freedom-and-human-rights",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: Measuring “Freedom” and “Human Rights”",
    "text": "Example: Measuring “Freedom” and “Human Rights”",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#operationalization",
    "href": "w01/index.html#operationalization",
    "title": "Week 1: Introduction to the Course",
    "section": "Operationalization",
    "text": "Operationalization\n\n\n\n\n\n\n\nThink about claims commonly made on the basis of “data”:\n\nMarkets create economic prosperity\nA glass of wine in the evening prevents cancer\nPolicing makes communities safer\n\nHow exactly are “prosperity”, “preventing cancer”, “policing”, “community safety” being measured?\n\n\n\n\n\n\n\n\n\nStiglitz, Sen, and Fitoussi (2010)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#what-is-being-compared",
    "href": "w01/index.html#what-is-being-compared",
    "title": "Week 1: Introduction to the Course",
    "section": "What Is Being Compared?",
    "text": "What Is Being Compared?\n\nAre countries with 1 billion people comparable to countries with 10 million people?\nAre countries which were colonized comparable to the colonizing countries?\nWhen did the colonized countries gain independence?\n\n\n\n\nDrèze and Sen (1991)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#implementation",
    "href": "w01/index.html#implementation",
    "title": "Week 1: Introduction to the Course",
    "section": "Implementation",
    "text": "Implementation\n\n\n\n\n\n\n\n\n\nFrom D’Ignazio and Klein (2020), Ch. 6 (see also)\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Lerman and Weaver (2014)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#fairness",
    "href": "w01/index.html#fairness",
    "title": "Week 1: Introduction to the Course",
    "section": "Fairness… 🧐",
    "text": "Fairness… 🧐\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Lily Hu, Direct Effects: How Should We Measure Racial Discrimination?, Phenomenal World, 25 September 2020\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: From Kasy and Abebe (2021)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#and-inverse-fairness",
    "href": "w01/index.html#and-inverse-fairness",
    "title": "Week 1: Introduction to the Course",
    "section": "…And INVERSE Fairness 🤯",
    "text": "…And INVERSE Fairness 🤯\n\n\n\nFrom Machine Learning What Policymakers Value (Björkegren, Blumenstock, and Knight 2022)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#facial-recognition-algorithms",
    "href": "w01/index.html#facial-recognition-algorithms",
    "title": "Week 1: Introduction to the Course",
    "section": "Facial Recognition Algorithms",
    "text": "Facial Recognition Algorithms\n\n\n\n\n\n\n\n\n\nFacia.ai (2023)\n\n\n\n\n\n\n\nWellcome Collection (1890)\n\n\n\n\n\n\n\n\n\nOuz (2023)\n\n\n\n\n\n\n\nWang and Kosinski (2018)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#large-language-models",
    "href": "w01/index.html#large-language-models",
    "title": "Week 1: Introduction to the Course",
    "section": "Large Language Models",
    "text": "Large Language Models\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: From Schiebinger et al. (2020)\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: From DeepLearning.AI’s Deep Learning course",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#military-and-police-applications-of-ai",
    "href": "w01/index.html#military-and-police-applications-of-ai",
    "title": "Week 1: Introduction to the Course",
    "section": "Military and Police Applications of AI",
    "text": "Military and Police Applications of AI\n\n\n\n\n\n\n\n\n\nAyyub (2019)\n\n\n\n\n\n\n\nMcNeil (2022)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#from-week-7-onwards-you-work-at-a-think-tank",
    "href": "w01/index.html#from-week-7-onwards-you-work-at-a-think-tank",
    "title": "Week 1: Introduction to the Course",
    "section": "From Week 7 Onwards, You Work At A Think Tank",
    "text": "From Week 7 Onwards, You Work At A Think Tank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMorozov (2015)\n\n\n\n\n\n\n\nFrom Ames (2014)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#references",
    "href": "w01/index.html#references",
    "title": "Week 1: Introduction to the Course",
    "section": "References",
    "text": "References\n\n\nAmes, Mark. 2014. “The Techtopus: How Silicon Valley’s Most Celebrated CEOs Conspired to Drive down 100,000 Tech Engineers’ Wages,” January. http://web.archive.org/web/20200920042121/https://pando.com/2014/01/23/the-techtopus-how-silicon-valleys-most-celebrated-ceos-conspired-to-drive-down-100000-tech-engineers-wages/.\n\n\nAyyub, Rami. 2019. “App Aims to Help Palestinian Drivers Find Their Way Around Checkpoints.” The Times of Israel, August. https://www.timesofisrael.com/app-aims-to-help-palestinian-drivers-find-their-way-around-checkpoints/.\n\n\nbin Laden, Osama. 2005. Messages to the World: The Statements of Osama Bin Laden. Verso Books.\n\n\nBjörkegren, Daniel, Joshua E. Blumenstock, and Samsun Knight. 2022. “(Machine) Learning What Policies Value.” arXiv. https://doi.org/10.48550/arXiv.2206.00727.\n\n\nBowles, Samuel. 2016. The Moral Economy: Why Good Incentives Are No Substitute for Good Citizens. Yale University Press.\n\n\nD’Ignazio, Catherine, and Lauren F. Klein. 2020. Data Feminism. MIT Press.\n\n\nDrèze, Jean, and Amartya Sen. 1991. “China and India.” In Hunger and Public Action, 0. Oxford University Press. https://doi.org/10.1093/0198283652.003.0011.\n\n\nFacia.ai. 2023. “Facial Recognition Helps Vendors in Healthcare.” Facia.ai. https://facia.ai/blog/facial-recognition-healthcare/.\n\n\nGeertz, Clifford. 1973. The Interpretation Of Cultures. Basic Books.\n\n\nHume, David. 1739. A Treatise of Human Nature: Being an Attempt to Introduce the Experimental Method of Reasoning Into Moral Subjects; and Dialogues Concerning Natural Religion. Longmans, Green.\n\n\nKasy, Maximilian, and Rediet Abebe. 2021. “Fairness, Equality, and Power in Algorithmic Decision-Making.” In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 576–86. FAccT ’21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445919.\n\n\nLerman, Amy E., and Vesla M. Weaver. 2014. Arresting Citizenship: The Democratic Consequences of American Crime Control. University of Chicago Press.\n\n\nMarx, Karl. 1845. Thesen über Feuerbach. Stuttgart: J. H. W. Dietz. https://de.wikisource.org/wiki/Thesen_%C3%BCber_Feuerbach.\n\n\nMcNeil, Sam. 2022. “Israel Deploys Remote-Controlled Robotic Guns in West Bank.” AP News, November. https://apnews.com/article/technology-business-israel-robotics-west-bank-cfc889a120cbf59356f5044eb43d5b88.\n\n\nMorozov, Evgeny. 2015. “Socialize the Data Centres!” New Left Review, no. 91 (February): 45–66.\n\n\nOlson, Mancur. 1965. The Logic of Collective Action. Harvard University Press.\n\n\nOuz. 2023. “Google Pixel 8 Face Unlock Vulnerability Discovered, Allowing Others to Unlock Devices.” Gizmochina. https://www.gizmochina.com/2023/10/16/google-pixel-8-face-unlock/.\n\n\nRousseau, Jean-Jacques. 1762. The Social Contract. Geneva: J. M. Dent.\n\n\nSchelling, Thomas C. 1978. Micromotives and Macrobehavior. Norton.\n\n\nSchiebinger, Londa, Ineke Klinga, Hee Young Paik, Inés Sánchez de Madariaga, Martina Schraudner, and Marcia Stefanick. 2020. “Machine Translation: Gendered Innovations.” http://genderedinnovations.stanford.edu/case-studies/nlp.html#tabs-2.\n\n\nSteingart, Alma. 2023. Axiomatics: Mathematical Thought and High Modernism. University of Chicago Press.\n\n\nStiglitz, Joseph E., Amartya Sen, and Jean-Paul Fitoussi. 2010. Mismeasuring Our Lives: Why GDP Doesn’t Add Up. The New Press.\n\n\nWang, Yilun, and Michal Kosinski. 2018. “Deep Neural Networks Are More Accurate Than Humans at Detecting Sexual Orientation from Facial Images.” Journal of Personality and Social Psychology 114 (2): 246–57. https://doi.org/10.1037/pspa0000098.\n\n\nWellcome Collection. 1890. “Composite Photographs: \"The Jewish Type\".” https://wellcomecollection.org/works/ngq29vyw.\n\n\nWhitehead, Alfred North, and Bertrand Russell. 1910. Principia Mathematica. Cambridge University Press.",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSAN 5450: Data Ethics and Policy",
    "section": "",
    "text": "?var:w07.date\nWelcome to the homepage for DSAN 5450: Data Ethics and Policy at Georgetown University, for the Spring 2024 semester!\nThe course meets on Wednesdays from 3:30pm to 6:00pm in the Walsh Building, Room 498.\nCheck out the syllabus (or any other link in the sidebar) for more info! Or, use the following links to view notes for individual weeks:\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nWeek 1: Introduction to the Course\n\n\nJanuary 17\n\n\n\n\nWeek 2: Machine Learning, Training Data, and Bias\n\n\nJanuary 24\n\n\n\n\nWeek 3: (Descriptive) Fairness in AI\n\n\nJanuary 31\n\n\n\n\nWeek 4: Fairness in AI\n\n\nFebruary 6\n\n\n\n\nWeek 5: Context-Sensitive Fairness\n\n\nFebruary 14\n\n\n\n\nWeek 6: Causality in Ethics and Policy\n\n\nFebruary 21\n\n\n\n\nWeek 7: In-Class Midterm: Data Ethics, Fairness, Privacy, Causality\n\n\nFebruary 28\n\n\n\n\n\nNo matching items\n\n\nCourse Description:\nThis graduate-level course will train students to navigate the landscape of ethical issues which arise at each step of the data science process, with an eye towards developing policy recommendations for governments and organizations seeking expert advice on how to tackle these issues from a regulatory perspective. Students will explore and critically evaluate a range of data-related issues in contemporary society, such as responsible data collection, algorithmic bias, privacy, transparency, accountability, democratic participation in data usage and data-driven decisions, and the ethical implications of emerging technologies like artificial intelligence and machine learning (self-driving cars, ChatGPT, crowd-sourced training data, etc.).\nBeginning with a set of historical case studies—instances in which scientists, engineers, and policymakers have been forced to re-evaluate their ethical intuitions in light of technological developments (nuclear power, use of social media platforms to organize protests and influence political outcomes, deployment of facial recognition software and predictive AI by police and military forces)—the course then introduces a set of general ethical frameworks (consequentialism, deontological ethics, and virtue ethics), challenging students to consider their relative strengths and weaknesses for addressing modern technological-ethical dilemmas faced by businesses, healthcare organizations, governments, and academic institutions. After a final portion of the course linking these ethical frameworks with practical regulatory and policy considerations, students will write and present a policy whitepaper analyzing a data-ethical issue of particular interest to them, integrating ethical perspectives, regulatory principles, and domain knowledge into a recommendation of best practices for the relevant agency, firm, or institution.\nThe course will thus equip students with a robust ethical “toolbox” for conscientiously gathering, interpreting, and extracting meaning from data throughout their careers as data scientists, while respecting privacy, fairness, transparency, democratic accountability, and other social concerns. Prerequisites: None. 3 credits.",
    "crumbs": [
      "<i class='bi bi-house pe-1'></i> Home"
    ]
  },
  {
    "objectID": "writeups/index.html",
    "href": "writeups/index.html",
    "title": "Extra Writeups",
    "section": "",
    "text": "Order By\n       Default\n         \n          Last Updated - Oldest\n        \n         \n          Last Updated - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nLast Updated\n\n\nCategory\n\n\n\n\n\n\nA Quick Introduction to Probabilistic Graphical Models\n\n\nSunday, February 18, 2024\n\n\nExtra Writeups\n\n\n\n\nWeek 3 Resources / Loose-Thread Tying\n\n\nSaturday, February 3, 2024\n\n\nExtra Writeups\n\n\n\n\nWeek 2 Resources / Priming Your Brain for HW1\n\n\nWednesday, January 24, 2024\n\n\nExtra Writeups\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Writeups"
    ]
  },
  {
    "objectID": "writeups/w02.html",
    "href": "writeups/w02.html",
    "title": "Week 2 Resources / Priming Your Brain for HW1",
    "section": "",
    "text": "Hi all :) It’s in my nature or something to kvetch about “loose ends” that haven’t been tied up once class ends (plus, there are fun studies about so-called spaced repetition and how it massively increases retention and understanding, if u wanna be science about it), so I’ll try to get into the habit of sending these after class, so you have some stuff to pursue in the intervening week, if you’d like! (Update: I accidentally wrote way too much for an email, so, I’ll also add these to the course webpage in the “Writeups” section, linked in the sidebar)"
  },
  {
    "objectID": "writeups/w02.html#things-i-googled-opened-during-class",
    "href": "writeups/w02.html#things-i-googled-opened-during-class",
    "title": "Week 2 Resources / Priming Your Brain for HW1",
    "section": "1. Things I Googled / Opened During Class",
    "text": "1. Things I Googled / Opened During Class\n\n(a) Eugenia Cheng talk at Google, “The Art of Logic” (YouTube)\nIt’s the part from 14 minutes onwards where she starts drawing the diagrams relevant to us: “tracing back” an ethically-charged scenario from observed consequents (e.g., person gets beaten up and taken off the plane) to the massive collection of hypothesized antecedents (e.g., flight delays, policies of overbooking, capitalism, efficiency of the airline, and the incentives thereof). To map it back into something from the slides for this class: this “tracing back” corresponds (in my view) to the term I mentioned in the slides from last week: “unraveling history”.\nHopefully the Eugenia Cheng talk, in combination with this notion of “unraveling history” or “tracing consequents to antecedents”, can help you in seeing how difficult it is to answer the question of when to stop doing this “tracing back” and start intervening. If I was to keep ranting, I would mention how my “solution” here, to the extent that “solutions” are possible, is (i) humans aren’t fully rational, but we can incorporate the limits of our own rationality into our models of humans in some sense, e.g. as is done in models of boundedly rational; then, with a bounded-rationality-based model in hand, (ii) Bayes rule literally gives us a mathematically “optimal” rule, given an objective function of “choosing the best course of action given all information available to us at a given moment”, for which course of action to choose. This essay by Simon DeDeo from Carnegie Mellon University does a better job than I ever could at explaining and justifying why this might be a good model for decision-making under uncertainty (and why it makes sense to call it “Bayesian Reasoning”), despite its horribly pretentious/condescending title :P\n\n\n(b) Walter Thabit, How East New York Became A Ghetto (2003): PDF\nThis one is a bit more peripheral to the main topics in this class, but yeah I wanted to bring it up in class and then also send the PDF here because: if data science in urban policy is your jam, it’s a perfect example of how the data we have nowadays about differential health outcomes and correlates of crime and etc. for different neighborhoods in NYC didn’t magically “appear” in nice .csv format – it exists because of some combination of political organizing and agitation and etc. (which Walter Thabit himself very much took part in), in conjunction with the discrepancies that were pointed out in a more “qualitative” way by works in urban sociology like this one and its precursors…"
  },
  {
    "objectID": "writeups/w02.html#exploitation-as-descriptive-vs.-normative-term-in-economics",
    "href": "writeups/w02.html#exploitation-as-descriptive-vs.-normative-term-in-economics",
    "title": "Week 2 Resources / Priming Your Brain for HW1",
    "section": "2. “Exploitation” as Descriptive vs. Normative Term in Economics",
    "text": "2. “Exploitation” as Descriptive vs. Normative Term in Economics\nI basically completely stammered my way through answering this question in-class, which I’m mad at myself for since imo “exploitation” is a 100% perfect example for looking at how words can have entirely different meanings, and how people can make diametrically opposed judgements of their validity, both within and between the “descriptive” and “normative” realms.\nIn this case, analysis/discussion in the descriptive realm could look like: should we attach the label [“exploitation” (as descriptive term)] to [equation \\(A\\)] or [equation \\(B\\)]? Then, in the normative realm, analysis/discussion could look like: is [“exploitation” (as descriptive term, labeling equation \\(X \\in \\{A, B\\}\\))] morally objectionable? Is it something an institution could feasibly reduce, in theory? And if so, should they use the scarce resources available to them to try and reduce it?\nThe reason I stammered and felt so embarrassed that I couldn’t give a good succinct answer is because… I have no idea how to explain it without sounding like I’m doing a cringey flex/humblebrag type of thing but here goes:\nPrinceton University Press literally commissioned me to write a book chapter answering exactly that question back in 2018 lol, as basically part of a little companion book to a new edition of Das Kapital coming out in September this year (as part of my role on the editorial board for that), woohoo! But then, 10% because of covid and 90% because of my inability to finish anything, the chapter still isn’t finished and isn’t coming out anytime soon. Worse, it’s not even helpful to link the pdf draft in its current state (since there are literally like, half-finished equations in it, section headers without text, etc.). But if the question of different ethical perspectives on economically-defined exploitation is interesting to you, I am happy to send you a sloppy-but-finished pdf of the next draft in ~a week or two!\nSo yeah, embarrassed because I couldn’t just say “read my book!” given its current disheveled state, SO the resolution to all this is that I’m just going to link PDFs for two finished and published book! One by a person I mentioned in week 1, John Roemer:\n\n(a) Roemer, Free to Lose: An Introduction to Marxist Economic Philosophy (1988) [PDF], Chs. 2 and 4\nThis book gives an “intuitive” model of exploitation in plain English in Chapter 2, then a mathematical model with a semi-formal microeconomic definition of exploitation in Chapter 4.1\n\n\n(b) Morishima, Marx’s Economics (1973) [PDF], Ch. 5: “Surplus Value and Exploitation”\nIf you were an econ major, and especially if you feel good about econometrics stuff that uses linear algebra and matrix equations, you might instead prefer [chapter 5 of this book] by Michio Morishima, which (a) is better in the sense that it uses more standard econ terms, but then (b) is worse in the sense that it is all building to the argument it became famous for (in chapter 14), that Marxian exploitation can be defined without assuming the so-called Labor Theory of Value. Which was interesting in the 70s when it came out, but by 1988 Roemer could mostly just get to the point of defining and discussing exploitation without having to call it Exploitation-but-not-the-kind-thats-defined-using-Labor-Theory-of-Value.\nMoving back on-topic to DSAN 5450, though, the Morishima book does have a nice feature in that Chapter 2 is called “Hidden Assumptions”! Where he goes more into what antecedents might be hiding behind the term “exploitation” when it is used by neoclassical economists vs. Marxian economists."
  },
  {
    "objectID": "writeups/w02.html#hw1-nuts-and-bolts-for-fairness-in-ai",
    "href": "writeups/w02.html#hw1-nuts-and-bolts-for-fairness-in-ai",
    "title": "Week 2 Resources / Priming Your Brain for HW1",
    "section": "3. HW1: Nuts and Bolts for Fairness in AI",
    "text": "3. HW1: Nuts and Bolts for Fairness in AI\nI’ve already written way too much and included way too many PDFs here, but I’d rather have you overly rather than under-ly prepared for HW1, so I just wanted to give a quick preview of what will be on it, with pointers towards stuff where, if you skim them for example, you’ll know what to do when the homework comes along.\nTo be clear: most of the contents of these readings will be scary and confusing, since (a) we haven’t discussed them yet, but also (b) they’re entire papers/books devoted solely to a single topic that is just one among several topics in this class. And so the idea is just: you can look at these, maybe read the ones that you find sufficiently interesting and ignore the ones you don’t, and then your brain will be “primed” for the full-on understanding we’ll develop through slides + homework!\n\n(a) Recovering “Race” from Proxy Variables\nThere are a million bazillion books and articles and essays from humanities and the social sciences which I am forcing myself not to list here, because I want to just give yall a short-and-sweet primer you can use to understand the issue with “Step 1: remove the variable called ‘race’ -&gt; Step 2: problem solved 🥳💯” from a straightforward, data-science-rooted standpoint. So, for that, I’d go with this one:\n\nMichael Carl Tschantz, “What is Proxy Discrimination?” (2022)\n\n\n\n(b) Discrimination in Advertising\n\nAli et al. (2019). “Discrimination through optimization: How Facebook’s ad delivery can lead to skewed outcomes”, arXiv Preprint\n\nThis topic purposefully comes after (a) though (a) and (b) form a connected pair, since the results in this paper will seem very confusing/suspicious without knowledge about more and less valid ways of “recovering” race despite absence of a variable called “race” in the dataset. In the study, they employ an absolutely brilliant method (imo) for discovering discrimination in Facebook’s ads, but then they do a bit of a “sleight of hand” in just saying “we’ve found that the discrimination is based on race”, when in fact it’s “we’ve found that the discrimination is based on [estimated race inferred from proxy variables in a way that you might think is valid but you also might think is invalid]”.\n\n\n(c) Confusion matrix fairness\nAs you might see on the slides we haven’t gotten to yet, the two main resources I’m drawing on for this part are:\n\nChapter 3 of Barocas, Hardt, and Narayanan’s Fairness in Machine Learning (2023) (the full book is online for free, legally!), titled “Classification”\nMitchell et al. “Algorithmic Fairness: Choices, Assumptions, and Definitions”. Annual Review of Statistics and its Applications (2021)\n\nBut then, really, an approach to the confusion matrix-based definitions (among others!) that probably fits even better with the class is this presentation from Narayanan (the third author on the above Fairness in ML book), which is refreshing in that it explicitly links fairness definitions with political considerations, rather than trying to “hide” them behind… math/science/greek letters\n\nArvind Narayanan, “Tutorial: 21 Fairness Definitions and Their Politics”, from FAT-ML Conference, 2018 (YouTube)\n\n\n\n(d) Causal-path fairness\n\nChapter 5 of the Fairness in Machine Learning book mentioned above is all about causality-based approaches.\n\nIt’s not my favorite starting point tbh, but since I already linked that book, if you find that you like its approach, you can read Ch 6 as well…\nTo me, a central work in this sphere is:\n\nLily Hu, “What is ‘Race’ in Algorithmic Discrimination on the Basis of Race?”, Journal of Moral Philosophy (2024, forthcoming)\n\nThis is the distillation of Lily’s “thick constructivist” theory of race that I mentioned today. But the intuition behind it is broken down into maybe more digestible chunks with pictures and stuff in her blog posts on the Phenomenal World blog. There are 5 things listed there, but the last 2 are interviews so just skip those, I’m referring to “Disparate Causes Pt. I”, “Disparate Causes Pt. II”, and “Direct Effects”\nThe thing I’m scared of with this part, though, is that Lily’s work is a critique of causal-path fairness definitions, meaning that it can be hard to start there if you don’t know the thing she’s critiquing in the first place… the issue is that the literature on causal pathways is really brutally tough to “break into”, honestly. But, probably the book with the fewest barriers to entry—basically, a book that you have all the necessary background for, as DSAN students—is:\n\nMorgan and Winship (2014). Counterfactuals and Causal Inference [PDF]\n\nAnd then I’ll just say that: a book with the full-on details of everything you’d ever want to know about causal pathways is:\n\nJudea Pearl (2000). Causality: Models, Reasoning, and Inference [PDF, EPUB]\n\n\n\n(e) Reverse fairness\nThis one was rough tbh, in terms of trying to intro it in Week 2 without the details you’ll have by Week ~7 to 9 when we’ll get into this. Because, it’s actually completely rooted in a topic that maybe sounds… either miserably boring or miserably presumptuous at first: “Optimal Tax Rate Theory” (Optimal labor income taxation / Optimal capital income taxation)\nBut, if you are willing to see what they mean when they say that a tax rate is quote-unquote “optimal”, it will get you most of the way to understanding inverse fairness. As you’re hopefully getting used to, descriptively it means something like:\n\n“[set of criteria \\(C\\) and objective function \\(f\\)] =&gt; [tax rate \\(z^*\\) = maximum of \\(f\\) subject to constraints \\(C\\)]”,\n\nand then normatively it means something like:\n\n“[if \\((C,f)\\) characterize your policy goal(s)] \\(\\implies\\) [you ought to set tax rate to be \\(z\\)]”.\n\nThat’s not as fun or conclusive/satisfying as they way some economists present it (“this is the best most GOATed tax rate and if you don’t choose this tax rate you’re dumb and don’t understand economics!!”), but it allows us to understand the word “optimal” as the \\(q\\) in \\(p \\implies q\\) and move on 😜\nBecause then, we can use Bayes’ rule to go back and forth: from \\(p\\) to \\(q\\), or (!) from \\(q\\) backwards to \\(p\\). And in this case that means: given a set of distributional concerns (\\(p\\)), we can derive an optimal tax rate (\\(q\\)), OR (!) given an existing tax rate \\(q\\), we can infer the distributional concerns \\(p\\) that such a tax rate is implicitly implementing, in the sense of which groups in society are “weighted” higher and lower in the aggregation of individual preferences that manifests in the form of the tax policy.\nSince this is so much later in the class, and the HW1 problem will just be tiiny baby steps in that direction, I’m not too worried about specific articles or anything here – instead, I think actually a really helpful thing to read (though it may seem totally out of nowhere) is:\n\nJean-Paul Sartre (1946) Existentialism is a Humanism [PDF, EPUB], pgs. 30-34\n\nIf you use the EPUB: it’s the series of paragraphs starting with “To give you an example that will help you to better understand what we mean by abandonment”; it’s a section where he talks about a student coming to him for help with “ethically deciding” whether to join the anti-Nazi resistance or stay home and care for his sick mother.\nThe reason I cite that here is because it highlights how, once we’ve set up all these fancy definitions of fairness and causality and social welfare and etc., there is still always going to be an indeterminacy in ethical decision-making: Sartre’s point in giving this anecdote, in my reading of it at least, was to drive home the fact that he could teach this student 20 years of seminars on ethics, and the student could know 500 ethical frameworks in minute detail, and he would still have to do the hard, agonizing emotional work of making the decision. I think that can be a pretty good lesson to help us “zoom out” a bit, if we find ourselves lost in the sauce of “algorithms are gonna make all our decisions and fix everything!!”\nK I’m done,\nJeff"
  },
  {
    "objectID": "writeups/w02.html#footnotes",
    "href": "writeups/w02.html#footnotes",
    "title": "Week 2 Resources / Priming Your Brain for HW1",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you want the full set of gruesome axioms/antecedents which give rise to this definition, that’s in the more-intense-math but fully-axiomatized “version” of the book: Analytical Foundations of Marxian Economic Theory↩︎"
  },
  {
    "objectID": "w02/slides.html#data-science-for-whom",
    "href": "w02/slides.html#data-science-for-whom",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Data Science for Who(m)?",
    "text": "Data Science for Who(m)?\n\nWhat are the processes by which data is measured, recorded, and distributed?\n\n\nThe Library of Missing Datasets. From D’Ignazio and Klein (2020)"
  },
  {
    "objectID": "w02/slides.html#example-measuring-freedom-and-human-rights",
    "href": "w02/slides.html#example-measuring-freedom-and-human-rights",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Example: Measuring “Freedom” and “Human Rights”",
    "text": "Example: Measuring “Freedom” and “Human Rights”\n\nFreedom House Ratings are the most common measure of “freedom” in a country, across social science literature; US State Dept. Country Reports on Human Rights Practices are the most common measure of “human rights” in a country, across social science literature\n\n(you can take my word for it, or browse e.g. American Political Science Review)\n\n…So what’s the issue? (What is Jeff whining about this time?)\n\n\n\n\n\n\n\nFrom Freedom House, Inc., Notes to Financial Statements (2023), p. 21\n\n\n\n\n\n\n\nFrom state.gov/reports"
  },
  {
    "objectID": "w02/slides.html#example-measuring-freedom-and-human-rights-1",
    "href": "w02/slides.html#example-measuring-freedom-and-human-rights-1",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Example: Measuring “Freedom” and “Human Rights”",
    "text": "Example: Measuring “Freedom” and “Human Rights”"
  },
  {
    "objectID": "w02/slides.html#operationalization",
    "href": "w02/slides.html#operationalization",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Operationalization",
    "text": "Operationalization\n\n\n\n\nThink of common claims made on basis of “data”:\n\nMarkets create economic prosperity\nA glass of wine in the evening prevents cancer\nPolicing makes communities safer\n\nHow exactly are “prosperity”, “preventing cancer”, “policing”, “community safety” being measured?\n\n\n\n\nThumbnail from full video (Quarto crashes when I embed it directly 😑)\n\n\n\n\n\n\n\nStiglitz, Sen, and Fitoussi (2010)"
  },
  {
    "objectID": "w02/slides.html#what-is-being-compared",
    "href": "w02/slides.html#what-is-being-compared",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "What Is Being Compared?",
    "text": "What Is Being Compared?\n\nAre countries with 1 billion people comparable to countries with 10 million people?\nAre countries which were colonized comparable to the colonizing countries?\nWhen did the colonized countries gain independence?\n\n\nDrèze and Sen (1991)"
  },
  {
    "objectID": "w02/slides.html#implementation",
    "href": "w02/slides.html#implementation",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Implementation",
    "text": "Implementation\n\n\n\n\n\n\nFrom D’Ignazio and Klein (2020), Ch. 6 (see also)\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Lerman and Weaver (2014)"
  },
  {
    "objectID": "w02/slides.html#fairness",
    "href": "w02/slides.html#fairness",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Fairness… 🧐",
    "text": "Fairness… 🧐\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: From Lily Hu, Direct Effects: How Should We Measure Racial Discrimination?, Phenomenal World, 25 September 2020\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Kasy and Abebe (2021)"
  },
  {
    "objectID": "w02/slides.html#and-inverse-fairness",
    "href": "w02/slides.html#and-inverse-fairness",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "…And INVERSE Fairness 🤯",
    "text": "…And INVERSE Fairness 🤯\n\nFrom Machine Learning What Policymakers Value (Björkegren, Blumenstock, and Knight 2022)"
  },
  {
    "objectID": "w02/slides.html#facial-recognition-algorithms",
    "href": "w02/slides.html#facial-recognition-algorithms",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Facial Recognition Algorithms",
    "text": "Facial Recognition Algorithms\n\n\n\n\n\n\nFacia.ai (2023)\n\n\n\n\n\n\n\nWellcome Collection (1890)\n\n\n\n\n\n\n\n\n\nOuz (2023)\n\n\n\n\n\n\n\nWang and Kosinski (2018)"
  },
  {
    "objectID": "w02/slides.html#large-language-models",
    "href": "w02/slides.html#large-language-models",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Large Language Models",
    "text": "Large Language Models\n\n\n\n\n\n\n\n\n\nFigure 3: From Schiebinger et al. (2020)\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: From DeepLearning.AI’s Deep Learning course"
  },
  {
    "objectID": "w02/slides.html#military-and-police-applications-of-ai",
    "href": "w02/slides.html#military-and-police-applications-of-ai",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Military and Police Applications of AI",
    "text": "Military and Police Applications of AI\n\n\n\n\n\n\nAyyub (2019)\n\n\n\n\n\n\n\nMcNeil (2022)"
  },
  {
    "objectID": "w02/slides.html#three-component-parts-of-machine-learning",
    "href": "w02/slides.html#three-component-parts-of-machine-learning",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Three Component Parts of Machine Learning",
    "text": "Three Component Parts of Machine Learning\n\nA cool algorithm 😎😍\n[Possibly benign but possibly biased] Training data ❓🧐\nExploitation of below-minimum-wage human labor 😞🤐 (Dube et al. 2020, like and subscribe yall, get those ❤️s goin)"
  },
  {
    "objectID": "w02/slides.html#a-cool-algorithm",
    "href": "w02/slides.html#a-cool-algorithm",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "A Cool Algorithm 😎😍",
    "text": "A Cool Algorithm 😎😍"
  },
  {
    "objectID": "w02/slides.html#training-data-with-acknowledged-bias",
    "href": "w02/slides.html#training-data-with-acknowledged-bias",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Training Data With Acknowledged Bias",
    "text": "Training Data With Acknowledged Bias\n\nOne potentially fruitful approach to fairness: since we can’t eliminate it, bring it out into the open and study it!\n\nThis can, at very least, help us brainstorm how we might “correct” for it (next slides!)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Gendered Innovations in Science, Health & Medicine, Engineering, and Environment"
  },
  {
    "objectID": "w02/slides.html#word-embeddings",
    "href": "w02/slides.html#word-embeddings",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Word Embeddings",
    "text": "Word Embeddings\n\nBolukbasi et al. (2016)\nNotice how the \\(x\\)-axis has been selected by the researcher specifically to draw out (one) gendered dimension of language!\n\n\\(\\overrightarrow{\\texttt{she}}\\) mapped to \\(\\langle -1,0\\rangle\\), \\(\\overrightarrow{\\texttt{he}}\\) mapped to \\(\\langle 1,0 \\rangle\\), others projected onto this dimension"
  },
  {
    "objectID": "w02/slides.html#removing-vs.-studying-biases",
    "href": "w02/slides.html#removing-vs.-studying-biases",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Removing vs. Studying Biases",
    "text": "Removing vs. Studying Biases\n\n\n\n\n\n\nFrom Kozlowski, Taddy, and Evans (2019)\n\n\n\n\n\n\n\nWordBias: An Interactive Tool for Discovering Intersectional Biases Encoded in Word Embeddings"
  },
  {
    "objectID": "w02/slides.html#references",
    "href": "w02/slides.html#references",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "References",
    "text": "References\n\n\nAyyub, Rami. 2019. “App Aims to Help Palestinian Drivers Find Their Way Around Checkpoints.” The Times of Israel, August. https://www.timesofisrael.com/app-aims-to-help-palestinian-drivers-find-their-way-around-checkpoints/.\n\n\nBjörkegren, Daniel, Joshua E. Blumenstock, and Samsun Knight. 2022. “(Machine) Learning What Policies Value.” arXiv. https://doi.org/10.48550/arXiv.2206.00727.\n\n\nBolukbasi, Tolga, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai. 2016. “Man Is to Computer Programmer as Woman Is to Homemaker? Debiasing Word Embeddings.” In Advances in Neural Information Processing Systems. Vol. 29. Curran Associates, Inc. https://proceedings.neurips.cc/paper_files/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html.\n\n\nD’Ignazio, Catherine, and Lauren F. Klein. 2020. Data Feminism. MIT Press.\n\n\nDrèze, Jean, and Amartya Sen. 1991. “China and India.” In Hunger and Public Action, 0. Oxford University Press. https://doi.org/10.1093/0198283652.003.0011.\n\n\nDube, Arindrajit, Jeff Jacobs, Suresh Naidu, and Siddharth Suri. 2020. “Monopsony in Online Labor Markets.” American Economic Review: Insights 2 (1): 33–46. https://doi.org/10.1257/aeri.20180150.\n\n\nFacia.ai. 2023. “Facial Recognition Helps Vendors in Healthcare.” Facia.ai. https://facia.ai/blog/facial-recognition-healthcare/.\n\n\nKasy, Maximilian, and Rediet Abebe. 2021. “Fairness, Equality, and Power in Algorithmic Decision-Making.” In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 576–86. FAccT ’21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445919.\n\n\nKozlowski, Austin C., Matt Taddy, and James A. Evans. 2019. “The Geometry of Culture: Analyzing the Meanings of Class Through Word Embeddings.” American Sociological Review 84 (5): 905–49. https://doi.org/10.1177/0003122419877135.\n\n\nLerman, Amy E., and Vesla M. Weaver. 2014. Arresting Citizenship: The Democratic Consequences of American Crime Control. University of Chicago Press.\n\n\nMcNeil, Sam. 2022. “Israel Deploys Remote-Controlled Robotic Guns in West Bank.” AP News, November. https://apnews.com/article/technology-business-israel-robotics-west-bank-cfc889a120cbf59356f5044eb43d5b88.\n\n\nOuz. 2023. “Google Pixel 8 Face Unlock Vulnerability Discovered, Allowing Others to Unlock Devices.” Gizmochina. https://www.gizmochina.com/2023/10/16/google-pixel-8-face-unlock/.\n\n\nSchiebinger, Londa, Ineke Klinga, Hee Young Paik, Inés Sánchez de Madariaga, Martina Schraudner, and Marcia Stefanick. 2020. “Machine Translation: Gendered Innovations.” http://genderedinnovations.stanford.edu/case-studies/nlp.html#tabs-2.\n\n\nStiglitz, Joseph E., Amartya Sen, and Jean-Paul Fitoussi. 2010. Mismeasuring Our Lives: Why GDP Doesn’t Add Up. The New Press.\n\n\nWang, Yilun, and Michal Kosinski. 2018. “Deep Neural Networks Are More Accurate Than Humans at Detecting Sexual Orientation from Facial Images.” Journal of Personality and Social Psychology 114 (2): 246–57. https://doi.org/10.1037/pspa0000098.\n\n\nWellcome Collection. 1890. “Composite Photographs: \"The Jewish Type\".” https://wellcomecollection.org/works/ngq29vyw.\n\n\n\n\n\nDSAN 5450 Week 2: Machine Learning, Training Data, and Bias"
  },
  {
    "objectID": "w02/index.html",
    "href": "w02/index.html",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#data-science-for-whom",
    "href": "w02/index.html#data-science-for-whom",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Data Science for Who(m)?",
    "text": "Data Science for Who(m)?\n\nWhat are the processes by which data is measured, recorded, and distributed?\n\n\n\n\nThe Library of Missing Datasets. From D’Ignazio and Klein (2020)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#example-measuring-freedom-and-human-rights",
    "href": "w02/index.html#example-measuring-freedom-and-human-rights",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Example: Measuring “Freedom” and “Human Rights”",
    "text": "Example: Measuring “Freedom” and “Human Rights”\n\nFreedom House Ratings are the most common measure of “freedom” in a country, across social science literature; US State Dept. Country Reports on Human Rights Practices are the most common measure of “human rights” in a country, across social science literature\n\n(you can take my word for it, or browse e.g. American Political Science Review)\n\n…So what’s the issue? (What is Jeff whining about this time?)\n\n\n\n\n\n\n\n\n\n\nFrom Freedom House, Inc., Notes to Financial Statements (2023), p. 21\n\n\n\n\n\n\n\nFrom state.gov/reports",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#example-measuring-freedom-and-human-rights-1",
    "href": "w02/index.html#example-measuring-freedom-and-human-rights-1",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Example: Measuring “Freedom” and “Human Rights”",
    "text": "Example: Measuring “Freedom” and “Human Rights”",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#operationalization",
    "href": "w02/index.html#operationalization",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Operationalization",
    "text": "Operationalization\n\n\n\n\n\n\n\nThink of common claims made on basis of “data”:\n\nMarkets create economic prosperity\nA glass of wine in the evening prevents cancer\nPolicing makes communities safer\n\nHow exactly are “prosperity”, “preventing cancer”, “policing”, “community safety” being measured?\n\n\n\n\nThumbnail from full video (Quarto crashes when I embed it directly 😑)\n\n\n\n\n\n\n\nStiglitz, Sen, and Fitoussi (2010)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#what-is-being-compared",
    "href": "w02/index.html#what-is-being-compared",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "What Is Being Compared?",
    "text": "What Is Being Compared?\n\nAre countries with 1 billion people comparable to countries with 10 million people?\nAre countries which were colonized comparable to the colonizing countries?\nWhen did the colonized countries gain independence?\n\n\n\n\nDrèze and Sen (1991)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#implementation",
    "href": "w02/index.html#implementation",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Implementation",
    "text": "Implementation\n\n\n\n\n\n\n\n\n\nFrom D’Ignazio and Klein (2020), Ch. 6 (see also)\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Lerman and Weaver (2014)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#fairness",
    "href": "w02/index.html#fairness",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Fairness… 🧐",
    "text": "Fairness… 🧐\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: From Lily Hu, Direct Effects: How Should We Measure Racial Discrimination?, Phenomenal World, 25 September 2020\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Kasy and Abebe (2021)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#and-inverse-fairness",
    "href": "w02/index.html#and-inverse-fairness",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "…And INVERSE Fairness 🤯",
    "text": "…And INVERSE Fairness 🤯\n\n\n\nFrom Machine Learning What Policymakers Value (Björkegren, Blumenstock, and Knight 2022)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#facial-recognition-algorithms",
    "href": "w02/index.html#facial-recognition-algorithms",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Facial Recognition Algorithms",
    "text": "Facial Recognition Algorithms\n\n\n\n\n\n\n\n\n\nFacia.ai (2023)\n\n\n\n\n\n\n\nWellcome Collection (1890)\n\n\n\n\n\n\n\n\n\nOuz (2023)\n\n\n\n\n\n\n\nWang and Kosinski (2018)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#large-language-models",
    "href": "w02/index.html#large-language-models",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Large Language Models",
    "text": "Large Language Models\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: From Schiebinger et al. (2020)\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: From DeepLearning.AI’s Deep Learning course",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#military-and-police-applications-of-ai",
    "href": "w02/index.html#military-and-police-applications-of-ai",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Military and Police Applications of AI",
    "text": "Military and Police Applications of AI\n\n\n\n\n\n\n\n\n\nAyyub (2019)\n\n\n\n\n\n\n\nMcNeil (2022)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#three-component-parts-of-machine-learning",
    "href": "w02/index.html#three-component-parts-of-machine-learning",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Three Component Parts of Machine Learning",
    "text": "Three Component Parts of Machine Learning\n\nA cool algorithm 😎😍\n[Possibly benign but possibly biased] Training data ❓🧐\nExploitation of below-minimum-wage human labor 😞🤐 (Dube et al. 2020, like and subscribe yall, get those ❤️s goin)",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#a-cool-algorithm",
    "href": "w02/index.html#a-cool-algorithm",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "A Cool Algorithm 😎😍",
    "text": "A Cool Algorithm 😎😍",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#training-data-with-acknowledged-bias",
    "href": "w02/index.html#training-data-with-acknowledged-bias",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Training Data With Acknowledged Bias",
    "text": "Training Data With Acknowledged Bias\n\nOne potentially fruitful approach to fairness: since we can’t eliminate it, bring it out into the open and study it!\n\nThis can, at very least, help us brainstorm how we might “correct” for it (next slides!)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Gendered Innovations in Science, Health & Medicine, Engineering, and Environment",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#word-embeddings",
    "href": "w02/index.html#word-embeddings",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Word Embeddings",
    "text": "Word Embeddings\n\n\n\nBolukbasi et al. (2016)\n\n\n\nNotice how the \\(x\\)-axis has been selected by the researcher specifically to draw out (one) gendered dimension of language!\n\n\\(\\overrightarrow{\\texttt{she}}\\) mapped to \\(\\langle -1,0\\rangle\\), \\(\\overrightarrow{\\texttt{he}}\\) mapped to \\(\\langle 1,0 \\rangle\\), others projected onto this dimension",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#removing-vs.-studying-biases",
    "href": "w02/index.html#removing-vs.-studying-biases",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "Removing vs. Studying Biases",
    "text": "Removing vs. Studying Biases\n\n\n\n\n\n\n\n\n\nFrom Kozlowski, Taddy, and Evans (2019)\n\n\n\n\n\n\n\nWordBias: An Interactive Tool for Discovering Intersectional Biases Encoded in Word Embeddings",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "w02/index.html#references",
    "href": "w02/index.html#references",
    "title": "Week 2: Machine Learning, Training Data, and Bias",
    "section": "References",
    "text": "References\n\n\nAyyub, Rami. 2019. “App Aims to Help Palestinian Drivers Find Their Way Around Checkpoints.” The Times of Israel, August. https://www.timesofisrael.com/app-aims-to-help-palestinian-drivers-find-their-way-around-checkpoints/.\n\n\nBjörkegren, Daniel, Joshua E. Blumenstock, and Samsun Knight. 2022. “(Machine) Learning What Policies Value.” arXiv. https://doi.org/10.48550/arXiv.2206.00727.\n\n\nBolukbasi, Tolga, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai. 2016. “Man Is to Computer Programmer as Woman Is to Homemaker? Debiasing Word Embeddings.” In Advances in Neural Information Processing Systems. Vol. 29. Curran Associates, Inc. https://proceedings.neurips.cc/paper_files/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html.\n\n\nD’Ignazio, Catherine, and Lauren F. Klein. 2020. Data Feminism. MIT Press.\n\n\nDrèze, Jean, and Amartya Sen. 1991. “China and India.” In Hunger and Public Action, 0. Oxford University Press. https://doi.org/10.1093/0198283652.003.0011.\n\n\nDube, Arindrajit, Jeff Jacobs, Suresh Naidu, and Siddharth Suri. 2020. “Monopsony in Online Labor Markets.” American Economic Review: Insights 2 (1): 33–46. https://doi.org/10.1257/aeri.20180150.\n\n\nFacia.ai. 2023. “Facial Recognition Helps Vendors in Healthcare.” Facia.ai. https://facia.ai/blog/facial-recognition-healthcare/.\n\n\nKasy, Maximilian, and Rediet Abebe. 2021. “Fairness, Equality, and Power in Algorithmic Decision-Making.” In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 576–86. FAccT ’21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445919.\n\n\nKozlowski, Austin C., Matt Taddy, and James A. Evans. 2019. “The Geometry of Culture: Analyzing the Meanings of Class Through Word Embeddings.” American Sociological Review 84 (5): 905–49. https://doi.org/10.1177/0003122419877135.\n\n\nLerman, Amy E., and Vesla M. Weaver. 2014. Arresting Citizenship: The Democratic Consequences of American Crime Control. University of Chicago Press.\n\n\nMcNeil, Sam. 2022. “Israel Deploys Remote-Controlled Robotic Guns in West Bank.” AP News, November. https://apnews.com/article/technology-business-israel-robotics-west-bank-cfc889a120cbf59356f5044eb43d5b88.\n\n\nOuz. 2023. “Google Pixel 8 Face Unlock Vulnerability Discovered, Allowing Others to Unlock Devices.” Gizmochina. https://www.gizmochina.com/2023/10/16/google-pixel-8-face-unlock/.\n\n\nSchiebinger, Londa, Ineke Klinga, Hee Young Paik, Inés Sánchez de Madariaga, Martina Schraudner, and Marcia Stefanick. 2020. “Machine Translation: Gendered Innovations.” http://genderedinnovations.stanford.edu/case-studies/nlp.html#tabs-2.\n\n\nStiglitz, Joseph E., Amartya Sen, and Jean-Paul Fitoussi. 2010. Mismeasuring Our Lives: Why GDP Doesn’t Add Up. The New Press.\n\n\nWang, Yilun, and Michal Kosinski. 2018. “Deep Neural Networks Are More Accurate Than Humans at Detecting Sexual Orientation from Facial Images.” Journal of Personality and Social Psychology 114 (2): 246–57. https://doi.org/10.1037/pspa0000098.\n\n\nWellcome Collection. 1890. “Composite Photographs: \"The Jewish Type\".” https://wellcomecollection.org/works/ngq29vyw.",
    "crumbs": [
      "Week 2: {{< var w02.date-md >}}"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignment Point Distributions",
    "section": "",
    "text": "Use the tabs at the bottom of the spreadsheet (e.g., click the label HW1) to view the point distributions for different assignments.\nThe distributions are imported from a Google Sheet mainly for transparency: so that you can see exactly how totals are computed as a sum of the individual points allocated for each test!",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "w03/slides.html#loose-ends",
    "href": "w03/slides.html#loose-ends",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Loose Ends",
    "text": "Loose Ends\n\nNormative vs. Descriptive “Exploitation”: How can we disentangle these in our understanding of the term? (Roemer 1988)\n\nUnder descriptive definition, one can “exploit” corn or land in the exact same way one “exploits” human labor (just another type of input into the production process)\nUtility-wise, an economy with exploitation can be unambiguously better than one without exploitation: if 10 people \\(H\\) own means of production, and 990 people \\(S\\) own only their labor power (landless peasants, for example), allowing \\(H\\) to exploit \\(S\\) for a wage increases utility for both: \\(H\\) acquires profits, \\(S\\) doesn’t starve to death\n\n“Tracing back” causes / unraveling history\n\n“The result [of modern 24-hour news cycles] is a litany of events with no beginning and no real end, thrown together only because they occurred at the same time[,] cut off from their antecedents and consequenes” (Bourdieu 2010)"
  },
  {
    "objectID": "w03/slides.html#ethics-of-eliciting-sensitive-linguistic-data",
    "href": "w03/slides.html#ethics-of-eliciting-sensitive-linguistic-data",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Ethics of Eliciting Sensitive Linguistic Data",
    "text": "Ethics of Eliciting Sensitive Linguistic Data\n\n\n\n\n\n\nFrom Labov (2013), pg. 4\n\n\n\n\n\n\n\nFrom “80 Years On, Dominicans And Haitians Revisit Painful Memories Of Parsley Massacre”, NPR Parallels, 7 Oct 2017 (Bishop and Fernandez 2017)"
  },
  {
    "objectID": "w03/slides.html#part-3-the-training-data-bottleneck",
    "href": "w03/slides.html#part-3-the-training-data-bottleneck",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Part 3: The “Training Data Bottleneck”",
    "text": "Part 3: The “Training Data Bottleneck”\n\n\n\n\n\n\n\n\n\n\n\n\n\nSnorkel.AI, An Introduction to Snorkel and Data-Centric AI\n\n\n\n\n\n\nWith so much technical progress […] why is there so little real enterprise success? The answer all too often is that many enterprises continue to be bottlenecked by one key ingredient: the large amounts of labeled data [needed] to train these new systems.\n\n\n\nFigure 1: ibid. (PS, if it seems like I’m picking on them: these are the ‘good guys’ IMO! W.r.t. foregrounding training data as labor)"
  },
  {
    "objectID": "w03/slides.html#human-labor",
    "href": "w03/slides.html#human-labor",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Human Labor",
    "text": "Human Labor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Snorkel AI, “The Principles of Data-Centric AI Development by Alex Ratner” (YouTube)\n\n\n\n\n\n\n\n\nGray and Suri (2019)"
  },
  {
    "objectID": "w03/slides.html#computer-scientists-being-responsible-at-georgetown",
    "href": "w03/slides.html#computer-scientists-being-responsible-at-georgetown",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Computer Scientists Being Responsible (At Georgetown!)",
    "text": "Computer Scientists Being Responsible (At Georgetown!)\n\nDr. Redmiles’ homepage (Since Quarto also freezes when I try to embed it…)\n(PS… UMD undergrad CS class of 2013 extremely overrepresented here 😜)"
  },
  {
    "objectID": "w03/slides.html#computer-scientists-being-responsible-at-georgetown-1",
    "href": "w03/slides.html#computer-scientists-being-responsible-at-georgetown-1",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Computer Scientists Being Responsible (At Georgetown!)",
    "text": "Computer Scientists Being Responsible (At Georgetown!)\n\nGU360 Course Page"
  },
  {
    "objectID": "w03/slides.html#so-what-comes-with-human-labels-human-biases",
    "href": "w03/slides.html#so-what-comes-with-human-labels-human-biases",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "So, What Comes With Human Labels? Human Biases!",
    "text": "So, What Comes With Human Labels? Human Biases!\n\n\n\n\n\n\nCrawford and Paglen (2019)\n\n\n\n\n\n\n\nImage tagged in ImageNet with the label “BOLSHEVIK”. From Crawford and Paglen (2019)"
  },
  {
    "objectID": "w03/slides.html#biases-in-our-brains-rightarrow-biases-in-our-models-rightarrow-material-effects",
    "href": "w03/slides.html#biases-in-our-brains-rightarrow-biases-in-our-models-rightarrow-material-effects",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Biases In Our Brains \\(\\rightarrow\\) Biases in Our Models \\(\\rightarrow\\) Material Effects",
    "text": "Biases In Our Brains \\(\\rightarrow\\) Biases in Our Models \\(\\rightarrow\\) Material Effects\n\n\n\n\n“Reification”: Pretentious word for an important phenomenon, whereby talking about something (e.g., race) as if it was real ends up leading to it becoming real (having real impacts on people’s lives)1\n\n\nOn average, being classified as a White man as opposed to a Coloured man would have more than quadrupled a person’s income. (Pellicer and Ranchhod 2023)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFields and Fields (2012), for example, coined “racecraft” to describe reification of blackness in US… much more on this later!"
  },
  {
    "objectID": "w03/slides.html#reification-in-science",
    "href": "w03/slides.html#reification-in-science",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Reification in Science",
    "text": "Reification in Science\n\n\n\n\n“““Intelligence”“” Testing\n\n\n\n\nGould (1980)\n\n\n\n\n\nMore Generally\n\n\nGoodhart’s Law: “When a measure becomes a target, it ceases to be a good measure”\nCat-and-mouse game between goals (🚩) and ways of measuring progress towards goals (also 🚩)"
  },
  {
    "objectID": "w03/slides.html#reflective-equilibrium",
    "href": "w03/slides.html#reflective-equilibrium",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Reflective Equilibrium",
    "text": "Reflective Equilibrium\n\nMost criticisms of any framework boil down to, “great in theory, but doesn’t work in practice”\nThe way to take this seriously: reflective equilibrium\nIntroduced by Rawls (1951), but popularized by Rawls (1971)\n\n\nFrom Awad et al. (2022)"
  },
  {
    "objectID": "w03/slides.html#easy-mode-descriptive-judgements",
    "href": "w03/slides.html#easy-mode-descriptive-judgements",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Easy Mode: Descriptive Judgements",
    "text": "Easy Mode: Descriptive Judgements\nHow did you acquire the concept “red”?\n\nPeople pointed to stuff with certain properties and said “red” (or “rojo” or “红”), as pieces of an intersubjective communication system\nThese descriptive labels enable coordination, like driving on left or right side of road!\nNothing very profound or difficult in committing to this descriptive coordination: “for ease of communication, I’ll vibrate my vocal chords like this (or write these symbols) to indicate \\(x\\), and vibrate them like this (or write these other symbols) to indicate \\(y\\)” \nLinguistic choices, when it comes to description, are arbitrary*: Our mouths can make these sounds, and each language is a mapping: [combinations of sounds] \\(\\leftrightarrow\\) [things]\n\ndiːsˈæn ˈfɪfti fɔr ˈfɪfti [US Accent  / Icelandic Accent ]\n\n\n\n\n*(Tiny text footnote: Except for, perhaps, a few fun but rare onomatopoetic cases)"
  },
  {
    "objectID": "w03/slides.html#what-makes-ethical-judgements-more-difficult",
    "href": "w03/slides.html#what-makes-ethical-judgements-more-difficult",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "What Makes Ethical Judgements “More Difficult”?",
    "text": "What Makes Ethical Judgements “More Difficult”?\nHow did you acquire the concept “good”?\n\nPeople pointed to actions with certain properties and said “good” (and pointed at others and said “bad”), as part of instilling values in you\n“Grass is green” just links two descriptive referents together, while “Honesty is good” takes the descriptive concept “honesty” and links it with the normative concept “good”\nIn doing this, parents/teachers/friends are doing way more than just linking sounds and things in the world (describing): they are also prescribing rules of moral conduct!\nNormative concepts go beyond “mere” communication: course of your life / future / [things that matter deeply to people] differ if you act on one set of norms vs. another\n\\(\\implies\\) Ethics centrally involves non-arbitrarily-chosen commitments!"
  },
  {
    "objectID": "w03/slides.html#tldr",
    "href": "w03/slides.html#tldr",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Tl;dr",
    "text": "Tl;dr\n\nLanguages are arbitrary conventions for communication\nEthical systems build on this language to non-arbitrarily mark out things that are good/bad\nLife would not be very different if we “shuffled” words (we’d just vibrate our vocal chords differently), but would be very different if we “shuffled” good/bad labeling"
  },
  {
    "objectID": "w03/slides.html#quick-aside-top-10-linguist-beefs",
    "href": "w03/slides.html#quick-aside-top-10-linguist-beefs",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Quick Aside: Top 10 Linguist Beefs",
    "text": "Quick Aside: Top 10 Linguist Beefs\n\nStatement on previous slide (“Life would not be very different if we shuffled words”), might seem weird/closed-minded/dismissive if you have a certain popular prior belief…\n\n\n\n\n\n\n\nDeutscher (2010)\n\n\n\n\n\n\n\nMcWhorter (2014)"
  },
  {
    "objectID": "w03/slides.html#the-last-time-i-use-this-i-promise",
    "href": "w03/slides.html#the-last-time-i-use-this-i-promise",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "The Last Time I Use This, I Promise",
    "text": "The Last Time I Use This, I Promise"
  },
  {
    "objectID": "w03/slides.html#historical-example-capitalism-and-the-protestant-ethic",
    "href": "w03/slides.html#historical-example-capitalism-and-the-protestant-ethic",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Historical Example: Capitalism and the “Protestant Ethic”",
    "text": "Historical Example: Capitalism and the “Protestant Ethic”\n\nBig changes in history are associated with changes in this good/bad labeling!\nMax Weber (second most-cited sociologist of all time*): Protestant value system gave rise to capitalist system by relabeling what things are good vs. bad (Weber 1904):\n\n\n\n\n\nJesus said to his disciples, “Truly, I say to you, only with difficulty will a rich person enter the kingdom of heaven. Again I tell you, it is easier for a camel to go through the eye of a needle than for a rich person to enter the kingdom of God.” (Matthew 19:23-24)\n\n\nOh, were we loving God worthily, we should have no love at all for money! (St. Augustine 1874, pg. 28)\n\n*(…jumpscare: REIFICATION!)\n\n\n\nThe earliest capitalists lacked legitimacy in the moral climate in which they found themselves. One of the means they found [to legitimize their behavior] was to appropriate the evaluative vocabulary of Protestantism. (Skinner 2012, pg. 157)\n\n\nCalvinism added [to Luther’s doctrine] the necessity of proving one’s faith in worldly activity, [replacing] spiritual aristocracy of monks outside of/above the world with spiritual aristocracy of predestined saints within it. (pg. 121)."
  },
  {
    "objectID": "w03/slides.html#contemporary-example-palestine",
    "href": "w03/slides.html#contemporary-example-palestine",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Contemporary Example: Palestine",
    "text": "Contemporary Example: Palestine\n\nVery few of the relevant empirical facts are in dispute, since opening of crucial archives to three so-called “New Historians” in the 1980s. So why do people still argue?\n\n\n\n\n\nIlan Pappe, one of these historians, concluded from this material that:\n\nThe Israeli state was built upon a massive ethnic cleansing, and\nIs not morally justifiable (Pappe 2006)\n\n\n\nThe immunity Israel has received over the last fifty years encourages others, regimes and oppositions alike, to believe that human and civil rights are irrelevant in the Middle East. The dismantling of the mega-prison in Palestine will send a different, and more hopeful, message.\n\n\n\n\nBenny Morris, another of these historians, concluded that:\n\nThe Israeli state was built upon a massive ethnic cleansing, and\nIs morally justifiable (Morris 1987)\n\n\n\nA Jewish state would not have come into being without the uprooting of 700,000 Palestinians. Therefore it was necessary to uproot them. There was no choice but to expel that population. It was necessary to cleanse the hinterland and cleanse the border areas and cleanse the main roads."
  },
  {
    "objectID": "w03/slides.html#from-week-1-counterargument-to-consequentialism",
    "href": "w03/slides.html#from-week-1-counterargument-to-consequentialism",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "(From Week 1) Counterargument to Consequentialism",
    "text": "(From Week 1) Counterargument to Consequentialism\n\n\n\n\nMillions are kept permanently happy, on the one simple condition that a certain lost soul on the far-off edge of things should lead a life of lonely torture (James 1891)\n\n\nModern example: people “out there” suffer so we can have iPhones, etc.\n\n\n\n\n\n\nLe Guin (1973)"
  },
  {
    "objectID": "w03/slides.html#one-solution-individual-rights",
    "href": "w03/slides.html#one-solution-individual-rights",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "One Solution: Individual Rights",
    "text": "One Solution: Individual Rights\n\n\n\n\nRights are vetoes which individuals can use to cancel out collective/institutional decisions which affect them (key example for us: right to privacy)\nRawls/liberalism: individual rights are lexically prior to “efficiency” and/or distributional concerns\nWhy the buzzword “lexically”? Enter (non-scary) math!\nWe can put lowercase letters of English alphabet in an order: \\(\\texttt{a} \\prec \\texttt{b} \\prec \\cdots \\texttt{z}\\)\nWe can put capital letters of English alphabet in an order: \\(\\texttt{A} \\prec \\texttt{B} \\prec \\cdots \\prec \\texttt{Z}\\)\nWhat if we need to sort stuff with both types? We can decide that capital letters are lexically prior to lowercase letters, giving us a combined ordering:\n\n\n\n\n\n\nDworkin (1977)\n\n\n\n\n\n\\[\n\\boxed{\\texttt{A} \\prec \\texttt{B} \\prec \\cdots \\prec \\texttt{Z} \\prec \\texttt{a} \\prec \\texttt{b} \\prec \\cdots \\prec \\texttt{z}}\n\\]"
  },
  {
    "objectID": "w03/slides.html#lexical-ordering-i-tricked-you",
    "href": "w03/slides.html#lexical-ordering-i-tricked-you",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Lexical Ordering (I Tricked You 😈)",
    "text": "Lexical Ordering (I Tricked You 😈)\n\n\n\n\nYou thought I was just talking about letters, but they’re actually variables: capital letters are rights, lowercase letters are distributive principles\n\n\\[\n\\underbrace{\\texttt{A} \\prec \\texttt{B} \\prec \\cdots \\prec \\texttt{Z}}_{\\mathclap{\\substack{\\text{Individual Rights} \\\\ \\text{Basic Goods}}}} \\phantom{\\prec} \\prec \\phantom{\\prec} \\underbrace{\\texttt{a} \\prec \\texttt{b} \\prec \\cdots \\prec \\texttt{z}}_{\\mathclap{\\substack{\\text{Distributive Principles} \\\\ \\text{Money and whatnot}}}}\n\\]"
  },
  {
    "objectID": "w03/slides.html#better-metaphor-than-letters",
    "href": "w03/slides.html#better-metaphor-than-letters",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Better Metaphor Than Letters",
    "text": "Better Metaphor Than Letters\n\nLetters are where Rawls gets “lexically prior” from, but letters are total orderings (we know where every letter “stands” in relation to every other letter)\nBetter metaphor: a high school with a hierarchy such that\n\n\\[\n\\text{Seniors} \\prec \\text{Juniors} \\prec \\text{Sophomores}  \\prec \\text{Freshmen}\n\\]\n\n\\(\\implies\\) If you’re a Freshman, whether at the “top” or “bottom” of a ranking of Freshmen, you’re still prior to all Sophomores…\nWhy is this more helpful? Because we don’t need to define the rankings within classes to know the rankings between classes in this case"
  },
  {
    "objectID": "w03/slides.html#counterarguments-to-deontology",
    "href": "w03/slides.html#counterarguments-to-deontology",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Counterargument(s) to Deontology",
    "text": "Counterargument(s) to Deontology\n\n\n\n\nDeontological rule: “Don’t lie”\n\nBut then: Nazis come to your house, ask you if you’re harboring any Jews\n\nk, new deontological rule: “Don’t lie unless necessary”\n\nWho decides when it’s necessary?\n\nDeontological commitment: Pacifism / Nonviolence\n\nBut then: someone swingin on you\n\nk, new deontological commitment: Pacifism / Nonviolence Except In Self-Defense\n\nWho decides what counts as self-defense?\n\nDeontological maxim: “The master’s tools will never dismantle the master’s house”\n\nWho conceded “ownership” to the master?\n\n(Trolley problems, etc.)\n\n\n\n\n\n\nChurchill and Ryan (1998) (Derrick Jensen intro removed from later editions so… I put it on dang GitHub)"
  },
  {
    "objectID": "w03/slides.html#a-synthesis-two-level-utilitarianism",
    "href": "w03/slides.html#a-synthesis-two-level-utilitarianism",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "A Synthesis: Two-Level Utilitarianism",
    "text": "A Synthesis: Two-Level Utilitarianism\n\n\n\n\nIt would be exhausting to compute Nash equilibrium strategies for every scenario\nInstead, we can develop heuristics that work for most cases, then reevaluate and update when we encounter tough cases\n(Brings us back to reflective equilibrium!)\n\n\n\n\n\n\nKahneman (2011)"
  },
  {
    "objectID": "w03/slides.html#individual-vs.-social-morality",
    "href": "w03/slides.html#individual-vs.-social-morality",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Individual vs. Social Morality",
    "text": "Individual vs. Social Morality\n\nThat was all already hard enough, to reason about individual morality\nNow add in the fact that we live in a society 😰\nThings that happen depend not only on our choices but also the choices of others\n\n\n\n\nSeinfeld: Living in a Society (Clip) | TBS"
  },
  {
    "objectID": "w03/slides.html#enter-game-theory",
    "href": "w03/slides.html#enter-game-theory",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Enter Game Theory",
    "text": "Enter Game Theory\n\nA tool for analyzing how individual choices + choices of others \\(\\rightarrow\\) outcomes!\n\n\n\n\n\nExample: You (\\(A\\)) and a friend (\\(B\\)) committed a robbery, and you’re brought into the police station for questioning.\nYou’re placed in separate rooms, and each of you is offered a plea deal: if you testify while your partner stays silent, you go free and they go to jail for 3 years.\nOtherwise, if you both stay silent, they have very little evidence and can only jail you for 1 year\nHowever, there’s a catch: if you both confess, you both get two years in jail, since they now have maximal evidence\n\n\n\n\n\n\nSource: Wikimedia Commons"
  },
  {
    "objectID": "w03/slides.html#individual-decision-making",
    "href": "w03/slides.html#individual-decision-making",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Individual Decision-Making",
    "text": "Individual Decision-Making\n\n\n\n\nLet’s think through \\(A\\)’s best responses to the possible choices \\(B\\) could make:\nIf \\(B\\) stays silent, what is \\(A\\)’s best option?\n\nStaying silent results in 1 year of jail\nTestifying results in 0 years of jail\nSo it is better to testify\n\nIf \\(B\\) testifies, what is \\(A\\)’s best option?\n\nStaying silent results in 3 years of jail\nTestifying results in 2 years of jail\nSo it is better to testify\n\nThe result: regardless of what \\(B\\) does, \\(A\\) is better off testifying!\n\n\n\n\n\n\nSource: Wikimedia Commons"
  },
  {
    "objectID": "w03/slides.html#the-social-outcome",
    "href": "w03/slides.html#the-social-outcome",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "The Social Outcome",
    "text": "The Social Outcome\n\n\n\n\nThe game is symmetric, so the same logic applies for \\(B\\)\nConclusion: the outcome of the game will be \\(s^* = (\\text{Testify}, \\text{Testify})\\)\nThis is called a Nash equilibrium: no player \\(i\\) can make themselves better off by deviating from \\(s_i\\)\n\n\n\n\n\n\nSource: Wikimedia Commons"
  },
  {
    "objectID": "w03/slides.html#how-do-we-fix-this-conventions",
    "href": "w03/slides.html#how-do-we-fix-this-conventions",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "How Do We Fix This? Conventions!",
    "text": "How Do We Fix This? Conventions!\n\n\n\n\nWe encounter this type of problem every day if we drive! You (\\(A\\)) and another driver (\\(B\\)) arrive at an intersection:\n\n\n\n\n\n\n\n\n\\(B\\)\n\n\n\n\nStop\nDrive\n\n\n\\(A\\)\nStop\n\\(-1,-1\\)\n\\(-3,\\phantom{-}0\\)\n\n\nDrive\n\\(\\phantom{-}0, -3\\)\n\\(-10,-10\\)\n\n\n\n\n\n\n\nIf both stop, we’re mostly bored: \\(u_A = -1\\)\nIf we stop and the other person drives, we’re mad that they got to go and we didn’t: \\(u_A = -3\\)\nIf both drive, we crash: \\(u_A = -10\\)"
  },
  {
    "objectID": "w03/slides.html#without-a-convention",
    "href": "w03/slides.html#without-a-convention",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Without A Convention",
    "text": "Without A Convention\n\n\n\n\nWe’re “frozen”: this game has no unique Nash equilibrium, so we cannot say (on the basis of individual rationality) what will happen!\nWithout a convention: power/aggression takes over. “War of all against all”, only the strong survive, etc. (life is “nasty, brutish, and short”)\n\n\n\n\n\n\n\n\n\n\\(B\\)\n\n\n\n\nStop\nDrive\n\n\n\\(A\\)\nStop\n\\({\\color{orange}\\cancel{\\color{black}-1}},{\\color{lightblue}\\cancel{\\color{black}-1}}\\)\n\\(\\boxed{-3},\\boxed{0}\\)\n\n\nDrive\n\\(\\boxed{0}, \\boxed{-3}\\)\n\\({\\color{orange}\\cancel{\\color{black}-10}},{\\color{lightblue}\\cancel{\\color{black}-10}}\\)\n\n\n\n\n\n\n\n\nIf \\(A\\)’s aggression is \\(\\Pr(s_A = \\textsf{Drive}) = X \\sim \\mathcal{U}[0,1]\\), \\(B\\)’s aggression is \\(\\Pr(s_B = \\textsf{Drive}) = Y \\sim \\mathcal{U}[0,1]\\), what happens at individual and societal levels?\n\n\\[\n\\begin{align*}\n\\mathbb{E}[u_A] = \\mathbb{E}[u_B] &= \\int_{0}^{1}\\int_{0}^{1}\\left(x - 2y -8xy - 1\\right)dy \\, dx = -3.5 \\\\\n\\underbrace{\\mathbb{E}\\mkern-3mu\\left[u_A + u_B\\right]}_{\\mathclap{\\text{Utilitarian Social Welfare}}} &= -3.5\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w03/slides.html#the-convention-of-traffic-lights",
    "href": "w03/slides.html#the-convention-of-traffic-lights",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "The Convention of Traffic Lights",
    "text": "The Convention of Traffic Lights\n\nIf we don’t want a world where \\(\\text{Happiness}(i) \\propto \\Pr(i \\text{ more aggro than }j)\\), we can introduce traffic lights:\n\n\n\n\n\nNow in “correlated equilibrium”, where we ensure* coordinated \\(\\Pr((\\textsf{Drive}, \\textsf{Stop})) = 0.5\\), \\(\\Pr((\\textsf{Stop}, \\textsf{Drive})) = 0.5\\)\n\\(\\mathbb{E}[u_A] = (0.5)(0) + (0.5)(-3) = -1.5\\)\n\\(\\mathbb{E}[u_B] = (0.5)(-3) + (0.5)(0) = -1.5\\)\n\n\n\n\n\n\n\n\n\n\\(B\\)\n\n\n\n\nStop\nDrive\n\n\n\\(A\\)\nStop\n\\({\\color{orange}\\cancel{\\color{black}-1}},{\\color{lightblue}\\cancel{\\color{black}-1}}\\)\n\\(\\boxed{-3},\\boxed{0}\\)\n\n\nDrive\n\\(\\boxed{0}, \\boxed{-3}\\)\n\\({\\color{orange}\\cancel{\\color{black}-10}},{\\color{lightblue}\\cancel{\\color{black}-10}}\\)\n\n\n\n\n\n\n\n\nEmpirical (anthropological) findings across literally thousands of different cultures throughout the world: people are willing to give up rewards to ensure fairness (see, e.g., Henrich et al. (2001))\n\n*(through, for example, traffic laws: equal in theory… In practice? Another story)"
  },
  {
    "objectID": "w03/slides.html#so-how-should-we-makechoose-conventions",
    "href": "w03/slides.html#so-how-should-we-makechoose-conventions",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "So How Should We Make/Choose Conventions?",
    "text": "So How Should We Make/Choose Conventions?\n\nHobbes (1651): Only way out of “war of all against all” is to surrender all power to one sovereign (the Leviathan)\nRousseau (1762): Social contract\n[Big big ~200 year gap here… can you think of why? Hint: French Revolution in 1789]\nRawls (1971): Social contract behind the “veil of ignorance”\n\nIf we didn’t know where we were going to end up in society, how would we set it up?"
  },
  {
    "objectID": "w03/slides.html#rawls-veil-of-ignorance",
    "href": "w03/slides.html#rawls-veil-of-ignorance",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Rawls’ Veil of Ignorance",
    "text": "Rawls’ Veil of Ignorance\n\nProbably the most important tool for policy whitepapers!\n“Justice as fairness” (next week: fairness in AI 😜)\nWe don’t know whether we’ll be \\(A\\) or \\(B\\) in the intersection game, so we’d choose the traffic light!\nMore profoundly: We don’t know what race, gender, class, ethnicity, sexuality, disability status we’ll have; We don’t know whether we’ll be Israeli or Palestinian; we don’t know whether we’ll own means of production or own only our labor power (and thus have to sell it on a market to survive)… 🤔"
  },
  {
    "objectID": "w03/slides.html#one-final-reminder",
    "href": "w03/slides.html#one-final-reminder",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "One Final Reminder",
    "text": "One Final Reminder\n\nIndustry rule #4080: Cannot “prove” \\(q(x) = \\text{``Algorithm }x\\text{ is fair''}\\)! Only \\(p(x) \\implies q(y)\\):\n\n\\[\n\\underbrace{p(x)}_{\\substack{\\text{Accept ethical} \\\\ \\text{framework }x}} \\implies \\underbrace{q(y)}_{\\substack{\\text{Algorithms should} \\\\ \\text{satisfy condition }y}}\n\\]\n\nBefore: possible ethical frameworks (values for \\(x\\))\nNow: possible fairness criteria (values for \\(y\\))"
  },
  {
    "objectID": "w03/slides.html#categories-of-fairness-criteria",
    "href": "w03/slides.html#categories-of-fairness-criteria",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Categories of Fairness Criteria",
    "text": "Categories of Fairness Criteria\n\nRoughly, approaches to fairness/bias in AI can be categorized as follows:\n\n\nFairness\n\n\n\n\n\n\nContext-Free\n\n\nSingle-Threshold Fairness\nEqual Prediction\nEqual Decision\n\n\n\n\n\n\n\n\n\nContext-Sensitive\n\n\nFairness via Similarity Metric(s)\nCausal Definitions\n\n\n\n\n\n\n\n[Today] Context-Free Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of Machine Learning (you already know much of it, given DSAN 5000!)\nBut easy-to-grasp notion \\(\\neq\\) “good” notion!\nYour job: push yourself to (a) consider what is getting left out of the context-free definitions, and (b) the loopholes that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”"
  },
  {
    "objectID": "w03/slides.html#laws-often-perfectly-technically-fair",
    "href": "w03/slides.html#laws-often-perfectly-technically-fair",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Laws: Often Perfectly “Technically Fair”",
    "text": "Laws: Often Perfectly “Technically Fair”\n\nAh, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!\n\n\n(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)\n\nAnatole France, Le Lys Rouge (France 1894)"
  },
  {
    "objectID": "w03/slides.html#the-brogrammers-criterion",
    "href": "w03/slides.html#the-brogrammers-criterion",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "The Brogrammer’s Criterion",
    "text": "The Brogrammer’s Criterion\ndf.drop(columns=[\"race\"], inplace=True)\n\nRacism solved, folks! 🥳🎊🎉 End of the course, have a great rest of your data science career ✌️"
  },
  {
    "objectID": "w03/slides.html#no-fairness-through-unawareness",
    "href": "w03/slides.html#no-fairness-through-unawareness",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "(No) Fairness Through Unawareness",
    "text": "(No) Fairness Through Unawareness\n\nHW1: Using tiny sample (\\(N &lt; 10K\\)) of Florida voter registrations… RandomForestClassifier (default settings, no hyperparameter tuning, no cross-validation, no ensembling with other methods) will predict self-reported race with \\(&gt;90\\%\\) accuracy (in balanced sample) from just surname and county of residence\n\nCan reach \\(70\\text{-}75\\%\\) with just surname or just county of residence\n\nAlso in HW1: Facebook ad matching service provides over 1,000 different user attributes for (micro)targeting\n\n\nFrom Datta et al. (2017)"
  },
  {
    "objectID": "w03/slides.html#to-make-it-even-more-concrete",
    "href": "w03/slides.html#to-make-it-even-more-concrete",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "To Make It Even More Concrete…",
    "text": "To Make It Even More Concrete…\n\nBloomberg analysis of neighborhoods with same-day delivery from Amazon:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Figures from Ingold and Soper (2016)"
  },
  {
    "objectID": "w03/slides.html#we-can-do-a-bit-better",
    "href": "w03/slides.html#we-can-do-a-bit-better",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "We Can Do (A Bit) Better…",
    "text": "We Can Do (A Bit) Better…\n\nUse random variables to model inferences made by an algorithm (or a human!)\n\\(\\implies\\) fairness by statistically equalizing loan rejections, error rate, etc. between groups\nObvious societal drawback: equality does not ameliorate the effects of past injustices (see: police contact vs. trust-in-government plot from last week)\n\nThis one we saw coming, given “context-free” nature!\n\nLess obvious mathematical drawback: impossibility results (because algebra 😳)\n\nRoughly: can’t satisfy [more than] two statistical fairness criteria at once; similar to how setting \\(\\Pr(X) = p\\) also determines \\(\\Pr(\\text{not }X) = 1 - p\\), or how plugging \\(x = 3\\) into \\(x + y = 5\\) leaves only one possibility \\(y = 2\\)\n\nBUT, “impossibility” \\(\\neq\\) impossibility: (a) one criteria may be “all you need” in given setting; (b) can derive more robust measures by “relaxing” confusion-matrix measures"
  },
  {
    "objectID": "w03/slides.html#what-the-fairness-measures-will-feel-like-for-now",
    "href": "w03/slides.html#what-the-fairness-measures-will-feel-like-for-now",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "What the Fairness Measures Will Feel Like For Now",
    "text": "What the Fairness Measures Will Feel Like For Now\n\n\n(They will get more robust and will incorporate context soon, I promise!)"
  },
  {
    "objectID": "w03/slides.html#who-remembers-confusion-matrices",
    "href": "w03/slides.html#who-remembers-confusion-matrices",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Who Remembers… 🎉Confusion Matrices!!!🎉",
    "text": "Who Remembers… 🎉Confusion Matrices!!!🎉\n\nTerrifyingly higher stakes than in DSAN 5000, however!\nNow \\(D = 1\\) could literally mean “shoot this person” or “throw this person in jail for life”\n\n\nFrom Mitchell et al. (2021)"
  },
  {
    "objectID": "w03/slides.html#our-first-fairness-measure-finally",
    "href": "w03/slides.html#our-first-fairness-measure-finally",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Our First Fairness Measure (Finally)!",
    "text": "Our First Fairness Measure (Finally)!\n\nStandard across the literature: Random Variable \\(A_i\\) “encoding” membership in protected/sensitive group. In HW1, for example:\n\n\\[\nA_i = \\begin{cases}\n0 &\\text{if }i\\text{ self-reported ``white''} \\\\\n1 &\\text{if }i\\text{ self-reported ``black''}\n\\end{cases}\n\\]\n\nNotice: choice of mapping into \\(\\{0, 1\\}\\) here non-arbitrary!\nWe want our models/criteria to be descriptively but also normatively robust; e.g.:\nIf (antecedent I hold, though majority in US do not) one believes that ending (much less repairing) centuries of unrelenting white supremacist violence here might require asymmetric race-based policies,\nThen our model should allow different normative labels and differential weights on\n\\[\n\\begin{align*}\n\\Delta &= (\\text{Fairness} \\mid A = 1) - (\\text{Fairness} \\mid A = 0) \\\\\n\\nabla &= (\\text{Fairness} \\mid A = 0) - (\\text{Fairness} \\mid A = 1)\n\\end{align*}\n\\]\ndespite the descriptive fact that \\(\\Delta = -\\nabla\\)."
  },
  {
    "objectID": "w03/slides.html#where-descriptive-and-normative-become-intertwined",
    "href": "w03/slides.html#where-descriptive-and-normative-become-intertwined",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Where Descriptive and Normative Become Intertwined",
    "text": "Where Descriptive and Normative Become Intertwined\n\nAllowing this asymmetry is precisely what enables bring descriptive facts to bear on normative concerns!\nMathematically we can always “flip” the mapping from racial labels into \\(\\{0, 1\\}\\)…\nBut this (in a precise, mathematical sense: namely, isomorphism) implies that we’re treating racial categorization as the same type of phenomenon as driving on left or right side of road (see: prev slides on why we make the descriptive vs. normative distinction)\n(See also: Sweden’s Dagen H!)"
  },
  {
    "objectID": "w03/slides.html#fairness-through-equalized-positive-rates",
    "href": "w03/slides.html#fairness-through-equalized-positive-rates",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "“Fairness” Through Equalized Positive Rates",
    "text": "“Fairness” Through Equalized Positive Rates\n\\[\n\\Pr(D = 1 \\mid A = 0) = \\Pr(D = 1 \\mid A = 1)\n\\]\n\nThis works specifically for discrete, binary-valued categories\nFor general attributes (whether discrete or continuous!), generalizes to:\n\n\\[\nD \\perp A \\iff \\Pr(D = d, A = a) = \\Pr(D = d)\\Pr(A = a)\n\\]"
  },
  {
    "objectID": "w03/slides.html#fairness-through-equalized-error-rates",
    "href": "w03/slides.html#fairness-through-equalized-error-rates",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "“Fairness” Through Equalized Error Rates",
    "text": "“Fairness” Through Equalized Error Rates\n\nEqualized False Positive Rate:\n\n\\[\n\\Pr(D = 1 \\mid Y = 0, A = 0) = \\Pr(D = 1 \\mid Y = 0, A = 1)\n\\]\n\nEqualized False Negative Rate:\n\n\\[\n\\Pr(D = 0 \\mid Y = 1, A = 0) = \\Pr(D = 0 \\mid Y = 1, A = 1)\n\\]\n\nFor general (non-binary) attributes: \\((D \\perp A) \\mid Y\\):\n\n\\[\n\\Pr(D = d, A = a \\mid Y = y) = \\Pr(D = d \\mid Y = y)\\Pr(A = a \\mid Y = y)\n\\]"
  },
  {
    "objectID": "w03/slides.html#no-more-equations",
    "href": "w03/slides.html#no-more-equations",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "NO MORE EQUATIONS! 😤",
    "text": "NO MORE EQUATIONS! 😤\n\nDepending on your background and/or learning style (say, visual vs. auditory), you may be able to look at equations on previous slides and “see” what they’re “saying”\nIf your brain works similarly to mine, however, your eyes glazed over, you began dissociating, planning an escape route, etc.\nIf you’re in the latter group, welcome to the cult of Probabilistic Graphical Models 😈"
  },
  {
    "objectID": "w03/slides.html#baby-steps-a-real-world-confusion-matrix",
    "href": "w03/slides.html#baby-steps-a-real-world-confusion-matrix",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Baby Steps: A Real-World Confusion Matrix",
    "text": "Baby Steps: A Real-World Confusion Matrix\n\n\n\n\n\n\n\n\n\nLabeled Low-Risk\nLabeled High-Risk\n\n\n\n\nDidn’t Do More Crimes\nTrue Negative\nFalse Positive\n\n\nDid More Crimes\nFalse Negative\nTrue Positive\n\n\n\n\nWhat kinds of causal connections and/or feedback loops might there be between our decision variable (low vs. high risk) and our outcome variable (did vs. didn’t do more crimes)\nWhat types of policy implications might this process have, after it “runs” for several “iterations”?\nWhy might some segments of society, with some shared ethical framework(s), weigh the “costs” of false negatives and false positives differently from other segments of society with different shared ethical framework(s)?\n(Non-rhetorical questions!)"
  },
  {
    "objectID": "w03/slides.html#references",
    "href": "w03/slides.html#references",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "References",
    "text": "References\n\n\nAwad, Edmond, Sydney Levine, Michael Anderson, Susan Leigh Anderson, Vincent Conitzer, M. J. Crockett, Jim A. C. Everett, et al. 2022. “Computational Ethics.” Trends in Cognitive Sciences 26 (5): 388–405. https://doi.org/10.1016/j.tics.2022.02.009.\n\n\nBishop, Marlon, and Tatiana Fernandez. 2017. “80 Years On, Dominicans And Haitians Revisit Painful Memories Of Parsley Massacre.” NPR, October. https://www.npr.org/sections/parallels/2017/10/07/555871670/80-years-on-dominicans-and-haitians-revisit-painful-memories-of-parsley-massacre.\n\n\nBourdieu, Pierre. 2010. Sociology Is a Martial Art: Political Writings by Pierre Bourdieu. New Press.\n\n\nChurchill, Ward, and Michael Ryan. 1998. Pacifism as Pathology: Reflections on the Role of Armed Struggle in North America. PM Press.\n\n\nCrawford, Kate, and Trevor Paglen. 2019. “Excavating AI: The Politics of Training Sets for Machine Learning.” AI Now Institute, NYU. https://excavating.ai.\n\n\nDatta, Anupam, Matt Fredrikson, Gihyuk Ko, Piotr Mardziel, and Shayak Sen. 2017. “Proxy Non-Discrimination in Data-Driven Systems.” arXiv. https://doi.org/10.48550/arXiv.1707.08120.\n\n\nDeutscher, Guy. 2010. Through the Language Glass: Why the World Looks Different in Other Languages. Henry Holt and Company.\n\n\nDube, Arindrajit, Jeff Jacobs, Suresh Naidu, and Siddharth Suri. 2020. “Monopsony in Online Labor Markets.” American Economic Review: Insights 2 (1): 33–46. https://doi.org/10.1257/aeri.20180150.\n\n\nDworkin, Ronald. 1977. Taking Rights Seriously. A&C Black.\n\n\nFields, Barbara J., and Karen E. Fields. 2012. Racecraft: The Soul of Inequality in American Life. Verso Books.\n\n\nFrance, Anatole. 1894. Le Lys Rouge (The Red Lily). G. Wells.\n\n\nGould, Stephen Jay. 1980. The Mismeasure of Man (Revised and Expanded). W. W. Norton & Company.\n\n\nGray, Mary L., and Siddharth Suri. 2019. Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass. HarperCollins.\n\n\nHenrich, Joseph, Robert Boyd, Samuel Bowles, Colin Camerer, Ernst Fehr, Herbert Gintis, and Richard McElreath. 2001. “In Search of Homo Economicus: Behavioral Experiments in 15 Small-Scale Societies.” American Economic Review 91 (2): 73–78. https://doi.org/10.1257/aer.91.2.73.\n\n\nHobbes, Thomas. 1651. Leviathan: With Selected Variants from the Latin Edition of 1668. Hackett Publishing.\n\n\nIngold, David, and Spencer Soper. 2016. “Amazon Doesn’t Consider the Race of Its Customers. Should It?” Bloomberg, April. http://www.bloomberg.com/graphics/2016-amazon-same-day/.\n\n\nJames, William. 1891. “The Moral Philosopher and the Moral Life.” International Journal of Ethics 1 (3): 330–54. https://www.jstor.org/stable/2375309.\n\n\nKahneman, Daniel. 2011. Thinking, Fast and Slow. Farrar, Straus and Giroux.\n\n\nLabov, William. 2013. The Language of Life and Death: The Transformation of Experience in Oral Narrative. Cambridge University Press.\n\n\nLe Guin, Ursula K. 1973. The Ones Who Walk Away from Omelas: A Story. HarperCollins.\n\n\nMcWhorter, John H. 2014. The Language Hoax: Why the World Looks the Same in Any Language. Oxford University Press.\n\n\nMitchell, Shira, Eric Potash, Solon Barocas, Alexander D’Amour, and Kristian Lum. 2021. “Algorithmic Fairness: Choices, Assumptions, and Definitions.” Annual Review of Statistics and Its Application 8 (1): 141–63. https://doi.org/10.1146/annurev-statistics-042720-125902.\n\n\nMorris, Benny. 1987. The Birth of the Palestinian Refugee Problem, 1947-1949. Cambridge University Press.\n\n\nPappe, Ilan. 2006. The Ethnic Cleansing of Palestine. Simon and Schuster.\n\n\nPellicer, Miquel, and Vimal Ranchhod. 2023. “Understanding the Effects of Racial Classification in Apartheid South Africa.” Journal of Development Economics 160 (January): 102998. https://doi.org/10.1016/j.jdeveco.2022.102998.\n\n\nRawls, John. 1951. “Outline of a Decision Procedure for Ethics.” The Philosophical Review 60 (2): 177–97. https://doi.org/10.2307/2181696.\n\n\n———. 1971. A Theory of Justice: Original Edition. Harvard University Press.\n\n\nRoemer, John E. 1988. Free to Lose: An Introduction to Marxist Economic Philosophy. Harvard University Press.\n\n\nRousseau, Jean-Jacques. 1762. The Social Contract. Geneva: J. M. Dent.\n\n\nSkinner, Quentin. 2012. Visions of Politics, Volume 1: Regarding Method. Cambridge: Cambridge University Press.\n\n\nSt. Augustine. 1874. The Works of Aurelius Augustine: Lectures or Tractates on the Gospel According to St. John, v. 2. T. & T. Clark.\n\n\nWeber, Max. 1904. The Protestant Ethic and the Spirit of Capitalism. Courier Corporation.\n\n\n\n\n\nDSAN 5450 Week 3: (Descriptive) Fairness in AI"
  },
  {
    "objectID": "w03/index.html",
    "href": "w03/index.html",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#loose-ends",
    "href": "w03/index.html#loose-ends",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Loose Ends",
    "text": "Loose Ends\n\nNormative vs. Descriptive “Exploitation”: How can we disentangle these in our understanding of the term? (Roemer 1988)\n\nUnder descriptive definition, one can “exploit” corn or land in the exact same way one “exploits” human labor (just another type of input into the production process)\nUtility-wise, an economy with exploitation can be unambiguously better than one without exploitation: if 10 people \\(H\\) own means of production, and 990 people \\(S\\) own only their labor power (landless peasants, for example), allowing \\(H\\) to exploit \\(S\\) for a wage increases utility for both: \\(H\\) acquires profits, \\(S\\) doesn’t starve to death\n\n“Tracing back” causes / unraveling history\n\n“The result [of modern 24-hour news cycles] is a litany of events with no beginning and no real end, thrown together only because they occurred at the same time[,] cut off from their antecedents and consequenes” (Bourdieu 2010)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#ethics-of-eliciting-sensitive-linguistic-data",
    "href": "w03/index.html#ethics-of-eliciting-sensitive-linguistic-data",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Ethics of Eliciting Sensitive Linguistic Data",
    "text": "Ethics of Eliciting Sensitive Linguistic Data\n\n\n\n\n\n\n\n\n\nFrom Labov (2013), pg. 4\n\n\n\n\n\n\n\nFrom “80 Years On, Dominicans And Haitians Revisit Painful Memories Of Parsley Massacre”, NPR Parallels, 7 Oct 2017 (Bishop and Fernandez 2017)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#part-3-the-training-data-bottleneck",
    "href": "w03/index.html#part-3-the-training-data-bottleneck",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Part 3: The “Training Data Bottleneck”",
    "text": "Part 3: The “Training Data Bottleneck”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSnorkel.AI, An Introduction to Snorkel and Data-Centric AI\n\n\n\n\n\n\nWith so much technical progress […] why is there so little real enterprise success? The answer all too often is that many enterprises continue to be bottlenecked by one key ingredient: the large amounts of labeled data [needed] to train these new systems.\n\n\n\nFigure 1: ibid. (PS, if it seems like I’m picking on them: these are the ‘good guys’ IMO! W.r.t. foregrounding training data as labor)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#human-labor",
    "href": "w03/index.html#human-labor",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Human Labor",
    "text": "Human Labor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Snorkel AI, “The Principles of Data-Centric AI Development by Alex Ratner” (YouTube)\n\n\n\n\n\n\n\n\nGray and Suri (2019)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#computer-scientists-being-responsible-at-georgetown",
    "href": "w03/index.html#computer-scientists-being-responsible-at-georgetown",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Computer Scientists Being Responsible (At Georgetown!)",
    "text": "Computer Scientists Being Responsible (At Georgetown!)\n\n\n\nDr. Redmiles’ homepage (Since Quarto also freezes when I try to embed it…)\n\n\n\n(PS… UMD undergrad CS class of 2013 extremely overrepresented here 😜)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#computer-scientists-being-responsible-at-georgetown-1",
    "href": "w03/index.html#computer-scientists-being-responsible-at-georgetown-1",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Computer Scientists Being Responsible (At Georgetown!)",
    "text": "Computer Scientists Being Responsible (At Georgetown!)\n\n\n\nGU360 Course Page",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#so-what-comes-with-human-labels-human-biases",
    "href": "w03/index.html#so-what-comes-with-human-labels-human-biases",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "So, What Comes With Human Labels? Human Biases!",
    "text": "So, What Comes With Human Labels? Human Biases!\n\n\n\n\n\n\n\n\n\nCrawford and Paglen (2019)\n\n\n\n\n\n\n\nImage tagged in ImageNet with the label “BOLSHEVIK”. From Crawford and Paglen (2019)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#biases-in-our-brains-rightarrow-biases-in-our-models-rightarrow-material-effects",
    "href": "w03/index.html#biases-in-our-brains-rightarrow-biases-in-our-models-rightarrow-material-effects",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Biases In Our Brains \\(\\rightarrow\\) Biases in Our Models \\(\\rightarrow\\) Material Effects",
    "text": "Biases In Our Brains \\(\\rightarrow\\) Biases in Our Models \\(\\rightarrow\\) Material Effects\n\n\n\n\n\n\n\n“Reification”: Pretentious word for an important phenomenon, whereby talking about something (e.g., race) as if it was real ends up leading to it becoming real (having real impacts on people’s lives)1\n\n\nOn average, being classified as a White man as opposed to a Coloured man would have more than quadrupled a person’s income. (Pellicer and Ranchhod 2023)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#reification-in-science",
    "href": "w03/index.html#reification-in-science",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Reification in Science",
    "text": "Reification in Science\n\n\n\n\n\n\n\n“““Intelligence”“” Testing\n\n\n\n\nGould (1980)\n\n\n\n\n\nMore Generally\n\n\nGoodhart’s Law: “When a measure becomes a target, it ceases to be a good measure”\nCat-and-mouse game between goals (🚩) and ways of measuring progress towards goals (also 🚩)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#reflective-equilibrium",
    "href": "w03/index.html#reflective-equilibrium",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Reflective Equilibrium",
    "text": "Reflective Equilibrium\n\nMost criticisms of any framework boil down to, “great in theory, but doesn’t work in practice”\nThe way to take this seriously: reflective equilibrium\nIntroduced by Rawls (1951), but popularized by Rawls (1971)\n\n\n\n\nFrom Awad et al. (2022)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#easy-mode-descriptive-judgements",
    "href": "w03/index.html#easy-mode-descriptive-judgements",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Easy Mode: Descriptive Judgements",
    "text": "Easy Mode: Descriptive Judgements\nHow did you acquire the concept “red”?\n\nPeople pointed to stuff with certain properties and said “red” (or “rojo” or “红”), as pieces of an intersubjective communication system\nThese descriptive labels enable coordination, like driving on left or right side of road!\nNothing very profound or difficult in committing to this descriptive coordination: “for ease of communication, I’ll vibrate my vocal chords like this (or write these symbols) to indicate \\(x\\), and vibrate them like this (or write these other symbols) to indicate \\(y\\)” \nLinguistic choices, when it comes to description, are arbitrary*: Our mouths can make these sounds, and each language is a mapping: [combinations of sounds] \\(\\leftrightarrow\\) [things]\n\ndiːsˈæn ˈfɪfti fɔr ˈfɪfti [US Accent  / Icelandic Accent ]\n\n\n\n\n*(Tiny text footnote: Except for, perhaps, a few fun but rare onomatopoetic cases)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#what-makes-ethical-judgements-more-difficult",
    "href": "w03/index.html#what-makes-ethical-judgements-more-difficult",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "What Makes Ethical Judgements “More Difficult”?",
    "text": "What Makes Ethical Judgements “More Difficult”?\nHow did you acquire the concept “good”?\n\nPeople pointed to actions with certain properties and said “good” (and pointed at others and said “bad”), as part of instilling values in you\n“Grass is green” just links two descriptive referents together, while “Honesty is good” takes the descriptive concept “honesty” and links it with the normative concept “good”\nIn doing this, parents/teachers/friends are doing way more than just linking sounds and things in the world (describing): they are also prescribing rules of moral conduct!\nNormative concepts go beyond “mere” communication: course of your life / future / [things that matter deeply to people] differ if you act on one set of norms vs. another\n\\(\\implies\\) Ethics centrally involves non-arbitrarily-chosen commitments!",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#tldr",
    "href": "w03/index.html#tldr",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Tl;dr",
    "text": "Tl;dr\n\nLanguages are arbitrary conventions for communication\nEthical systems build on this language to non-arbitrarily mark out things that are good/bad\nLife would not be very different if we “shuffled” words (we’d just vibrate our vocal chords differently), but would be very different if we “shuffled” good/bad labeling",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#quick-aside-top-10-linguist-beefs",
    "href": "w03/index.html#quick-aside-top-10-linguist-beefs",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Quick Aside: Top 10 Linguist Beefs",
    "text": "Quick Aside: Top 10 Linguist Beefs\n\nStatement on previous slide (“Life would not be very different if we shuffled words”), might seem weird/closed-minded/dismissive if you have a certain popular prior belief…\n\n\n\n\n\n\n\n\n\n\nDeutscher (2010)\n\n\n\n\n\n\n\nMcWhorter (2014)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#the-last-time-i-use-this-i-promise",
    "href": "w03/index.html#the-last-time-i-use-this-i-promise",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "The Last Time I Use This, I Promise",
    "text": "The Last Time I Use This, I Promise",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#historical-example-capitalism-and-the-protestant-ethic",
    "href": "w03/index.html#historical-example-capitalism-and-the-protestant-ethic",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Historical Example: Capitalism and the “Protestant Ethic”",
    "text": "Historical Example: Capitalism and the “Protestant Ethic”\n\nBig changes in history are associated with changes in this good/bad labeling!\nMax Weber (second most-cited sociologist of all time*): Protestant value system gave rise to capitalist system by relabeling what things are good vs. bad (Weber 1904):\n\n\n\n\n\n\n\n\nJesus said to his disciples, “Truly, I say to you, only with difficulty will a rich person enter the kingdom of heaven. Again I tell you, it is easier for a camel to go through the eye of a needle than for a rich person to enter the kingdom of God.” (Matthew 19:23-24)\n\n\nOh, were we loving God worthily, we should have no love at all for money! (St. Augustine 1874, pg. 28)\n\n*(…jumpscare: REIFICATION!)\n\n\n\nThe earliest capitalists lacked legitimacy in the moral climate in which they found themselves. One of the means they found [to legitimize their behavior] was to appropriate the evaluative vocabulary of Protestantism. (Skinner 2012, pg. 157)\n\n\nCalvinism added [to Luther’s doctrine] the necessity of proving one’s faith in worldly activity, [replacing] spiritual aristocracy of monks outside of/above the world with spiritual aristocracy of predestined saints within it. (pg. 121).",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#contemporary-example-palestine",
    "href": "w03/index.html#contemporary-example-palestine",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Contemporary Example: Palestine",
    "text": "Contemporary Example: Palestine\n\nVery few of the relevant empirical facts are in dispute, since opening of crucial archives to three so-called “New Historians” in the 1980s. So why do people still argue?\n\n\n\n\n\n\n\n\nIlan Pappe, one of these historians, concluded from this material that:\n\nThe Israeli state was built upon a massive ethnic cleansing, and\nIs not morally justifiable (Pappe 2006)\n\n\n\nThe immunity Israel has received over the last fifty years encourages others, regimes and oppositions alike, to believe that human and civil rights are irrelevant in the Middle East. The dismantling of the mega-prison in Palestine will send a different, and more hopeful, message.\n\n\n\n\nBenny Morris, another of these historians, concluded that:\n\nThe Israeli state was built upon a massive ethnic cleansing, and\nIs morally justifiable (Morris 1987)\n\n\n\nA Jewish state would not have come into being without the uprooting of 700,000 Palestinians. Therefore it was necessary to uproot them. There was no choice but to expel that population. It was necessary to cleanse the hinterland and cleanse the border areas and cleanse the main roads.",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#from-week-1-counterargument-to-consequentialism",
    "href": "w03/index.html#from-week-1-counterargument-to-consequentialism",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "(From Week 1) Counterargument to Consequentialism",
    "text": "(From Week 1) Counterargument to Consequentialism\n\n\n\n\n\n\n\nMillions are kept permanently happy, on the one simple condition that a certain lost soul on the far-off edge of things should lead a life of lonely torture (James 1891)\n\n\nModern example: people “out there” suffer so we can have iPhones, etc.\n\n\n\n\n\n\nLe Guin (1973)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#one-solution-individual-rights",
    "href": "w03/index.html#one-solution-individual-rights",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "One Solution: Individual Rights",
    "text": "One Solution: Individual Rights\n\n\n\n\n\n\n\nRights are vetoes which individuals can use to cancel out collective/institutional decisions which affect them (key example for us: right to privacy)\nRawls/liberalism: individual rights are lexically prior to “efficiency” and/or distributional concerns\nWhy the buzzword “lexically”? Enter (non-scary) math!\nWe can put lowercase letters of English alphabet in an order: \\(\\texttt{a} \\prec \\texttt{b} \\prec \\cdots \\texttt{z}\\)\nWe can put capital letters of English alphabet in an order: \\(\\texttt{A} \\prec \\texttt{B} \\prec \\cdots \\prec \\texttt{Z}\\)\nWhat if we need to sort stuff with both types? We can decide that capital letters are lexically prior to lowercase letters, giving us a combined ordering:\n\n\n\n\n\n\nDworkin (1977)\n\n\n\n\n\n\\[\n\\boxed{\\texttt{A} \\prec \\texttt{B} \\prec \\cdots \\prec \\texttt{Z} \\prec \\texttt{a} \\prec \\texttt{b} \\prec \\cdots \\prec \\texttt{z}}\n\\]",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#lexical-ordering-i-tricked-you",
    "href": "w03/index.html#lexical-ordering-i-tricked-you",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Lexical Ordering (I Tricked You 😈)",
    "text": "Lexical Ordering (I Tricked You 😈)\n\n\n\n\n\n\n\nYou thought I was just talking about letters, but they’re actually variables: capital letters are rights, lowercase letters are distributive principles\n\n\\[\n\\underbrace{\\texttt{A} \\prec \\texttt{B} \\prec \\cdots \\prec \\texttt{Z}}_{\\mathclap{\\substack{\\text{Individual Rights} \\\\ \\text{Basic Goods}}}} \\phantom{\\prec} \\prec \\phantom{\\prec} \\underbrace{\\texttt{a} \\prec \\texttt{b} \\prec \\cdots \\prec \\texttt{z}}_{\\mathclap{\\substack{\\text{Distributive Principles} \\\\ \\text{Money and whatnot}}}}\n\\]",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#better-metaphor-than-letters",
    "href": "w03/index.html#better-metaphor-than-letters",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Better Metaphor Than Letters",
    "text": "Better Metaphor Than Letters\n\nLetters are where Rawls gets “lexically prior” from, but letters are total orderings (we know where every letter “stands” in relation to every other letter)\nBetter metaphor: a high school with a hierarchy such that\n\n\\[\n\\text{Seniors} \\prec \\text{Juniors} \\prec \\text{Sophomores}  \\prec \\text{Freshmen}\n\\]\n\n\\(\\implies\\) If you’re a Freshman, whether at the “top” or “bottom” of a ranking of Freshmen, you’re still prior to all Sophomores…\nWhy is this more helpful? Because we don’t need to define the rankings within classes to know the rankings between classes in this case",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#counterarguments-to-deontology",
    "href": "w03/index.html#counterarguments-to-deontology",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Counterargument(s) to Deontology",
    "text": "Counterargument(s) to Deontology\n\n\n\n\n\n\n\nDeontological rule: “Don’t lie”\n\nBut then: Nazis come to your house, ask you if you’re harboring any Jews\n\nk, new deontological rule: “Don’t lie unless necessary”\n\nWho decides when it’s necessary?\n\nDeontological commitment: Pacifism / Nonviolence\n\nBut then: someone swingin on you\n\nk, new deontological commitment: Pacifism / Nonviolence Except In Self-Defense\n\nWho decides what counts as self-defense?\n\nDeontological maxim: “The master’s tools will never dismantle the master’s house”\n\nWho conceded “ownership” to the master?\n\n(Trolley problems, etc.)\n\n\n\n\n\n\nChurchill and Ryan (1998) (Derrick Jensen intro removed from later editions so… I put it on dang GitHub)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#a-synthesis-two-level-utilitarianism",
    "href": "w03/index.html#a-synthesis-two-level-utilitarianism",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "A Synthesis: Two-Level Utilitarianism",
    "text": "A Synthesis: Two-Level Utilitarianism\n\n\n\n\n\n\n\nIt would be exhausting to compute Nash equilibrium strategies for every scenario\nInstead, we can develop heuristics that work for most cases, then reevaluate and update when we encounter tough cases\n(Brings us back to reflective equilibrium!)\n\n\n\n\n\n\nKahneman (2011)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#individual-vs.-social-morality",
    "href": "w03/index.html#individual-vs.-social-morality",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Individual vs. Social Morality",
    "text": "Individual vs. Social Morality\n\nThat was all already hard enough, to reason about individual morality\nNow add in the fact that we live in a society 😰\nThings that happen depend not only on our choices but also the choices of others\n\n\n\n\nSeinfeld: Living in a Society (Clip) | TBS",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#enter-game-theory",
    "href": "w03/index.html#enter-game-theory",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Enter Game Theory",
    "text": "Enter Game Theory\n\nA tool for analyzing how individual choices + choices of others \\(\\rightarrow\\) outcomes!\n\n\n\n\n\n\n\n\nExample: You (\\(A\\)) and a friend (\\(B\\)) committed a robbery, and you’re brought into the police station for questioning.\nYou’re placed in separate rooms, and each of you is offered a plea deal: if you testify while your partner stays silent, you go free and they go to jail for 3 years.\nOtherwise, if you both stay silent, they have very little evidence and can only jail you for 1 year\nHowever, there’s a catch: if you both confess, you both get two years in jail, since they now have maximal evidence\n\n\n\n\n\n\nSource: Wikimedia Commons",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#individual-decision-making",
    "href": "w03/index.html#individual-decision-making",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Individual Decision-Making",
    "text": "Individual Decision-Making\n\n\n\n\n\n\n\nLet’s think through \\(A\\)’s best responses to the possible choices \\(B\\) could make:\nIf \\(B\\) stays silent, what is \\(A\\)’s best option?\n\nStaying silent results in 1 year of jail\nTestifying results in 0 years of jail\nSo it is better to testify\n\nIf \\(B\\) testifies, what is \\(A\\)’s best option?\n\nStaying silent results in 3 years of jail\nTestifying results in 2 years of jail\nSo it is better to testify\n\nThe result: regardless of what \\(B\\) does, \\(A\\) is better off testifying!\n\n\n\n\n\n\nSource: Wikimedia Commons",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#the-social-outcome",
    "href": "w03/index.html#the-social-outcome",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "The Social Outcome",
    "text": "The Social Outcome\n\n\n\n\n\n\n\nThe game is symmetric, so the same logic applies for \\(B\\)\nConclusion: the outcome of the game will be \\(s^* = (\\text{Testify}, \\text{Testify})\\)\nThis is called a Nash equilibrium: no player \\(i\\) can make themselves better off by deviating from \\(s_i\\)\n\n\n\n\n\n\nSource: Wikimedia Commons",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#how-do-we-fix-this-conventions",
    "href": "w03/index.html#how-do-we-fix-this-conventions",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "How Do We Fix This? Conventions!",
    "text": "How Do We Fix This? Conventions!\n\n\n\n\n\n\n\nWe encounter this type of problem every day if we drive! You (\\(A\\)) and another driver (\\(B\\)) arrive at an intersection:\n\n\n\n\n\n\n\n\n\\(B\\)\n\n\n\n\nStop\nDrive\n\n\n\\(A\\)\nStop\n\\(-1,-1\\)\n\\(-3,\\phantom{-}0\\)\n\n\nDrive\n\\(\\phantom{-}0, -3\\)\n\\(-10,-10\\)\n\n\n\n\n\n\n\nIf both stop, we’re mostly bored: \\(u_A = -1\\)\nIf we stop and the other person drives, we’re mad that they got to go and we didn’t: \\(u_A = -3\\)\nIf both drive, we crash: \\(u_A = -10\\)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#without-a-convention",
    "href": "w03/index.html#without-a-convention",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Without A Convention",
    "text": "Without A Convention\n\n\n\n\n\n\n\nWe’re “frozen”: this game has no unique Nash equilibrium, so we cannot say (on the basis of individual rationality) what will happen!\nWithout a convention: power/aggression takes over. “War of all against all”, only the strong survive, etc. (life is “nasty, brutish, and short”)\n\n\n\n\n\n\n\n\n\n\\(B\\)\n\n\n\n\nStop\nDrive\n\n\n\\(A\\)\nStop\n\\({\\color{orange}\\cancel{\\color{black}-1}},{\\color{lightblue}\\cancel{\\color{black}-1}}\\)\n\\(\\boxed{-3},\\boxed{0}\\)\n\n\nDrive\n\\(\\boxed{0}, \\boxed{-3}\\)\n\\({\\color{orange}\\cancel{\\color{black}-10}},{\\color{lightblue}\\cancel{\\color{black}-10}}\\)\n\n\n\n\n\n\n\n\nIf \\(A\\)’s aggression is \\(\\Pr(s_A = \\textsf{Drive}) = X \\sim \\mathcal{U}[0,1]\\), \\(B\\)’s aggression is \\(\\Pr(s_B = \\textsf{Drive}) = Y \\sim \\mathcal{U}[0,1]\\), what happens at individual and societal levels?\n\n\\[\n\\begin{align*}\n\\mathbb{E}[u_A] = \\mathbb{E}[u_B] &= \\int_{0}^{1}\\int_{0}^{1}\\left(x - 2y -8xy - 1\\right)dy \\, dx = -3.5 \\\\\n\\underbrace{\\mathbb{E}\\mkern-3mu\\left[u_A + u_B\\right]}_{\\mathclap{\\text{Utilitarian Social Welfare}}} &= -3.5\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#the-convention-of-traffic-lights",
    "href": "w03/index.html#the-convention-of-traffic-lights",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "The Convention of Traffic Lights",
    "text": "The Convention of Traffic Lights\n\nIf we don’t want a world where \\(\\text{Happiness}(i) \\propto \\Pr(i \\text{ more aggro than }j)\\), we can introduce traffic lights:\n\n\n\n\n\n\n\n\nNow in “correlated equilibrium”, where we ensure* coordinated \\(\\Pr((\\textsf{Drive}, \\textsf{Stop})) = 0.5\\), \\(\\Pr((\\textsf{Stop}, \\textsf{Drive})) = 0.5\\)\n\\(\\mathbb{E}[u_A] = (0.5)(0) + (0.5)(-3) = -1.5\\)\n\\(\\mathbb{E}[u_B] = (0.5)(-3) + (0.5)(0) = -1.5\\)\n\n\n\n\n\n\n\n\n\n\\(B\\)\n\n\n\n\nStop\nDrive\n\n\n\\(A\\)\nStop\n\\({\\color{orange}\\cancel{\\color{black}-1}},{\\color{lightblue}\\cancel{\\color{black}-1}}\\)\n\\(\\boxed{-3},\\boxed{0}\\)\n\n\nDrive\n\\(\\boxed{0}, \\boxed{-3}\\)\n\\({\\color{orange}\\cancel{\\color{black}-10}},{\\color{lightblue}\\cancel{\\color{black}-10}}\\)\n\n\n\n\n\n\n\n\nEmpirical (anthropological) findings across literally thousands of different cultures throughout the world: people are willing to give up rewards to ensure fairness (see, e.g., Henrich et al. (2001))\n\n*(through, for example, traffic laws: equal in theory… In practice? Another story)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#so-how-should-we-makechoose-conventions",
    "href": "w03/index.html#so-how-should-we-makechoose-conventions",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "So How Should We Make/Choose Conventions?",
    "text": "So How Should We Make/Choose Conventions?\n\nHobbes (1651): Only way out of “war of all against all” is to surrender all power to one sovereign (the Leviathan)\nRousseau (1762): Social contract\n[Big big ~200 year gap here… can you think of why? Hint: French Revolution in 1789]\nRawls (1971): Social contract behind the “veil of ignorance”\n\nIf we didn’t know where we were going to end up in society, how would we set it up?",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#rawls-veil-of-ignorance",
    "href": "w03/index.html#rawls-veil-of-ignorance",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Rawls’ Veil of Ignorance",
    "text": "Rawls’ Veil of Ignorance\n\nProbably the most important tool for policy whitepapers!\n“Justice as fairness” (next week: fairness in AI 😜)\nWe don’t know whether we’ll be \\(A\\) or \\(B\\) in the intersection game, so we’d choose the traffic light!\nMore profoundly: We don’t know what race, gender, class, ethnicity, sexuality, disability status we’ll have; We don’t know whether we’ll be Israeli or Palestinian; we don’t know whether we’ll own means of production or own only our labor power (and thus have to sell it on a market to survive)… 🤔",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#one-final-reminder",
    "href": "w03/index.html#one-final-reminder",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "One Final Reminder",
    "text": "One Final Reminder\n\nIndustry rule #4080: Cannot “prove” \\(q(x) = \\text{``Algorithm }x\\text{ is fair''}\\)! Only \\(p(x) \\implies q(y)\\):\n\n\\[\n\\underbrace{p(x)}_{\\substack{\\text{Accept ethical} \\\\ \\text{framework }x}} \\implies \\underbrace{q(y)}_{\\substack{\\text{Algorithms should} \\\\ \\text{satisfy condition }y}}\n\\]\n\nBefore: possible ethical frameworks (values for \\(x\\))\nNow: possible fairness criteria (values for \\(y\\))",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#categories-of-fairness-criteria",
    "href": "w03/index.html#categories-of-fairness-criteria",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Categories of Fairness Criteria",
    "text": "Categories of Fairness Criteria\n\nRoughly, approaches to fairness/bias in AI can be categorized as follows:\n\n\nFairness\n\n\n\n\n\n\nContext-Free\n\n\nSingle-Threshold Fairness\nEqual Prediction\nEqual Decision\n\n\n\n\n\n\n\n\n\nContext-Sensitive\n\n\nFairness via Similarity Metric(s)\nCausal Definitions\n\n\n\n\n\n\n\n[Today] Context-Free Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of Machine Learning (you already know much of it, given DSAN 5000!)\nBut easy-to-grasp notion \\(\\neq\\) “good” notion!\nYour job: push yourself to (a) consider what is getting left out of the context-free definitions, and (b) the loopholes that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#laws-often-perfectly-technically-fair",
    "href": "w03/index.html#laws-often-perfectly-technically-fair",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Laws: Often Perfectly “Technically Fair”",
    "text": "Laws: Often Perfectly “Technically Fair”\n\nAh, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!\n\n\n(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)\n\nAnatole France, Le Lys Rouge (France 1894)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#the-brogrammers-criterion",
    "href": "w03/index.html#the-brogrammers-criterion",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "The Brogrammer’s Criterion",
    "text": "The Brogrammer’s Criterion\ndf.drop(columns=[\"race\"], inplace=True)\n\nRacism solved, folks! 🥳🎊🎉 End of the course, have a great rest of your data science career ✌️",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#no-fairness-through-unawareness",
    "href": "w03/index.html#no-fairness-through-unawareness",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "(No) Fairness Through Unawareness",
    "text": "(No) Fairness Through Unawareness\n\nHW1: Using tiny sample (\\(N &lt; 10K\\)) of Florida voter registrations… RandomForestClassifier (default settings, no hyperparameter tuning, no cross-validation, no ensembling with other methods) will predict self-reported race with \\(&gt;90\\%\\) accuracy (in balanced sample) from just surname and county of residence\n\nCan reach \\(70\\text{-}75\\%\\) with just surname or just county of residence\n\nAlso in HW1: Facebook ad matching service provides over 1,000 different user attributes for (micro)targeting\n\n\n\n\nFrom Datta et al. (2017)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#to-make-it-even-more-concrete",
    "href": "w03/index.html#to-make-it-even-more-concrete",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "To Make It Even More Concrete…",
    "text": "To Make It Even More Concrete…\n\nBloomberg analysis of neighborhoods with same-day delivery from Amazon:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Figures from Ingold and Soper (2016)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#we-can-do-a-bit-better",
    "href": "w03/index.html#we-can-do-a-bit-better",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "We Can Do (A Bit) Better…",
    "text": "We Can Do (A Bit) Better…\n\nUse random variables to model inferences made by an algorithm (or a human!)\n\\(\\implies\\) fairness by statistically equalizing loan rejections, error rate, etc. between groups\nObvious societal drawback: equality does not ameliorate the effects of past injustices (see: police contact vs. trust-in-government plot from last week)\n\nThis one we saw coming, given “context-free” nature!\n\nLess obvious mathematical drawback: impossibility results (because algebra 😳)\n\nRoughly: can’t satisfy [more than] two statistical fairness criteria at once; similar to how setting \\(\\Pr(X) = p\\) also determines \\(\\Pr(\\text{not }X) = 1 - p\\), or how plugging \\(x = 3\\) into \\(x + y = 5\\) leaves only one possibility \\(y = 2\\)\n\nBUT, “impossibility” \\(\\neq\\) impossibility: (a) one criteria may be “all you need” in given setting; (b) can derive more robust measures by “relaxing” confusion-matrix measures",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#what-the-fairness-measures-will-feel-like-for-now",
    "href": "w03/index.html#what-the-fairness-measures-will-feel-like-for-now",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "What the Fairness Measures Will Feel Like For Now",
    "text": "What the Fairness Measures Will Feel Like For Now\n\n\n\n\n\n\n(They will get more robust and will incorporate context soon, I promise!)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#who-remembers-confusion-matrices",
    "href": "w03/index.html#who-remembers-confusion-matrices",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Who Remembers… 🎉Confusion Matrices!!!🎉",
    "text": "Who Remembers… 🎉Confusion Matrices!!!🎉\n\nTerrifyingly higher stakes than in DSAN 5000, however!\nNow \\(D = 1\\) could literally mean “shoot this person” or “throw this person in jail for life”\n\n\n\n\nFrom Mitchell et al. (2021)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#our-first-fairness-measure-finally",
    "href": "w03/index.html#our-first-fairness-measure-finally",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Our First Fairness Measure (Finally)!",
    "text": "Our First Fairness Measure (Finally)!\n\nStandard across the literature: Random Variable \\(A_i\\) “encoding” membership in protected/sensitive group. In HW1, for example:\n\n\\[\nA_i = \\begin{cases}\n0 &\\text{if }i\\text{ self-reported ``white''} \\\\\n1 &\\text{if }i\\text{ self-reported ``black''}\n\\end{cases}\n\\]\n\nNotice: choice of mapping into \\(\\{0, 1\\}\\) here non-arbitrary!\nWe want our models/criteria to be descriptively but also normatively robust; e.g.:\nIf (antecedent I hold, though majority in US do not) one believes that ending (much less repairing) centuries of unrelenting white supremacist violence here might require asymmetric race-based policies,\nThen our model should allow different normative labels and differential weights on\n\\[\n\\begin{align*}\n\\Delta &= (\\text{Fairness} \\mid A = 1) - (\\text{Fairness} \\mid A = 0) \\\\\n\\nabla &= (\\text{Fairness} \\mid A = 0) - (\\text{Fairness} \\mid A = 1)\n\\end{align*}\n\\]\ndespite the descriptive fact that \\(\\Delta = -\\nabla\\).",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#where-descriptive-and-normative-become-intertwined",
    "href": "w03/index.html#where-descriptive-and-normative-become-intertwined",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Where Descriptive and Normative Become Intertwined",
    "text": "Where Descriptive and Normative Become Intertwined\n\nAllowing this asymmetry is precisely what enables bring descriptive facts to bear on normative concerns!\nMathematically we can always “flip” the mapping from racial labels into \\(\\{0, 1\\}\\)…\nBut this (in a precise, mathematical sense: namely, isomorphism) implies that we’re treating racial categorization as the same type of phenomenon as driving on left or right side of road (see: prev slides on why we make the descriptive vs. normative distinction)\n(See also: Sweden’s Dagen H!)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#fairness-through-equalized-positive-rates",
    "href": "w03/index.html#fairness-through-equalized-positive-rates",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "“Fairness” Through Equalized Positive Rates",
    "text": "“Fairness” Through Equalized Positive Rates\n\\[\n\\Pr(D = 1 \\mid A = 0) = \\Pr(D = 1 \\mid A = 1)\n\\]\n\nThis works specifically for discrete, binary-valued categories\nFor general attributes (whether discrete or continuous!), generalizes to:\n\n\\[\nD \\perp A \\iff \\Pr(D = d, A = a) = \\Pr(D = d)\\Pr(A = a)\n\\]",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#fairness-through-equalized-error-rates",
    "href": "w03/index.html#fairness-through-equalized-error-rates",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "“Fairness” Through Equalized Error Rates",
    "text": "“Fairness” Through Equalized Error Rates\n\nEqualized False Positive Rate:\n\n\\[\n\\Pr(D = 1 \\mid Y = 0, A = 0) = \\Pr(D = 1 \\mid Y = 0, A = 1)\n\\]\n\nEqualized False Negative Rate:\n\n\\[\n\\Pr(D = 0 \\mid Y = 1, A = 0) = \\Pr(D = 0 \\mid Y = 1, A = 1)\n\\]\n\nFor general (non-binary) attributes: \\((D \\perp A) \\mid Y\\):\n\n\\[\n\\Pr(D = d, A = a \\mid Y = y) = \\Pr(D = d \\mid Y = y)\\Pr(A = a \\mid Y = y)\n\\]",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#no-more-equations",
    "href": "w03/index.html#no-more-equations",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "NO MORE EQUATIONS! 😤",
    "text": "NO MORE EQUATIONS! 😤\n\nDepending on your background and/or learning style (say, visual vs. auditory), you may be able to look at equations on previous slides and “see” what they’re “saying”\nIf your brain works similarly to mine, however, your eyes glazed over, you began dissociating, planning an escape route, etc.\nIf you’re in the latter group, welcome to the cult of Probabilistic Graphical Models 😈",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#baby-steps-a-real-world-confusion-matrix",
    "href": "w03/index.html#baby-steps-a-real-world-confusion-matrix",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Baby Steps: A Real-World Confusion Matrix",
    "text": "Baby Steps: A Real-World Confusion Matrix\n\n\n\n\n\n\n\n\n\nLabeled Low-Risk\nLabeled High-Risk\n\n\n\n\nDidn’t Do More Crimes\nTrue Negative\nFalse Positive\n\n\nDid More Crimes\nFalse Negative\nTrue Positive\n\n\n\n\nWhat kinds of causal connections and/or feedback loops might there be between our decision variable (low vs. high risk) and our outcome variable (did vs. didn’t do more crimes)\nWhat types of policy implications might this process have, after it “runs” for several “iterations”?\nWhy might some segments of society, with some shared ethical framework(s), weigh the “costs” of false negatives and false positives differently from other segments of society with different shared ethical framework(s)?\n(Non-rhetorical questions!)",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#references",
    "href": "w03/index.html#references",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "References",
    "text": "References\n\n\nAwad, Edmond, Sydney Levine, Michael Anderson, Susan Leigh Anderson, Vincent Conitzer, M. J. Crockett, Jim A. C. Everett, et al. 2022. “Computational Ethics.” Trends in Cognitive Sciences 26 (5): 388–405. https://doi.org/10.1016/j.tics.2022.02.009.\n\n\nBishop, Marlon, and Tatiana Fernandez. 2017. “80 Years On, Dominicans And Haitians Revisit Painful Memories Of Parsley Massacre.” NPR, October. https://www.npr.org/sections/parallels/2017/10/07/555871670/80-years-on-dominicans-and-haitians-revisit-painful-memories-of-parsley-massacre.\n\n\nBourdieu, Pierre. 2010. Sociology Is a Martial Art: Political Writings by Pierre Bourdieu. New Press.\n\n\nChurchill, Ward, and Michael Ryan. 1998. Pacifism as Pathology: Reflections on the Role of Armed Struggle in North America. PM Press.\n\n\nCrawford, Kate, and Trevor Paglen. 2019. “Excavating AI: The Politics of Training Sets for Machine Learning.” AI Now Institute, NYU. https://excavating.ai.\n\n\nDatta, Anupam, Matt Fredrikson, Gihyuk Ko, Piotr Mardziel, and Shayak Sen. 2017. “Proxy Non-Discrimination in Data-Driven Systems.” arXiv. https://doi.org/10.48550/arXiv.1707.08120.\n\n\nDeutscher, Guy. 2010. Through the Language Glass: Why the World Looks Different in Other Languages. Henry Holt and Company.\n\n\nDube, Arindrajit, Jeff Jacobs, Suresh Naidu, and Siddharth Suri. 2020. “Monopsony in Online Labor Markets.” American Economic Review: Insights 2 (1): 33–46. https://doi.org/10.1257/aeri.20180150.\n\n\nDworkin, Ronald. 1977. Taking Rights Seriously. A&C Black.\n\n\nFields, Barbara J., and Karen E. Fields. 2012. Racecraft: The Soul of Inequality in American Life. Verso Books.\n\n\nFrance, Anatole. 1894. Le Lys Rouge (The Red Lily). G. Wells.\n\n\nGould, Stephen Jay. 1980. The Mismeasure of Man (Revised and Expanded). W. W. Norton & Company.\n\n\nGray, Mary L., and Siddharth Suri. 2019. Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass. HarperCollins.\n\n\nHenrich, Joseph, Robert Boyd, Samuel Bowles, Colin Camerer, Ernst Fehr, Herbert Gintis, and Richard McElreath. 2001. “In Search of Homo Economicus: Behavioral Experiments in 15 Small-Scale Societies.” American Economic Review 91 (2): 73–78. https://doi.org/10.1257/aer.91.2.73.\n\n\nHobbes, Thomas. 1651. Leviathan: With Selected Variants from the Latin Edition of 1668. Hackett Publishing.\n\n\nIngold, David, and Spencer Soper. 2016. “Amazon Doesn’t Consider the Race of Its Customers. Should It?” Bloomberg, April. http://www.bloomberg.com/graphics/2016-amazon-same-day/.\n\n\nJames, William. 1891. “The Moral Philosopher and the Moral Life.” International Journal of Ethics 1 (3): 330–54. https://www.jstor.org/stable/2375309.\n\n\nKahneman, Daniel. 2011. Thinking, Fast and Slow. Farrar, Straus and Giroux.\n\n\nLabov, William. 2013. The Language of Life and Death: The Transformation of Experience in Oral Narrative. Cambridge University Press.\n\n\nLe Guin, Ursula K. 1973. The Ones Who Walk Away from Omelas: A Story. HarperCollins.\n\n\nMcWhorter, John H. 2014. The Language Hoax: Why the World Looks the Same in Any Language. Oxford University Press.\n\n\nMitchell, Shira, Eric Potash, Solon Barocas, Alexander D’Amour, and Kristian Lum. 2021. “Algorithmic Fairness: Choices, Assumptions, and Definitions.” Annual Review of Statistics and Its Application 8 (1): 141–63. https://doi.org/10.1146/annurev-statistics-042720-125902.\n\n\nMorris, Benny. 1987. The Birth of the Palestinian Refugee Problem, 1947-1949. Cambridge University Press.\n\n\nPappe, Ilan. 2006. The Ethnic Cleansing of Palestine. Simon and Schuster.\n\n\nPellicer, Miquel, and Vimal Ranchhod. 2023. “Understanding the Effects of Racial Classification in Apartheid South Africa.” Journal of Development Economics 160 (January): 102998. https://doi.org/10.1016/j.jdeveco.2022.102998.\n\n\nRawls, John. 1951. “Outline of a Decision Procedure for Ethics.” The Philosophical Review 60 (2): 177–97. https://doi.org/10.2307/2181696.\n\n\n———. 1971. A Theory of Justice: Original Edition. Harvard University Press.\n\n\nRoemer, John E. 1988. Free to Lose: An Introduction to Marxist Economic Philosophy. Harvard University Press.\n\n\nRousseau, Jean-Jacques. 1762. The Social Contract. Geneva: J. M. Dent.\n\n\nSkinner, Quentin. 2012. Visions of Politics, Volume 1: Regarding Method. Cambridge: Cambridge University Press.\n\n\nSt. Augustine. 1874. The Works of Aurelius Augustine: Lectures or Tractates on the Gospel According to St. John, v. 2. T. & T. Clark.\n\n\nWeber, Max. 1904. The Protestant Ethic and the Spirit of Capitalism. Courier Corporation.",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w03/index.html#footnotes",
    "href": "w03/index.html#footnotes",
    "title": "Week 3: (Descriptive) Fairness in AI",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFields and Fields (2012), for example, coined “racecraft” to describe reification of blackness in US… much more on this later!↩︎",
    "crumbs": [
      "Week 3: {{< var w03.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html",
    "href": "w04/index.html",
    "title": "Week 4: Fairness in AI",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#baby-steps-a-real-world-confusion-matrix",
    "href": "w04/index.html#baby-steps-a-real-world-confusion-matrix",
    "title": "Week 4: Fairness in AI",
    "section": "Baby Steps: A Real-World Confusion Matrix",
    "text": "Baby Steps: A Real-World Confusion Matrix\n\n\n\n\n\n\n\n\n\nLabeled Low-Risk\nLabeled High-Risk\n\n\n\n\nDidn’t Do More Crimes\nTrue Negative\nFalse Positive\n\n\nDid More Crimes\nFalse Negative\nTrue Positive\n\n\n\n\nWhat kinds of causal connections and/or feedback loops might there be between our decision variable (low vs. high risk) and our outcome variable (did vs. didn’t do more crimes)\nWhat types of policy implications might this process have, after it “runs” for several “iterations”?\nWhy might some segments of society, with some shared ethical framework(s), weigh the “costs” of false negatives and false positives differently from other segments of society with different shared ethical framework(s)?\n(Non-rhetorical questions!)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#categories-of-fairness-criteria",
    "href": "w04/index.html#categories-of-fairness-criteria",
    "title": "Week 4: Fairness in AI",
    "section": "Categories of Fairness Criteria",
    "text": "Categories of Fairness Criteria\n\nRoughly, approaches to fairness/bias in AI can be categorized as follows:\n\n\nFairness\n\n\n\n\n\n\nContext-Free\n\n\nSingle-Threshold Fairness\nEqual Prediction\nEqual Decision\n\n\n\n\n\n\n\n\n\nContext-Sensitive\n\n\nFairness via Similarity Metric(s)\nCausal Definitions\n\n\n\n\n\n\n\n[Today] Context-Free Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of Machine Learning (you already know much of it, given DSAN 5000!)\nBut easy-to-grasp notion \\(\\neq\\) “good” notion!\nYour job: push yourself to (a) consider what is getting left out of the context-free definitions, and (b) the loopholes that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#laws-often-perfectly-technically-fair",
    "href": "w04/index.html#laws-often-perfectly-technically-fair",
    "title": "Week 4: Fairness in AI",
    "section": "Laws: Often Perfectly “Technically Fair”",
    "text": "Laws: Often Perfectly “Technically Fair”\n\nAh, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!\n\n\n(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)\n\nAnatole France, Le Lys Rouge (France 1894)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#no-fairness-through-unawareness",
    "href": "w04/index.html#no-fairness-through-unawareness",
    "title": "Week 4: Fairness in AI",
    "section": "(No) Fairness Through Unawareness",
    "text": "(No) Fairness Through Unawareness\n\nHW1: Using tiny sample (\\(N &lt; 10K\\)) of Florida voter registrations… RandomForestClassifier (default settings, no hyperparameter tuning, no cross-validation, no ensembling with other methods) will predict self-reported race with \\(&gt;90\\%\\) accuracy (in balanced sample) from just surname and county of residence\n\nCan reach \\(70\\text{-}75\\%\\) with just surname or just county of residence\n\nAlso in HW1: Facebook ad matching service provides over 1,000 different user attributes for (micro)targeting\n\n\n\n\nFrom Datta et al. (2017)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#to-make-it-even-more-concrete",
    "href": "w04/index.html#to-make-it-even-more-concrete",
    "title": "Week 4: Fairness in AI",
    "section": "To Make It Even More Concrete…",
    "text": "To Make It Even More Concrete…\n\nBloomberg analysis of neighborhoods with same-day delivery from Amazon:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Figures from Ingold and Soper (2016)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#last-one-i-promise",
    "href": "w04/index.html#last-one-i-promise",
    "title": "Week 4: Fairness in AI",
    "section": "Last One I Promise",
    "text": "Last One I Promise\n\n\n\nPredicting self-reported whiteness with 70% accuracy",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#last-one-i-promise-1",
    "href": "w04/index.html#last-one-i-promise-1",
    "title": "Week 4: Fairness in AI",
    "section": "Last One I Promise",
    "text": "Last One I Promise\n\n\n\nPredicting self-reported non-whiteness with 90% accuracy",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#we-can-do-a-bit-better",
    "href": "w04/index.html#we-can-do-a-bit-better",
    "title": "Week 4: Fairness in AI",
    "section": "We Can Do (A Bit) Better…",
    "text": "We Can Do (A Bit) Better…\n\nUse random variables to model inferences made by an algorithm (or a human!)\n\\(\\implies\\) fairness by statistically equalizing loan rejections, error rate, etc. between groups\nObvious societal drawback: equality does not ameliorate the effects of past injustices (see: police contact vs. trust-in-government plot from last week)\n\nThis one we saw coming, given “context-free” nature!\n\nLess obvious mathematical drawback: impossibility results (because algebra 😳)\n\nRoughly: can’t satisfy [more than] two statistical fairness criteria at once; similar to how setting \\(\\Pr(X) = p\\) also determines \\(\\Pr(\\text{not }X) = 1 - p\\), or how plugging \\(x = 3\\) into \\(x + y = 5\\) leaves only one possibility \\(y = 2\\)\n\nBUT, “impossibility” \\(\\neq\\) impossibility: (a) one criteria may be “all you need” in given setting; (b) can derive more robust measures by “relaxing” confusion-matrix measures",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#protectedsensitive-attributes",
    "href": "w04/index.html#protectedsensitive-attributes",
    "title": "Week 4: Fairness in AI",
    "section": "Protected/Sensitive Attributes",
    "text": "Protected/Sensitive Attributes\n\nStandard across the literature: Random Variable \\(A_i\\) “encoding” membership in protected/sensitive group. In HW1, for example:\n\n\\[\nA_i = \\begin{cases}\n0 &\\text{if }i\\text{ self-reported ``white''} \\\\\n1 &\\text{if }i\\text{ self-reported ``black''}\n\\end{cases}\n\\]\n\nNotice: choice of mapping into \\(\\{0, 1\\}\\) here non-arbitrary!\nWe want our models/criteria to be descriptively but also normatively robust; e.g.:\nIf (antecedent I hold, though majority in US do not) one believes that ending (much less repairing) centuries of unrelenting white supremacist violence here might require asymmetric race-based policies,\nThen our model should allow different normative labels and differential weights on\n\\[\n\\begin{align*}\n\\Delta &= (\\text{Fairness} \\mid A = 1) - (\\text{Fairness} \\mid A = 0) \\\\\n\\nabla &= (\\text{Fairness} \\mid A = 0) - (\\text{Fairness} \\mid A = 1)\n\\end{align*}\n\\]\ndespite the descriptive fact that \\(\\Delta = -\\nabla\\).",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#where-descriptive-and-normative-become-intertwined",
    "href": "w04/index.html#where-descriptive-and-normative-become-intertwined",
    "title": "Week 4: Fairness in AI",
    "section": "Where Descriptive and Normative Become Intertwined",
    "text": "Where Descriptive and Normative Become Intertwined\n\nAllowing this asymmetry is precisely what enables bring descriptive facts to bear on normative concerns!\nMathematically we can always “flip” the mapping from racial labels into \\(\\{0, 1\\}\\)…\nBut this (in a precise, mathematical sense: namely, isomorphism) implies that we’re treating racial categorization as the same type of phenomenon as driving on left or right side of road (see: prev slides on why we make the descriptive vs. normative distinction)\n(See also: Sweden’s Dagen H!)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#fairness-through-equalized-positive-rates-epr",
    "href": "w04/index.html#fairness-through-equalized-positive-rates-epr",
    "title": "Week 4: Fairness in AI",
    "section": "“Fairness” Through Equalized Positive Rates (EPR)",
    "text": "“Fairness” Through Equalized Positive Rates (EPR)\n\n \n\n\\[\n\\boxed{\\Pr(D = 1 \\mid A = 0) = \\Pr(D = 1 \\mid A = 1)}\n\\]\n\nThis works specifically for discrete, binary-valued categories\nFor general attributes (whether discrete or continuous!), generalizes to:\n\n\\[\n\\boxed{D \\perp A} \\iff \\Pr(D = d, A = a) = \\Pr(D = d)\\Pr(A = a)\n\\]\n\nImagine you learn that a person received a scholarship (\\(D = 1\\)); [with equalized positive rates], this fact would give you no knowledge about the race (or sex, or class, as desired) \\(A\\) of the individual in question. (DeDeo 2016)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#achieving-equalized-positive-rates",
    "href": "w04/index.html#achieving-equalized-positive-rates",
    "title": "Week 4: Fairness in AI",
    "section": "Achieving Equalized Positive Rates",
    "text": "Achieving Equalized Positive Rates\n\nThe good news: if we want this, there is a closed-form solution: take your datapoints \\(X_i\\) and re-weigh each point to obtain \\(\\widetilde{X}_i = w_iX_i\\), where\n\\[\n  w_i = \\frac{\\Pr(Y_i = 1)}{\\Pr(Y_i = 1 \\mid A_i = 1)}\n  \\]\nand use derived dataset \\(\\widetilde{X}_i\\) to learn \\(r(X)\\) (via ML algorithm)… Why does this work?\nLet \\(\\mathcal{X}_{\\text{fair}}\\) be the set of all possible reweighted versions of \\(X_i\\) ensuring \\(Y_i \\perp A_i\\). Then\n\n\\[\n\\widetilde{X}_i = \\min_{X_i' \\in \\mathcal{X}_{\\text{fair}}}\\textsf{distance}(X_i', X_i) = \\min_{X_i' \\in \\mathcal{X}_{\\text{fair}}}\\underbrace{KL(X_i' \\| X_i)}_{\\text{Relative entropy!}}\n\\]\n\nThe bad news: nobody in the fairness in AI community read DeDeo (2016), which proves this using information theory? Idk. It has a total of 22 citations 😐",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#fairness-through-equalized-error-rates",
    "href": "w04/index.html#fairness-through-equalized-error-rates",
    "title": "Week 4: Fairness in AI",
    "section": "“Fairness” Through Equalized Error Rates",
    "text": "“Fairness” Through Equalized Error Rates\n\nEqualized positive rates didn’t take outcomes \\(Y_i\\) into account…\n\n(Even if \\(A_i = 1 \\Rightarrow Y_i = 1, A_i = 0 \\Rightarrow Y_i = 0\\), we’d have to choose \\(\\widehat{Y}_i = c\\))\n\nThis time, we consider the outcome \\(Y\\) that\nEqualized False Positive Rate (EFPR):\n\n\\[\n\\Pr(D = 1 \\mid Y = 0, A = 0) = \\Pr(D = 1 \\mid Y = 0, A = 1)\n\\]\n\nEqualized False Negative Rate (EFNR):\n\n\\[\n\\Pr(D = 0 \\mid Y = 1, A = 0) = \\Pr(D = 0 \\mid Y = 1, A = 1)\n\\]\n\nFor general (non-binary) attributes: \\((D \\perp A) \\mid Y\\):\n\n\\[\n\\Pr(D = d, A = a \\mid Y = y) = \\Pr(D = d \\mid Y = y)\\Pr(A = a \\mid Y = y)\n\\]",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#less-equations-please",
    "href": "w04/index.html#less-equations-please",
    "title": "Week 4: Fairness in AI",
    "section": "⚠️ LESS EQUATIONS PLEASE! 😤",
    "text": "⚠️ LESS EQUATIONS PLEASE! 😤\n\nDepending on your background and/or learning style (say, visual vs. auditory), you may be able to look at equations on previous two slides and “see” what they’re “saying”\nIf your brain works similarly to mine, however, your eyes glazed over, you began dissociating, planning an escape route, etc., the moment \\(&gt; 2\\) variables appeared\nIf you’re in the latter group, welcome to the cult of Probabilistic Graphical Models 😈\n\n\n\n\nYour first PGM, illustrating hypothesized causal relationships between three random variables \\(Y\\) (outcome), \\(D\\) (decision), and \\(A\\) (protected attribute). The \\(Y\\) node is shaded to indicate that it is an observed value in our model, rendering the unobserved values \\(D\\) and \\(A\\) independent conditional on it. If I was elected Emperor of Math, equations would be abolished in favor of PGMs.",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#section",
    "href": "w04/index.html#section",
    "title": "Week 4: Fairness in AI",
    "section": "",
    "text": "Equalized False Negative/Positive Rates\n\n\n\n\nOur first measure that 🥳🎉matches a principle of justice in society!!!🕺🪩\nBlackstone’s Ratio: “It is better that ten guilty persons escape, than that one innocent suffers.” (Blackstone 1769)\n(…break time!)",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#back-to-equalized-error-rates",
    "href": "w04/index.html#back-to-equalized-error-rates",
    "title": "Week 4: Fairness in AI",
    "section": "Back to Equalized Error Rates",
    "text": "Back to Equalized Error Rates\n\nBlackstone’s Ratio: “It is better that ten guilty persons escape, than that one innocent suffers.” (Blackstone 1769)\nMathematically \\(\\Rightarrow \\text{Cost}(FPR) = 10\\cdot \\text{Cost}(FNR)\\)\nLegally \\(\\Rightarrow\\) beyond reasonable doubt standard for conviction\nEFPR \\(\\iff\\) rates of false conviction should be the same for everyone, including members of different racial groups.\n\nViolated when black people are disproportionately likely to be incorrectly convicted, as if a lower evidentiary standard were applied to black people.",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#one-final-context-free-criterion-calibration",
    "href": "w04/index.html#one-final-context-free-criterion-calibration",
    "title": "Week 4: Fairness in AI",
    "section": "One Final Context-Free Criterion: Calibration",
    "text": "One Final Context-Free Criterion: Calibration\n\nA risk function \\(r(X)\\) is calibrated if\n\n\\[\n\\Pr(Y = 1 \\mid r(X) = v_r) = v_r\n\\]\n\n(Sweeping a lot of details under the rug), I see this one as: the risk function “tracks” real-world probabilities\nThen, \\(r(X)\\) is calibrated by group if\n\n\\[\n\\Pr(Y = y \\mid r(X) = v_r, A = a) = v_r\n\\]",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#impossibility-results",
    "href": "w04/index.html#impossibility-results",
    "title": "Week 4: Fairness in AI",
    "section": "Impossibility Results",
    "text": "Impossibility Results\n\ntldr: We cannot possibly achieve all three of equalized positive rates (often also termed “anti-classification”), classification parity, and calibration (regardless of base rates)\nMore alarmingly: We can’t even achieve both classification parity and calibration, except in the special case of equal base rates",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#impossibility-vs.-impossibility",
    "href": "w04/index.html#impossibility-vs.-impossibility",
    "title": "Week 4: Fairness in AI",
    "section": "“Impossibility” vs. Impossibility",
    "text": "“Impossibility” vs. Impossibility\n\nSometimes “impossibility results” are, for all intents and purposes, mathematical curiosities: often there’s some pragmatic way of getting around them\nExample: “Arrow’s Impossibility Theorem”\n\n[In theory] It is mathematically impossible to aggregate individual preferences into societal preferences\n[The catch] True only if people are restricted to ordinal preferences: “I prefer \\(x\\) to \\(y\\).” No more information allowed\n[The way around it] Allow people to indicate the magnitude of their preferences: “I prefer \\(x\\) 5 times more than \\(y\\)”\n\nIn this case, though, there are direct and (often) unavoidable real-world barriers that fairness impossibility imposes 😕",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#arrows-impossibility-theorem",
    "href": "w04/index.html#arrows-impossibility-theorem",
    "title": "Week 4: Fairness in AI",
    "section": "Arrow’s Impossibility Theorem",
    "text": "Arrow’s Impossibility Theorem\n\nAziza, Bogdan, and Charles are competing in a fitness test with four events. Goal: determine who is most fit overall\n\n\n\n\n\nRun\nJump\nHurdle\nWeights\n\n\n\n\nAziza\n10.1”\n6.0’\n40”\n150 lb\n\n\nBogdan\n9.2”\n5.9’\n42”\n140 lb\n\n\nCharles\n10.0”\n6.1’\n39”\n145 lb\n\n\n\n\nWe can rank unambiguously on individual events: Jump: Charles \\(\\succ_J\\) Aziza \\(\\succ_J\\) Bogdan\nNow, axioms for aggregation:\n\n\\(\\text{WP}\\) (Weak Pareto Optimality): if \\(x \\succ_i y\\) for all events \\(i\\), \\(x \\succ y\\)\n\\(\\text{IIA}\\) (Independence of Irrelevant Alternatives): If a fourth competitor enters, but Aziza and Bogdan still have the same relative standing on all events, their relative standing overall should not change\n\nLong story short: only aggregation that can satisfy these is “dictatorship”: choose one event, give it importance of 100%, the rest have importance 0% 😰",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#propublica-vs.-northpointe",
    "href": "w04/index.html#propublica-vs.-northpointe",
    "title": "Week 4: Fairness in AI",
    "section": "ProPublica vs. Northpointe",
    "text": "ProPublica vs. Northpointe\n\nThis is… an example with 1000s of books and papers and discussions around it! (A red flag 🚩, since, obsession with one example may conceal much wider range of issues!)\nBut, tldr, Northpointe created a ML algorithm called COMPAS, used by court systems all over the US to predict “risk” of arrestees\nIn 2016, ProPublica published results from an investigative report documenting COMPAS’s racial discrimination, in the form of violating equal error rates between black and white arrestees\nNorthpointe responded that COMPAS does not discriminate, as it satisfies calibration\nPeople have argued about who is “right” for 8 years, with some progress, but… not a lot",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#so-what-do-we-do",
    "href": "w04/index.html#so-what-do-we-do",
    "title": "Week 4: Fairness in AI",
    "section": "So… What Do We Do?",
    "text": "So… What Do We Do?\n\nOne option: argue about which of the two definitions is “better” for the next 100 years (what is the best way to give food to the poor?)\n\n\nIt appears to reveal an unfortunate but inexorable fact about our world: we must choose between two intuitively appealing ways to understand fairness in ML. Many scholars have done just that, defending either ProPublica’s or Northpointe’s definitions against what they see as the misguided alternative. (Simons 2023)\n\n\nAnother option: study and then work to ameliorate the social conditions which force us into this realm of mathematical impossibility (why do the poor have no food?)\n\n\nThe impossibility result is about much more than math. [It occurs because] the underlying outcome is distributed unevenly in society. This is a fact about society, not mathematics, and requires engaging with a complex, checkered history of systemic racism in the US. Predicting an outcome whose distribution is shaped by this history requires tradeoffs because the inequalities and injustices are encoded in data—in this case, because America has criminalized Blackness for as long as America has existed.",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#why-not-both",
    "href": "w04/index.html#why-not-both",
    "title": "Week 4: Fairness in AI",
    "section": "Why Not Both??",
    "text": "Why Not Both??\n\nOn the one hand: yes, both! On the other hand: fallacy of the “middle ground”\nWe’re back at descriptive vs. normative:\n\nDescriptively, given 100 values \\(v_1, \\ldots, v_{100}\\), their mean may be a good way to summarize, if we have to choose a single number\nBut, normatively, imagine that these are opinions that people hold about fairness.\nNow, if it’s the US South in 1860 and \\(v_i\\) represents person \\(i\\)’s approval of slavery, from a sample of 100 people, then approx. 97 of the \\(v_i\\)’s are “does not disapprove” (Rousey 2001) — in this case, normatively, is the mean \\(0.97\\) the “correct” answer?\n\nWe have another case where, like the “grass is green” vs. “grass ought to be green” example, we cannot just “import” our logical/mathematical tools from the former to solve the latter! (However: this does not mean they are useless! This is the fallacy of the excluded middle, sort of the opposite of the fallacy of the middle ground)\nThis is why we have ethical frameworks in the first place! Going back to Rawls: “97% of Americans think black people shouldn’t have rights”  \\(\\nimplies\\)“black people shouldn’t have rights”, since rights are a primary good",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/index.html#references",
    "href": "w04/index.html#references",
    "title": "Week 4: Fairness in AI",
    "section": "References",
    "text": "References\n\n\nBlackstone, William. 1769. Commentaries on the Laws of England, Volume 2: A Facsimile of the First Edition of 1765-1769. University of Chicago Press.\n\n\nDatta, Anupam, Matt Fredrikson, Gihyuk Ko, Piotr Mardziel, and Shayak Sen. 2017. “Proxy Non-Discrimination in Data-Driven Systems.” arXiv. https://doi.org/10.48550/arXiv.1707.08120.\n\n\nDeDeo, Simon. 2016. “Wrong Side of the Tracks: Big Data and Protected Categories.” arXiv. https://doi.org/10.48550/arXiv.1412.4643.\n\n\nFrance, Anatole. 1894. Le Lys Rouge (The Red Lily). G. Wells.\n\n\nIngold, David, and Spencer Soper. 2016. “Amazon Doesn’t Consider the Race of Its Customers. Should It?” Bloomberg, April. http://www.bloomberg.com/graphics/2016-amazon-same-day/.\n\n\nRousey, Dennis C. 2001. “Friends and Foes of Slavery: Foreigners and Northerners in the Old South.” Journal of Social History 35 (2): 373–96. https://www.jstor.org/stable/3790193.\n\n\nSimons, Josh. 2023. Algorithms for the People: Democracy in the Age of AI. Princeton University Press.",
    "crumbs": [
      "Week 4: {{< var w04.date-md >}}"
    ]
  },
  {
    "objectID": "w04/slides.html#baby-steps-a-real-world-confusion-matrix",
    "href": "w04/slides.html#baby-steps-a-real-world-confusion-matrix",
    "title": "Week 4: Fairness in AI",
    "section": "Baby Steps: A Real-World Confusion Matrix",
    "text": "Baby Steps: A Real-World Confusion Matrix\n\n\n\n\n\n\n\n\n\nLabeled Low-Risk\nLabeled High-Risk\n\n\n\n\nDidn’t Do More Crimes\nTrue Negative\nFalse Positive\n\n\nDid More Crimes\nFalse Negative\nTrue Positive\n\n\n\n\nWhat kinds of causal connections and/or feedback loops might there be between our decision variable (low vs. high risk) and our outcome variable (did vs. didn’t do more crimes)\nWhat types of policy implications might this process have, after it “runs” for several “iterations”?\nWhy might some segments of society, with some shared ethical framework(s), weigh the “costs” of false negatives and false positives differently from other segments of society with different shared ethical framework(s)?\n(Non-rhetorical questions!)"
  },
  {
    "objectID": "w04/slides.html#categories-of-fairness-criteria",
    "href": "w04/slides.html#categories-of-fairness-criteria",
    "title": "Week 4: Fairness in AI",
    "section": "Categories of Fairness Criteria",
    "text": "Categories of Fairness Criteria\n\nRoughly, approaches to fairness/bias in AI can be categorized as follows:\n\n\nFairness\n\n\n\n\n\n\nContext-Free\n\n\nSingle-Threshold Fairness\nEqual Prediction\nEqual Decision\n\n\n\n\n\n\n\n\n\nContext-Sensitive\n\n\nFairness via Similarity Metric(s)\nCausal Definitions\n\n\n\n\n\n\n\n[Today] Context-Free Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of Machine Learning (you already know much of it, given DSAN 5000!)\nBut easy-to-grasp notion \\(\\neq\\) “good” notion!\nYour job: push yourself to (a) consider what is getting left out of the context-free definitions, and (b) the loopholes that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”"
  },
  {
    "objectID": "w04/slides.html#laws-often-perfectly-technically-fair",
    "href": "w04/slides.html#laws-often-perfectly-technically-fair",
    "title": "Week 4: Fairness in AI",
    "section": "Laws: Often Perfectly “Technically Fair”",
    "text": "Laws: Often Perfectly “Technically Fair”\n\nAh, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!\n\n\n(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)\n\nAnatole France, Le Lys Rouge (France 1894)"
  },
  {
    "objectID": "w04/slides.html#no-fairness-through-unawareness",
    "href": "w04/slides.html#no-fairness-through-unawareness",
    "title": "Week 4: Fairness in AI",
    "section": "(No) Fairness Through Unawareness",
    "text": "(No) Fairness Through Unawareness\n\nHW1: Using tiny sample (\\(N &lt; 10K\\)) of Florida voter registrations… RandomForestClassifier (default settings, no hyperparameter tuning, no cross-validation, no ensembling with other methods) will predict self-reported race with \\(&gt;90\\%\\) accuracy (in balanced sample) from just surname and county of residence\n\nCan reach \\(70\\text{-}75\\%\\) with just surname or just county of residence\n\nAlso in HW1: Facebook ad matching service provides over 1,000 different user attributes for (micro)targeting\n\n\nFrom Datta et al. (2017)"
  },
  {
    "objectID": "w04/slides.html#to-make-it-even-more-concrete",
    "href": "w04/slides.html#to-make-it-even-more-concrete",
    "title": "Week 4: Fairness in AI",
    "section": "To Make It Even More Concrete…",
    "text": "To Make It Even More Concrete…\n\nBloomberg analysis of neighborhoods with same-day delivery from Amazon:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Figures from Ingold and Soper (2016)"
  },
  {
    "objectID": "w04/slides.html#last-one-i-promise",
    "href": "w04/slides.html#last-one-i-promise",
    "title": "Week 4: Fairness in AI",
    "section": "Last One I Promise",
    "text": "Last One I Promise\n\nPredicting self-reported whiteness with 70% accuracy"
  },
  {
    "objectID": "w04/slides.html#last-one-i-promise-1",
    "href": "w04/slides.html#last-one-i-promise-1",
    "title": "Week 4: Fairness in AI",
    "section": "Last One I Promise",
    "text": "Last One I Promise\n\nPredicting self-reported non-whiteness with 90% accuracy"
  },
  {
    "objectID": "w04/slides.html#we-can-do-a-bit-better",
    "href": "w04/slides.html#we-can-do-a-bit-better",
    "title": "Week 4: Fairness in AI",
    "section": "We Can Do (A Bit) Better…",
    "text": "We Can Do (A Bit) Better…\n\nUse random variables to model inferences made by an algorithm (or a human!)\n\\(\\implies\\) fairness by statistically equalizing loan rejections, error rate, etc. between groups\nObvious societal drawback: equality does not ameliorate the effects of past injustices (see: police contact vs. trust-in-government plot from last week)\n\nThis one we saw coming, given “context-free” nature!\n\nLess obvious mathematical drawback: impossibility results (because algebra 😳)\n\nRoughly: can’t satisfy [more than] two statistical fairness criteria at once; similar to how setting \\(\\Pr(X) = p\\) also determines \\(\\Pr(\\text{not }X) = 1 - p\\), or how plugging \\(x = 3\\) into \\(x + y = 5\\) leaves only one possibility \\(y = 2\\)\n\nBUT, “impossibility” \\(\\neq\\) impossibility: (a) one criteria may be “all you need” in given setting; (b) can derive more robust measures by “relaxing” confusion-matrix measures"
  },
  {
    "objectID": "w04/slides.html#protectedsensitive-attributes",
    "href": "w04/slides.html#protectedsensitive-attributes",
    "title": "Week 4: Fairness in AI",
    "section": "Protected/Sensitive Attributes",
    "text": "Protected/Sensitive Attributes\n\nStandard across the literature: Random Variable \\(A_i\\) “encoding” membership in protected/sensitive group. In HW1, for example:\n\n\\[\nA_i = \\begin{cases}\n0 &\\text{if }i\\text{ self-reported ``white''} \\\\\n1 &\\text{if }i\\text{ self-reported ``black''}\n\\end{cases}\n\\]\n\nNotice: choice of mapping into \\(\\{0, 1\\}\\) here non-arbitrary!\nWe want our models/criteria to be descriptively but also normatively robust; e.g.:\nIf (antecedent I hold, though majority in US do not) one believes that ending (much less repairing) centuries of unrelenting white supremacist violence here might require asymmetric race-based policies,\nThen our model should allow different normative labels and differential weights on\n\\[\n\\begin{align*}\n\\Delta &= (\\text{Fairness} \\mid A = 1) - (\\text{Fairness} \\mid A = 0) \\\\\n\\nabla &= (\\text{Fairness} \\mid A = 0) - (\\text{Fairness} \\mid A = 1)\n\\end{align*}\n\\]\ndespite the descriptive fact that \\(\\Delta = -\\nabla\\)."
  },
  {
    "objectID": "w04/slides.html#where-descriptive-and-normative-become-intertwined",
    "href": "w04/slides.html#where-descriptive-and-normative-become-intertwined",
    "title": "Week 4: Fairness in AI",
    "section": "Where Descriptive and Normative Become Intertwined",
    "text": "Where Descriptive and Normative Become Intertwined\n\nAllowing this asymmetry is precisely what enables bring descriptive facts to bear on normative concerns!\nMathematically we can always “flip” the mapping from racial labels into \\(\\{0, 1\\}\\)…\nBut this (in a precise, mathematical sense: namely, isomorphism) implies that we’re treating racial categorization as the same type of phenomenon as driving on left or right side of road (see: prev slides on why we make the descriptive vs. normative distinction)\n(See also: Sweden’s Dagen H!)"
  },
  {
    "objectID": "w04/slides.html#fairness-through-equalized-positive-rates-epr",
    "href": "w04/slides.html#fairness-through-equalized-positive-rates-epr",
    "title": "Week 4: Fairness in AI",
    "section": "“Fairness” Through Equalized Positive Rates (EPR)",
    "text": "“Fairness” Through Equalized Positive Rates (EPR)\n\n \n\n\\[\n\\boxed{\\Pr(D = 1 \\mid A = 0) = \\Pr(D = 1 \\mid A = 1)}\n\\]\n\nThis works specifically for discrete, binary-valued categories\nFor general attributes (whether discrete or continuous!), generalizes to:\n\n\\[\n\\boxed{D \\perp A} \\iff \\Pr(D = d, A = a) = \\Pr(D = d)\\Pr(A = a)\n\\]\n\nImagine you learn that a person received a scholarship (\\(D = 1\\)); [with equalized positive rates], this fact would give you no knowledge about the race (or sex, or class, as desired) \\(A\\) of the individual in question. (DeDeo 2016)"
  },
  {
    "objectID": "w04/slides.html#achieving-equalized-positive-rates",
    "href": "w04/slides.html#achieving-equalized-positive-rates",
    "title": "Week 4: Fairness in AI",
    "section": "Achieving Equalized Positive Rates",
    "text": "Achieving Equalized Positive Rates\n\nThe good news: if we want this, there is a closed-form solution: take your datapoints \\(X_i\\) and re-weigh each point to obtain \\(\\widetilde{X}_i = w_iX_i\\), where\n\\[\n  w_i = \\frac{\\Pr(Y_i = 1)}{\\Pr(Y_i = 1 \\mid A_i = 1)}\n  \\]\nand use derived dataset \\(\\widetilde{X}_i\\) to learn \\(r(X)\\) (via ML algorithm)… Why does this work?\nLet \\(\\mathcal{X}_{\\text{fair}}\\) be the set of all possible reweighted versions of \\(X_i\\) ensuring \\(Y_i \\perp A_i\\). Then\n\n\\[\n\\widetilde{X}_i = \\min_{X_i' \\in \\mathcal{X}_{\\text{fair}}}\\textsf{distance}(X_i', X_i) = \\min_{X_i' \\in \\mathcal{X}_{\\text{fair}}}\\underbrace{KL(X_i' \\| X_i)}_{\\text{Relative entropy!}}\n\\]\n\nThe bad news: nobody in the fairness in AI community read DeDeo (2016), which proves this using information theory? Idk. It has a total of 22 citations 😐"
  },
  {
    "objectID": "w04/slides.html#fairness-through-equalized-error-rates",
    "href": "w04/slides.html#fairness-through-equalized-error-rates",
    "title": "Week 4: Fairness in AI",
    "section": "“Fairness” Through Equalized Error Rates",
    "text": "“Fairness” Through Equalized Error Rates\n\nEqualized positive rates didn’t take outcomes \\(Y_i\\) into account…\n\n(Even if \\(A_i = 1 \\Rightarrow Y_i = 1, A_i = 0 \\Rightarrow Y_i = 0\\), we’d have to choose \\(\\widehat{Y}_i = c\\))\n\nThis time, we consider the outcome \\(Y\\) that\nEqualized False Positive Rate (EFPR):\n\n\\[\n\\Pr(D = 1 \\mid Y = 0, A = 0) = \\Pr(D = 1 \\mid Y = 0, A = 1)\n\\]\n\nEqualized False Negative Rate (EFNR):\n\n\\[\n\\Pr(D = 0 \\mid Y = 1, A = 0) = \\Pr(D = 0 \\mid Y = 1, A = 1)\n\\]\n\nFor general (non-binary) attributes: \\((D \\perp A) \\mid Y\\):\n\n\\[\n\\Pr(D = d, A = a \\mid Y = y) = \\Pr(D = d \\mid Y = y)\\Pr(A = a \\mid Y = y)\n\\]"
  },
  {
    "objectID": "w04/slides.html#less-equations-please",
    "href": "w04/slides.html#less-equations-please",
    "title": "Week 4: Fairness in AI",
    "section": "⚠️ LESS EQUATIONS PLEASE! 😤",
    "text": "⚠️ LESS EQUATIONS PLEASE! 😤\n\nDepending on your background and/or learning style (say, visual vs. auditory), you may be able to look at equations on previous two slides and “see” what they’re “saying”\nIf your brain works similarly to mine, however, your eyes glazed over, you began dissociating, planning an escape route, etc., the moment \\(&gt; 2\\) variables appeared\nIf you’re in the latter group, welcome to the cult of Probabilistic Graphical Models 😈\n\n\nYour first PGM, illustrating hypothesized causal relationships between three random variables \\(Y\\) (outcome), \\(D\\) (decision), and \\(A\\) (protected attribute). The \\(Y\\) node is shaded to indicate that it is an observed value in our model, rendering the unobserved values \\(D\\) and \\(A\\) independent conditional on it. If I was elected Emperor of Math, equations would be abolished in favor of PGMs."
  },
  {
    "objectID": "w04/slides.html#section",
    "href": "w04/slides.html#section",
    "title": "Week 4: Fairness in AI",
    "section": "",
    "text": "Equalized False Negative/Positive Rates\n\n\n\nOur first measure that 🥳🎉matches a principle of justice in society!!!🕺🪩\nBlackstone’s Ratio: “It is better that ten guilty persons escape, than that one innocent suffers.” (Blackstone 1769)\n(…break time!)"
  },
  {
    "objectID": "w04/slides.html#back-to-equalized-error-rates",
    "href": "w04/slides.html#back-to-equalized-error-rates",
    "title": "Week 4: Fairness in AI",
    "section": "Back to Equalized Error Rates",
    "text": "Back to Equalized Error Rates\n\nBlackstone’s Ratio: “It is better that ten guilty persons escape, than that one innocent suffers.” (Blackstone 1769)\nMathematically \\(\\Rightarrow \\text{Cost}(FPR) = 10\\cdot \\text{Cost}(FNR)\\)\nLegally \\(\\Rightarrow\\) beyond reasonable doubt standard for conviction\nEFPR \\(\\iff\\) rates of false conviction should be the same for everyone, including members of different racial groups.\n\nViolated when black people are disproportionately likely to be incorrectly convicted, as if a lower evidentiary standard were applied to black people."
  },
  {
    "objectID": "w04/slides.html#one-final-context-free-criterion-calibration",
    "href": "w04/slides.html#one-final-context-free-criterion-calibration",
    "title": "Week 4: Fairness in AI",
    "section": "One Final Context-Free Criterion: Calibration",
    "text": "One Final Context-Free Criterion: Calibration\n\nA risk function \\(r(X)\\) is calibrated if\n\n\\[\n\\Pr(Y = 1 \\mid r(X) = v_r) = v_r\n\\]\n\n(Sweeping a lot of details under the rug), I see this one as: the risk function “tracks” real-world probabilities\nThen, \\(r(X)\\) is calibrated by group if\n\n\\[\n\\Pr(Y = y \\mid r(X) = v_r, A = a) = v_r\n\\]"
  },
  {
    "objectID": "w04/slides.html#impossibility-results",
    "href": "w04/slides.html#impossibility-results",
    "title": "Week 4: Fairness in AI",
    "section": "Impossibility Results",
    "text": "Impossibility Results\n\ntldr: We cannot possibly achieve all three of equalized positive rates (often also termed “anti-classification”), classification parity, and calibration (regardless of base rates)\nMore alarmingly: We can’t even achieve both classification parity and calibration, except in the special case of equal base rates"
  },
  {
    "objectID": "w04/slides.html#impossibility-vs.-impossibility",
    "href": "w04/slides.html#impossibility-vs.-impossibility",
    "title": "Week 4: Fairness in AI",
    "section": "“Impossibility” vs. Impossibility",
    "text": "“Impossibility” vs. Impossibility\n\nSometimes “impossibility results” are, for all intents and purposes, mathematical curiosities: often there’s some pragmatic way of getting around them\nExample: “Arrow’s Impossibility Theorem”\n\n[In theory] It is mathematically impossible to aggregate individual preferences into societal preferences\n[The catch] True only if people are restricted to ordinal preferences: “I prefer \\(x\\) to \\(y\\).” No more information allowed\n[The way around it] Allow people to indicate the magnitude of their preferences: “I prefer \\(x\\) 5 times more than \\(y\\)”\n\nIn this case, though, there are direct and (often) unavoidable real-world barriers that fairness impossibility imposes 😕"
  },
  {
    "objectID": "w04/slides.html#arrows-impossibility-theorem",
    "href": "w04/slides.html#arrows-impossibility-theorem",
    "title": "Week 4: Fairness in AI",
    "section": "Arrow’s Impossibility Theorem",
    "text": "Arrow’s Impossibility Theorem\n\nAziza, Bogdan, and Charles are competing in a fitness test with four events. Goal: determine who is most fit overall\n\n\n\n\n\nRun\nJump\nHurdle\nWeights\n\n\n\n\nAziza\n10.1”\n6.0’\n40”\n150 lb\n\n\nBogdan\n9.2”\n5.9’\n42”\n140 lb\n\n\nCharles\n10.0”\n6.1’\n39”\n145 lb\n\n\n\n\nWe can rank unambiguously on individual events: Jump: Charles \\(\\succ_J\\) Aziza \\(\\succ_J\\) Bogdan\nNow, axioms for aggregation:\n\n\\(\\text{WP}\\) (Weak Pareto Optimality): if \\(x \\succ_i y\\) for all events \\(i\\), \\(x \\succ y\\)\n\\(\\text{IIA}\\) (Independence of Irrelevant Alternatives): If a fourth competitor enters, but Aziza and Bogdan still have the same relative standing on all events, their relative standing overall should not change\n\nLong story short: only aggregation that can satisfy these is “dictatorship”: choose one event, give it importance of 100%, the rest have importance 0% 😰"
  },
  {
    "objectID": "w04/slides.html#propublica-vs.-northpointe",
    "href": "w04/slides.html#propublica-vs.-northpointe",
    "title": "Week 4: Fairness in AI",
    "section": "ProPublica vs. Northpointe",
    "text": "ProPublica vs. Northpointe\n\nThis is… an example with 1000s of books and papers and discussions around it! (A red flag 🚩, since, obsession with one example may conceal much wider range of issues!)\nBut, tldr, Northpointe created a ML algorithm called COMPAS, used by court systems all over the US to predict “risk” of arrestees\nIn 2016, ProPublica published results from an investigative report documenting COMPAS’s racial discrimination, in the form of violating equal error rates between black and white arrestees\nNorthpointe responded that COMPAS does not discriminate, as it satisfies calibration\nPeople have argued about who is “right” for 8 years, with some progress, but… not a lot"
  },
  {
    "objectID": "w04/slides.html#so-what-do-we-do",
    "href": "w04/slides.html#so-what-do-we-do",
    "title": "Week 4: Fairness in AI",
    "section": "So… What Do We Do?",
    "text": "So… What Do We Do?\n\nOne option: argue about which of the two definitions is “better” for the next 100 years (what is the best way to give food to the poor?)\n\n\nIt appears to reveal an unfortunate but inexorable fact about our world: we must choose between two intuitively appealing ways to understand fairness in ML. Many scholars have done just that, defending either ProPublica’s or Northpointe’s definitions against what they see as the misguided alternative. (Simons 2023)\n\n\nAnother option: study and then work to ameliorate the social conditions which force us into this realm of mathematical impossibility (why do the poor have no food?)\n\n\nThe impossibility result is about much more than math. [It occurs because] the underlying outcome is distributed unevenly in society. This is a fact about society, not mathematics, and requires engaging with a complex, checkered history of systemic racism in the US. Predicting an outcome whose distribution is shaped by this history requires tradeoffs because the inequalities and injustices are encoded in data—in this case, because America has criminalized Blackness for as long as America has existed."
  },
  {
    "objectID": "w04/slides.html#why-not-both",
    "href": "w04/slides.html#why-not-both",
    "title": "Week 4: Fairness in AI",
    "section": "Why Not Both??",
    "text": "Why Not Both??\n\nOn the one hand: yes, both! On the other hand: fallacy of the “middle ground”\nWe’re back at descriptive vs. normative:\n\nDescriptively, given 100 values \\(v_1, \\ldots, v_{100}\\), their mean may be a good way to summarize, if we have to choose a single number\nBut, normatively, imagine that these are opinions that people hold about fairness.\nNow, if it’s the US South in 1860 and \\(v_i\\) represents person \\(i\\)’s approval of slavery, from a sample of 100 people, then approx. 97 of the \\(v_i\\)’s are “does not disapprove” (Rousey 2001) — in this case, normatively, is the mean \\(0.97\\) the “correct” answer?\n\nWe have another case where, like the “grass is green” vs. “grass ought to be green” example, we cannot just “import” our logical/mathematical tools from the former to solve the latter! (However: this does not mean they are useless! This is the fallacy of the excluded middle, sort of the opposite of the fallacy of the middle ground)\nThis is why we have ethical frameworks in the first place! Going back to Rawls: “97% of Americans think black people shouldn’t have rights”  \\(\\nimplies\\)“black people shouldn’t have rights”, since rights are a primary good"
  },
  {
    "objectID": "w04/slides.html#references",
    "href": "w04/slides.html#references",
    "title": "Week 4: Fairness in AI",
    "section": "References",
    "text": "References\n\n\nBlackstone, William. 1769. Commentaries on the Laws of England, Volume 2: A Facsimile of the First Edition of 1765-1769. University of Chicago Press.\n\n\nDatta, Anupam, Matt Fredrikson, Gihyuk Ko, Piotr Mardziel, and Shayak Sen. 2017. “Proxy Non-Discrimination in Data-Driven Systems.” arXiv. https://doi.org/10.48550/arXiv.1707.08120.\n\n\nDeDeo, Simon. 2016. “Wrong Side of the Tracks: Big Data and Protected Categories.” arXiv. https://doi.org/10.48550/arXiv.1412.4643.\n\n\nFrance, Anatole. 1894. Le Lys Rouge (The Red Lily). G. Wells.\n\n\nIngold, David, and Spencer Soper. 2016. “Amazon Doesn’t Consider the Race of Its Customers. Should It?” Bloomberg, April. http://www.bloomberg.com/graphics/2016-amazon-same-day/.\n\n\nRousey, Dennis C. 2001. “Friends and Foes of Slavery: Foreigners and Northerners in the Old South.” Journal of Social History 35 (2): 373–96. https://www.jstor.org/stable/3790193.\n\n\nSimons, Josh. 2023. Algorithms for the People: Democracy in the Age of AI. Princeton University Press.\n\n\n\n\n\nDSAN 5450 Week 4: Fairness in AI"
  },
  {
    "objectID": "w05/index.html",
    "href": "w05/index.html",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#impossibility-results",
    "href": "w05/index.html#impossibility-results",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Impossibility Results",
    "text": "Impossibility Results\n\ntldr: We cannot possibly achieve all three of equalized positive rates (often also termed “anti-classification”), classification parity, and calibration (regardless of base rates)\nMore alarmingly: We can’t even achieve both classification parity and calibration, except in the special case of equal base rates",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#impossibility-vs.-impossibility",
    "href": "w05/index.html#impossibility-vs.-impossibility",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "“Impossibility” vs. Impossibility",
    "text": "“Impossibility” vs. Impossibility\n\nSometimes “impossibility results” are, for all intents and purposes, mathematical curiosities: often there’s some pragmatic way of getting around them\nExample: “Arrow’s Impossibility Theorem”\n\n[In theory] It is mathematically impossible to aggregate individual preferences into societal preferences\n[The catch] True only if people are restricted to ordinal preferences: “I prefer \\(x\\) to \\(y\\).” No more information allowed\n[The way around it] Allow people to indicate the magnitude of their preferences: “I prefer \\(x\\) 5 times more than \\(y\\)”\n\nIn this case, though, there are direct and (often) unavoidable real-world barriers that fairness impossibility imposes 😕",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#arrows-impossibility-theorem",
    "href": "w05/index.html#arrows-impossibility-theorem",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Arrow’s Impossibility Theorem",
    "text": "Arrow’s Impossibility Theorem\n\nAziza, Bogdan, and Charles are competing in a fitness test with four events. Goal: determine who is most fit overall\n\n\n\n\n\nRun\nJump\nHurdle\nWeights\n\n\n\n\nAziza\n10.1”\n6.0’\n40”\n150 lb\n\n\nBogdan\n9.2”\n5.9’\n42”\n140 lb\n\n\nCharles\n10.0”\n6.1’\n39”\n145 lb\n\n\n\n\nWe can rank unambiguously on individual events: Jump: Charles \\(\\succ_J\\) Aziza \\(\\succ_J\\) Bogdan\nNow, axioms for aggregation:\n\n\\(\\text{WP}\\) (Weak Pareto Optimality): if \\(x \\succ_i y\\) for all events \\(i\\), \\(x \\succ y\\)\n\\(\\text{IIA}\\) (Independence of Irrelevant Alternatives): If a fourth competitor enters, but Aziza and Bogdan still have the same relative standing on all events, their relative standing overall should not change\n\nLong story short: only aggregation that can satisfy these is “dictatorship”: choose one event, give it importance of 100%, the rest have importance 0% 😰",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#propublica-vs.-northpointe",
    "href": "w05/index.html#propublica-vs.-northpointe",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "ProPublica vs. Northpointe",
    "text": "ProPublica vs. Northpointe\n\nThis is… an example with 1000s of books and papers and discussions around it! (A red flag 🚩, since, obsession with one example may conceal much wider range of issues!)\nBut, tldr, Northpointe created a ML algorithm called COMPAS, used by court systems all over the US to predict “risk” of arrestees\nIn 2016, ProPublica published results from an investigative report documenting COMPAS’s racial discrimination, in the form of violating equal error rates between black and white arrestees\nNorthpointe responded that COMPAS does not discriminate, as it satisfies calibration\nPeople have argued about who is “right” for 8 years, with some progress, but… not a lot",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#so-what-do-we-do",
    "href": "w05/index.html#so-what-do-we-do",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "So… What Do We Do?",
    "text": "So… What Do We Do?\n\nOne option: argue about which of the two definitions is “better” for the next 100 years (what is the best way to give food to the poor?)\n\n\nIt appears to reveal an unfortunate but inexorable fact about our world: we must choose between two intuitively appealing ways to understand fairness in ML. Many scholars have done just that, defending either ProPublica’s or Northpointe’s definitions against what they see as the misguided alternative. (Simons 2023)\n\n\nAnother option: study and then work to ameliorate the social conditions which force us into this realm of mathematical impossibility (why do the poor have no food?)\n\n\nThe impossibility result is about much more than math. [It occurs because] the underlying outcome is distributed unevenly in society. This is a fact about society, not mathematics, and requires engaging with a complex, checkered history of systemic racism in the US. Predicting an outcome whose distribution is shaped by this history requires tradeoffs because the inequalities and injustices are encoded in data—in this case, because America has criminalized Blackness for as long as America has existed.",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#why-not-both",
    "href": "w05/index.html#why-not-both",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Why Not Both??",
    "text": "Why Not Both??\n\nOn the one hand: yes, both! On the other hand: fallacy of the “middle ground”\nWe’re back at descriptive vs. normative:\n\nDescriptively, given 100 values \\(v_1, \\ldots, v_{100}\\), their mean may be a good way to summarize, if we have to choose a single number\nBut, normatively, imagine that these are opinions that people hold about fairness.\nNow, if it’s the US South in 1860 and \\(v_i\\) represents person \\(i\\)’s approval of slavery, from a sample of 100 people, then approx. 97 of the \\(v_i\\)’s are “does not disapprove” (Rousey 2001) — in this case, normatively, is the mean \\(0.97\\) the “correct” answer?\n\nWe have another case where, like the “grass is green” vs. “grass ought to be green” example, we cannot just “import” our logical/mathematical tools from the former to solve the latter! (However: this does not mean they are useless! This is the fallacy of the excluded middle, sort of the opposite of the fallacy of the middle ground)\nThis is why we have ethical frameworks in the first place! Going back to Rawls: “97% of Americans think black people shouldn’t have rights”  \\(\\nimplies\\)“black people shouldn’t have rights”, since rights are a primary good",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#motivation-linguistic-meaning",
    "href": "w05/index.html#motivation-linguistic-meaning",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Motivation: Linguistic Meaning",
    "text": "Motivation: Linguistic Meaning\n\n\n\n\n\n\n The Distributional Hypothesis (Firth 1968, 179)\n\n\n\nYou shall know a word by the company it keeps!\n\n\n\nRelated to Chomsky’s context-free vs. context-sensitive distinction!\nBut why is it relevant to DSAN 5450?…",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-meaning-of-fairness",
    "href": "w05/index.html#the-meaning-of-fairness",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The “Meaning” of Fairness",
    "text": "The “Meaning” of Fairness\n\n\n\n\n\n\n The Distributional [Fairness] Hypothesis\n\n\n\nYou shall know “fairness” by the company it keeps [i.e., the context it incorporates].\n\n\n\nContext-free (confusion-matrix-based) fairness: “plug the confusion matrix values into a formula and see if the formula is satisfied”\nContext-sensitive fairness: analyze fairness relative to a set of antecedents regarding how normative concerns should enter into our measurements of fairness",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#group-fairness-rightarrow-individual-fairness",
    "href": "w05/index.html#group-fairness-rightarrow-individual-fairness",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Group Fairness \\(\\rightarrow\\) Individual Fairness",
    "text": "Group Fairness \\(\\rightarrow\\) Individual Fairness\n\nThe crucial insight of Dwork: group-level fairness does not ensure that individuals are treated fairly as individuals\nExactly the issue we’ve seen with utilitarianism: optimizing society-level “happiness” may lead to individuals being brutally mistreated (e.g., having their rights violated)\nSo, at a high level, Dwork’s proposal could provide a Rawls-style ordering: individual fairness lexically prior to group-level fairness (optimize group-level fairness once individual-level is satisfied)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-normative-antecedent",
    "href": "w05/index.html#the-normative-antecedent",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The (Normative!) Antecedent",
    "text": "The (Normative!) Antecedent\n\n\n\n\n\n\nFairness Through Awareness (Dwork et al. 2011)\n\n\n\nIndividuals who are similar with respect to a task should be classified similarly.\n\n\n\n\n\n\n\n\n\nNot well-liked in industry / policy because you can’t just “plug in” results of your classifier and get True/False “we satisfied fairness!” …But this is exactly the point!\n\n\n\n\n\n\nFrom Kiat (2018)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#bringing-in-context-1",
    "href": "w05/index.html#bringing-in-context-1",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Bringing In Context",
    "text": "Bringing In Context\n\nIn itself, the principle of equal treatment is abstract, a formal relationship that lacks substantive content”\nThe principle must be given content by defining which cases are similar and which are different, and by considering what kinds of differences justify differential treatment\nDeciding what differences are relevant, and what kinds of differential treatment are justified by particular differences, requires wrestling with moral and political debates about the responsibilities of different institutions to address persistent injustice (Simons 2023, 51)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#remember-distance-metrics",
    "href": "w05/index.html#remember-distance-metrics",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Remember Distance Metrics?(!)",
    "text": "Remember Distance Metrics?(!)\n\n\n\n\n\n\n\nA core element in both similarity-based and causal fairness!\nAlready difficult to choose a metric on pragmatic grounds (ambulance needs to get to hospital)\nNow people will also have fundamental normative disagreements about what should and should not determine difference\n\n\n\n\n\n\nFrom Shahid et al. (2009)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#satisfying-individual-vs.-group-fairness",
    "href": "w05/index.html#satisfying-individual-vs.-group-fairness",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Satisfying Individual vs. Group Fairness",
    "text": "Satisfying Individual vs. Group Fairness\n\nAn algorithm is individually fair if, for all individuals \\(x\\) and \\(y\\), we have\n\\[\n\\textsf{dist}(r(x), r(y)) \\leq \\textsf{dist}(x, y)\n\\]\n\\(\\implies\\) an advertising system must show similar sets of ads to similar users.\nIt achieves group fairness-through-parity for two groups of users \\(S\\) and \\(T\\) when:\n\\[\n\\textsf{dist}(\\mathbb{E}_{s \\in S}[r(s)], \\mathbb{E}_{t \\in T}[r(t)]) \\leq \\varepsilon\n\\]\nwhere \\(\\mathbb{E}_{s \\in S}\\) and \\(\\mathbb{E}_{t \\in T}\\) denote the expectation of ads seen by an individual chosen uniformly among \\(S\\) and \\(T\\). This definition implies that the difference in probability between two groups of seeing a particular ad will be bounded by \\(\\varepsilon\\).\nGiven these definitions: Individual fairness  \\(\\nimplies\\) group fairness, and vice versa! (Riederer and Chaintreau 2017)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-importance-of-not-excluding-race",
    "href": "w05/index.html#the-importance-of-not-excluding-race",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Importance of Not Excluding Race!",
    "text": "The Importance of Not Excluding Race!\n\nOn HW2 you will see how, on the one hand: excluding race from the similarity metric ensures race-blind fairness\nBut, on the other hand: race-blind fairness can not only maintain but also amplify preexisting inequalities\nBy including race in our similarity metric, we can explicitly take this into account!\nEx: someone with a (morally irrelevant) disadvantage due to birth lottery who achieves an SAT score of 1400 is similar to someone with a (morally irrelevant) advantage due to birth lottery who achieves an SAT score of 1500",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#equality-of-opportunity",
    "href": "w05/index.html#equality-of-opportunity",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Equality of Opportunity",
    "text": "Equality of Opportunity\n\n\n\n\n\n\n\nThis notion (last bullet of the previous slide) is contentious, to say the least\nBut also, crucially: our job is not to decide the similarity metric unilaterally!\nThe equality of opportunity approach is not itself a similarity metric!\nIt is a “meta-algorithm” for translating normative positions (consequents of an ethical framework) into concrete fairness constraints that you can then impose on ML algorithms\n\n\n\n\n\n\nRoemer (1998)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#roemers-algorithm",
    "href": "w05/index.html#roemers-algorithm",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Roemer’s Algorithm",
    "text": "Roemer’s Algorithm\n\nRoughly, the Equality of Opportunity algorithm boils down to:\nInput 1 (!): A set of attributes \\(X_{\\text{advantage}}\\) that a society (real or hypothetical) considers normatively relevant for an outcome, but that people are not individually responsible for (e.g., race or nationality via birth lottery)\nInput 2: A set of attributes \\(X_{\\text{merit}}\\) that a society considers appropriate to hold people individually responsible for (e.g., effort, sacrificing short-term pleasure for longer-term benefits, etc.)\nStep 1: Set of individuals in society \\(S\\) is partitioned into subsets \\(S_i\\), where \\(i\\) is some combination of particular values for the attributes in \\(X_{\\text{advantage}}\\)\nStep 2: Individuals’ context-sensitive scores are computed relative to their group \\(S_i\\), as \\(z\\)-score of their \\(X_{\\text{merit}}\\) value relative to distribution of \\(X_{\\text{merit}}\\) values across \\(S_i\\)\nOutcome: Now that we have incorporated social context, by converting the original context-free units (e.g., numeric SAT score) into context-sensitive units (\\(z\\)-score of numeric SAT score within distribution of comparable individuals), we can compare people across groups on the basis of context-sensitive scores!",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-state-of-the-art",
    "href": "w05/index.html#the-state-of-the-art",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The State of the Art!",
    "text": "The State of the Art!\n\nMy view of the current state of fairness in AI: measures which explicitly model causal connections between variables of interest are the most promising for robust notions of fairness\nRobust in the sense of:\n\nBeing normatively desirable (as in, matching the key tenets of our ethical frameworks) while also being\nDescriptively tractable (as in, concretely implementable in math/code, and transparent enough to allow us to evaluate and update these implementations, using a process like reflective equilibrium).",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-antecedent",
    "href": "w05/index.html#the-antecedent",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Antecedent",
    "text": "The Antecedent\n\nSince it’s impossible to eliminate information about sensitive attributes like race/gender/etc. from our ML algorithms, fairness should instead be defined on the basis of how this sensitive information “flows” through the causal chain of decisions which lead to an given (observed) outcome",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-new-object-of-analysis-causal-pathways",
    "href": "w05/index.html#the-new-object-of-analysis-causal-pathways",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The New Object of Analysis: Causal Pathways",
    "text": "The New Object of Analysis: Causal Pathways\nThe reason this approach is so promising is because, once we have a model of the causal connections among the variables that we care about (socially/normatively), and among the variables that are used by a Machine Learning algorithm, we can then use techniques developed by statisticians who study causal inference to block certain “causal pathways” that we deem normatively unjustifiable while allowing other pathways that we deem to be normatively justifiable.",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#causal-fairness-in-hw2",
    "href": "w05/index.html#causal-fairness-in-hw2",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Causal Fairness in HW2",
    "text": "Causal Fairness in HW2\nGiven this, the first subpart of this portion of the assignment will focus specifically on helping you develop intuition around the way of thinking required to make the jump from the correlational approach used in statistics and probability generally (and used in DSAN 5100 specifically!) to the causal approach which builds on the correlational approach but has a stricter standard for determining whether two or more Random Variables are related to one another. Then, in the second subpart, you will take this intuition and use it to evaluate fairness in a real-world setting!",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#causal-building-blocks",
    "href": "w05/index.html#causal-building-blocks",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Causal Building Blocks",
    "text": "Causal Building Blocks\n\nDSAN 5100 precedent: nodes in the network \\(X\\), \\(Y\\) are Random Variables, connections \\(X \\leftrightarrow Y\\) are joint distributions \\(\\Pr(X, Y)\\)\nDirectional edges \\(X \\rightarrow Y\\), then, just represent conditional distributions: \\(X \\rightarrow Y\\) is \\(\\Pr(Y \\mid X)\\)\nWhere we’re going: connections \\(X \\leftrightarrow Y\\) represent unknown but extant causal connections between \\(X\\) and \\(Y\\), while \\(X \\rightarrow Y\\) represents a causal relationship between \\(X\\) and \\(Y\\)\nSpecifically, \\(X \\rightarrow Y\\) now means: an intervention that changes the value of \\(X\\) by \\(\\varepsilon\\) causes a change in the value of \\(Y\\) by \\(f(\\varepsilon)\\)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-intuitive-problem-of-causal-inference",
    "href": "w05/index.html#the-intuitive-problem-of-causal-inference",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Intuitive Problem of Causal Inference",
    "text": "The Intuitive Problem of Causal Inference\n\n\n\nsource(\"../_globals.r\")\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nga_lawyers &lt;- c(21362, 22254, 23134, 23698, 24367, 24930, 25632, 26459, 27227, 27457)\nski_df &lt;- tibble::tribble(\n  ~year, ~varname, ~value,\n  2000, \"ski_revenue\", 1551,\n  2001, \"ski_revenue\", 1635,\n  2002, \"ski_revenue\", 1801,\n  2003, \"ski_revenue\", 1827,\n  2004, \"ski_revenue\", 1956,\n  2005, \"ski_revenue\", 1989,\n  2006, \"ski_revenue\", 2178,\n  2007, \"ski_revenue\", 2257,\n  2008, \"ski_revenue\", 2476,\n  2009, \"ski_revenue\", 2438,\n)\nski_mean &lt;- mean(ski_df$value)\nski_sd &lt;- sd(ski_df$value)\nski_df &lt;- ski_df %&gt;% mutate(val_scaled = 12*value, val_norm = (value - ski_mean)/ski_sd)\nlaw_df &lt;- tibble::tibble(year=2000:2009, varname=\"ga_lawyers\", value=ga_lawyers)\nlaw_mean &lt;- mean(law_df$value)\nlaw_sd &lt;- sd(law_df$value)\nlaw_df &lt;- law_df %&gt;% mutate(val_norm = (value - law_mean)/law_sd)\nspur_df &lt;- dplyr::bind_rows(ski_df, law_df)\nggplot(spur_df, aes(x=year, y=val_norm, color=factor(varname, labels = c(\"Ski Revenue\",\"Lawyers in Georgia\")))) +\n  stat_smooth(method=\"loess\", se=FALSE) +\n  geom_point(size=g_pointsize/1.5) +\n  labs(\n    fill=\"\",\n    title=\"Ski Revenue vs. Georgia Lawyers\",\n    x=\"Year\",\n    color=\"Correlation: 99.2%\",\n    linetype=NULL\n  ) +\n  dsan_theme(\"custom\", 18) +\n  scale_x_continuous(\n    breaks=seq(from=2000, to=2014, by=2)\n  ) +\n  #scale_y_continuous(\n  #  name=\"Total Revenue, Ski Facilities (Million USD)\",\n  #  sec.axis = sec_axis(~ . * law_sd + law_mean, name = \"Number of Lawyers in Georgia\")\n  #) +\n  scale_y_continuous(breaks = -1:1,\n    labels = ~ . * round(ski_sd,1) + round(ski_mean,1),\n    name=\"Total Revenue, Ski Facilities (Million USD)\",\n    sec.axis = sec_axis(~ . * law_sd + law_mean, name = \"Number of Lawyers in Georgia\")) +\n  expand_limits(x=2010) +\n  #geom_hline(aes(yintercept=x, color=\"Mean Values\"), as.data.frame(list(x=0)), linewidth=0.75, alpha=1.0, show.legend = TRUE) +\n  scale_color_manual(\n    breaks=c('Ski Revenue', 'Lawyers in Georgia'),\n    values=c('Ski Revenue'=cbPalette[1], 'Lawyers in Georgia'=cbPalette[2]))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\ncor(ski_df$value, law_df$value)\n\n[1] 0.9921178\n\n\n\n(Based on Spurious Correlations, Tyler Vigen)",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#the-fundamental-problem-of-causal-inference",
    "href": "w05/index.html#the-fundamental-problem-of-causal-inference",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Fundamental Problem of Causal Inference",
    "text": "The Fundamental Problem of Causal Inference\nThe only workable definition of “\\(X\\) causes \\(Y\\)”:\n\n\n\n\n\n\n Defining Causality\n\n\n\n\\(X\\) causes \\(Y\\) if and only if:\n\nX temporally precedes \\(Y\\) and\nIn two worlds \\(W_0\\) and \\(W_1\\) where everything is exactly the same except that \\(X = 0\\) in \\(W_0\\) and \\(X = 1\\) in \\(W_1\\), \\(Y = 0\\) in \\(W_0\\) and \\(Y = 1\\) in \\(W_1\\) (Hume 1739)\n\n\n\n\nThe problem? We live in one world, not two simultaneous worlds 😭",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#what-is-to-be-done",
    "href": "w05/index.html#what-is-to-be-done",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "What Is To Be Done?",
    "text": "What Is To Be Done?",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "href": "w05/index.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm",
    "text": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm\n\nFind good comparison cases: Treatment and Control\nWithout a control group, you cannot make inferences!\nSelecting on the dependent variable…",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#selecting-on-the-dependent-variable",
    "href": "w05/index.html#selecting-on-the-dependent-variable",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Selecting on the Dependent Variable",
    "text": "Selecting on the Dependent Variable\n\n\n\nWhat “““research”“” “““says”“” about identifying people who might commit mass shootings\n\n\n\nJeff’s rant: If you care about actually solving social issues, this should infuriate you",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#complications-selection",
    "href": "w05/index.html#complications-selection",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Complications: Selection",
    "text": "Complications: Selection\n\nTldr: Why did this person (unit) end up in the treatment group? Why did this other person (unit) end up in the control group?\nAre there systematic differences?\nVietnam/Indochina Draft: Why can’t we just study [men who join the military] versus [men who don’t], and take the difference as a causal estimate?",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#complications-compliance",
    "href": "w05/index.html#complications-compliance",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Complications: Compliance",
    "text": "Complications: Compliance\n\nWe ideally want people assigned to the treatment to take the treatment, and people assigned to the control to take the control.\n“Compliance”: degree to which this is true in experiment\n\nHigh compliance = most people actually took what they were assigned\nLow compliance = lots of people who were assigned to treatment actually took control, and vice-versa\n\nWhat problems might exist w.r.t compliance in the Draft example?",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#next-week-and-hw2-experimental-rightarrow-observational-data",
    "href": "w05/index.html#next-week-and-hw2-experimental-rightarrow-observational-data",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Next Week and HW2: Experimental \\(\\rightarrow\\) Observational Data",
    "text": "Next Week and HW2: Experimental \\(\\rightarrow\\) Observational Data\n\nIn observational studies, researchers have no control over assignment to treatment/control 😨\nOn the one hand… Forget Everything And Run [to randomized, controlled experiments], if you can.\nOn the other hand… statisticians over the last ~4 centuries have developed fancy causal inference tools/techniques to help us Face Everything And Rise 🧐",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#for-now-matching",
    "href": "w05/index.html#for-now-matching",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "For Now: Matching",
    "text": "For Now: Matching\n\nIn a randomized, controlled experiment, we can ensure (since we have control over the assignment mechanism) that the only systematic difference between \\(C\\) and \\(T\\) is that \\(T\\) received the treatment and \\(C\\) did not\nIn an observational study, we “show up too late”!\nThus, we no longer refer to assignment but to selection\nAnd, our job is to figure out (reverse engineer!) the selection mechanism, then correct for its non-randomness: basically, we “transform” from observational to experimental setting through weighting",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/index.html#references",
    "href": "w05/index.html#references",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "References",
    "text": "References\n\n\nDwork, Cynthia, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Rich Zemel. 2011. “Fairness Through Awareness.” arXiv. https://doi.org/10.48550/arXiv.1104.3913.\n\n\nFirth, John Rupert. 1968. Selected Papers of J.R. Firth, 1952-59. Longmans.\n\n\nHume, David. 1739. A Treatise of Human Nature: Being an Attempt to Introduce the Experimental Method of Reasoning Into Moral Subjects; and Dialogues Concerning Natural Religion. Longmans, Green.\n\n\nKiat, Lim Swee. 2018. “Machines Gone Wrong.” PhD thesis, Singapore University of Technology; Design. https://machinesgonewrong.com/about/.\n\n\nRiederer, Christopher, and Augustin Chaintreau. 2017. “The Price of Fairness in Location Based Advertising.” Fairness, Accountability, and Transparency Workshop on Responsible Recommendation. https://doi.org/10.18122/B2MD8C.\n\n\nRoemer, John E. 1998. Equality of Opportunity. Harvard University Press.\n\n\nRousey, Dennis C. 2001. “Friends and Foes of Slavery: Foreigners and Northerners in the Old South.” Journal of Social History 35 (2): 373–96. https://www.jstor.org/stable/3790193.\n\n\nShahid, Rizwan, Stefania Bertazzon, Merril L. Knudtson, and William A. Ghali. 2009. “Comparison of Distance Measures in Spatial Analytical Modeling for Health Service Planning.” BMC Health Services Research 9 (1): 200. https://doi.org/10.1186/1472-6963-9-200.\n\n\nSimons, Josh. 2023. Algorithms for the People: Democracy in the Age of AI. Princeton University Press.",
    "crumbs": [
      "Week 5: {{< var w05.date-md >}}"
    ]
  },
  {
    "objectID": "w05/slides.html#impossibility-results",
    "href": "w05/slides.html#impossibility-results",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Impossibility Results",
    "text": "Impossibility Results\n\ntldr: We cannot possibly achieve all three of equalized positive rates (often also termed “anti-classification”), classification parity, and calibration (regardless of base rates)\nMore alarmingly: We can’t even achieve both classification parity and calibration, except in the special case of equal base rates"
  },
  {
    "objectID": "w05/slides.html#impossibility-vs.-impossibility",
    "href": "w05/slides.html#impossibility-vs.-impossibility",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "“Impossibility” vs. Impossibility",
    "text": "“Impossibility” vs. Impossibility\n\nSometimes “impossibility results” are, for all intents and purposes, mathematical curiosities: often there’s some pragmatic way of getting around them\nExample: “Arrow’s Impossibility Theorem”\n\n[In theory] It is mathematically impossible to aggregate individual preferences into societal preferences\n[The catch] True only if people are restricted to ordinal preferences: “I prefer \\(x\\) to \\(y\\).” No more information allowed\n[The way around it] Allow people to indicate the magnitude of their preferences: “I prefer \\(x\\) 5 times more than \\(y\\)”\n\nIn this case, though, there are direct and (often) unavoidable real-world barriers that fairness impossibility imposes 😕"
  },
  {
    "objectID": "w05/slides.html#arrows-impossibility-theorem",
    "href": "w05/slides.html#arrows-impossibility-theorem",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Arrow’s Impossibility Theorem",
    "text": "Arrow’s Impossibility Theorem\n\nAziza, Bogdan, and Charles are competing in a fitness test with four events. Goal: determine who is most fit overall\n\n\n\n\n\nRun\nJump\nHurdle\nWeights\n\n\n\n\nAziza\n10.1”\n6.0’\n40”\n150 lb\n\n\nBogdan\n9.2”\n5.9’\n42”\n140 lb\n\n\nCharles\n10.0”\n6.1’\n39”\n145 lb\n\n\n\n\nWe can rank unambiguously on individual events: Jump: Charles \\(\\succ_J\\) Aziza \\(\\succ_J\\) Bogdan\nNow, axioms for aggregation:\n\n\\(\\text{WP}\\) (Weak Pareto Optimality): if \\(x \\succ_i y\\) for all events \\(i\\), \\(x \\succ y\\)\n\\(\\text{IIA}\\) (Independence of Irrelevant Alternatives): If a fourth competitor enters, but Aziza and Bogdan still have the same relative standing on all events, their relative standing overall should not change\n\nLong story short: only aggregation that can satisfy these is “dictatorship”: choose one event, give it importance of 100%, the rest have importance 0% 😰"
  },
  {
    "objectID": "w05/slides.html#propublica-vs.-northpointe",
    "href": "w05/slides.html#propublica-vs.-northpointe",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "ProPublica vs. Northpointe",
    "text": "ProPublica vs. Northpointe\n\nThis is… an example with 1000s of books and papers and discussions around it! (A red flag 🚩, since, obsession with one example may conceal much wider range of issues!)\nBut, tldr, Northpointe created a ML algorithm called COMPAS, used by court systems all over the US to predict “risk” of arrestees\nIn 2016, ProPublica published results from an investigative report documenting COMPAS’s racial discrimination, in the form of violating equal error rates between black and white arrestees\nNorthpointe responded that COMPAS does not discriminate, as it satisfies calibration\nPeople have argued about who is “right” for 8 years, with some progress, but… not a lot"
  },
  {
    "objectID": "w05/slides.html#so-what-do-we-do",
    "href": "w05/slides.html#so-what-do-we-do",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "So… What Do We Do?",
    "text": "So… What Do We Do?\n\nOne option: argue about which of the two definitions is “better” for the next 100 years (what is the best way to give food to the poor?)\n\n\nIt appears to reveal an unfortunate but inexorable fact about our world: we must choose between two intuitively appealing ways to understand fairness in ML. Many scholars have done just that, defending either ProPublica’s or Northpointe’s definitions against what they see as the misguided alternative. (Simons 2023)\n\n\nAnother option: study and then work to ameliorate the social conditions which force us into this realm of mathematical impossibility (why do the poor have no food?)\n\n\nThe impossibility result is about much more than math. [It occurs because] the underlying outcome is distributed unevenly in society. This is a fact about society, not mathematics, and requires engaging with a complex, checkered history of systemic racism in the US. Predicting an outcome whose distribution is shaped by this history requires tradeoffs because the inequalities and injustices are encoded in data—in this case, because America has criminalized Blackness for as long as America has existed."
  },
  {
    "objectID": "w05/slides.html#why-not-both",
    "href": "w05/slides.html#why-not-both",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Why Not Both??",
    "text": "Why Not Both??\n\nOn the one hand: yes, both! On the other hand: fallacy of the “middle ground”\nWe’re back at descriptive vs. normative:\n\nDescriptively, given 100 values \\(v_1, \\ldots, v_{100}\\), their mean may be a good way to summarize, if we have to choose a single number\nBut, normatively, imagine that these are opinions that people hold about fairness.\nNow, if it’s the US South in 1860 and \\(v_i\\) represents person \\(i\\)’s approval of slavery, from a sample of 100 people, then approx. 97 of the \\(v_i\\)’s are “does not disapprove” (Rousey 2001) — in this case, normatively, is the mean \\(0.97\\) the “correct” answer?\n\nWe have another case where, like the “grass is green” vs. “grass ought to be green” example, we cannot just “import” our logical/mathematical tools from the former to solve the latter! (However: this does not mean they are useless! This is the fallacy of the excluded middle, sort of the opposite of the fallacy of the middle ground)\nThis is why we have ethical frameworks in the first place! Going back to Rawls: “97% of Americans think black people shouldn’t have rights”  \\(\\nimplies\\)“black people shouldn’t have rights”, since rights are a primary good"
  },
  {
    "objectID": "w05/slides.html#motivation-linguistic-meaning",
    "href": "w05/slides.html#motivation-linguistic-meaning",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Motivation: Linguistic Meaning",
    "text": "Motivation: Linguistic Meaning\n\n\n\n\n The Distributional Hypothesis (Firth 1968, 179)\n\n\nYou shall know a word by the company it keeps!\n\n\n\n\n\nRelated to Chomsky’s context-free vs. context-sensitive distinction!\nBut why is it relevant to DSAN 5450?…"
  },
  {
    "objectID": "w05/slides.html#the-meaning-of-fairness",
    "href": "w05/slides.html#the-meaning-of-fairness",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The “Meaning” of Fairness",
    "text": "The “Meaning” of Fairness\n\n\n\n\n The Distributional [Fairness] Hypothesis\n\n\nYou shall know “fairness” by the company it keeps [i.e., the context it incorporates].\n\n\n\n\n\nContext-free (confusion-matrix-based) fairness: “plug the confusion matrix values into a formula and see if the formula is satisfied”\nContext-sensitive fairness: analyze fairness relative to a set of antecedents regarding how normative concerns should enter into our measurements of fairness"
  },
  {
    "objectID": "w05/slides.html#group-fairness-rightarrow-individual-fairness",
    "href": "w05/slides.html#group-fairness-rightarrow-individual-fairness",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Group Fairness \\(\\rightarrow\\) Individual Fairness",
    "text": "Group Fairness \\(\\rightarrow\\) Individual Fairness\n\nThe crucial insight of Dwork: group-level fairness does not ensure that individuals are treated fairly as individuals\nExactly the issue we’ve seen with utilitarianism: optimizing society-level “happiness” may lead to individuals being brutally mistreated (e.g., having their rights violated)\nSo, at a high level, Dwork’s proposal could provide a Rawls-style ordering: individual fairness lexically prior to group-level fairness (optimize group-level fairness once individual-level is satisfied)"
  },
  {
    "objectID": "w05/slides.html#the-normative-antecedent",
    "href": "w05/slides.html#the-normative-antecedent",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The (Normative!) Antecedent",
    "text": "The (Normative!) Antecedent\n\n\n\n\nFairness Through Awareness (Dwork et al. 2011)\n\n\nIndividuals who are similar with respect to a task should be classified similarly.\n\n\n\n\n\n\n\n\nNot well-liked in industry / policy because you can’t just “plug in” results of your classifier and get True/False “we satisfied fairness!” …But this is exactly the point!\n\n\n\n\n\n\nFrom Kiat (2018)"
  },
  {
    "objectID": "w05/slides.html#bringing-in-context-1",
    "href": "w05/slides.html#bringing-in-context-1",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Bringing In Context",
    "text": "Bringing In Context\n\nIn itself, the principle of equal treatment is abstract, a formal relationship that lacks substantive content”\nThe principle must be given content by defining which cases are similar and which are different, and by considering what kinds of differences justify differential treatment\nDeciding what differences are relevant, and what kinds of differential treatment are justified by particular differences, requires wrestling with moral and political debates about the responsibilities of different institutions to address persistent injustice (Simons 2023, 51)"
  },
  {
    "objectID": "w05/slides.html#remember-distance-metrics",
    "href": "w05/slides.html#remember-distance-metrics",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Remember Distance Metrics?(!)",
    "text": "Remember Distance Metrics?(!)\n\n\n\n\nA core element in both similarity-based and causal fairness!\nAlready difficult to choose a metric on pragmatic grounds (ambulance needs to get to hospital)\nNow people will also have fundamental normative disagreements about what should and should not determine difference\n\n\n\n\n\n\nFrom Shahid et al. (2009)"
  },
  {
    "objectID": "w05/slides.html#satisfying-individual-vs.-group-fairness",
    "href": "w05/slides.html#satisfying-individual-vs.-group-fairness",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Satisfying Individual vs. Group Fairness",
    "text": "Satisfying Individual vs. Group Fairness\n\nAn algorithm is individually fair if, for all individuals \\(x\\) and \\(y\\), we have\n\\[\n\\textsf{dist}(r(x), r(y)) \\leq \\textsf{dist}(x, y)\n\\]\n\\(\\implies\\) an advertising system must show similar sets of ads to similar users.\nIt achieves group fairness-through-parity for two groups of users \\(S\\) and \\(T\\) when:\n\\[\n\\textsf{dist}(\\mathbb{E}_{s \\in S}[r(s)], \\mathbb{E}_{t \\in T}[r(t)]) \\leq \\varepsilon\n\\]\nwhere \\(\\mathbb{E}_{s \\in S}\\) and \\(\\mathbb{E}_{t \\in T}\\) denote the expectation of ads seen by an individual chosen uniformly among \\(S\\) and \\(T\\). This definition implies that the difference in probability between two groups of seeing a particular ad will be bounded by \\(\\varepsilon\\).\nGiven these definitions: Individual fairness  \\(\\nimplies\\) group fairness, and vice versa! (Riederer and Chaintreau 2017)"
  },
  {
    "objectID": "w05/slides.html#the-importance-of-not-excluding-race",
    "href": "w05/slides.html#the-importance-of-not-excluding-race",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Importance of Not Excluding Race!",
    "text": "The Importance of Not Excluding Race!\n\nOn HW2 you will see how, on the one hand: excluding race from the similarity metric ensures race-blind fairness\nBut, on the other hand: race-blind fairness can not only maintain but also amplify preexisting inequalities\nBy including race in our similarity metric, we can explicitly take this into account!\nEx: someone with a (morally irrelevant) disadvantage due to birth lottery who achieves an SAT score of 1400 is similar to someone with a (morally irrelevant) advantage due to birth lottery who achieves an SAT score of 1500"
  },
  {
    "objectID": "w05/slides.html#equality-of-opportunity",
    "href": "w05/slides.html#equality-of-opportunity",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Equality of Opportunity",
    "text": "Equality of Opportunity\n\n\n\n\nThis notion (last bullet of the previous slide) is contentious, to say the least\nBut also, crucially: our job is not to decide the similarity metric unilaterally!\nThe equality of opportunity approach is not itself a similarity metric!\nIt is a “meta-algorithm” for translating normative positions (consequents of an ethical framework) into concrete fairness constraints that you can then impose on ML algorithms\n\n\n\n\n\n\nRoemer (1998)"
  },
  {
    "objectID": "w05/slides.html#roemers-algorithm",
    "href": "w05/slides.html#roemers-algorithm",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Roemer’s Algorithm",
    "text": "Roemer’s Algorithm\n\nRoughly, the Equality of Opportunity algorithm boils down to:\nInput 1 (!): A set of attributes \\(X_{\\text{advantage}}\\) that a society (real or hypothetical) considers normatively relevant for an outcome, but that people are not individually responsible for (e.g., race or nationality via birth lottery)\nInput 2: A set of attributes \\(X_{\\text{merit}}\\) that a society considers appropriate to hold people individually responsible for (e.g., effort, sacrificing short-term pleasure for longer-term benefits, etc.)\nStep 1: Set of individuals in society \\(S\\) is partitioned into subsets \\(S_i\\), where \\(i\\) is some combination of particular values for the attributes in \\(X_{\\text{advantage}}\\)\nStep 2: Individuals’ context-sensitive scores are computed relative to their group \\(S_i\\), as \\(z\\)-score of their \\(X_{\\text{merit}}\\) value relative to distribution of \\(X_{\\text{merit}}\\) values across \\(S_i\\)\nOutcome: Now that we have incorporated social context, by converting the original context-free units (e.g., numeric SAT score) into context-sensitive units (\\(z\\)-score of numeric SAT score within distribution of comparable individuals), we can compare people across groups on the basis of context-sensitive scores!"
  },
  {
    "objectID": "w05/slides.html#the-state-of-the-art",
    "href": "w05/slides.html#the-state-of-the-art",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The State of the Art!",
    "text": "The State of the Art!\n\nMy view of the current state of fairness in AI: measures which explicitly model causal connections between variables of interest are the most promising for robust notions of fairness\nRobust in the sense of:\n\nBeing normatively desirable (as in, matching the key tenets of our ethical frameworks) while also being\nDescriptively tractable (as in, concretely implementable in math/code, and transparent enough to allow us to evaluate and update these implementations, using a process like reflective equilibrium)."
  },
  {
    "objectID": "w05/slides.html#the-antecedent",
    "href": "w05/slides.html#the-antecedent",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Antecedent",
    "text": "The Antecedent\n\nSince it’s impossible to eliminate information about sensitive attributes like race/gender/etc. from our ML algorithms, fairness should instead be defined on the basis of how this sensitive information “flows” through the causal chain of decisions which lead to an given (observed) outcome"
  },
  {
    "objectID": "w05/slides.html#the-new-object-of-analysis-causal-pathways",
    "href": "w05/slides.html#the-new-object-of-analysis-causal-pathways",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The New Object of Analysis: Causal Pathways",
    "text": "The New Object of Analysis: Causal Pathways\nThe reason this approach is so promising is because, once we have a model of the causal connections among the variables that we care about (socially/normatively), and among the variables that are used by a Machine Learning algorithm, we can then use techniques developed by statisticians who study causal inference to block certain “causal pathways” that we deem normatively unjustifiable while allowing other pathways that we deem to be normatively justifiable."
  },
  {
    "objectID": "w05/slides.html#causal-fairness-in-hw2",
    "href": "w05/slides.html#causal-fairness-in-hw2",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Causal Fairness in HW2",
    "text": "Causal Fairness in HW2\nGiven this, the first subpart of this portion of the assignment will focus specifically on helping you develop intuition around the way of thinking required to make the jump from the correlational approach used in statistics and probability generally (and used in DSAN 5100 specifically!) to the causal approach which builds on the correlational approach but has a stricter standard for determining whether two or more Random Variables are related to one another. Then, in the second subpart, you will take this intuition and use it to evaluate fairness in a real-world setting!"
  },
  {
    "objectID": "w05/slides.html#causal-building-blocks",
    "href": "w05/slides.html#causal-building-blocks",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Causal Building Blocks",
    "text": "Causal Building Blocks\n\nDSAN 5100 precedent: nodes in the network \\(X\\), \\(Y\\) are Random Variables, connections \\(X \\leftrightarrow Y\\) are joint distributions \\(\\Pr(X, Y)\\)\nDirectional edges \\(X \\rightarrow Y\\), then, just represent conditional distributions: \\(X \\rightarrow Y\\) is \\(\\Pr(Y \\mid X)\\)\nWhere we’re going: connections \\(X \\leftrightarrow Y\\) represent unknown but extant causal connections between \\(X\\) and \\(Y\\), while \\(X \\rightarrow Y\\) represents a causal relationship between \\(X\\) and \\(Y\\)\nSpecifically, \\(X \\rightarrow Y\\) now means: an intervention that changes the value of \\(X\\) by \\(\\varepsilon\\) causes a change in the value of \\(Y\\) by \\(f(\\varepsilon)\\)"
  },
  {
    "objectID": "w05/slides.html#the-intuitive-problem-of-causal-inference",
    "href": "w05/slides.html#the-intuitive-problem-of-causal-inference",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Intuitive Problem of Causal Inference",
    "text": "The Intuitive Problem of Causal Inference\n\n\n\n\n\n\n\n\n\n\n\n\n\ncor(ski_df$value, law_df$value)\n\n[1] 0.9921178\n\n\n\n(Based on Spurious Correlations, Tyler Vigen)"
  },
  {
    "objectID": "w05/slides.html#the-fundamental-problem-of-causal-inference",
    "href": "w05/slides.html#the-fundamental-problem-of-causal-inference",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "The Fundamental Problem of Causal Inference",
    "text": "The Fundamental Problem of Causal Inference\nThe only workable definition of “\\(X\\) causes \\(Y\\)”:\n\n\n\n\n Defining Causality\n\n\n\\(X\\) causes \\(Y\\) if and only if:\n\nX temporally precedes \\(Y\\) and\nIn two worlds \\(W_0\\) and \\(W_1\\) where everything is exactly the same except that \\(X = 0\\) in \\(W_0\\) and \\(X = 1\\) in \\(W_1\\), \\(Y = 0\\) in \\(W_0\\) and \\(Y = 1\\) in \\(W_1\\) (Hume 1739)\n\n\n\n\n\n\nThe problem? We live in one world, not two simultaneous worlds 😭"
  },
  {
    "objectID": "w05/slides.html#what-is-to-be-done",
    "href": "w05/slides.html#what-is-to-be-done",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "What Is To Be Done?",
    "text": "What Is To Be Done?"
  },
  {
    "objectID": "w05/slides.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "href": "w05/slides.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm",
    "text": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm\n\nFind good comparison cases: Treatment and Control\nWithout a control group, you cannot make inferences!\nSelecting on the dependent variable…"
  },
  {
    "objectID": "w05/slides.html#selecting-on-the-dependent-variable",
    "href": "w05/slides.html#selecting-on-the-dependent-variable",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Selecting on the Dependent Variable",
    "text": "Selecting on the Dependent Variable\n\nWhat “““research”“” “““says”“” about identifying people who might commit mass shootings\nJeff’s rant: If you care about actually solving social issues, this should infuriate you"
  },
  {
    "objectID": "w05/slides.html#complications-selection",
    "href": "w05/slides.html#complications-selection",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Complications: Selection",
    "text": "Complications: Selection\n\nTldr: Why did this person (unit) end up in the treatment group? Why did this other person (unit) end up in the control group?\nAre there systematic differences?\nVietnam/Indochina Draft: Why can’t we just study [men who join the military] versus [men who don’t], and take the difference as a causal estimate?"
  },
  {
    "objectID": "w05/slides.html#complications-compliance",
    "href": "w05/slides.html#complications-compliance",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Complications: Compliance",
    "text": "Complications: Compliance\n\nWe ideally want people assigned to the treatment to take the treatment, and people assigned to the control to take the control.\n“Compliance”: degree to which this is true in experiment\n\nHigh compliance = most people actually took what they were assigned\nLow compliance = lots of people who were assigned to treatment actually took control, and vice-versa\n\nWhat problems might exist w.r.t compliance in the Draft example?"
  },
  {
    "objectID": "w05/slides.html#next-week-and-hw2-experimental-rightarrow-observational-data",
    "href": "w05/slides.html#next-week-and-hw2-experimental-rightarrow-observational-data",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "Next Week and HW2: Experimental \\(\\rightarrow\\) Observational Data",
    "text": "Next Week and HW2: Experimental \\(\\rightarrow\\) Observational Data\n\nIn observational studies, researchers have no control over assignment to treatment/control 😨\nOn the one hand… Forget Everything And Run [to randomized, controlled experiments], if you can.\nOn the other hand… statisticians over the last ~4 centuries have developed fancy causal inference tools/techniques to help us Face Everything And Rise 🧐"
  },
  {
    "objectID": "w05/slides.html#for-now-matching",
    "href": "w05/slides.html#for-now-matching",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "For Now: Matching",
    "text": "For Now: Matching\n\nIn a randomized, controlled experiment, we can ensure (since we have control over the assignment mechanism) that the only systematic difference between \\(C\\) and \\(T\\) is that \\(T\\) received the treatment and \\(C\\) did not\nIn an observational study, we “show up too late”!\nThus, we no longer refer to assignment but to selection\nAnd, our job is to figure out (reverse engineer!) the selection mechanism, then correct for its non-randomness: basically, we “transform” from observational to experimental setting through weighting"
  },
  {
    "objectID": "w05/slides.html#references",
    "href": "w05/slides.html#references",
    "title": "Week 5: Context-Sensitive Fairness",
    "section": "References",
    "text": "References\n\n\nDwork, Cynthia, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Rich Zemel. 2011. “Fairness Through Awareness.” arXiv. https://doi.org/10.48550/arXiv.1104.3913.\n\n\nFirth, John Rupert. 1968. Selected Papers of J.R. Firth, 1952-59. Longmans.\n\n\nHume, David. 1739. A Treatise of Human Nature: Being an Attempt to Introduce the Experimental Method of Reasoning Into Moral Subjects; and Dialogues Concerning Natural Religion. Longmans, Green.\n\n\nKiat, Lim Swee. 2018. “Machines Gone Wrong.” PhD thesis, Singapore University of Technology; Design. https://machinesgonewrong.com/about/.\n\n\nRiederer, Christopher, and Augustin Chaintreau. 2017. “The Price of Fairness in Location Based Advertising.” Fairness, Accountability, and Transparency Workshop on Responsible Recommendation. https://doi.org/10.18122/B2MD8C.\n\n\nRoemer, John E. 1998. Equality of Opportunity. Harvard University Press.\n\n\nRousey, Dennis C. 2001. “Friends and Foes of Slavery: Foreigners and Northerners in the Old South.” Journal of Social History 35 (2): 373–96. https://www.jstor.org/stable/3790193.\n\n\nShahid, Rizwan, Stefania Bertazzon, Merril L. Knudtson, and William A. Ghali. 2009. “Comparison of Distance Measures in Spatial Analytical Modeling for Health Service Planning.” BMC Health Services Research 9 (1): 200. https://doi.org/10.1186/1472-6963-9-200.\n\n\nSimons, Josh. 2023. Algorithms for the People: Democracy in the Age of AI. Princeton University Press.\n\n\n\n\n\nDSAN 5450 Week 5: Context-Sensitive Fairness"
  },
  {
    "objectID": "recordings/index.html",
    "href": "recordings/index.html",
    "title": "Lecture Recordings",
    "section": "",
    "text": "Week\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\n5\n\n\nWeek 5: Context-Sensitive Fairness\n\n\nWednesday Feb 14, 2024\n\n\n\n\n4\n\n\nWeek 4: Fairness in AI\n\n\nTuesday Feb 6, 2024\n\n\n\n\n3\n\n\nWeek 3: (Descriptive) Fairness in AI\n\n\nWednesday Jan 31, 2024\n\n\n\n\n2\n\n\nWeek 2: Machine Learning, Training Data, and Bias\n\n\nWednesday Jan 24, 2024\n\n\n\n\n1\n\n\nWeek 1: Introduction to the Course\n\n\nWednesday Jan 17, 2024\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Recordings"
    ]
  },
  {
    "objectID": "writeups/w03.html",
    "href": "writeups/w03.html",
    "title": "Week 3 Resources / Loose-Thread Tying",
    "section": "",
    "text": "Hi all! As has become my tradition, I am writing this as a “wrap-up” of loose threads that I felt were left un-tied at the end of lecture on Wednesday. This week, right after class ended, I did a deeper dive into the Sapir-Whorf Hypothesis, to try to (a) clarify the discussion we had around Sapir-Whorf vs. Linguistic Relativism and Linguistic Determinism, and (b) tie it back into the main course topics! But first, the stuff-I-googled portion:"
  },
  {
    "objectID": "writeups/w03.html#things-i-googled-opened-during-class",
    "href": "writeups/w03.html#things-i-googled-opened-during-class",
    "title": "Week 3 Resources / Loose-Thread Tying",
    "section": "1. Things I Googled / Opened During Class",
    "text": "1. Things I Googled / Opened During Class\n\nExcavating AI: The Politics of Images in Machine Learning Training Sets: Crawford and Paglen (2019)\nDecoding the Thought Vector, from Gabriel Goh’s Blog: Machine Learning, Data Science, and Optimization"
  },
  {
    "objectID": "writeups/w03.html#linguistic-relativism-linguistic-determinism-and-the-sapir-whorf-hypothesis",
    "href": "writeups/w03.html#linguistic-relativism-linguistic-determinism-and-the-sapir-whorf-hypothesis",
    "title": "Week 3 Resources / Loose-Thread Tying",
    "section": "2. Linguistic Relativism, Linguistic Determinism, and the Sapir-Whorf Hypothesis",
    "text": "2. Linguistic Relativism, Linguistic Determinism, and the Sapir-Whorf Hypothesis\nHonestly, this question simmered in my brain from the minute it came up until the end of class! So, from the time class ended up until now, I went back and re-read two of the four books that had put these concepts into my brain in the first place. The two I read were:\n\nMarcel Danesi (2021), Linguistic Relativity Today: Language, Mind, Society, and the Foundations of Linguistic Anthropology (Danesi 2021) [PDF; this one is particularly difficult and expensive to obtain a hard copy of!]\nJohn McWhorter (2014), The Language Hoax: Why the World Looks the Same in Any Language (McWhorter 2014): This one I did explicitly mention in class and put it on the slides [EPUB]\n\nWhile the two I didn’t re-read, but did impact my brain at some earlier point, were:\n\nSteven Pinker (2005), The Stuff of Thought: Language as a Window into Human Nature (Pinker 2005) [EPUB]\nGeorge Lakoff (1987), Women, Fire, and Dangerous Things: What Categories Reveal about the Mind (Lakoff 1987) [PDF]\n\nBesides the time factor, the reason I only re-read the first two is because: (a) I remember feeling like the Pinker book was overly dismissive of the whole idea; as in, I don’t feel like it gave a very “fair trial” to the nuances of the degrees to which language and thought affect one another. And (b) Lakoff’s books are… I feel like I should like them, the specific topics he looks at are fascinating and relevant and important imo, but then when I actually open them up and read them I often feel like the writing is a bit dry and monotonous1.\nAnd, my followup thought on this is: I was too dismissive of the Sapir-Whorf Hypothesis! One of the reasons I settled on the Danesi book at spot #1 is because, I think it does a really good job of separating the strong and weak forms of this hypothesis, and it matches 100% with how Cynthia summarized it in class! So, I hereby delegate Cynthia as the class consultant for language in data ethics and society 😎. The summary I can come up with, trying to synthesize what Cynthia said and how it’s described in the Danesi book, is that:\n\nLinguistic Determinism, or the Strong Sapir-Whorf Hypothesis, posits that “language determines how people think” (Danesi 2021, x), whereas\nLinguistic Relativism, or the Weak Sapir-Whorf Hypothesis, posits that language shapes (without determining) how people think.\n\nBasically, the Danesi book’s preface mentions the strong version but quickly dismisses it: “From the relevant studies, there is little support for the so-called ‘strong’ version” (Danesi 2021, x). The first chapter then goes in-depth into the weak version, in a really fascinating way.\nI was taking the term “Sapir-Whorf Hypothesis” in general and conflating it with the strong version, and that’s where my criticism was coming from. I should have phrased what I was saying as: the strong Sapir-Whorf Hypothesis can be problematic, from my perspective, given the implications that could come from believing it to be true when it isn’t.\nIn its strong form, for example, it strikes me as alarmingly reminiscent of Samuel Huntington’s Clash of Civilizations hypothesis (and the many similar and similarly-influential global-cultural claims), which have the effect of telling policymakers something like “we’ll never be able to bridge the humongous gap between ‘Eastern’ and ‘Western’ cultures, so they’ll just have to eternally clash with one another, and uh, I hope ‘we’ win!”\nThis is the kind of danger that, in my reading, McWhorter is warning about in the Language Hoax book whose cover was in my slides: just that, we have to be very careful when talking about concepts as fuzzy and hard-to-define as “a culture” or “a language” since, despite their vagueness in theory, they can become reified and morph into dehumanizing claims and then entire books about e.g. the “Arab mind”, and then these kinds of books can hypothetically become “the basis of” one’s “cultural instruction” in the US Army, with predictable consequences…\n\n“At the institution where I teach military officers,”” as retired U.S. Army Col. Norvell De Atkine writes in the book’s foreword, “The Arab Mind forms the basis of my cultural instruction.” (from Slate, “Inside The Arab Mind: What’s wrong with the White House’s book on Arab nationalism”)\n\nWith that said, I don’t think there’s anything in Whorf’s original description of the idea that lends itself to this kind of cultural essentialism! I think the following quote from Whorf, quoted at the beginning of the Danesi book, makes the distinction really clear:\n\nWe are thus introduced to a new principle of relativity, which holds that all observers are not led by the same physical evidence to the same picture of the universe, unless their linguistic backgrounds are similar, or can in some way be calibrated. (Whorf 1956, 229)\n\nBasically, this quote is how I’ll remember Sapir-Whorf as linguistic relativism, rather than determinism, from now on!"
  },
  {
    "objectID": "writeups/w03.html#mental-math-speed-as-an-example-of-weak-sapir-whorf",
    "href": "writeups/w03.html#mental-math-speed-as-an-example-of-weak-sapir-whorf",
    "title": "Week 3 Resources / Loose-Thread Tying",
    "section": "3. Mental Math Speed as an Example of Weak Sapir-Whorf",
    "text": "3. Mental Math Speed as an Example of Weak Sapir-Whorf\nThe example that came up during that same discussion—where Keqin helped a ton by pointing out the syllabic differences in mathematical symbols/terms between different languages!—I think was first implanted in my brain by a 2014 article from the Wall Street Journal, “The Best Language for Math: Confusing English Number Words Are Linked to Weaker Skills” (Shellenbarger 2014), that went 2014-style viral, or at least viral among… cross-cultural linguistics nerds?\nI tried to find the presentation (or at least the paper) about the cross-cultural mental math experiments that I went to while I was at the Santa Fe Institute, but I wasn’t able to track it down. And, I found it surprisingly difficult to find actual scientific studies of it more generally2. However, I did find a super-interesting deep-dive into aspects of the original Wall Street Journal article, and an even more super-interesting book:\n\nBarbara M. Birch and Sean Fulop (2021), English L2 Reading: Getting to the Bottom (4th Edition) (Birch and Fulop 2021) [PDF]\n\nwhich goes into an awesome amount of analytic detail about second-language learning. It even has a neural network diagram right in the first chapter, which is how I knew I had to read it 🤓:\n\n\n\n\n\nFor our purposes, though, the two most interesting parts of that book come at the end of Chatper 2 and then… the entirety of Chapter 3, which is on “Interlanguage Reading and Transfer”. As a segue into this chapter, which contains a bunch of material on studies of mental math, the end of Chapter 2 presents the following as its fourth “Discussion Question”, which I wanted to copy here as a “food for thought” exercise for you, having had our discussion around mental math and language!\n\n\n\n\n\n\nMental Math Discussion Question (Birch and Fulop 2021, 50–51)\n\n\n\nThis quote comes from Tzeng and Hung (1981): “Miller … has pointed out the importance of notational design in the history of mathematics. In Miller’s words (1957) ‘In order to study the interaction of thought and symbol it is not necessary to travel with Whorf to the Zuni Indians; the language of mathematics is rich with excellent examples. Why are Arabic numbers so superior to Roman?’” (p. 238).\nIn that spirit, compare these different representations of the same meaning concept (the number seven): 7, seven, vii. Which type of writing does each correspond to? (If 7 and vii are both logographic, what is the difference between them?) What are the advantages and disadvantages of each type of number? Do you agree that the history of mathematics has been affected by the type of notations developed? Could mathematics have advanced without the symbols like 7?\nCould language and culture be similarly affected by the writing systems that evolved in different civilizations? Logan (1986) argues that alphabetic writing was related to the growth of theoretical science in Western civilization and not in Eastern: “The effects of the alphabet and the abstract, logical, systematic thought that it encouraged explain why science began in the West and not in the East, despite the much greater technological sophistication of the Chinese […] the inventors of metallurgy, irrigation systems, animal harnesses, paper, ink” (p. 23).\n\n\nThen, the section of Chapter 3 with the title “Writing Systems and Transfer” contains the “meat” of the question, with references to individual studies you can read for a true deep-dive (including a study that very specifically looks at Hong Kong ESL learners! For those interested: (Yeung, Siegel, and Chan 2013)).\nI’m copying that section of the chapter in full below, so that you have the previous “discussion question” and this section all in one place, and you don’t have to worry about going and obtaining the full book if you don’t want to! (This one is collasped by default, to make the page look less scarily-long)\n\n\n\n\n\n\nWriting Systems and Transfer (Birch and Fulop 2021, 63–65)\n\n\n\n\n\nWriting Systems and Transfer\nOne question that researchers have tried to answer is whether logograms like Chinese characters or Japanese kanji are read holistically or not. There was early evidence for this idea because reading logograms was more like processing pictures than reading (Henderson 1982, 196). Morton and Sasanuma (1984) concluded that for Japanese writing, although the kana were read analytically, the kanji were read holistically. To them, there seems to be “a strong dissociation between the processes involved in reading the two scripts [kana vs. kanji]” (p. 40). However, Leong and Tamaoka (1995) argued that both visual and phonological processing occur in accessing difficult kanji with phonetic elements.\n\n\n\n\n\n\nReading Logograms\nKoda (1995) explained how both holistic and phonological processing are involved in reading logograms. Koda suggested that all writing systems require readers to access phonological information because working memory is better for phonological material than for visual material. However, the timing of the phonological access is different. Alphabetic writing requires access to a phonological representation prior to or at the time that the word is retrieved from memory. A logographic code requires phonological access only after the word is retrieved because that is the time when phonological information becomes available to the reader, as shown in Figure 3.1. It is, in fact, impossible to pronounce an unknown character because often the phonetic cues are not enough. Logograms may also be read without access to sound, as in mental math calculations, where thinking of the name of the number symbol slows down the process. This evidence supports the claim that readers use different linguistic strategies to handle logograms (holism) vs. alphabetic words (analysis) but that the universal phonological principle does hold.\nTan et al. (2003) studied intermediate Chinese/English graduate students who began learning English after the age of 12, comparing them with a group of English monolinguals. They found that phonological processing of Chinese characters activates portions of the brain that process spatial information. The activation of this system was related to the square configuration of the character, which then maps onto a monosyllabic unit of speech. When the Chinese students performed a phonological task on English words, they activated the very same visual processing system, unlike the brain areas activated by the English monolinguals when they performed phonemic analyses.\nTan et al. (2003) thought that their Chinese subjects were trying to use their L1 system to read in English. Since they lacked the infrastructure for English, they could not process the alphabetic writing system like the English readers did. In other words, the Chinese graduate students were not taking advantage of the alphabetic writing. However, little is known about their background as language learners. Yeung, Siegel, and Chan (2013, 699) found that if Chinese-speaking children gained in phonological awareness, their reading also improved. They suggested that “once children acquire phoneme awareness, even without explicit instruction in letter-sound correspondences, they change the reading strategy and readily apply the phoneme awareness to aid word recognition.”\nKoda (1995) studied Japanese, Arabic, Spanish, and English readers of English and found that symbols that had no phonological cues and unpronounceable words interfered less with the Japanese readers than with the alphabetic readers. Unpronounceable words interfere with English reading because of the difficulty they pose for phonological analysis. English readers stumble over the unpronounceable foreign names in a novel like War and Peace. They try to process them holistically by remembering the appearance of the name and associating it with a certain character. Or they try a laborious analytical strategy of sounding out the names and remembering them by sound. Either way, they are obstacles for reading.\nHowever, unpronounceable words did not cause difficulty for the Japanese readers that Koda (1995) studied because they treated the problem words as they did kanji. They did not try to pronounce them; they tried to remember them visually. Also, English reading comprehension among Japanese college students was unaffected by the unpronounceability of English words, suggesting a strategy of relying little on phonological information in reading the unknown words. The strategy these Japanese students were applying to unknown English words was holistic, visual, and meaning-based, discarding the very strengths of the alphabetic writing system with its cues to sound. The short-term strategy of treating unfamiliar words as logograms may assist English beginning readers at first, but over time, it is more efficient to decode unknown words and assign a pronunciation to them. In short, there is evidence for transfer of processing strategies from L1 to L2 if the writing systems have some similarity such as Chinese characters, Japanese kanji, and symbols or unpronounceable words. This is facilitation, but it may only offer a short-term benefit"
  },
  {
    "objectID": "writeups/w03.html#footnotes",
    "href": "writeups/w03.html#footnotes",
    "title": "Week 3 Resources / Loose-Thread Tying",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI’m mostly thinking of his book with Mark Johnson here which I read more recently, Metaphors We Live By (Lakoff and Johnson 1980), so maybe the newer one is more interesting and I’m being unfair here, but yeah limited resources, I wanted to be able to read at least one full book between end-of-class and this writeup!↩︎\nIf you try searching for it by googling something like \"mental math\" \"speed\" \"mandarin\" \"english\" however, you will find lots of fun videos and books about 史丰收 / Shi Fengshou, who created a very fun-to-watch mental math technique involving rapid hand gestures!↩︎"
  },
  {
    "objectID": "writeups/pgm-intro/index.html",
    "href": "writeups/pgm-intro/index.html",
    "title": "A Quick Introduction to Probabilistic Graphical Models",
    "section": "",
    "text": "A Probabilistic Graphical Model (PGM) is just a formal mathematical representation of a data-generating process. So, if we wanted to model the relationship between weather and a person’s choice of whether to go out and party or stay in and watch a movie on a given Saturday evening, we could begin by proposing the following data-generating process:\nNow, given the description of a PGM given above (nodes as variables, edges as relationships between variables), we can perform the move alluded to in the previous section: we can convert our data-generating process into a PGM, by defining nodes (variables) and edges (relationships) as follows:\nThe resulting PGM, in graphical form1, is presented below, followed by the Conditional Probability Table describing the edge from the \\(W\\) node to the \\(Y\\) node.\nPGMs can help us make inferences about the world in the face of incomplete information, which is the situation in nearly every real-world problem. The key tool here is the separation of nodes into two categories: observed (represented graphically as a shaded node) and latent (represented graphically as an unshaded node).\nThus we can now use our model as a weather-inference machine: if we observe that the person we’re modeling is out at a party with us, what can we infer from this information about the weather outside? We can draw this situation as a PGM with shaded and unshaded nodes, as in the figure below, and then use Bayes’ Rule to perform calculations over the network, to see how the observed information about the person at the party “flows” back into the node representing the weather.\nKeeping in mind that Bayes’ Rule tells us, for any two events \\(A\\) and \\(B\\), how to use information about \\(\\Pr(B \\mid A)\\) to obtain information about \\(\\Pr(A \\mid B)\\):\n\\[\n\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)},\n\\]\nWe can now apply this rule to obtain our new probability distribution over the weather, taking into account the new information that the person has chosen to go out:\n\\[\n\\begin{align*}\n&\\Pr(W = \\textsf{Sunny} \\mid Y = \\textsf{Go Out})\n= \\frac{\\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Sunny})}{\\Pr(Y = \\textsf{Go Out})} \\\\\n= &\\frac{\\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Sunny})}{\\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Sunny}) + \\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Rainy})}\n\\end{align*}\n\\]\nAnd now we simply plug in the information we already have from our conditional probability table to obtain our new (conditional) probability of interest:\n\\[\n\\begin{align*}\n\\Pr(W = \\textsf{Sunny} \\mid Y = \\textsf{Go Out}) &= \\frac{(0.8)(0.5)}{(0.8)(0.5) + (0.1)(0.5)} \\\\\n&= \\frac{0.4}{0.4 + 0.05} = \\frac{0.4}{0.45} \\approx 0.89.\n\\end{align*}\n\\]\nWe have learned something interesting: now that we’ve observed the person out at a party, the probability that it is sunny out jumps from \\(0.5\\) (called the “prior” estimate of \\(W\\), i.e., our best guess without any other relevant information) to \\(0.89\\) (called the “posterior” estimate of \\(W\\), i.e., our best guess after incorporating relevant information)."
  },
  {
    "objectID": "writeups/pgm-intro/index.html#footnotes",
    "href": "writeups/pgm-intro/index.html#footnotes",
    "title": "A Quick Introduction to Probabilistic Graphical Models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe term “Graphical” in Probabilistic Graphical Model is not used in the same sense as the “graphical” we’re used to from vernacular English. Capital-G Graphical denotes that the Probabilistic Model is represented as a Graph, a well-defined mathematical object consisting of nodes and edges, which does not have to be represented graphically (though it could be, like in our example here with circles and arrows). In fact, when a computer program is estimating a PGM, it is by definition not in a graphical form—it’s in the form of 0s and 1s, stored in the computer’s memory.↩︎"
  },
  {
    "objectID": "w06/index.html",
    "href": "w06/index.html",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#dgps-and-the-emergence-of-order",
    "href": "w06/index.html#dgps-and-the-emergence-of-order",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "DGPs and the Emergence of Order",
    "text": "DGPs and the Emergence of Order\n\n\n\n\n\n\n\nWho (besides Aaron) can guess the state of this process after 10 steps, with 1 person?\n10 people? 50? 100? (If they find themselves on the same spot, they stand on each other’s heads)\n100 steps? 1000?",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#the-result-16-steps",
    "href": "w06/index.html#the-result-16-steps",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Result: 16 Steps",
    "text": "The Result: 16 Steps\n\n\nCode\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(ggExtra)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(tidyr)\n# From McElreath!\ngen_histo &lt;- function(reps, num_steps) {\n  support &lt;- c(-1,1)\n  pos &lt;-replicate(reps, sum(sample(support,num_steps,replace=TRUE,prob=c(0.5,0.5))))\n  #print(mean(pos))\n  #print(var(pos))\n  pos_df &lt;- tibble(x=pos)\n  clt_distr &lt;- function(x) dnorm(x, 0, sqrt(num_steps))\n  plot &lt;- ggplot(pos_df, aes(x=x)) +\n    geom_histogram(aes(y = after_stat(density)), fill=cbPalette[1], binwidth = 2) +\n    stat_function(fun = clt_distr) +\n    dsan_theme(\"quarter\") +\n    theme(title=element_text(size=16)) +\n    labs(\n      title=paste0(reps,\" Random Walks, \",num_steps,\" Steps\")\n    )\n  return(plot)\n}\ngen_walkplot &lt;- function(num_people, num_steps, opacity=0.15) {\n  support &lt;- c(-1, 1)\n  # Unique id for each person\n  pid &lt;- seq(1, num_people)\n  pid_tib &lt;- tibble(pid)\n  pos_df &lt;- tibble()\n  end_df &lt;- tibble()\n  all_steps &lt;- t(replicate(num_people, sample(support, num_steps, replace = TRUE, prob = c(0.5, 0.5))))\n  csums &lt;- t(apply(all_steps, 1, cumsum))\n  csums &lt;- cbind(0, csums)\n  # Last col is the ending positions\n  ending_pos &lt;- csums[, dim(csums)[2]]\n  end_tib &lt;- tibble(pid = seq(1, num_people), endpos = ending_pos, x = num_steps)\n  # Now convert to tibble\n  ctib &lt;- as_tibble(csums, name_repair = \"none\")\n  merged_tib &lt;- bind_cols(pid_tib, ctib)\n  long_tib &lt;- merged_tib %&gt;% pivot_longer(!pid)\n  # Convert name -&gt; step_num\n  long_tib &lt;- long_tib %&gt;% mutate(step_num = strtoi(gsub(\"V\", \"\", name)) - 1)\n  # print(end_df)\n  grid_color &lt;- rgb(0, 0, 0, 0.1)\n\n  # And plot!\n  walkplot &lt;- ggplot(\n      long_tib,\n      aes(\n          x = step_num,\n          y = value,\n          group = pid,\n          # color=factor(label)\n      )\n  ) +\n      geom_line(linewidth = g_linesize, alpha = opacity, color = cbPalette[1]) +\n      geom_point(data = end_tib, aes(x = x, y = endpos), alpha = 0) +\n      scale_x_continuous(breaks = seq(0, num_steps, num_steps / 4)) +\n      scale_y_continuous(breaks = seq(-20, 20, 10)) +\n      dsan_theme(\"quarter\") +\n      theme(\n          legend.position = \"none\",\n          title = element_text(size = 16)\n      ) +\n      theme(\n          panel.grid.major.y = element_line(color = grid_color, linewidth = 1, linetype = 1)\n      ) +\n      labs(\n          title = paste0(num_people, \" Random Walks, \", num_steps, \" Steps\"),\n          x = \"Number of Steps\",\n          y = \"Position\"\n      )\n}\nwp1 &lt;- gen_walkplot(500, 16, 0.05)\n\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n\nCode\nggMarginal(wp1, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#the-result-64-steps",
    "href": "w06/index.html#the-result-64-steps",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Result: 64 Steps",
    "text": "The Result: 64 Steps\n\n\nCode\nlibrary(ggExtra)\nwp2 &lt;- gen_walkplot(5000,64,0.008) +\n  ylim(-30,30)\n\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\n\n\nCode\nggMarginal(wp2, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#mathematicalscientific-modeling",
    "href": "w06/index.html#mathematicalscientific-modeling",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "“Mathematical/Scientific Modeling”",
    "text": "“Mathematical/Scientific Modeling”\n\nThing we observe (poking out of water): data\nHidden but possibly discoverable through deeper investigation (ecosystem under surface): model / DGP",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#so-whats-the-problem",
    "href": "w06/index.html#so-whats-the-problem",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "So What’s the Problem?",
    "text": "So What’s the Problem?\n\nNon-probabilistic models: High potential for being garbage (see: Bayesianism)\nProbabilistic models: Getting there, still “surface” phenomena\n\nOf the \\(N = 100\\) times we observed event \\(X\\) occurring, event \\(Y\\) also occurred \\(90\\) of those times\n\\(\\implies \\Pr(Y \\mid X) = \\frac{\\#[X, Y]}{\\#[X]} = \\frac{90}{100} = 0.9\\)\n\nCausal models: Does \\(Y\\) happen because of \\(X\\) happening? For that, need to start modeling what’s happening under the surface that make \\(X\\) and \\(Y\\) “pop up” together so often",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#the-intuitive-problem-of-inferring-causality",
    "href": "w06/index.html#the-intuitive-problem-of-inferring-causality",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Intuitive Problem of Inferring Causality",
    "text": "The Intuitive Problem of Inferring Causality\n\n\n\nsource(\"../_globals.r\")\nlibrary(dplyr)\nlibrary(ggplot2)\nga_lawyers &lt;- c(21362, 22254, 23134, 23698, 24367, 24930, 25632, 26459, 27227, 27457)\nski_df &lt;- tibble::tribble(\n  ~year, ~varname, ~value,\n  2000, \"ski_revenue\", 1551,\n  2001, \"ski_revenue\", 1635,\n  2002, \"ski_revenue\", 1801,\n  2003, \"ski_revenue\", 1827,\n  2004, \"ski_revenue\", 1956,\n  2005, \"ski_revenue\", 1989,\n  2006, \"ski_revenue\", 2178,\n  2007, \"ski_revenue\", 2257,\n  2008, \"ski_revenue\", 2476,\n  2009, \"ski_revenue\", 2438,\n)\nski_mean &lt;- mean(ski_df$value)\nski_sd &lt;- sd(ski_df$value)\nski_df &lt;- ski_df %&gt;% mutate(val_scaled = 12*value, val_norm = (value - ski_mean)/ski_sd)\nlaw_df &lt;- tibble::tibble(year=2000:2009, varname=\"ga_lawyers\", value=ga_lawyers)\nlaw_mean &lt;- mean(law_df$value)\nlaw_sd &lt;- sd(law_df$value)\nlaw_df &lt;- law_df %&gt;% mutate(val_norm = (value - law_mean)/law_sd)\nspur_df &lt;- dplyr::bind_rows(ski_df, law_df)\nggplot(spur_df, aes(x=year, y=val_norm, color=factor(varname, labels = c(\"Ski Revenue\",\"Lawyers in Georgia\")))) +\n  stat_smooth(method=\"loess\", se=FALSE) +\n  geom_point(size=g_pointsize/1.5) +\n  labs(\n    fill=\"\",\n    title=\"Ski Revenue vs. Georgia Lawyers\",\n    x=\"Year\",\n    color=\"Correlation: 99.2%\",\n    linetype=NULL\n  ) +\n  dsan_theme(\"custom\", 18) +\n  scale_x_continuous(\n    breaks=seq(from=2000, to=2014, by=2)\n  ) +\n  #scale_y_continuous(\n  #  name=\"Total Revenue, Ski Facilities (Million USD)\",\n  #  sec.axis = sec_axis(~ . * law_sd + law_mean, name = \"Number of Lawyers in Georgia\")\n  #) +\n  scale_y_continuous(breaks = -1:1,\n    labels = ~ . * round(ski_sd,1) + round(ski_mean,1),\n    name=\"Total Revenue, Ski Facilities (Million USD)\",\n    sec.axis = sec_axis(~ . * law_sd + law_mean, name = \"Number of Lawyers in Georgia\")) +\n  expand_limits(x=2010) +\n  #geom_hline(aes(yintercept=x, color=\"Mean Values\"), as.data.frame(list(x=0)), linewidth=0.75, alpha=1.0, show.legend = TRUE) +\n  scale_color_manual(\n    breaks=c('Ski Revenue', 'Lawyers in Georgia'),\n    values=c('Ski Revenue'=cbPalette[1], 'Lawyers in Georgia'=cbPalette[2]))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\ncor(ski_df$value, law_df$value)\n\n[1] 0.9921178\n\n\n\n(Based on Spurious Correlations, Tyler Vigen)\n\n\nThis, however, is only a mini-boss. Beyond it lies the truly invincible FINAL BOSS… 🙀",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#the-fundamental-problem-of-causal-inference",
    "href": "w06/index.html#the-fundamental-problem-of-causal-inference",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Fundamental Problem of Causal Inference",
    "text": "The Fundamental Problem of Causal Inference\nThe only workable definition of “\\(X\\) causes \\(Y\\)”:\n\n\n\n\n\n\n Defining Causality\n\n\n\n\\(X\\) causes \\(Y\\) if and only if:\n\n\\(X\\) temporally precedes \\(Y\\) and\n\nIn two worlds \\(W_0\\) and \\(W_1\\) where\neverything is exactly the same except that \\(X = 0\\) in \\(W_0\\) and \\(X = 1\\) in \\(W_1\\),\n\\(Y = 0\\) in \\(W_0\\) and \\(Y = 1\\) in \\(W_1\\).\n\n\n(Hume 1739, ruining everything as usual 😤)\n\n\n\nThe problem? We live in one world, not two identical worlds simultaneously 😭",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#what-is-to-be-done",
    "href": "w06/index.html#what-is-to-be-done",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "What Is To Be Done?",
    "text": "What Is To Be Done?",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "href": "w06/index.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm",
    "text": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm\n\nFind good comparison cases: Treatment and Control\nWithout a control group, you cannot make inferences!\nSelecting on the dependent variable…",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#selecting-on-the-dependent-variable",
    "href": "w06/index.html#selecting-on-the-dependent-variable",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Selecting on the Dependent Variable",
    "text": "Selecting on the Dependent Variable\n\n\n\nWhat “““research”“” “““says”“” about identifying people who might commit mass shootings\n\n\n\nJeff’s rant: If you care about actually solving social issues, this should infuriate you",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#complications-selection",
    "href": "w06/index.html#complications-selection",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Complications: Selection",
    "text": "Complications: Selection\n\nTldr: Why did this person (unit) end up in the treatment group? Why did this other person (unit) end up in the control group?\nAre there systematic differences?\n“““Vietnam”“” “““War”“” Draft: Why can’t we just study [men who join the military] versus [men who don’t], and take the difference as a causal estimate?",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#the-solution-matching",
    "href": "w06/index.html#the-solution-matching",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Solution: Matching",
    "text": "The Solution: Matching\n\nControlled experiment: we can ensure (since we have control over the assignment mechanism) the only systematic difference between \\(C\\) and \\(T\\) is: \\(T\\) received treatment, \\(C\\) did not\nIn an observational study, we’re “too late”! Thus, we no longer refer to assignment but to selection\nOur job is to figure out (reverse engineer!) the selection mechanism, then correct for its non-randomness. Spoiler: “transform” observational \\(\\rightarrow\\) experimental via weighting.\nThat’s the gold at end of rainbow. The rainbow itself is…",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#our-data-generating-process",
    "href": "w06/index.html#our-data-generating-process",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Our Data-Generating Process",
    "text": "Our Data-Generating Process\n\n\\(Y\\): Future success, \\(\\mathcal{R}_Y = \\{0, 1\\}\\)\n\\(E\\): Private school education, \\(\\mathcal{R}_E = \\{0, 1\\}\\)\n\\(V\\): Born into poverty, \\(\\mathcal{R}_V = \\{0, 1\\}\\)\n\n\n\n\n\n\n\nThe Private School \\(\\leadsto\\) Success Pipeline 🤑\n\n\n\n\nSample independent RVs \\(U_1 \\sim \\mathcal{B}(1/2)\\), \\(U_2 \\sim \\mathcal{B}(1/3)\\), \\(U_3 \\sim \\mathcal{B}(1/3)\\)\n\\(V \\leftarrow U_1\\)\n\\(E \\leftarrow \\textsf{if }(V = 1)\\textsf{ then } 0\\textsf{ else }U_2\\)\n\\(Y \\leftarrow \\textsf{if }(V = 1)\\textsf{ then }0\\textsf{ else }U_3\\)",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#chalkboard-time",
    "href": "w06/index.html#chalkboard-time",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Chalkboard Time…",
    "text": "Chalkboard Time…\n\n\\(\\Pr(Y = 1) = \\; ?\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\; ?\\)",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#top-secret-answers-slide-dont-peek",
    "href": "w06/index.html#top-secret-answers-slide-dont-peek",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Top Secret Answers Slide (Don’t Peek)",
    "text": "Top Secret Answers Slide (Don’t Peek)\n\n\\(\\Pr(Y = 1) = \\frac{1}{6}\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\frac{1}{3}\\)\n\\(\\overset{✅}{\\implies}\\) One out of every three private-school graduates is successful, vs. one out of every six graduates overall\n\\(\\overset{❓}{\\implies}\\) Private school education doubles likelihood of success!\nThe latter is only true if intervening/changing/doing \\(E = 0 \\leadsto E = 1\\) is what moves \\(\\Pr(Y = 1)\\) from \\(\\frac{1}{6}\\) to \\(\\frac{1}{3}\\)!",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#chalkboard-time-2-electric-boogaloo",
    "href": "w06/index.html#chalkboard-time-2-electric-boogaloo",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Chalkboard Time 2: Electric Boogaloo",
    "text": "Chalkboard Time 2: Electric Boogaloo\n\n\\(\\Pr(Y = 1) = \\frac{1}{6}\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\frac{1}{3}\\)\n\\(\\Pr(Y = 1 \\mid \\textsf{do}(E = 1)) = \\; ?\\)\nHere, \\(\\textsf{do}(E = 1)\\) means diving into the DGP below the surface and changing it so that \\(E = 1\\)… Setting \\(E\\) to be \\(1\\)\n\n\n\n\n\n\n\n\\(\\text{DGP}(Y \\mid \\textsf{do}(E = 1))\\)\n\n\n\n\nSample independent RVs \\(U_1 \\sim \\mathcal{B}(1/2)\\), \\(U_2 \\sim \\mathcal{B}(1/3)\\), \\(U_3 \\sim \\mathcal{B}(1/3)\\)\n\\(V \\leftarrow U_1\\)\n\\(E \\leftarrow \\textsf{if }(V = 1)\\textsf{ then } 0\\textsf{ else }U_2\\)\n\\(Y \\leftarrow \\textsf{if }(V = 1)\\textsf{ then }0\\textsf{ else }U_3\\)",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#double-quadruple-secret-answer-slide",
    "href": "w06/index.html#double-quadruple-secret-answer-slide",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Double Quadruple Secret Answer Slide",
    "text": "Double Quadruple Secret Answer Slide\n\n\\(\\Pr(Y = 1) = \\frac{1}{6}\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\frac{1}{3}\\)\n\\(\\Pr(Y = 1 \\mid \\textsf{do}(E = 1)) = \\frac{1}{6}\\)",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/index.html#references",
    "href": "w06/index.html#references",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "References",
    "text": "References\n\n\nHume, David. 1739. A Treatise of Human Nature: Being an Attempt to Introduce the Experimental Method of Reasoning Into Moral Subjects; and Dialogues Concerning Natural Religion. Longmans, Green.",
    "crumbs": [
      "Week 6: {{< var w06.date-md >}}"
    ]
  },
  {
    "objectID": "w06/slides.html#dgps-and-the-emergence-of-order",
    "href": "w06/slides.html#dgps-and-the-emergence-of-order",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "DGPs and the Emergence of Order",
    "text": "DGPs and the Emergence of Order\n\n\n\n\nWho (besides Aaron) can guess the state of this process after 10 steps, with 1 person?\n10 people? 50? 100? (If they find themselves on the same spot, they stand on each other’s heads)\n100 steps? 1000?"
  },
  {
    "objectID": "w06/slides.html#the-result-16-steps",
    "href": "w06/slides.html#the-result-16-steps",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Result: 16 Steps",
    "text": "The Result: 16 Steps"
  },
  {
    "objectID": "w06/slides.html#the-result-64-steps",
    "href": "w06/slides.html#the-result-64-steps",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Result: 64 Steps",
    "text": "The Result: 64 Steps"
  },
  {
    "objectID": "w06/slides.html#mathematicalscientific-modeling",
    "href": "w06/slides.html#mathematicalscientific-modeling",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "“Mathematical/Scientific Modeling”",
    "text": "“Mathematical/Scientific Modeling”\n\nThing we observe (poking out of water): data\nHidden but possibly discoverable through deeper investigation (ecosystem under surface): model / DGP"
  },
  {
    "objectID": "w06/slides.html#so-whats-the-problem",
    "href": "w06/slides.html#so-whats-the-problem",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "So What’s the Problem?",
    "text": "So What’s the Problem?\n\nNon-probabilistic models: High potential for being garbage (see: Bayesianism)\nProbabilistic models: Getting there, still “surface” phenomena\n\nOf the \\(N = 100\\) times we observed event \\(X\\) occurring, event \\(Y\\) also occurred \\(90\\) of those times\n\\(\\implies \\Pr(Y \\mid X) = \\frac{\\#[X, Y]}{\\#[X]} = \\frac{90}{100} = 0.9\\)\n\nCausal models: Does \\(Y\\) happen because of \\(X\\) happening? For that, need to start modeling what’s happening under the surface that make \\(X\\) and \\(Y\\) “pop up” together so often"
  },
  {
    "objectID": "w06/slides.html#the-intuitive-problem-of-inferring-causality",
    "href": "w06/slides.html#the-intuitive-problem-of-inferring-causality",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Intuitive Problem of Inferring Causality",
    "text": "The Intuitive Problem of Inferring Causality\n\n\n\n\n\n\n\n\n\n\n\n\n\ncor(ski_df$value, law_df$value)\n\n[1] 0.9921178\n\n\n\n(Based on Spurious Correlations, Tyler Vigen)\n\n\nThis, however, is only a mini-boss. Beyond it lies the truly invincible FINAL BOSS… 🙀"
  },
  {
    "objectID": "w06/slides.html#the-fundamental-problem-of-causal-inference",
    "href": "w06/slides.html#the-fundamental-problem-of-causal-inference",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Fundamental Problem of Causal Inference",
    "text": "The Fundamental Problem of Causal Inference\nThe only workable definition of “\\(X\\) causes \\(Y\\)”:\n\n\n\n\n Defining Causality\n\n\n\\(X\\) causes \\(Y\\) if and only if:\n\n\\(X\\) temporally precedes \\(Y\\) and\n\nIn two worlds \\(W_0\\) and \\(W_1\\) where\neverything is exactly the same except that \\(X = 0\\) in \\(W_0\\) and \\(X = 1\\) in \\(W_1\\),\n\\(Y = 0\\) in \\(W_0\\) and \\(Y = 1\\) in \\(W_1\\).\n\n\n(Hume 1739, ruining everything as usual 😤)\n\n\n\n\n\nThe problem? We live in one world, not two identical worlds simultaneously 😭"
  },
  {
    "objectID": "w06/slides.html#what-is-to-be-done",
    "href": "w06/slides.html#what-is-to-be-done",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "What Is To Be Done?",
    "text": "What Is To Be Done?"
  },
  {
    "objectID": "w06/slides.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "href": "w06/slides.html#face-everything-and-rise-controlled-randomized-experiment-paradigm",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm",
    "text": "Face Everything And Rise: Controlled, Randomized Experiment Paradigm\n\nFind good comparison cases: Treatment and Control\nWithout a control group, you cannot make inferences!\nSelecting on the dependent variable…"
  },
  {
    "objectID": "w06/slides.html#selecting-on-the-dependent-variable",
    "href": "w06/slides.html#selecting-on-the-dependent-variable",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Selecting on the Dependent Variable",
    "text": "Selecting on the Dependent Variable\n\nWhat “““research”“” “““says”“” about identifying people who might commit mass shootings\nJeff’s rant: If you care about actually solving social issues, this should infuriate you"
  },
  {
    "objectID": "w06/slides.html#complications-selection",
    "href": "w06/slides.html#complications-selection",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Complications: Selection",
    "text": "Complications: Selection\n\nTldr: Why did this person (unit) end up in the treatment group? Why did this other person (unit) end up in the control group?\nAre there systematic differences?\n“““Vietnam”“” “““War”“” Draft: Why can’t we just study [men who join the military] versus [men who don’t], and take the difference as a causal estimate?"
  },
  {
    "objectID": "w06/slides.html#the-solution-matching",
    "href": "w06/slides.html#the-solution-matching",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "The Solution: Matching",
    "text": "The Solution: Matching\n\nControlled experiment: we can ensure (since we have control over the assignment mechanism) the only systematic difference between \\(C\\) and \\(T\\) is: \\(T\\) received treatment, \\(C\\) did not\nIn an observational study, we’re “too late”! Thus, we no longer refer to assignment but to selection\nOur job is to figure out (reverse engineer!) the selection mechanism, then correct for its non-randomness. Spoiler: “transform” observational \\(\\rightarrow\\) experimental via weighting.\nThat’s the gold at end of rainbow. The rainbow itself is…"
  },
  {
    "objectID": "w06/slides.html#our-data-generating-process",
    "href": "w06/slides.html#our-data-generating-process",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Our Data-Generating Process",
    "text": "Our Data-Generating Process\n\n\\(Y\\): Future success, \\(\\mathcal{R}_Y = \\{0, 1\\}\\)\n\\(E\\): Private school education, \\(\\mathcal{R}_E = \\{0, 1\\}\\)\n\\(V\\): Born into poverty, \\(\\mathcal{R}_V = \\{0, 1\\}\\)\n\n\n\n\n\n\n\n\nThe Private School \\(\\leadsto\\) Success Pipeline 🤑\n\n\n\nSample independent RVs \\(U_1 \\sim \\mathcal{B}(1/2)\\), \\(U_2 \\sim \\mathcal{B}(1/3)\\), \\(U_3 \\sim \\mathcal{B}(1/3)\\)\n\\(V \\leftarrow U_1\\)\n\\(E \\leftarrow \\textsf{if }(V = 1)\\textsf{ then } 0\\textsf{ else }U_2\\)\n\\(Y \\leftarrow \\textsf{if }(V = 1)\\textsf{ then }0\\textsf{ else }U_3\\)"
  },
  {
    "objectID": "w06/slides.html#chalkboard-time",
    "href": "w06/slides.html#chalkboard-time",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Chalkboard Time…",
    "text": "Chalkboard Time…\n\n\\(\\Pr(Y = 1) = \\; ?\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\; ?\\)"
  },
  {
    "objectID": "w06/slides.html#top-secret-answers-slide-dont-peek",
    "href": "w06/slides.html#top-secret-answers-slide-dont-peek",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Top Secret Answers Slide (Don’t Peek)",
    "text": "Top Secret Answers Slide (Don’t Peek)\n\n\\(\\Pr(Y = 1) = \\frac{1}{6}\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\frac{1}{3}\\)\n\\(\\overset{✅}{\\implies}\\) One out of every three private-school graduates is successful, vs. one out of every six graduates overall\n\\(\\overset{❓}{\\implies}\\) Private school education doubles likelihood of success!\nThe latter is only true if intervening/changing/doing \\(E = 0 \\leadsto E = 1\\) is what moves \\(\\Pr(Y = 1)\\) from \\(\\frac{1}{6}\\) to \\(\\frac{1}{3}\\)!"
  },
  {
    "objectID": "w06/slides.html#chalkboard-time-2-electric-boogaloo",
    "href": "w06/slides.html#chalkboard-time-2-electric-boogaloo",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Chalkboard Time 2: Electric Boogaloo",
    "text": "Chalkboard Time 2: Electric Boogaloo\n\n\\(\\Pr(Y = 1) = \\frac{1}{6}\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\frac{1}{3}\\)\n\\(\\Pr(Y = 1 \\mid \\textsf{do}(E = 1)) = \\; ?\\)\nHere, \\(\\textsf{do}(E = 1)\\) means diving into the DGP below the surface and changing it so that \\(E = 1\\)… Setting \\(E\\) to be \\(1\\)\n\n\n\n\n\n\n\n\n\\(\\text{DGP}(Y \\mid \\textsf{do}(E = 1))\\)\n\n\n\nSample independent RVs \\(U_1 \\sim \\mathcal{B}(1/2)\\), \\(U_2 \\sim \\mathcal{B}(1/3)\\), \\(U_3 \\sim \\mathcal{B}(1/3)\\)\n\\(V \\leftarrow U_1\\)\n\\(E \\leftarrow \\textsf{if }(V = 1)\\textsf{ then } 0\\textsf{ else }U_2\\)\n\\(Y \\leftarrow \\textsf{if }(V = 1)\\textsf{ then }0\\textsf{ else }U_3\\)"
  },
  {
    "objectID": "w06/slides.html#double-quadruple-secret-answer-slide",
    "href": "w06/slides.html#double-quadruple-secret-answer-slide",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "Double Quadruple Secret Answer Slide",
    "text": "Double Quadruple Secret Answer Slide\n\n\\(\\Pr(Y = 1) = \\frac{1}{6}\\)\n\\(\\Pr(Y = 1 \\mid E = 1) = \\frac{1}{3}\\)\n\\(\\Pr(Y = 1 \\mid \\textsf{do}(E = 1)) = \\frac{1}{6}\\)"
  },
  {
    "objectID": "w06/slides.html#references",
    "href": "w06/slides.html#references",
    "title": "Week 6: Causality in Ethics and Policy",
    "section": "References",
    "text": "References\n\n\nHume, David. 1739. A Treatise of Human Nature: Being an Attempt to Introduce the Experimental Method of Reasoning Into Moral Subjects; and Dialogues Concerning Natural Religion. Longmans, Green.\n\n\n\n\n\nDSAN 5450 Week 6: Causality"
  }
]