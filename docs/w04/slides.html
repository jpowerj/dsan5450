<!DOCTYPE html>
<html lang="en"><head>
<link href="../favicon.png" rel="icon" type="image/png">
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.40">

  <meta name="author" content="Jeff Jacobs">
  <title>DSAN 5450 – Week 4: (Descriptive) Fairness in AI</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-50eeacc152a2459e6a2c1e8407b82f47.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/simplemenu/simplemenu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/dreampulse/computer-modern-web-font@master/fonts.css">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Week 4: (Descriptive) Fairness in AI</h1>
  <p class="subtitle"><em>DSAN 5450: Data Ethics and Policy</em><br><span class="subsubtitle">Spring 2025, Georgetown University</span></p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Jeff Jacobs 
</div>
        <p class="quarto-title-affiliation">
            <a href="mailto:jj1088@georgetown.edu"><code>jj1088@georgetown.edu</code></a>
          </p>
    </div>
</div>

  <p class="date">Wednesday, February 5, 2025</p>
</section>
<section>
<section id="tumbling-into-fairness" class="title-slide slide level1 center" data-stack-name="Recap">
<h1>Tumbling into Fairness</h1>
<div class="hidden">
<p><span class="math display">\[
\newcommand{\nimplies}{\;\not\!\!\!\!\implies}
\]</span></p>
</div>
<blockquote>
<p>“Repetition is the mother of perfection” - Dwayne Michael “Lil Wayne” Carter, Jr.</p>
</blockquote>
</section>
<section id="so-how-should-we-makechoose-conventions" class="slide level2 title-08">
<h2>So How Should We Make/Choose Conventions?</h2>
<ul>
<li><span class="citation" data-cites="hobbes_leviathan_1668">Hobbes (<a href="#/references" role="doc-biblioref" onclick="">1668</a>)</span>: Only way out of “war of all against all” is to surrender all power to one <strong>sovereign</strong> (the <em>Leviathan</em>)</li>
<li><span class="citation" data-cites="rousseau_social_1762">Rousseau (<a href="#/references" role="doc-biblioref" onclick="">1762</a>)</span>: Social contract</li>
<li><em>[Big big ~200 year gap here… can you think of why? Hint: French Revolution in 1789]</em></li>
<li><span class="citation" data-cites="rawls_theory_1971">Rawls (<a href="#/references" role="doc-biblioref" onclick="">1971</a>)</span>: Social contract <strong>behind the “veil of ignorance”</strong>
<ul>
<li>If we didn’t know <strong>where we were going to end up</strong> in society, how would we set it up? <!-- * @dworkin_what_1981: Yes, plus also people can **buy insurance** against ending up in a bad place $\rightarrow$ level of "just" redistribution --></li>
</ul></li>
</ul>
</section>
<section id="rawls-veil-of-ignorance" class="slide level2 crunch-title">
<h2>Rawls’ Veil of Ignorance</h2>
<ul>
<li>Probably the most important tool for policy whitepapers!</li>
<li>“Justice as fairness” (next week: fairness in AI 😜)</li>
<li>We don’t know whether we’ll be <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span> in the intersection game, so we’d choose the <strong>traffic light</strong>!</li>
<li>More profoundly: We don’t know what <strong>race</strong>, <strong>gender</strong>, <strong>class</strong>, <strong>ethnicity</strong>, <strong>sexuality</strong>, <strong>disability status</strong> we’ll have; We don’t know whether we’ll be <strong>Israeli</strong> or <strong>Palestinian</strong>; we don’t know whether we’ll own <strong>means of production</strong> or own only our <strong>labor power</strong> (and thus have to sell it on a market to survive)… 🤔</li>
</ul>
</section></section>
<section>
<section id="nuts-and-bolts-for-fairness" class="title-slide slide level1 center" data-stack-name="Fairness">
<h1>Nuts and Bolts for Fairness</h1>

</section>
<section id="one-final-reminder" class="slide level2 crunch-title">
<h2>One Final Reminder</h2>
<ul>
<li>Industry rule #4080: Cannot “prove” <span class="math inline">\(q(x) = \text{``Algorithm }x\text{ is fair''}\)</span>! Only <span class="math inline">\(p(x) \implies q(y)\)</span>:</li>
</ul>
<p><span class="math display">\[
\underbrace{p(x)}_{\substack{\text{Accept ethical} \\ \text{framework }x}} \implies \underbrace{q(y)}_{\substack{\text{Algorithms should} \\ \text{satisfy condition }y}}
\]</span></p>
<ul>
<li>Before: <strong>possible ethical frameworks</strong> (values for <span class="math inline">\(x\)</span>)</li>
<li>Now: <strong>possible fairness criteria</strong> (values for <span class="math inline">\(y\)</span>)</li>
</ul>
</section>
<section id="categories-of-fairness-criteria" class="slide level2 smaller crunch-title">
<h2>Categories of Fairness Criteria</h2>
<style>
#fairness-box .columns {
  display: flex !important;
  height: 100% !important;
}

#fairness-box .column {
  /* border: 2px solid black !important; */
  padding: 14px !important;
  box-sizing: border-box !important;
  /* height: 100% !important; */
}
</style>
<p>Roughly, approaches to fairness/bias in AI can be categorized as follows:</p>
<div id="fairness-box" style="border: 2px solid black !important; box-sizing: border-box !important;">
<center>
<strong>Fairness</strong>
</center>
<!-- start columns -->
<div class="columns">
<div class="column" style="width:46%;">
<div style="border: 2px solid black !important; height: 100% !important;">
<center>
<strong>Context-Free</strong>
</center>
<ul>
<li>Single-Threshold Fairness</li>
<li>Equal Prediction</li>
<li>Equal Decision</li>
</ul>
</div>
</div><div class="column" style="width:8%;">
<center>
<span style="font-size: 180% !important;"><i class="bi bi-repeat"></i>
</span></center>
</div><div class="column" style="width:46%;">
<div style="border: 2px solid black !important; height: 100% !important;">
<center style="margin: 0px !important;">
<strong>Context-Sensitive</strong>
</center>
<ul>
<li>Fairness via Similarity Metric(s)</li>
<li>Causal Definitions</li>
</ul>
</div>
</div></div>
</div>
<!-- end quarto box -->
<ul>
<li>[Today] <strong>Context-Free</strong> Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of Machine Learning (you already know much of it, given DSAN 5000!)</li>
<li>But <strong>easy-to-grasp notion</strong> <span class="math inline">\(\neq\)</span> <strong>“good” notion</strong>!</li>
<li>Your job: push yourself to (a) consider what is getting <strong>left out of</strong> the context-free definitions, and (b) the <strong>loopholes</strong> that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”</li>
</ul>
</section>
<section id="laws-often-perfectly-technically-fair" class="slide level2 title-09">
<h2>Laws: Often Perfectly “Technically Fair”</h2>
<blockquote>
<p><em>Ah, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!</em></p>
</blockquote>
<blockquote>
<p>(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)</p>
</blockquote>
<p>Anatole France, <em>Le Lys Rouge</em> <span class="citation" data-cites="france_lys_1894">(<a href="#/references" role="doc-biblioref" onclick="">France 1894</a>)</span></p>
</section></section>
<section>
<section id="context-free-fairness" class="title-slide slide level1 smaller not-title-slide crunch-title center">
<h1>Context-Free Fairness</h1>

<img data-src="images/chomsky-hierarchy.jpeg" class="no-stretch r-stretch quarto-figure-center" width="200"><p class="caption">From <a href="https://www.cs.sfu.ca/~anoop/courses/MACM-300-Spring-2006/complexity.pdf" target="_blank"><em>Introduction to Formal Languages and Automata</em></a>, Simon Fraser University (2006). This figure summarizes the <strong>Chomsky Hierarchy</strong> of Languages, developed by Noam Chomsky, who also has a lot to say about Ethics and Policy!</p></section>
<section id="the-brogrammers-criterion" class="slide level2 crunch-title crunch-ul">
<h2>The Brogrammer’s Criterion</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a>df.drop(columns<span class="op">=</span>[<span class="st">"race"</span>], inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Racism solved, folks! 🥳🎊🎉 End of the course, have a great rest of your data science career ✌️</li>
</ul>

<img data-src="images/flocka.jpeg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="no-fairness-through-unawareness" class="slide level2 smaller crunch-title crunch-ul crunch-figcaption">
<h2>(No) Fairness Through Unawareness</h2>
<ul>
<li><strong>HW1</strong>: Using tiny sample (<span class="math inline">\(N &lt; 10K\)</span>) of Florida voter registrations… <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" target="_blank">RandomForestClassifier</a> (default settings, no hyperparameter tuning, no cross-validation, no ensembling with other methods) will predict self-reported race with <span class="math inline">\(&gt;90\%\)</span> accuracy (in balanced sample) from just <strong>surname</strong> and <strong>county of residence</strong>
<ul>
<li>Can reach <span class="math inline">\(70\text{-}75\%\)</span> with <strong>just</strong> surname or <strong>just</strong> county of residence</li>
</ul></li>
<li>End-of-HW1 discussion: <strong>Facebook</strong> ad matching service provides <strong>over 1,000 different user attributes</strong> for <strong>(micro)targeting</strong></li>
</ul>

<img data-src="images/proxy.svg" class="r-stretch quarto-figure-center"><p class="caption">From <span class="citation" data-cites="datta_proxy_2017">Datta et al. (<a href="#/references" role="doc-biblioref" onclick="">2017</a>)</span></p></section>
<section id="we-can-do-a-bit-better" class="slide level2 smaller">
<h2>We Can Do (A Bit) Better…</h2>
<ul>
<li>Use <strong>random variables</strong> to model inferences made by an algorithm (or a human!)</li>
<li><span class="math inline">\(\implies\)</span> fairness by statistically <strong>equalizing</strong> loan rejections, error rate, etc. between groups</li>
<li>Obvious <strong>societal</strong> drawback: <strong>equality</strong> does not ameliorate the effects of <strong>past injustices</strong> (see: police contact vs.&nbsp;trust-in-government plot from last week)
<ul>
<li>This one we saw coming, given “context-free” nature!</li>
</ul></li>
<li>Less obvious <strong>mathematical</strong> drawback: <strong>impossibility results</strong> (because algebra 😳)
<ul>
<li>Roughly: can’t satisfy [more than] two statistical fairness criteria at once; similar to how setting <span class="math inline">\(\Pr(X) = p\)</span> also determines <span class="math inline">\(\Pr(\neg X) = 1 - p\)</span>, or how plugging <span class="math inline">\(x = 3\)</span> into <span class="math inline">\(x + y = 5\)</span> leaves only one possibility <span class="math inline">\(y = 2\)</span></li>
</ul></li>
<li><strong>BUT</strong>, “impossibility” <span class="math inline">\(\neq\)</span> impossibility: (a) one criteria may be “all you need” in given setting; (b) can derive <strong>more robust</strong> measures by “relaxing” confusion-matrix measures</li>
</ul>
</section>
<section id="what-the-fairness-measures-will-feel-like-for-now" class="slide level2 smaller crunch-title title-10">
<h2>What the Fairness Measures Will Feel Like For Now</h2>

<img data-src="images/rock_on_rich_brian.jpeg" class="quarto-figure quarto-figure-center r-stretch"><ul>
<li>(They will get more robust and will <strong>incorporate context</strong> soon, I promise!)</li>
</ul>
</section>
<section id="who-remembers-confusion-matrices" class="slide level2 smaller crunch-title title-11">
<h2>Who Remembers… 🎉<em>Confusion Matrices!!!</em>🎉</h2>
<ul>
<li>Terrifyingly higher stakes than in DSAN 5000, however!</li>
<li>Now <span class="math inline">\(D = 1\)</span> could literally mean <em>“shoot this person”</em> or <em>“throw this person in jail for life”</em></li>
</ul>

<img data-src="images/mitchell_et_al.svg" class="r-stretch quarto-figure-center"><p class="caption">From <span class="citation" data-cites="mitchell_algorithmic_2021">Mitchell et al. (<a href="#/references" role="doc-biblioref" onclick="">2021</a>)</span></p></section>
<section id="baby-steps-a-real-world-confusion-matrix" class="slide level2 title-11 crunch-title smaller">
<h2>Baby Steps: A Real-World Confusion Matrix</h2>
<table class="caption-top" style="width:99%;">
<colgroup>
<col style="width: 27%">
<col style="width: 36%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Labeled Low-Risk</th>
<th>Labeled High-Risk</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Didn’t Do More Crimes</strong></td>
<td><em>True Negative</em></td>
<td><em>False Positive</em></td>
</tr>
<tr class="even">
<td><strong>Did More Crimes</strong></td>
<td><em>False Negative</em></td>
<td><em>True Positive</em></td>
</tr>
</tbody>
</table>
<ul>
<li>What kinds of <strong>causal connections</strong> and/or <strong>feedback loops</strong> might there be between our <strong>decision variable</strong> (low vs.&nbsp;high risk) and our <strong>outcome variable</strong> (did vs.&nbsp;didn’t do more crimes)</li>
<li>What types of <strong>policy implications</strong> might this process have, after it “runs” for several “iterations”?</li>
<li>Why might some segments of society, with some shared ethical framework(s), <strong>weigh</strong> the <strong>“costs”</strong> of false negatives and false positives <strong>differently</strong> from other segments of society with different shared ethical framework(s)?</li>
<li>(Non-rhetorical questions!)</li>
</ul>
</section>
<section id="categories-of-fairness-criteria-1" class="slide level2 smaller crunch-title">
<h2>Categories of Fairness Criteria</h2>
<style>
#fairness-box .columns {
  display: flex !important;
  height: 100% !important;
}

#fairness-box .column {
  /* border: 2px solid black !important; */
  padding: 14px !important;
  box-sizing: border-box !important;
  /* height: 100% !important; */
}
</style>
<p>Roughly, approaches to fairness/bias in AI can be categorized as follows:</p>
<div id="fairness-box" style="border: 2px solid black !important; box-sizing: border-box !important;">
<center>
<strong>Fairness</strong>
</center>
<!-- start columns -->
<div class="columns">
<div class="column" style="width:46%;">
<div style="border: 2px solid black !important; height: 100% !important;">
<center>
<strong>Context-Free</strong>
</center>
<ul>
<li>Single-Threshold Fairness</li>
<li>Equal Prediction</li>
<li>Equal Decision</li>
</ul>
</div>
</div><div class="column" style="width:8%;">
<center>
<span style="font-size: 180% !important;"><i class="bi bi-repeat"></i>
</span></center>
</div><div class="column" style="width:46%;">
<div style="border: 2px solid black !important; height: 100% !important;">
<center style="margin: 0px !important;">
<strong>Context-Sensitive</strong>
</center>
<ul>
<li>Fairness via Similarity Metric(s)</li>
<li>Causal Definitions</li>
</ul>
</div>
</div></div>
</div>
<!-- end quarto box -->
<ul>
<li>[Today] <strong>Context-Free</strong> Fairness: Easier to grasp from CS/data science perspective; rooted in “language” of Machine Learning (you already know much of it, given DSAN 5000!)</li>
<li>But <strong>easy-to-grasp notion</strong> <span class="math inline">\(\neq\)</span> <strong>“good” notion</strong>!</li>
<li>Your job: push yourself to (a) consider what is getting <strong>left out of</strong> the context-free definitions, and (b) the <strong>loopholes</strong> that are thus introduced into them, whereby people/computers can discriminate while remaining “technically fair”</li>
</ul>
</section>
<section id="laws-often-perfectly-technically-fair-1" class="slide level2 title-09">
<h2>Laws: Often Perfectly “Technically Fair”</h2>
<blockquote>
<p><em>Ah, la majestueuse égalité des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!</em></p>
</blockquote>
<blockquote>
<p>(Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)</p>
</blockquote>
<p>Anatole France, <em>Le Lys Rouge</em> <span class="citation" data-cites="france_lys_1894">(<a href="#/references" role="doc-biblioref" onclick="">France 1894</a>)</span></p>
</section>
<section id="no-fairness-through-unawareness-1" class="slide level2 smaller crunch-title crunch-ul crunch-figcaption">
<h2>(No) Fairness Through Unawareness</h2>
<ul>
<li><strong>HW1</strong>: Using tiny sample (<span class="math inline">\(N &lt; 10K\)</span>) of Florida voter registrations… <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" target="_blank">RandomForestClassifier</a> (default settings, no hyperparameter tuning, no cross-validation, no ensembling with other methods) will predict self-reported race with <span class="math inline">\(&gt;90\%\)</span> accuracy (in balanced sample) from just <strong>surname</strong> and <strong>county of residence</strong>
<ul>
<li>Can reach <span class="math inline">\(70\text{-}75\%\)</span> with <strong>just</strong> surname or <strong>just</strong> county of residence</li>
</ul></li>
<li>Also in HW1: <strong>Facebook</strong> ad matching service provides <strong>over 1,000 different user attributes</strong> for <strong>(micro)targeting</strong></li>
</ul>

<img data-src="images/proxy.svg" class="r-stretch quarto-figure-center"><p class="caption">From <span class="citation" data-cites="datta_proxy_2017">Datta et al. (<a href="#/references" role="doc-biblioref" onclick="">2017</a>)</span></p></section>
<section id="last-one-i-promise" class="slide level2">
<h2>Last One I Promise</h2>

<img data-src="images/census-tract-bethesda.png" class="r-stretch quarto-figure-center"><p class="caption">Predicting self-reported <strong>whiteness</strong> with <strong>70% accuracy</strong></p></section>
<section id="last-one-i-promise-1" class="slide level2">
<h2>Last One I Promise</h2>

<img data-src="images/census-tract-pg-cty.png" class="r-stretch quarto-figure-center"><p class="caption">Predicting self-reported <strong>non-whiteness</strong> with <strong>90% accuracy</strong></p></section>
<section id="we-can-do-a-bit-better-1" class="slide level2 smaller">
<h2>We Can Do (A Bit) Better…</h2>
<ul>
<li>Use <strong>random variables</strong> to model inferences made by an algorithm (or a human!)</li>
<li><span class="math inline">\(\implies\)</span> fairness by statistically <strong>equalizing</strong> loan rejections, error rate, etc. between groups</li>
<li>Obvious <strong>societal</strong> drawback: <strong>equality</strong> does not ameliorate the effects of <strong>past injustices</strong> (see: police contact vs.&nbsp;trust-in-government plot from last week)
<ul>
<li>This one we saw coming, given “context-free” nature!</li>
</ul></li>
<li>Less obvious <strong>mathematical</strong> drawback: <strong>impossibility results</strong> (because algebra 😳)
<ul>
<li>Roughly: can’t satisfy [more than] two statistical fairness criteria at once; similar to how setting <span class="math inline">\(\Pr(X) = p\)</span> also determines <span class="math inline">\(\Pr(\text{not }X) = 1 - p\)</span>, or how plugging <span class="math inline">\(x = 3\)</span> into <span class="math inline">\(x + y = 5\)</span> leaves only one possibility <span class="math inline">\(y = 2\)</span></li>
</ul></li>
<li><strong>BUT</strong>, “impossibility” <span class="math inline">\(\neq\)</span> impossibility: (a) one criteria may be “all you need” in given setting; (b) can derive <strong>more robust</strong> measures by “relaxing” confusion-matrix measures</li>
</ul>
</section></section>
<section>
<section id="definitions-and-impossibility-results" class="title-slide slide level1 center" data-stack-name="Definitions and Results">
<h1>Definitions and (Impossibility) Results</h1>
<p><em>(tldr:)</em></p>
<ul>
<li>We have information <span class="math inline">\(X_i\)</span> about person <span class="math inline">\(i\)</span>, and</li>
<li>We’re trying to <strong>predict</strong> a <strong>binary</strong> outcome <span class="math inline">\(Y_i\)</span> involving <span class="math inline">\(i\)</span>.</li>
<li>So, we use ML to learn a <strong>risk function</strong> <span class="math inline">\(r: \mathcal{R}_{X_i} \rightarrow \mathbb{R}\)</span>, then</li>
<li>Use this to make a <strong>binary decision</strong> <span class="math inline">\(\widehat{Y}_i = \mathbf{1}[r(X_i) &gt; t]\)</span></li>
</ul>
</section>
<section id="protectedsensitive-attributes" class="slide level2 crunch-title smaller crunch-ul crunch-math">
<h2>Protected/Sensitive Attributes</h2>
<ul>
<li>Standard across the literature: Random Variable <span class="math inline">\(A_i\)</span> “encoding” membership in protected/sensitive group. In HW1, for example:</li>
</ul>
<p><span class="math display">\[
A_i = \begin{cases}
0 &amp;\text{if }i\text{ self-reported ``white''} \\
1 &amp;\text{if }i\text{ self-reported ``black''}
\end{cases}
\]</span></p>
<ul>
<li><p><strong>Notice</strong>: choice of mapping into <span class="math inline">\(\{0, 1\}\)</span> here <strong>non-arbitrary</strong>!</p></li>
<li><p>We want our models/criteria to be <strong>descriptively</strong> but also <strong>normatively robust</strong>; e.g.:</p></li>
<li><p><strong>If</strong> (antecedent I hold, though <a href="https://www.pewresearch.org/politics/2021/08/12/deep-divisions-in-americans-views-of-nations-racial-history-and-how-to-address-it/" target="_blank">majority in US</a> do not) one believes that ending (much less repairing) centuries of unrelenting white supremacist violence here might require asymmetric race-based policies,</p></li>
<li><p><strong>Then</strong> our model should allow different <strong>normative labels</strong> and differential <strong>weights</strong> on</p>
<p><span class="math display">\[
\begin{align*}
\Delta &amp;= (\text{Fairness} \mid A = 1) - (\text{Fairness} \mid A = 0) \\
\nabla &amp;= (\text{Fairness} \mid A = 0) - (\text{Fairness} \mid A = 1)
\end{align*}
\]</span></p>
<p>despite the <strong>descriptive</strong> fact that <span class="math inline">\(\Delta = -\nabla\)</span>.</p></li>
</ul>
</section>
<section id="where-descriptive-and-normative-become-intertwined" class="slide level2 crunch-title title-07">
<h2>Where Descriptive and Normative Become Intertwined</h2>
<ul>
<li>Allowing this <strong>asymmetry</strong> is precisely what enables bring <strong>descriptive</strong> facts to bear on <strong>normative</strong> concerns!</li>
<li><strong>Mathematically</strong> we can always “flip” the mapping from racial labels into <span class="math inline">\(\{0, 1\}\)</span>…</li>
<li>But this (in a precise, mathematical sense: namely, <em>isomorphism</em>) implies that we’re treating <strong>racial categorization</strong> as the same type of phenomenon as <strong>driving on left or right side of road</strong> (see: prev slides on why we make the descriptive vs.&nbsp;normative distinction)</li>
<li>(See also: Sweden’s <a href="https://en.wikipedia.org/wiki/Dagen_H" target="_blank">Dagen H</a>!)</li>
</ul>
</section></section>
<section>
<section id="lab-time" class="title-slide slide level1 center" data-stack-name="Lab">
<h1>Lab Time!</h1>
<ul>
<li><a href="https://colab.research.google.com/drive/1Gucih9aILHt7r7Qklv6xM-EB7Rkoqj6C?usp=sharing">Lab 1: Coming face to face with Marlon Brando</a></li>
</ul>
</section>
<section id="fairness-through-equalized-positive-rates-epr" class="slide level2 crunch-ul title-07 math-95 crunch-math crunch-blockquote">
<h2>“Fairness” Through Equalized <em>Positive</em> Rates (EPR)</h2>
<div style="height: 8px !important;">
&nbsp;
</div>
<p><span class="math display">\[
\boxed{\Pr(D = 1 \mid A = 0) = \Pr(D = 1 \mid A = 1)}
\]</span></p>
<ul>
<li>This works specifically for discrete, <strong>binary</strong>-valued categories</li>
<li>For general attributes (whether discrete or continuous!), generalizes to:</li>
</ul>
<p><span class="math display">\[
\boxed{D \perp A} \iff \Pr(D = d, A = a) = \Pr(D = d)\Pr(A = a)
\]</span></p>
<blockquote>
<p>Imagine you learn that a person received a scholarship (<span class="math inline">\(D = 1\)</span>); [with equalized positive rates], this fact would give you no knowledge about the race (or sex, or class, as desired) <span class="math inline">\(A\)</span> of the individual in question. <span class="citation" data-cites="dedeo_wrong_2016">(<a href="#/references" role="doc-biblioref" onclick="">DeDeo 2016</a>)</span></p>
</blockquote>
</section>
<section id="achieving-equalized-positive-rates" class="slide level2 smaller crunch-title">
<h2>Achieving Equalized Positive Rates</h2>
<ul>
<li><p>The good news: if we want this, there is a <strong>closed-form solution</strong>: take your datapoints <span class="math inline">\(X_i\)</span> and <strong>re-weigh</strong> each point to obtain <span class="math inline">\(\widetilde{X}_i = w_iX_i\)</span>, where</p>
<p><span class="math display">\[
  w_i = \frac{\Pr(Y_i = 1)}{\Pr(Y_i = 1 \mid A_i = 1)}
  \]</span></p>
<p>and use derived dataset <span class="math inline">\(\widetilde{X}_i\)</span> to learn <span class="math inline">\(r(X)\)</span> (via ML algorithm)… Why does this work?</p></li>
<li><p>Let <span class="math inline">\(\mathcal{X}_{\text{fair}}\)</span> be the set of all possible <strong>reweighted versions</strong> of <span class="math inline">\(X_i\)</span> ensuring <span class="math inline">\(Y_i \perp A_i\)</span>. Then</p></li>
</ul>
<p><span class="math display">\[
\widetilde{X}_i = \min_{X_i' \in \mathcal{X}_{\text{fair}}}\textsf{distance}(X_i', X_i) = \min_{X_i' \in \mathcal{X}_{\text{fair}}}\underbrace{KL(X_i' \| X_i)}_{\text{Relative entropy!}}
\]</span></p>
<ul>
<li>The bad news: nobody in the fairness in AI community read <span class="citation" data-cites="dedeo_wrong_2016">DeDeo (<a href="#/references" role="doc-biblioref" onclick="">2016</a>)</span>, which proves this using information theory? Idk. It has a total of <a href="https://scholar.google.com/scholar?lookup=0&amp;q=wrong+side+of+the+tracks+dedeo&amp;hl=en&amp;as_sdt=0,9" target="_blank">22 citations</a> 😐</li>
</ul>
</section>
<section id="fairness-through-equalized-error-rates" class="slide level2 smaller crunch-title title-12 crunch-math">
<h2>“Fairness” Through Equalized <em>Error</em> Rates</h2>
<ul>
<li><p>Equalized <strong>positive</strong> rates didn’t take <strong>outcomes</strong> <span class="math inline">\(Y_i\)</span> into account…</p>
<ul>
<li>(Even if <span class="math inline">\(A_i = 1 \Rightarrow Y_i = 1, A_i = 0 \Rightarrow Y_i = 0\)</span>, we’d have to choose <span class="math inline">\(\widehat{Y}_i = c\)</span>)</li>
</ul></li>
<li><p>This time, we consider the <strong>outcome</strong> <span class="math inline">\(Y\)</span> that</p></li>
<li><p>Equalized <strong>False Positive Rate</strong> (<strong>EFPR</strong>):</p></li>
</ul>
<p><span class="math display">\[
\Pr(D = 1 \mid Y = 0, A = 0) = \Pr(D = 1 \mid Y = 0, A = 1)
\]</span></p>
<ul>
<li>Equalized <strong>False Negative Rate</strong> (<strong>EFNR</strong>):</li>
</ul>
<p><span class="math display">\[
\Pr(D = 0 \mid Y = 1, A = 0) = \Pr(D = 0 \mid Y = 1, A = 1)
\]</span></p>
<ul>
<li>For general (non-binary) attributes: <span class="math inline">\((D \perp A) \mid Y\)</span>:</li>
</ul>
<p><span class="math display">\[
\Pr(D = d, A = a \mid Y = y) = \Pr(D = d \mid Y = y)\Pr(A = a \mid Y = y)
\]</span></p>
</section>
<section id="less-equations-please" class="slide level2 smaller">
<h2>⚠️ LESS EQUATIONS PLEASE! 😤</h2>
<ul>
<li>Depending on your background and/or learning style (say, visual vs.&nbsp;auditory), you may be able to look at equations on previous two slides and “see” what they’re “saying”</li>
<li>If your brain works similarly to <strong>mine</strong>, however, your eyes glazed over, you began dissociating, planning an escape route, etc., the moment <span class="math inline">\(&gt; 2\)</span> variables appeared</li>
<li>If you’re in the latter group, welcome to the <strong>cult of Probabilistic Graphical Models</strong> 😈</li>
</ul>

<img data-src="images/pgm_fairness.svg" class="r-stretch quarto-figure-center"><p class="caption">Your first <strong>PGM</strong>, illustrating <strong>hypothesized causal relationships</strong> between three random variables <span class="math inline">\(Y\)</span> (outcome), <span class="math inline">\(D\)</span> (decision), and <span class="math inline">\(A\)</span> (protected attribute). The <span class="math inline">\(Y\)</span> node is <strong>shaded</strong> to indicate that it is an <strong>observed</strong> value in our model, rendering the <strong>unobserved</strong> values <span class="math inline">\(D\)</span> and <span class="math inline">\(A\)</span> <strong>independent</strong> conditional on it. If I was elected Emperor of Math, equations would be abolished in favor of PGMs.</p></section>
<section id="section" class="slide level2 crunch-title crunch-callout" data-background-video="https://jpj.georgetown.domains/dsan5450-scratch/Dead_Inside_Shuffle.mp4" data-background-size="contain" data-background-opacity="0.5">
<h2></h2>
<div>

</div>
<div class="quarto-layout-panel" data-layout-align="right" data-layout="[-70,30]">
<div class="quarto-layout-row">
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 70.0%;justify-content: flex-end;">
<p>&nbsp;</p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 30.0%;justify-content: flex-end;">
<div title="Equalized False Negative/Positive Rates" style="background-color: white !important;">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Equalized False Negative/Positive Rates</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Our first measure that <strong>🥳🎉matches a principle of justice in society!!!🕺🪩</strong></li>
<li><a href="https://en.wikipedia.org/wiki/Blackstone%27s_ratio" target="_blank"><strong>Blackstone’s Ratio</strong></a>: <em>“It is better that ten guilty persons escape, than that one innocent suffers.”</em> <span class="citation" data-cites="blackstone_commentaries_1769">(<a href="#/references" role="doc-biblioref" onclick="">Blackstone 1769</a>)</span></li>
<li>(…break time!)</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="back-to-equalized-error-rates" class="slide level2 crunch-title crunch-ul">
<h2>Back to Equalized Error Rates</h2>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Blackstone%27s_ratio" target="_blank"><strong>Blackstone’s Ratio</strong></a>: <em>“It is better that ten guilty persons escape, than that one innocent suffers.”</em> <span class="citation" data-cites="blackstone_commentaries_1769">(<a href="#/references" role="doc-biblioref" onclick="">Blackstone 1769</a>)</span></li>
<li>Mathematically <span class="math inline">\(\Rightarrow \text{Cost}(FPR) = 10\cdot \text{Cost}(FNR)\)</span></li>
<li>Legally <span class="math inline">\(\Rightarrow\)</span> <em>beyond reasonable doubt</em> standard for conviction</li>
<li>EFPR <span class="math inline">\(\iff\)</span> rates of false conviction should be the same for everyone, including members of different racial groups.
<ul>
<li>Violated when black people are disproportionately likely to be incorrectly convicted, as if a <strong>lower evidentiary standard</strong> were applied to black people.</li>
</ul></li>
</ul>
</section>
<section id="one-final-context-free-criterion-calibration" class="slide level2">
<h2>One Final Context-Free Criterion: Calibration</h2>
<ul>
<li>A risk function <span class="math inline">\(r(X)\)</span> is <strong>calibrated</strong> if</li>
</ul>
<p><span class="math display">\[
\Pr(Y = 1 \mid r(X) = v_r) = v_r
\]</span></p>
<ul>
<li>(Sweeping a lot of details under the rug), I see this one as: <strong>the risk function “tracks” real-world probabilities</strong></li>
<li>Then, <span class="math inline">\(r(X)\)</span> is <strong>calibrated by group</strong> if</li>
</ul>
<p><span class="math display">\[
\Pr(Y = y \mid r(X) = v_r, A = a) = v_r
\]</span></p>
<!-- ## Minimizing Loss Function Penalizing (Only) These Errors $\iff$ Single-Threshold Fairness {.smaller .crunch-title .title-09}

* Loss function: $\ell(d, \widehat{d})$
* An **optimal classifier** minimizes the expected loss: $\mathbb{E}[\ell(\widehat{d},d)]$
* A **decision** is considered to be fair if individuals with the same score $s_i = \psi(v_i)$ are treated equally, regardless of group membership (Corbett-Davies & Goel 2018). -->
</section>
<section id="impossibility-results" class="slide level2">
<h2>Impossibility Results</h2>
<ul>
<li>tldr: We cannot possibly achieve all three of <strong>equalized positive rates</strong> (often also termed “anti-classification”), classification <strong>parity</strong>, and <strong>calibration</strong> (regardless of <strong>base rates</strong>)</li>
<li>More alarmingly: We can’t even achieve both classification <strong>parity</strong> and <strong>calibration</strong>, except in the special case of <strong>equal base rates</strong></li>
</ul>
</section>
<section id="impossibility-vs.-impossibility" class="slide level2 smaller crunch-title">
<h2>“Impossibility” vs.&nbsp;Impossibility</h2>
<ul>
<li>Sometimes “impossibility results” are, for all intents and purposes, mathematical curiosities: often there’s some <strong>pragmatic</strong> way of getting around them</li>
<li>Example: “Arrow’s Impossibility Theorem”
<ul>
<li>[In theory] It is mathematically impossible to <strong>aggregate individual preferences</strong> into <strong>societal preferences</strong></li>
<li>[The catch] True only if people are restricted to <strong>ordinal preferences</strong>: “I prefer <span class="math inline">\(x\)</span> to <span class="math inline">\(y\)</span>.” No more information allowed</li>
<li>[The way around it] Allow people to indicate the <strong>magnitude</strong> of their preferences: “I prefer <span class="math inline">\(x\)</span> 5 times more than <span class="math inline">\(y\)</span>”</li>
</ul></li>
<li>In this case, though, there are direct and (often) unavoidable real-world barriers that fairness impossibility imposes 😕</li>
</ul>
</section>
<section id="arrows-impossibility-theorem" class="slide level2 crunch-title smaller crunch-ul">
<h2>Arrow’s Impossibility Theorem</h2>
<ul>
<li>Aziza, Bogdan, and Charles are competing in a <strong>fitness test</strong> with four events. Goal: determine who is <strong>most fit overall</strong></li>
</ul>
<table class="caption-top">
<thead>
<tr class="header">
<th></th>
<th>Run</th>
<th>Jump</th>
<th>Hurdle</th>
<th>Weights</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Aziza</td>
<td>10.1”</td>
<td>6.0’</td>
<td>40”</td>
<td>150 lb</td>
</tr>
<tr class="even">
<td>Bogdan</td>
<td>9.2”</td>
<td>5.9’</td>
<td>42”</td>
<td>140 lb</td>
</tr>
<tr class="odd">
<td>Charles</td>
<td>10.0”</td>
<td>6.1’</td>
<td>39”</td>
<td>145 lb</td>
</tr>
</tbody>
</table>
<ul>
<li>We <strong>can</strong> rank unambiguously on <strong>individual events</strong>: <strong>Jump</strong>: Charles <span class="math inline">\(\succ_J\)</span> Aziza <span class="math inline">\(\succ_J\)</span> Bogdan</li>
<li>Now, <strong>axioms</strong> for aggregation:
<ul>
<li><span class="math inline">\(\text{WP}\)</span> (Weak Pareto Optimality): if <span class="math inline">\(x \succ_i y\)</span> for all events <span class="math inline">\(i\)</span>, <span class="math inline">\(x \succ y\)</span></li>
<li><span class="math inline">\(\text{IIA}\)</span> (Independence of Irrelevant Alternatives): If a fourth competitor enters, but Aziza and Bogdan still have the same relative standing on all events, their relative standing overall should not change</li>
</ul></li>
<li>Long story short: only aggregation that can satisfy these is “dictatorship”: choose one event, give it importance of 100%, the rest have importance 0% 😰</li>
</ul>
</section>
<section id="propublica-vs.-northpointe" class="slide level2 smaller crunch-title">
<h2>ProPublica vs.&nbsp;Northpointe</h2>
<ul>
<li>This is… an example with 1000s of books and papers and discussions around it! (A red flag 🚩, since, obsession with one example may conceal much wider range of issues!)</li>
<li>But, tldr, Northpointe created a ML algorithm called COMPAS, used by court systems all over the US to predict “risk” of arrestees</li>
<li>In 2016, ProPublica published results from an investigative report documenting COMPAS’s racial discrimination, in the form of violating <strong>equal error rates</strong> between black and white arrestees</li>
<li>Northpointe responded that COMPAS does <strong>not</strong> discriminate, as it satisfies <strong>calibration</strong></li>
<li>People have argued about who is “right” for 8 years, with some progress, but… not a lot</li>
</ul>
</section>
<section id="so-what-do-we-do" class="slide level2 smaller crunch-title crunch-ul crunch-blockquote">
<h2>So… What Do We Do?</h2>
<ul>
<li>One option: argue about which of the two definitions is “better” for the next 100 years (what is the best way to give food to the poor?)</li>
</ul>
<blockquote>
<p>It appears to reveal an unfortunate but inexorable fact about our world: we must choose between two intuitively appealing ways to understand fairness in ML. Many scholars have done just that, defending either ProPublica’s or Northpointe’s definitions against what they see as the misguided alternative. <span class="citation" data-cites="simons_algorithms_2023">(<a href="#/references" role="doc-biblioref" onclick="">Simons 2023</a>)</span></p>
</blockquote>
<ul>
<li>Another option: study and then work to ameliorate the social conditions which <strong>force us into</strong> this realm of mathematical impossibility (why do the poor have no food?)</li>
</ul>
<blockquote>
<p>The impossibility result is about much more than math. [It occurs because] the underlying outcome is distributed unevenly in society. This is a fact about society, not mathematics, and requires engaging with a complex, checkered history of systemic racism in the US. Predicting an outcome whose distribution is shaped by this history requires tradeoffs because the inequalities and injustices are encoded in data—in this case, because America has criminalized Blackness for as long as America has existed.</p>
</blockquote>
</section>
<section id="why-not-both" class="slide level2 smaller crunch-title crunch-ul">
<h2>Why Not Both??</h2>
<ul>
<li>On the one hand: yes, both! On the other hand: <a hrf="https://en.wikipedia.org/wiki/Argument_to_moderation" target="_blank">fallacy of the “middle ground”</a></li>
<li>We’re back at <strong>descriptive vs.&nbsp;normative</strong>:
<ul>
<li><strong>Descriptively</strong>, given 100 values <span class="math inline">\(v_1, \ldots, v_{100}\)</span>, their <strong>mean</strong> may be a good way to summarize, if we have to choose a single number</li>
<li>But, <strong>normatively</strong>, imagine that these are <strong>opinions</strong> that people hold about fairness.</li>
<li>Now, if it’s the US South in 1860 and <span class="math inline">\(v_i\)</span> represents person <span class="math inline">\(i\)</span>’s approval of slavery, from a sample of 100 people, then approx. 97 of the <span class="math inline">\(v_i\)</span>’s are “does not disapprove” <span class="citation" data-cites="rousey_friends_2001">(<a href="#/references" role="doc-biblioref" onclick="">Rousey 2001</a>)</span> — in this case, normatively, is the mean <span class="math inline">\(0.97\)</span> the “correct” answer?</li>
</ul></li>
<li>We have another case where, like the “grass is green” vs.&nbsp;“grass ought to be green” example, we cannot just “import” our logical/mathematical tools from the former to solve the latter! (However: this does <strong>not</strong> mean they are <strong>useless</strong>! This is the fallacy of the <strong>excluded middle</strong>, sort of the opposite of the fallacy of the middle ground)</li>
<li>This is why we have <strong>ethical frameworks</strong> in the first place! Going back to <strong>Rawls</strong>: “97% of Americans think black people shouldn’t have rights” &nbsp;<span class="math inline">\(\nimplies\)</span>“black people shouldn’t have rights”, since rights are a <strong>primary good</strong></li>
</ul>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-blackstone_commentaries_1769" class="csl-entry" role="listitem">
Blackstone, William. 1769. <em>Commentaries on the <span>Laws</span> of <span>England</span>, <span>Volume</span> 2: <span>A Facsimile</span> of the <span>First Edition</span> of 1765-1769</em>. University of Chicago Press.
</div>
<div id="ref-datta_proxy_2017" class="csl-entry" role="listitem">
Datta, Anupam, Matt Fredrikson, Gihyuk Ko, Piotr Mardziel, and Shayak Sen. 2017. <span>“Proxy <span>Non-Discrimination</span> in <span>Data-Driven Systems</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1707.08120">https://doi.org/10.48550/arXiv.1707.08120</a>.
</div>
<div id="ref-dedeo_wrong_2016" class="csl-entry" role="listitem">
DeDeo, Simon. 2016. <span>“Wrong Side of the Tracks: <span>Big Data</span> and <span>Protected Categories</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1412.4643">https://doi.org/10.48550/arXiv.1412.4643</a>.
</div>
<div id="ref-france_lys_1894" class="csl-entry" role="listitem">
France, Anatole. 1894. <em>Le <span>Lys Rouge</span> (<span>The Red Lily</span>)</em>. G. Wells.
</div>
<div id="ref-hobbes_leviathan_1668" class="csl-entry" role="listitem">
Hobbes, Thomas. 1668. <em>Leviathan: <span>With</span> Selected Variants from the <span>Latin</span> Edition of 1668</em>. Hackett Publishing.
</div>
<div id="ref-mitchell_algorithmic_2021" class="csl-entry" role="listitem">
Mitchell, Shira, Eric Potash, Solon Barocas, Alexander D’Amour, and Kristian Lum. 2021. <span>“Algorithmic <span>Fairness</span>: <span>Choices</span>, <span>Assumptions</span>, and <span>Definitions</span>.”</span> <em>Annual Review of Statistics and Its Application</em> 8 (1): 141–63. <a href="https://doi.org/10.1146/annurev-statistics-042720-125902">https://doi.org/10.1146/annurev-statistics-042720-125902</a>.
</div>
<div id="ref-rawls_theory_1971" class="csl-entry" role="listitem">
Rawls, John. 1971. <em>A <span>Theory</span> of <span>Justice</span>: <span>Original Edition</span></em>. Harvard University Press.
</div>
<div id="ref-rousey_friends_2001" class="csl-entry" role="listitem">
Rousey, Dennis C. 2001. <span>“Friends and <span>Foes</span> of <span>Slavery</span>: <span>Foreigners</span> and <span>Northerners</span> in the <span>Old South</span>.”</span> <em>Journal of Social History</em> 35 (2): 373–96. <a href="https://www.jstor.org/stable/3790193">https://www.jstor.org/stable/3790193</a>.
</div>
<div id="ref-rousseau_social_1762" class="csl-entry" role="listitem">
Rousseau, Jean-Jacques. 1762. <em>The <span>Social Contract</span></em>. Geneva: J. M. Dent.
</div>
<div id="ref-simons_algorithms_2023" class="csl-entry" role="listitem">
Simons, Josh. 2023. <em>Algorithms for the <span>People</span>: <span>Democracy</span> in the <span>Age</span> of <span>AI</span></em>. Princeton University Press.
</div>
</div>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>DSAN 5450 Week 4: (Descriptive) Fairness in AI</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/simplemenu/simplemenu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'simplemenu': {"menubarclass":"menubar","menuclass":"menu","activeclass":"active","activeelement":"li","flat":true,"barhtml":{"header":"<div class='menubar'><span style='position: absolute; left: 8; padding-left: 8px;'><a href='./index.html'>&larr; Return to Notes</a></span><ul class='menu'></ul></div>","footer":""},"scale":0.5},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, Simplemenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
              // target, if specified
              link.setAttribute("target", "_blank");
              if (link.getAttribute("rel") === null) {
                link.setAttribute("rel", "noopener");
              }
              // default icon
              link.classList.add("external");
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>