---
title: "Week 3: Ethical Frameworks, Rights, and Discrimination"
subtitle: "*DSAN 5450: Data Ethics and Policy*<br><span class='subsubtitle'>Spring 2026, Georgetown University</span>"
author: "Jeff Jacobs"
institute: "<a href='mailto:jj1088@georgetown.edu' target='_blank'>`jj1088@georgetown.edu`</a>"
bibliography: "../_DSAN5450.bib"
date: 2026-01-28
date-format: full
lecnum: 3
categories:
  - "Class Sessions"
format:
  revealjs:
    df-print: kable
    footer: "DSAN 5450 Week 3: {{< var w03.footer >}}"
    include-in-header:
      text: "<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css'><link rel='stylesheet' type='text/css' href='https://cdn.jsdelivr.net/gh/dreampulse/computer-modern-web-font@master/fonts.css'>"
    output-file: "slides.html"
    html-math-method: mathjax
    theme: [default, "../dsan-globals/jjquarto.scss"]
    scrollable: true
    slide-number: true
    link-external-icon: true
    link-external-newwindow: true
    simplemenu:
      flat: true
      barhtml:
        header: "<div class='menubar'><span style='position: absolute; left: 8; padding-left: 8px;'><a href='./index.html'>&larr; Return to Notes</a></span><ul class='menu'></ul></div>"
      scale: 0.5
    revealjs-plugins:
      - simplemenu
  html:
    df-print: kable
    css: "../dsan-globals/jjstyles.css"
    output-file: "index.html"
    html-math-method: mathjax
---

::: {.content-visible unless-format="revealjs"}

<center>
<a class="h2" href="./slides.html" target="_blank">Open slides in new window &rarr;</a>
</center>

:::

# Schedule {.smaller .small-title .crunch-title .crunch-callout}

Today's Planned Schedule:

| | Start | End | Topic |
|:- |:- |:- |:- |
| | 3:30pm | 4:00pm | [More Toolkit &rarr;](#where-we-left-off) |
| | 4:00pm | 4:20pm | [Training Data = Human Labor &rarr;](#recap-three-component-parts-of-machine-learning) |
| | 4:20pm | 5:00pm | [Metaethics &rarr;](#metaethics) |
| **Break!** | 5:00pm | 5:10pm | |
| | 5:10pm | 5:30pm | [Individual $\leadsto$ Social Ethics &rarr;](#individual-vs.-social-morality) |
| | 5:30pm | 6:00pm | [Game Theory! &rarr;](#enter-game-theory) |

: {tbl-colwidths="[14,12,12,62]"}

# Where We Left Off: {.text-90}

<style>
@font-face {
    font-family: Monsters;
    src: url('./assets/ScaryHorror-Regular.ttf');
}
.monsters-jj {
    font-family: "Monsters", serif;
    font-size: 120%;
    color: red;
}
</style>

<i class='bi bi-1-circle'></i> Data Science for Who? ‚úÖ

<i class='bi bi-2-circle'></i> No more [Humans vs. Computers]{.monsters-jj} ($\leadsto$ Humans vs. Humans) ‚úÖ

<i class='bi bi-3-circle'></i> Operationalization ‚úÖ

<i class='bi bi-4-circle'></i> Apples-to-Apples Comparisons

<i class='bi bi-5-circle'></i> Implementation

<i class='bi bi-6-circle'></i> "Someone else's problem"?


## Operationalization {.smaller .crunch-title .crunch-li}

:::: {.columns}
::: {.column width="68%"}

* Think of claims commonly made based on "data":
  * Markets create economic prosperity
  * A glass of wine in the evening prevents cancer
  * Policing makes communities safer
* How exactly are "prosperity", "preventing cancer", "policing", "community safety" being **measured**? **Who** is measuring? Mechanisms for **feedback** $\leadsto$ **change**?

<center>
{{< video https://jpj.georgetown.domains/dsan5450-scratch/huey_trim.mp4 height="300" >}}
</center>

:::
::: {.column width="32%"}

![@stiglitz_mismeasuring_2010](images/mismeasuring.jpg){fig-align="center"}

:::
::::

## What Is Being Compared? üçé üçä üçê {.smaller .crunch-title .title-11 .crunch-ul .table-80}

| | üçé Apples üçé | üçä Oranges üçä | üçê Pears üçê |
| - | - | - | - |
| **"Countries" in General** | Polities w/250-500M people (US 335M, UP 250M, EU 450M) | LatAm Polities w/10-30M people (Venezuela, Cuba, Haiti) | Polities w/over 1 billion people (China 1.4B, India 1.4B, Africa 1.4B, N+S America 1B) |
| | Polities independent since 1776 (US) | Polities independent since 1990 (Namibia) | [Non-self-governing](https://www.un.org/dppa/decolonization/en/nsgt) polities (Puerto Rico, Palestine, New Caledonia) |
| **"Self-Sufficiency"** | Colonizing polities (US) | Polities colonized by them (Philippines) | Non-colonized polities (Ethiopia, Thailand) |
| | Polities w/infrastructure built up over [250 yrs](https://www.nps.gov/articles/000/arrival-of-the-first-africans-in-1619.htm) via slave labor (US üá∫üá∏) | Polities populated by former slaves (Liberia üá±üá∑) | Polities that [paid reparations](https://en.wikipedia.org/wiki/Reparations_Agreement_between_Israel_and_the_Federal_Republic_of_Germany) to descendants of [certain] enslaved groups (Germany) |
| **Political Systems** | Democracies (US) | Democracies til they democratically elected someone US didn't like (Iran 1953, Guatemala 1954, Chile 1973) | Non-democracies that violently repress democratic movements w/US arms (Saudi Arabia) |
| | Polities enforcing 66 yr embargo on Cuba (US) | Polities with 66 yr embargo imposed on them by US (Cuba) | Polities without 66 yr embargo imposed on them by US (...) |

: {tbl-colwidths="[10,26,32,32]"}

## How Are They Being Compared? {.crunch-title .title-09 .text-75 .crunch-quarto-layout-panel .crunch-quarto-figure .crunch-img .crunch-blockquote}

:::: {layout="[32,68]"}
::: {#india-china-left}

* What metric? Over what timespan?
* What unit of obs? Agg function? Level of aggregation?

:::
::: {#india-china-right}
::: {#sen-quote style="font-size: 64%;"}

> Comparing India's death rate of 12 per thousand with China's of 7 per thousand, and applying that difference to the Indian population of 781 million in 1986, we get an estimate of **excess normal mortality** in India of 3.9 million per year. This implies that every six years or so more people die in India because of its higher regular death rate than died in China in the gigantic famine of 1958-61. **India fills its cupboard with more skeletons every six years than China put there in its years of shame.** [@dreze_china_1991]

:::
:::
::::

:::: {#fig-life-expectancy}
::: {layout="[1,1]"}

![](images/china_india.svg){.lightbox fig-align="center"}

![](images/china_india_adjusted.svg){.lightbox fig-align="center"}

:::

Data from [UN World Population Prospects (WPP) 2024](https://population.un.org/wpp/)
::::

## Apple/Orange Criteria

:::: {layout="[1,1]" layout-valign="center"}

![](images/china_india_us.svg)

![](images/china_india_us_japan.svg)

::::

## ...There is Still Hope! I Promise! {.smaller .crunch-title .crunch-ul .crunch-blockquote .crunch-li-8}

* Apples-to-applies comparison via **Statistical Matching**:
* @lyall_divided_2020: "Treating certain ethnic groups as second-class citizens [...] leads victimized soldiers to subvert military authorities once war begins. The higher an army's inequality, the greater its rates of desertion, side-switching, and casualties"

> Matching constructs **pairs of belligerents** that are **similar** across a wide range of traits thought to dictate battlefield performance but that **vary** in levels of prewar inequality. The more similar the belligerents, the better our estimate of inequality's effects, as all other traits are shared and thus cannot explain observed differences in performance, helping assess how battlefield performance **would have** improved (declined) if the belligerent had a lower (higher) level of prewar inequality.
> 
> Since [non-matched] cases are **dropped** [...] selected cases are more representative of average belligerents/wars than outliers with few or no matches, [providing] surer ground for testing generalizability of the book's claims than focusing solely on canonical but unrepresentative usual suspects (Germany, the United States, Israel)

## Does Inequality Cause Poor Military Performance? {.smaller .crunch-title .title-10 .table-80}

| <br>Covariates | Sultanate of Morocco<br> *Spanish-Moroccan War, 1859-60* | Khanate of Kokand<br> *War with Russia, 1864-65* |
| - | - | - |
| **$X$: Military Inequality** | Low (0.01) | Extreme (0.70) |
| **$\mathbf{Z}$: Matched Covariates:** | | |
| Initial relative power | 66% | 66% |
| Total fielded force | 55,000 | 50,000 |
| Regime type | Absolutist Monarchy (‚àí6) | Absolute Monarchy (‚àí7) |
| Distance from capital | 208km | 265km |
| Standing army | Yes | Yes |
| Composite military | Yes | Yes |
| Initiator | No | No |
| Joiner | No | No |
| Democratic opponent | No | No |
| Great Power | No | No |
| Civil war | No | No |
| Combined arms | Yes | Yes |
| Doctrine | Offensive | Offensive |
| Superior weapons | No | No |
| Fortifications | Yes | Yes |
| Foreign advisors | Yes | Yes |
| Terrain | Semiarid coastal plain | Semiarid grassland plain |
| Topography | Rugged | Rugged |
| War duration | 126 days | 378 days |
| Recent war history w/opp | Yes | Yes |
| Facing colonizer | Yes | Yes |
| Identity dimension | Sunni Islam/Christian | Sunni Islam/Christian |
| New leader | Yes | Yes |
| Population | 8‚Äì8.5 million | 5‚Äì6 million |
| Ethnoling fractionalization (ELF) | High | High |
| Civ-mil relations | Ruler as commander | Ruler as commander |
| **$Y$: Battlefield Performance:** | | |
| Loss-exchange ratio | 0.43 | 0.02 |
| Mass desertion | No | Yes |
| Mass defection | No | No |
| Fratricidal violence | No | Yes |

: {tbl-colwidths="[30,35,35]"}

## Bro Snapped {.smaller .p-80 .cols-va}

*(I have no dog in this fight, I'm not trying to improve military performance of an army, but got damn)*

:::: {.columns}
::: {.column width="50%"}

![](images/lakers.gif){fig-align="center" width="500"}

:::
::: {.column width="50%"}

![](images/tuck_em_in.jpg){fig-align="center" width="400"}

:::
::::

## Implementation {.smaller .crunch-title .title-11 .crunch-quarto-layout-panel .crunch-quarto-figure .crunch-figcaption .crunch-images}

::: {layout="[1,1]"}

![From @dignazio_data_2020, Ch. 6 ([see also](https://www.insidehighered.com/news/2014/07/17/colleges-often-win-reduction-fines-federal-campus-safety-violations))](images/clery.jpg){fig-align="center"}

::: {#implementation-right}

![](images/arresting_citizenship.jpeg){fig-align="center" width="410"}

![From @lerman_arresting_2014 ([see also](https://www.aeaweb.org/articles?id=10.1257/aer.101.7.3221))](images/weaver_fig62.jpeg){fig-align="center" width="410"}

:::
:::

## Ethics of Eliciting Sensitive Linguistic Data {.smaller .crunch-title .title-11}

:::: {layout="[1,1]" layout-valign="center"}
::: {#labov-left}

![From @labov_language_2013, pg. 4](images/labov_interview.jpeg){.lightbox fig-align="center"}

:::
::: {#labov-right}

![From "80 Years On, Dominicans And Haitians Revisit Painful Memories Of Parsley Massacre", *NPR Parallels*, 7 Oct 2017 [@bishop_80_2017]](images/parsley.jpeg){.lightbox fig-align="center"}

:::
::::


## Privacy {.smaller .crunch-title .title-12 .crunch-img .crop-quarto-figure}

:::: {.columns}
::: {.column width="50%"}

![Fig 1.3: "Accuracy-Privacy Loss Tradeoff", from US Census Bureau (2021), *[Disclosure Avoidance for the 2020 Census](https://www2.census.gov/library/publications/decennial/2020/2020-census-disclosure-avoidance-handbook.pdf)*](images/accuracy-privacy-tradeoff.svg){fig-align="center" width="420"}

:::
::: {.column width="50%"}

!["Privacy-Loss Budget ($\varepsilon$) Acts as a Dial on Level of Noise"](images/census_epsilon_crop.svg){fig-align="center" width="420"}

:::
::::

![Seurat, *A Sunday Afternoon on the Island of La Grande Jatte*, [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:A_Sunday_on_La_Grande_Jatte,_Georges_Seurat,_1884.jpg)](images/seurat.jpg){fig-align="center" width="390" style="margin-top: 20px;"}

# Ethical Issues in *Applying* ML to *Particular* Problems {.crunch-title .smaller .title-09 .not-title-slide .crunch-quarto-layout-panel .crunch-quarto-figure data-stack-name="Applications"}

*(Ethical sanity check: what **problem** is this AI thing supposed to be a **solution** to?)*

<center>
![](images/airobot.jpeg){fig-align="center" width="800"}
</center>

## Facial Recognition Algorithms {.crunch-title .smaller .crunch-quarto-layout-panel .crunch-img .crunch-quarto-figure .crunch-figcaption .crunch-quarto-layout-cell .crunch-p .p-75}

*(aka AI eugenics... but I didn't say that out loud)*

::: {layout="[[1,1],[1,1]]" layout-valign="center"}

![@facia.ai_facial_2023](images/facial-recognition.webp){fig-align="center" width="400"}

![@wellcomecollection_composite_1890](images/wellcome_jewish_type_crop.jpeg){fig-align="center" width="340"}

![@ouz_google_2023](images/pixel-face-unlock.webp){fig-align="center" width="380"}

![@wang_deep_2018](images/deep_learning_gay_detection_crop.jpeg){fig-align="center" width="350"}

:::

## LLMs Encode Existing Biases {.smaller .crunch-title .crunch-img .cols-va .crunch-quarto-figure}

:::: {.columns}
::: {.column width="50%"}

![From @schiebinger_machine_2020](images/pronouns.jpg){.lightbox fig-align="center" width="75%"}

:::
::: {.column width="50%"}

![From [Google Translate](https://translate.google.com/?sl=en&tl=de&text=A%20nurse%0AA%20defendant&op=translate) (22 Jan 2025)](images/gtranslate_2025.jpg){fig-align="center"}

:::
::::

::: {#fig-chatgpt-gender .text-90}

| Prompt | Result |
| - | - |
| "Generate a reference letter for **Kelly**, a 22 year old **female** student at UCLA" | "She is an engaged **participant** in group projects, demonstrating exceptional teamwork and collaboration skills [...] a **well-liked member** of our community." |
| "Generate a reference letter for **Joseph**, a 22 year old **male** student at UCLA" | His enthusiasm and dedication have had a positive impact on those around him, making him a natural **leader** and **role model** for his peers." |

: {tbl-colwidths="[35,65]"}

@wan_kelly_2023, "Gender Biases in LLM-Generated Reference Letters"
:::

## What Is To Be Done? {.crunch-title .smaller .cols-va}

&nbsp;<br>

:::: {.columns}
::: {.column width="35%"}

<center>
When to **retain** biases...
</center>

:::
::: {.column width="65%"}

<center>
...and when to **debias**
</center>

:::
::::

:::: {.columns}
::: {.column width="40%"}

![From @kozlowski_geometry_2019](images/kozlowski_crop.jpeg){#fig-pronouns .lightbox fig-align="center"}

:::
::: {.column width="60%"}

::: {#fig-embedding-bias-right}

![](images/neutralizing.png){.lightbox fig-align="center"}
![](images/embeddings-equalizing.png){.lightbox fig-align="center"}

From DeepLearning.AI's <a href='https://www.coursera.org/lecture/nlp-sequence-models/debiasing-word-embeddings-zHASj' target='_blank'>Deep Learning course</a>
:::

:::
::::

## Recall: Military and Police Applications of AI {.crunch-title .smaller .title-11 .text-65}

[The AI Systems Directing Israel's Bombing Spree in Gaza](https://www.972mag.com/lavender-ai-israeli-army-gaza/): **Lavender** / **Where's Daddy?**

> For every junior Hamas operative that Lavender marked, it was permissible to kill up to **15 or 20 civilians**. [...] In the event that the target was a senior Hamas official with the rank of battalion or brigade commander [...] **more than 100 civilians**

> During the early stages of the war, the army gave sweeping approval for officers to adopt Lavender‚Äôs kill lists, with no requirement to thoroughly check **why the machine made those choices** or to examine the raw intelligence data on which they were based. One source stated that human personnel often served only as a "rubber stamp" for the machine‚Äôs decisions, adding that, normally, they would personally devote only about **"20 seconds" to each target** before authorizing a bombing

## Your Job: Policy Whitepaper {.crunch-title .crunch-ul}

* So is technology/data science/machine learning...
  * "Bad" in and of itself?
  * "Good" in and of itself? or
  * A tool that can be used to both "good" and "bad" ends?
* *"The master's tools will never dismantle the master's house"*... Who decided that the master "owns" the tools?
* How can we **curtail** some uses and/or **encourage** others?
* If only we had some sort of... institution... for **governing** its use in society... some sort of... **govern**... ment?

## From Week 7 On, You Work At A Think Tank {.smaller .crunch-title .title-10 .crunch-images .crunch-quarto-figure}

:::: {layout="[3,4]" layout-valign="center"}

::: {#think-tank-left}

![](images/aei_crop.jpeg){fig-align="center" width="360"}

![](images/aei2_crop.jpeg){fig-align="center" width="360"}

![@morozov_socialize_2015](images/morozov2.jpeg){fig-align="center" width="360"}

:::
::: {#think-tank-right}

![From @ames_techtopus_2014](images/techtopus.jpeg){.lightbox fig-align="center"}

:::
::::

## "Whatever You Do... Don't Be Bored" {.smaller .crunch-title .title-12}

![Clip from Richard Linklater's *[Waking Life](https://www.youtube.com/watch?v=J8jQuOjtPSQ)*](images/waking_life_dreamers.jpg){fig-align="center"}

# Machine Learning at 30,000 Feet {data-stack-name="Fair ML"}

## Three Component Parts of Machine Learning

1. A cool algorithm üòéüòç
2. [Possibly benign but possibly biased] Training data ‚ùìüßê
3. Exploitation of below-minimum-wage human labor üòûü§ê [@dube_monopsony_2020, like and subscribe yall ‚ù§Ô∏è]

## A Cool Algorithm üòéüòç {.smaller .crunch-title}

![](images/neural_network.svg){fig-align="center"}

## Context-Free Fairness {.smaller .title-12 .crunch-title}

* Who Remembers **üéâ*Confusion Matrices!!!*üéâ**
* Terrifyingly higher stakes than in DSAN 5000! Now $D = 1$ could literally mean *"shoot this person"* or *"throw this person in jail for life"*

![From @mitchell_algorithmic_2021](images/mitchell_et_al.svg){fig-align="center"}


## Categories of Fairness Criteria {.smaller .crunch-title}

```{=html}
<style>
#fairness-box .columns {
  display: flex !important;
  height: 100% !important;
}

#fairness-box .column {
  /* border: 2px solid black !important; */
  padding: 14px !important;
  box-sizing: border-box !important;
  /* height: 100% !important; */
}
</style>
```

Roughly, approaches to fairness/bias in AI can be categorized as follows:

<div id="fairness-box" style="border: 2px solid black !important; box-sizing: border-box !important;">

<center>
**Fairness**
</center>

<!-- start columns -->
::: {.columns}
::: {.column width="46%"}

<div style="border: 2px solid black !important; height: 100% !important;">
<center>
**Context-Free**
</center>

* Single-Threshold Fairness
* Equal Prediction
* Equal Decision

</div>

:::
::: {.column width="8%"}

<center>
<span style="font-size: 180% !important;"><i class='bi bi-repeat'></i>
</center>

:::
::: {.column width="46%"}

<div style="border: 2px solid black !important; height: 100% !important;">
<center style="margin: 0px !important;">
**Context-Sensitive**
</center>

* Fairness via Similarity Metric(s)
* Causal Definitions

</div>

:::
:::

</div>
<!-- end quarto box -->

* [Week 3-4] **Context-Free** Fairness: Easier to grasp from CS/data science perspective; rooted in "language" of ML (you already know much of it, given DSAN 5000!)
* But **easy-to-grasp notion** $\neq$ **"good" notion**!
* Your job: push yourself to (a) consider what is getting **left out of** the context-free definitions, and (b) the **loopholes** that are thus introduced into them, whereby people/computers can discriminate while remaining "technically fair"

## Laws: Often Perfectly "Technically Fair" (Context-Free Fairness) {.title-09}

> *Ah, la majestueuse √©galit√© des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!*
> 
> (Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)

Anatole France, *Le Lys Rouge* [@france_lys_1894]

## Context-Sensitive Fairness... üßê {.smaller .crunch-title .crunch-quarto-layout-panel .crunch-images .crunch-quarto-figure .crunch-figcaption .cols-va}

::: {#fig-amazon}

:::: {.columns}
::: {.column width="48%"}

*Decisions at Individual Level (Micro)*

![](images/dc-big-inset.png){fig-align="center"}

:::
::: {.column width="4%"}

$\leadsto$

:::
::: {.column width="48%"}

*Emergent Properties (Macro)*

![](images/dc-big-chart.png){fig-align="center"}

:::
::::

Figures from @ingold_amazon_2016, ["Amazon Doesn't Consider the Race of its Customers. Should It?"](https://www.bloomberg.com/graphics/2016-amazon-same-day/)
:::

## ...Enables INVERSE Fairness ü§Ø {.smaller .crunch-title .title-11 .cols-va}

:::: {.columns}
::: {.column width="50%"}

![From @kasy_fairness_2021, "Fairness, Equality, and Power in Algorithmic Decision-Making"](images/kasy_abebe.jpeg){#fig-kasy fig-align="center" width="95%"}

:::
::: {.column width="50%"}

![From @bjorkegren_machine_2022, "(Machine) Learning What Policymakers Value"](images/inverse_fairness.jpeg){#fig-bjorkegren fig-align="center" width="95%"}

:::
::::

## Context-Sensitive Fairness $\Leftrightarrow$ Unraveling History {.smaller .crunch-title .title-10 .crunch-ul .crunch-quarto-figure .crunch-p .crunch-blockquote .cols-va .crunch-li-8}

:::: {.columns}
::: {.column width="55%"}

* News: *"A litany of events with no beginning or end, thrown together because they occurred at the same time, cut off from **antecedents** and **consequences**"* [@bourdieu_sociology_2010]
* Do media outlets optimize for **explaining**? **Understanding**?
* Even in the eyes of the most responsible journalist I know, all media can do is point to things and say *"please, you need to study, understand, and [possibly] intervene here"*:

  > If we [journalists] have any reason for our existence, it must be our ability to report history as it happens, so that no one will be able to say, "We're sorry, we didn't know---no one told us." [@fisk_great_2005]

:::
::: {.column width="45%"}

![](images/al_durrah.jpg){fig-align="center"}

![](images/time_1982.jpg){fig-align="center" width="300"}

:::
::::

## Unraveling History {.smaller .crunch-title .title-12 .crunch-blockquote .cols-va .crunch-p}

[*(Someday I will do something with [this](https://unravelhistory.com/))*]{style="margin-bottom: 50px;"}

:::: {.columns}
::: {.column width="60%"}

> In the long evenings in West Beirut, there was time enough to consider where the core of the tragedy lay. In the age of Assyrians, the Empire of Rome, in the 1860s perhaps? In the French Mandate? In Auschwitz? In Palestine? In the rusting front-door keys now buried deep in the rubble of Shatila? In the 1978 Israeli invasion? In the 1982 invasion? Was there a point where one could have said: Stop, beyond this point there is no future? Did I witness the point of no return in 1976? That 12-year-old on the broken office chair in the ruins of the Beirut front line? Now he was, in his mid-twenties (if he was still alive), a gunboy no more. A gunman, no doubt... [@fisk_pity_1990]

:::
::: {.column width="40%"}

![[Image Source](https://www.akg-images.co.uk/CS.aspx?VP3=SearchResult&ITEMID=2UMEBM5U4433K&POPUPPN=1&POPUPIID=2UMEBM5U4433K)](images/pflp_child.jpg)

:::
::::

## Context-Sensitive Fairness $\Leftrightarrow$ Unraveling History {.smaller .crunch-title .title-10 .crunch-ul .crunch-quarto-figure .crunch-p}

*[(Reminder: Miracle of Immaculate Genocide)](#ontology-individuals-and-structures)*

:::: {.columns}
::: {.column width="50%"}

![From @cheng_art_2018 [*The Art of Logic*](https://www.youtube.com/watch?v=YHZKX0H6cUE) [plz watch if you can!]](images/cheng_plane.jpg){.lightbox fig-align="center" width="360"}

<!-- 17m 58s -->

:::
::: {.column width="50%"}

<!-- ![@giddens_central_1979](images/giddens.jpg){fig-align="center"} -->

![@sandburg_selected_1926](images/fight_you_for_it.webp){fig-align="center" width="380"}

:::
::::

## Loose Ends {.smaller .crunch-title}

* Normative vs. Descriptive **"Exploitation"**: How can we disentangle these in our understanding of the term? [@roemer_free_1988]
  * Under descriptive definition, one can "exploit" **corn** or **land** in the exact same way one "exploits" **human labor** (just another type of input into the production process)
  * Utility-wise, an economy **with** exploitation can be **unambiguously better** than one **without** exploitation: if 10 people $H$ own means of production, and 990 people $S$ own only their labor power (landless peasants, for example), allowing $H$ to exploit $S$ for a wage increases utility for both: $H$ acquires profits, $S$ doesn't starve to death
* "Tracing back" causes / **unraveling history**
  * *"The result [of modern 24-hour news cycles] is a litany of events with no beginning and no real end, thrown together only because they occurred at the same time[,] cut off from their **antecedents** and **consequenes**"* [@bourdieu_sociology_2010]

# (Recap) Three Component Parts of Machine Learning

1. [A cool algorithm ‚úÖ]{.cbg}
2. [[Possibly benign but possibly biased] Training data ‚úÖ]{.cbg}
3. $\Longrightarrow$ Exploitation of below-minimum-wage human labor üòûü§ê [@dube_monopsony_2020]

## Part 3: The "Training Data Bottleneck" {.smaller .crunch-title .crunch-quarto-layout-panel .crunch-figures .crunch-quarto-figure .title-12}

::: {layout="[1,1]"}

![](images/snorkel_1.svg){fig-align="center"}

::: {#snorkel-right}

![Snorkel.AI, <a href='assets/snorkel.pdf' target='_blank'>*An Introduction to Snorkel and Data-Centric AI*</a>](images/snorkel_2.svg){fig-align="center"}

::: {#fig-snorkel-quote}

> With so much technical progress [...] why is there so little real enterprise success? The answer all too often is that many enterprises continue to be **bottlenecked** by one key ingredient: the large amounts of **labeled data** [needed] to train these new systems.

*ibid. (PS, if it seems like I'm picking on them: these are the 'good guys' IMO! W.r.t. foregrounding training data as labor)*
:::

:::

:::

## Human Labor {.smaller .crunch-title .crunch-quarto-layout-panel .crunch-quarto-figure .crunch-figcaption}

::: {layout="[1,1]"}

::: {#fig-human-labor-left}

![](images/snorkel_human_labelers.jpg){fig-align="center" width="450"}

![](images/snorkel_training_data.jpg){fig-align="center" width="450"}

From Snorkel AI, <a href='https://www.youtube.com/watch?v=cb9DP3_QooA' target='_blank'>"The Principles of Data-Centric AI Development by Alex Ratner"</a> (YouTube)
:::
::: {#human-labor-right}

![@gray_ghost_2019](images/ghost_work.jpg){fig-align="center" width="360"}

:::
:::

## Computer Scientists Being Responsible (At Georgetown!) {.smaller .crunch-title .crunch-iframe .title-09}

![<a href='https://gufaculty360.georgetown.edu/s/course-catalog/a1oHp00000GvwGnIAJ/cosc882001?id=003Hp00002jN3TsIAK' target='_blank'>GU360 Course Page</a>](images/dr_redmiles_class.jpeg){fig-align="center"}

* *(PS... UMD undergrad CS class of 2013 extremely overrepresented here* üòú *go Terps)*

## So, What Comes With Human Labels? Human Biases! {.smaller .title-10 .crunch-quarto-layout-panel .crunch-quarto-figure .crunch-title .crunch-ul .crunch-figcaption}

::: {layout="[2,1]" layout-valign="center"}

![@crawford_excavating_2019](images/imagenet_jezebel.jpg){fig-align="center" width="660"}

![Image tagged in ImageNet with the label **"BOLSHEVIK"**. From @crawford_excavating_2019](images/bolshevik.JPEG){fig-align="center"}

:::

## Biases In Our Brains $\rightarrow$ Biases in Our Models $\rightarrow$ Material Effects {.smaller .crunch-title .title-08 .crunch-p .crunch-quarto-layout-panel .crunch-ul}

::: {layout="[1,1]"}

::: {#biases-text}

* **"Reification"**: Pretentious word for an important phenomenon, whereby talking about something (e.g., race) *as if* it was real ends up leading to it **becoming real** (having real impacts on people's lives)^[@fields_racecraft_2012, for example, coined **"racecraft"** to describe reification of blackness in US... *much* more on this later!]

> On average, being classified as a White man as opposed to a Coloured man would have more than quadrupled a person's income. [@pellicer_understanding_2023]

![](images/permit_crop.jpeg){fig-align="center"}

:::

![](images/passport.webp){fig-align="center" width="380"}

:::

## Reification in Science {.crunch-title .crunch-quarto-layout-panel .crunch-figcaption}

::: {layout="[1,1]"}

::: {#intelligence-testing}

<center>*"""Intelligence""" Testing*</center>

![@gould_mismeasure_1980](images/mismeasure.webp){fig-align="center" width="340"}

:::
::: {#goodhart}

<center>*More Generally*</center>

* <a href='https://en.wikipedia.org/wiki/Goodhart%27s_law' target='_blank'>Goodhart's Law</a>: "When a measure becomes a target, it ceases to be a good measure"
* Cat-and-mouse game between **goals** (üö©) and ways of **measuring** progress towards goals (also üö©)

:::
:::

# Metaethics {data-stack-name="Metaethics"}

A scary-sounding word that just means:

> "What we talk about when we talk about ethics",

in contrast to

> "What we talk about when we talk about [insert particular ethical framework here]"

## Reflective Equilibrium {.crunch-title}

* Most criticisms of any framework boil down to, "great in theory, but doesn't work in practice"
* The way to take this seriously: **reflective equilibrium** 
* Introduced by @rawls_outline_1951, but popularized by @rawls_theory_1971

![From @awad_computational_2022](images/reflective.jpg){fig-align="center"}

# Descriptive vs. Normative Judgements {.not-title-page .title-11}

| Descriptive (Is) | Normative (Ought) |
| - | - |
| Grass is green (true) | Grass ought to be green (?) |
| Grass is blue (false) | Grass ought to be blue (?) |

## Easy Mode: Descriptive Judgements {.smaller .crunch-title .crunch-p}

**How did you acquire the concept "red"?**

* People pointed to stuff with certain properties and said "red" (or "rojo" or "Á∫¢"), as pieces of an **intersubjective** communication system
* These **descriptive** labels enable *coordination*, like driving on left or right side of road!
* Nothing very profound or difficult in **committing** to this descriptive coordination: *"for **ease of communication**, I'll vibrate my vocal chords like this (or write these symbols) to indicate $x$, and vibrate them like this (or write these other symbols) to indicate $y$"*
<!-- * Technically you have the free will to **refuse** this prescription. But, nothing very "" -->
* Linguistic choices, when it comes to **description**, are arbitrary*: Our mouths can make [these sounds](https://en.wikipedia.org/wiki/International_Phonetic_Alphabet), and each language is a mapping: [combinations of sounds] $\leftrightarrow$ [things]
  * diÀêsÀà√¶n Ààf…™fti f…îr Ààf…™fti [US Accent](https://ipa-reader.com/?text=di%CB%90s%CB%88%C3%A6n%20%CB%88f%C9%AAfti%20f%C9%94r%20%CB%88f%C9%AAfti) / [Icelandic Accent](https://ipa-reader.com/?text=dis%C3%A6n%CB%88f%C9%AAfdif%C9%94%C9%B9%CB%88f%C9%AAfti&voice=Dora)

<!-- dis√¶nÀàf…™fdif…î…πÀàf…™fti  / dis√¶nÀàf…™fdif…î…πÀàf…™fti -->
<!-- * Our lives/the world would not be very different if "red" was switched with "green"; i.e., the main change would just be vibrating different vocal chords or writing different symbols to communicate the concept -->

::: {.aside}

\**(Tiny text footnote: Except for, perhaps, a few <a href='https://en.wikipedia.org/wiki/Bouba/kiki_effect' target='_blank'>fun but rare onomatopoetic cases</a>)*

:::

## What Makes Ethical Judgements "More Difficult"? {.smaller .title-11 .crunch-title .crunch-p}

**How did you acquire the concept "good"?**

* People pointed to **actions** with certain properties and said "good" (and pointed at others and said "bad"), as part of instilling **values** in you
* "Grass is green" just links two **descriptive** referents together, while "Honesty is good" takes the **descriptive** concept "honesty" and *links it* with the **normative** concept "good"
* In doing this, parents/teachers/friends are doing way more than just linking sounds and things in the world (**de**scribing): they are also **prescribing** rules of moral conduct!
* **Normative** concepts go beyond "mere" communication: course of your life / future / [things that matter deeply to people] differ if you **act on** one set of norms vs. another
* $\implies$ Ethics centrally involves non-arbitrarily-chosen **commitments**!

## Tl;dr {.crunch-title .crunch-ul .crunch-figcaption .crunch-quarto-figure}

:::: {.columns}
::: {.column width="62%"}

* **Languages** are **arbitrary conventions** for communication
* **Ethical systems** **build on** this language to **non-arbitrarily** mark out things that are good/bad
* Society **wouldn't** be too different if we "shuffled" words (we'd just vibrate our vocal chords differently), but **would** be very different if we "shuffled" good/bad labeling

:::
::: {.column width="38%"}

![@hare_language_1952](images/hare_morals.jpg){fig-align="center" width="330"}

:::
::::

## Quick Aside: Top 10 Linguist Beefs {.smaller .crunch-title .crunch-figcaption .crunch-quarto-layout-panel .crunch-ul .crunch-images}

* Statement on previous slide (*"Life would not be very different if we shuffled words"*), might seem weird/closed-minded/dismissive if you have a certain popular prior belief...

::: {layout="[1,1]"}

![@deutscher_language_2010](images/language_glass.jpg){fig-align="center" width="300"}

![@mcwhorter_language_2014](images/language_hoax.jpg){fig-align="center" width="325"}

:::

## The Last Time I Use This, I Promise

![](images/yells_at_sapir.jpeg)

## Historical Example: Capitalism and the "Protestant Ethic" {.crunch-title .smaller .title-09 .crunch-quarto-layout-panel .crunch-p .crunch-ul .crunch-quarto-layout-cell .crunch-blockquote}

* Big changes in history are associated with changes in this **good/bad labeling**!
* Max Weber (<a href='https://www.researchgate.net/figure/Top-50-sociologists-according-to-aggregate-weighted-citation-scores-normalized-score_fig1_332447162' target='_blank'>second most-cited</a> sociologist of all time\*): *Protestant value system* gave rise to *capitalist system* by **relabeling what things are good vs. bad** [@weber_protestant_1904]:

::: {layout="[1,1]"}

::: {#bible-money}

> Jesus said to his disciples, "Truly, I say to you, only with difficulty will a rich person enter the kingdom of heaven. Again I tell you, it is easier for a camel to go through the eye of a needle than for a rich person to enter the kingdom of God." (<a href='https://www.biblegateway.com/passage/?search=Matthew%2019&version=ESV' target='_blank'>Matthew 19:23-24</a>)

> Oh, were we loving God worthily, we should have **no love at all for money!** [@st.augustine_works_1874, pg. 28]

&nbsp;<br>

[\**(...jumpscare: REIFICATION!)*]{.fn-span}

:::
::: {#protestant-ethic}

> The earliest capitalists lacked legitimacy in the moral climate in which they found themselves. One of the means they found [to legitimize their behavior] was to appropriate the **evaluative vocabulary** of Protestantism. [@skinner_visions_2012, pg. 157]

> Calvinism added [to Luther's doctrine] the necessity of **proving one's faith** in worldly activity, [replacing] spiritual aristocracy of monks outside of/above the world with spiritual aristocracy of predestined saints within it. (pg. 121). 

:::
:::

## Aggressively Tossing Books at Your Head {.smaller .crunch-title .title-12}

:::: {.columns}
::: {.column width="50%"}

* (Reminder that there are no **required** readings, but that this means you should pick a few which seem mildly interesting to you and try them out, as first step towards final paper **lit review!** üòâ)
* Also, we'll be bringing this Hirschman guy back into the mix when we get to **policy**:  specifically, his earlier book, *Exit, Voice, and Loyalty* [@hirschman_exit_1970]

:::
::: {.column width="50%"}

![@hirschman_passions_1977](images/hirschman.jpg){fig-align="center" width="350"}

:::
::::

## Contemporary Example: Palestine {.smaller .crunch-quarto-layout-panel .crunch-title .crunch-ul .crunch-blockquote .crunch-li .crunch-p}

* Very few of the relevant **empirical** facts are in dispute, since opening of crucial archives to three so-called "New Historians" in the 1980s. So why do people still argue?

::: {layout="[1,1]"}
::: {#pappe-text}

* **Ilan Pappe**, one of these historians, concluded from this material that:
  * The Israeli state was built upon a massive ethnic cleansing, and
  * Is not morally justifiable [@pappe_ethnic_2006]

> The immunity Israel has received over the last fifty years encourages others, regimes and oppositions alike, to believe that human and civil rights are irrelevant in the Middle East. The dismantling of the mega-prison in Palestine will send a different, and more hopeful, message.

:::
::: {#morris-text}

* **Benny Morris**, another of these historians, concluded that:
  * The Israeli state was built upon a massive ethnic cleansing, and
  * Is morally justifiable [@morris_birth_1987]

> A Jewish state would not have come into being without the uprooting of 700,000 Palestinians. Therefore it was necessary to uproot them. There was no choice but to expel that population. It was necessary to cleanse the hinterland and cleanse the border areas and cleanse the main roads.

<!-- [...] The term "cleanse" doesn't sound nice but that's the term they used at the time. I adopted it from the 1948 documents. -->

:::
:::

# Individual Ethics $\rightarrow$ Social Ethics {data-stack-name="Individual vs. Social Ethics"}

## Standard Counterargument to Consequentialism {.crunch-title .title-07 .crunch-quarto-layout-panel .crunch-ul .crunch-quarto-figure .crunch-images .crunch-blockquote}

::: {layout="[1,1]"}

::: {#omelas-text}

> Millions are kept permanently happy, on the one simple condition that a certain lost soul on the far-off edge of things should lead a life of lonely torture [@james_moral_1891]

* Modern example: people "out there" suffer so we can have iPhones, etc.

:::

![@leguin_ones_1973](images/omelas.jpg){fig-align="center" width="360"}

:::

## One Solution: Individual Rights {.smaller .crunch-title .crunch-quarto-layout-panel .crunch-quarto-figure .crunch-figcaption .crunch-images .crunch-math .crunch-ul}

::: {layout="[2,1]" layout-valign="center"}

::: {#rights-text}

* Rights are **vetoes** which **individuals** can use to cancel out **collective**/institutional decisions which affect them (key example for us: right to **privacy**)
* Rawls/liberalism: individual rights are **lexically prior to** "efficiency" and/or distributional concerns
* Why the buzzword "lexically"? Enter (non-scary) math!
* We can put *lowercase* letters of English alphabet in an **order**: $\texttt{a} \prec \texttt{b} \prec \cdots \texttt{z}$
* We can put *capital* letters of English alphabet in an order: $\texttt{A} \prec \texttt{B} \prec \cdots \prec \texttt{Z}$
* What if we need to sort stuff with **both** types? We can decide that capital letters are **lexically prior** to lowercase letters, giving us a combined ordering:

:::

![@dworkin_taking_1977](images/dworkin.jpg){fig-align="center" width="300"}

:::

$$
\boxed{\texttt{A} \prec \texttt{B} \prec \cdots \prec \texttt{Z} \prec \texttt{a} \prec \texttt{b} \prec \cdots \prec \texttt{z}}
$$

## Lexical Ordering (I Tricked You üòà)

::: {layout="[2,1]"}
::: {#trick-left}

* You thought I was just talking about *letters*, but they're actually **variables**: capital letters are rights, lowercase letters are distributive principles

$$
\underbrace{\texttt{A} \prec \texttt{B} \prec \cdots \prec \texttt{Z}}_{\mathclap{\substack{\text{Individual Rights} \\ \text{Basic Goods}}}} \phantom{\prec} \prec \phantom{\prec} \underbrace{\texttt{a} \prec \texttt{b} \prec \cdots \prec \texttt{z}}_{\mathclap{\substack{\text{Distributive Principles} \\ \text{Money and whatnot}}}}
$$

:::
::: {#trick-right}

![](images/atrick_nocap.jpg){fig-align="center"}

:::
:::

## Better Metaphor Than Letters {.smaller .crunch-title .crunch-ul .crunch-math .crunch-quarto-figure}

* Letters are where Rawls gets "lexically prior" from, but letters are **total orderings** (we know where *every* letter "stands" in relation to *every* other letter)
* Better metaphor: a **high school** with a hierarchy such that

$$
\text{Seniors} \prec \text{Juniors} \prec \text{Sophomores}  \prec \text{Freshmen} 
$$

* $\implies$ If you're a Freshman, whether at the "top" or "bottom" of a ranking of Freshmen, you're still **prior to** all Sophomores...
* Why is this more helpful? Because **we don't need to define** the **rankings *within* classes** to know the **rankings *between* classes** in this case

![](images/ordinal_numbers.svg){fig-align="center" width="300"}

## Counterargument(s) to Deontology {.smaller .crunch-title .crunch-ul .crunch-figcaption .shift-ul .crunch-li-3 .crunch-images}

::: {layout="[7,3]"}
::: {#deontology-counter-left}

* Deontological **rule**: *"Don't lie"*
  * But then: Nazis come to your house, ask you if you're harboring any Jews
* k, new deontological **rule**: *"Don't lie unless necessary"*
  * Who decides when it's necessary?
* Deontological commitment: *Pacifism / Nonviolence*
  * But then: someone swingin on you
* k, new deontological **commitment**: *Pacifism / Nonviolence Except In Self-Defense*
  * Who decides what counts as self-defense?
* (Trolley problems, etc.)

:::
::: {#deontology-counter-right}

![@churchill_pacifism_1998 *(Derrick Jensen intro removed from later editions so I [put it on dang GitHub](https://github.com/jpowerj/mdb/blob/main/1998_Churchill_PacifismAsPathology.md)*](images/pacifism.jpg){fig-align="center" width="340"}

:::
:::

## A Synthesis: Two-Level Utilitarianism {.title-09 .crunch-title .crunch-quarto-layout-panel .crunch-quarto-figure .crunch-images .crunch-figcaption}

::: {layout="[1,1]"}

::: {#two-level-text}

* It would be exhausting to compute Nash equilibrium strategies for every scenario
* Instead, we can develop **heuristics** that work for most cases, then **reevaluate** and **update** when we encounter tough cases
* (Brings us back to **reflective equilibrium**!)

:::

![@kahneman_thinking_2011](images/thinking.jpg){fig-align="center" width="350"}

:::

## Individual vs. Social Morality {.smaller .crunch-title .crunch-ul .crunch-figcaption .crunch-images .crunch-quarto-figure}

* That was all already hard enough, to reason about **individual** morality
* Now add in the fact that we live in a society üò∞
* Things that happen depend not only on **our** choices but also the choices of others

[![<a href='https://www.youtube.com/watch?v=LHhbdXCzt_A' target='_blank'>Seinfeld: Living in a Society (Clip) | TBS</a>](images/seinfeld_society.jpeg){fig-align="center" width="700"}](https://www.youtube.com/watch?v=LHhbdXCzt_A)

## Enter Game Theory {.smaller .crunch-title .crunch-quarto-layout-panel .crunch-figcaption .crunch-ul}

* A tool for analyzing how **individual choices** + **choices of others** $\rightarrow$ **outcomes**!

::: {layout="[1,1]" layout-valign="center"}

::: {#game-theory-text}

* Example: You ($A$) and a friend ($B$) committed a robbery, and you're brought into the police station for questioning.
* You're placed in separate rooms, and each of you is offered a **plea deal**: if you **testify** while your partner **stays silent**, you go free and they go to jail for 3 years.
* Otherwise, if you **both stay silent**, they have very little evidence and can only jail you for **1 year**
* However, there's a catch: if you **both confess**, you both get **two years** in jail, since they now have maximal evidence

:::

![Source: <a href='https://commons.wikimedia.org/wiki/File:Prisoners_dilemma.svg' target='_blank'>Wikimedia Commons</a>](images/prisoners_dilemma.svg){fig-align="center"}

:::

## Individual Decision-Making {.smaller .title-11}

::: {layout="[1,1]" layout-valign="center"}

::: {#step-by-step}

* Let's think through $A$'s **best responses** to the possible choices $B$ could make:
* If $B$ **stays silent**, what is $A$'s best option?
  * **Staying silent** results in **1 year** of jail
  * **Testifying** results in **0 years** of jail
  * So it is **better to testify**
* If $B$ **testifies**, what is $A$'s best option?
  * **Staying silent** results in **3 years** of jail
  * **Testifying** results in **2 years** of jail
  * So it is **better to testify**
* The result: **regardless of what $B$ does**, $A$ is **better off testifying**!

:::

![Source: <a href='https://commons.wikimedia.org/wiki/File:Prisoners_dilemma.svg' target='_blank'>Wikimedia Commons</a>](images/prisoners_dilemma.svg){fig-align="center"}

:::

## The Social Outcome {.crunch-title .crunch-ul}

::: {layout="[1,1]" layout-valign="center"}

::: {#social-outcome-text}

* The game is **symmetric**, so the same logic applies for $B$
* Conclusion: **the outcome of the game will be $s^* = (\text{Testify}, \text{Testify})$**
* This is called a **Nash equilibrium**: no player $i$ can make themselves better off by **deviating** from $s_i$

:::

![Source: <a href='https://commons.wikimedia.org/wiki/File:Prisoners_dilemma.svg' target='_blank'>Wikimedia Commons</a>](images/prisoners_dilemma.svg){fig-align="center"}

:::

## How Do We Fix This? *Conventions!* {.crunch-title .inline-08 .crunch-quarto-layout-cell .crunch-quarto-layout-panel}

::: {layout="[1,1]" layout-valign="center"}

::: {#conventions-left}

* We encounter this type of problem every day if we **drive**! You ($A$) and another driver ($B$) arrive at an **intersection**:

:::

```{=html}
<table class='game-table'>
<thead>
</thead>
<tbody>
<tr>
  <td class='game-label'></td>
  <td class='game-label'></td>
  <td colspan="2" align="center" class='game-label'><span data-qmd="$B$"></span></td>
</tr>
<tr>
  <td class='game-label'></td>
  <td class='game-label'></td>
  <td class='game-label'>Stop</td>
  <td class='game-label'>Drive</td>
</tr>
<tr>
  <td rowspan="2" style="vertical-align: middle;" class='game-label td-no-bottom'><span data-qmd="$A$"></span></td>
  <td class='game-label'>Stop</td>
  <td class='game-cell'><span data-qmd="$-1,-1$"></span></td>
  <td class='game-cell'><span data-qmd="$-3,\phantom{-}0$"></span></td>
</tr>
<tr>
  <td class='game-label'>Drive</td>
  <td class='game-cell'><span data-qmd="$\phantom{-}0, -3$"></span></td>
  <td class='game-cell'><span data-qmd="$-10,-10$"></span></td>
</tr>
</tbody>
</table>
```

:::

* If **both stop**, we're mostly bored: $u_A = -1$
* If we stop and the other person drives, we're mad that they got to go and we didn't: $u_A = -3$
* If **both drive**, we crash: $u_A = -10$

## Without A Convention {.smaller .crunch-title .crunch-quarto-layout-panel .crunch-ul .crunch-math}

::: {layout="[6,4]" layout-valign="center"}

::: {#no-convention-text}

* We're "frozen": this game has **no unique Nash equilibrium**, so we cannot say (on the basis of individual rationality) what will happen!
* Without a convention: **power**/aggression takes over. "War of all against all", only the strong survive, etc. (life is "nasty, brutish, and short")

:::
::: {#no-convention-table}

```{=html}
<table class='game-table'>
<thead>
</thead>
<tbody>
<tr>
  <td class='game-label'></td>
  <td class='game-label'></td>
  <td colspan="2" align="center" class='game-label'><span data-qmd="$B$"></span></td>
</tr>
<tr>
  <td class='game-label'></td>
  <td class='game-label'></td>
  <td class='game-label'>Stop</td>
  <td class='game-label'>Drive</td>
</tr>
<tr>
  <td rowspan="2" style="vertical-align: middle;" class='game-label no-bottom-border'><span data-qmd="$A$"></span></td>
  <td class='game-label'>Stop</td>
  <td class='game-cell'><span data-qmd="${\color{orange}\cancel{\color{black}-1}},{\color{lightblue}\cancel{\color{black}-1}}$"></span></td>
  <td class='game-cell'><span data-qmd="$\boxed{-3},\boxed{0}$"></span></td>
</tr>
<tr>
  <td class='game-label'>Drive</td>
  <td class='game-cell'><span data-qmd="$\boxed{0}, \boxed{-3}$"></span></td>
  <td class='game-cell'><span data-qmd="${\color{orange}\cancel{\color{black}-10}},{\color{lightblue}\cancel{\color{black}-10}}$"></span></td>
</tr>
</tbody>
</table>
```

:::
:::

* If $A$'s aggression is $\Pr(s_A = \textsf{Drive}) = X \sim \mathcal{U}[0,1]$, $B$'s aggression is $\Pr(s_B = \textsf{Drive}) = Y \sim \mathcal{U}[0,1]$, what happens at individual and societal levels?

$$
\begin{align*}
\mathbb{E}[u_A] = \mathbb{E}[u_B] &= \int_{0}^{1}\int_{0}^{1}\left(x - 2y -8xy - 1\right)dy \, dx = -3.5 \\
\underbrace{\mathbb{E}\mkern-3mu\left[u_A + u_B\right]}_{\mathclap{\text{Utilitarian Social Welfare}}} &= -3.5
\end{align*}
$$

## The Convention of Traffic Lights {.smaller .crunch-title}

* If we don't want a world where $\text{Happiness}(i) \propto \Pr(i \text{ more aggro than }j)$, we can introduce **traffic lights**: 

::: {layout="[1,1]"}
::: {#traffic-light-text}

* Now in **"correlated equilibrium"**, where we ensure* coordinated $\Pr((\textsf{Drive}, \textsf{Stop})) = 0.5$, $\Pr((\textsf{Stop}, \textsf{Drive})) = 0.5$
* $\mathbb{E}[u_A] = (0.5)(0) + (0.5)(-3) = -1.5$
* $\mathbb{E}[u_B] = (0.5)(-3) + (0.5)(0) = -1.5$

:::
::: {#traffic-light-table}

```{=html}
<table class='game-table'>
<thead>
</thead>
<tbody>
<tr>
  <td class='game-label'></td>
  <td class='game-label'></td>
  <td colspan="2" align="center" class='game-label'><span data-qmd="$B$"></span></td>
</tr>
<tr>
  <td class='game-label'></td>
  <td class='game-label'></td>
  <td class='game-label'>Stop</td>
  <td class='game-label'>Drive</td>
</tr>
<tr>
  <td rowspan="2" style="vertical-align: middle;" class='game-label no-bottom-border'><span data-qmd="$A$"></span></td>
  <td class='game-label'>Stop</td>
  <td class='game-cell'><span data-qmd="${\color{orange}\cancel{\color{black}-1}},{\color{lightblue}\cancel{\color{black}-1}}$"></span></td>
  <td class='game-cell'><span data-qmd="$\boxed{-3},\boxed{0}$"></span></td>
</tr>
<tr>
  <td class='game-label'>Drive</td>
  <td class='game-cell'><span data-qmd="$\boxed{0}, \boxed{-3}$"></span></td>
  <td class='game-cell'><span data-qmd="${\color{orange}\cancel{\color{black}-10}},{\color{lightblue}\cancel{\color{black}-10}}$"></span></td>
</tr>
</tbody>
</table>
```

:::
:::

* Empirical (anthropological) findings across literally thousands of different cultures throughout the world: people are willing to **give up rewards** to **ensure fairness** (see, e.g., @henrich_search_2001)

[\**(through, for example, traffic laws: equal in theory... In practice? Another story)*]{.fn-span}

## So How Should We Make/Choose Conventions? {.title-08}

* @hobbes_leviathan_1668: Only way out of "war of all against all" is to surrender all power to one **sovereign** (the *Leviathan*)
* @rousseau_social_1762: Social contract
* *[Big big ~200 year gap here... can you think of why? Hint: French Revolution in 1789]*
* @rawls_theory_1971: Social contract **behind the "veil of ignorance"**
  * If we didn't know **where we were going to end up** in society, how would we set it up?
<!-- * @dworkin_what_1981: Yes, plus also people can **buy insurance** against ending up in a bad place $\rightarrow$ level of "just" redistribution -->

## Rawls' Veil of Ignorance {.crunch-title}

* Probably the most important tool for policy whitepapers!
* "Justice as fairness" (next week: fairness in AI üòú)
* We don't know whether we'll be $A$ or $B$ in the intersection game, so we'd choose the **traffic light**!
* More profoundly: We don't know what **race**, **gender**, **class**, **ethnicity**, **sexuality**, **disability status** we'll have; We don't know whether we'll be **Israeli** or **Palestinian**; we don't know whether we'll own **means of production** or own only our **labor power** (and thus have to sell it on a market to survive)... ü§î

# Nuts and Bolts for Fairness {data-stack-name="Fairness"}

## One Final Reminder {.crunch-title}

* Industry rule #4080: Cannot "prove" $q(x) = \text{``Algorithm }x\text{ is fair''}$! Only $p(x) \implies q(y)$:

$$
\underbrace{p(x)}_{\substack{\text{Accept ethical} \\ \text{framework }x}} \implies \underbrace{q(y)}_{\substack{\text{Algorithms should} \\ \text{satisfy condition }y}}
$$

* Before: **possible ethical frameworks** (values for $x$)
* Now: **possible fairness criteria** (values for $y$)

## Categories of Fairness Criteria {.smaller .crunch-title}

```{=html}
<style>
#fairness-box .columns {
  display: flex !important;
  height: 100% !important;
}

#fairness-box .column {
  /* border: 2px solid black !important; */
  padding: 14px !important;
  box-sizing: border-box !important;
  /* height: 100% !important; */
}
</style>
```

Roughly, approaches to fairness/bias in AI can be categorized as follows:

<div id="fairness-box" style="border: 2px solid black !important; box-sizing: border-box !important;">

<center>
**Fairness**
</center>

<!-- start columns -->
::: {.columns}
::: {.column width="46%"}

<div style="border: 2px solid black !important; height: 100% !important;">
<center>
**Context-Free**
</center>

* Single-Threshold Fairness
* Equal Prediction
* Equal Decision

</div>

:::
::: {.column width="8%"}

<center>
<span style="font-size: 180% !important;"><i class='bi bi-repeat'></i>
</center>

:::
::: {.column width="46%"}

<div style="border: 2px solid black !important; height: 100% !important;">
<center style="margin: 0px !important;">
**Context-Sensitive**
</center>

* Fairness via Similarity Metric(s)
* Causal Definitions

</div>

:::
:::

</div>
<!-- end quarto box -->

* [Today] **Context-Free** Fairness: Easier to grasp from CS/data science perspective; rooted in "language" of Machine Learning (you already know much of it, given DSAN 5000!)
* But **easy-to-grasp notion** $\neq$ **"good" notion**!
* Your job: push yourself to (a) consider what is getting **left out of** the context-free definitions, and (b) the **loopholes** that are thus introduced into them, whereby people/computers can discriminate while remaining "technically fair"

## Laws: Often Perfectly "Technically Fair" {.title-09}

> *Ah, la majestueuse √©galit√© des lois, qui interdit au riche comme au pauvre de coucher sous les ponts, de mendier dans les rues et de voler du pain!*

> (Ah, the majestic equality of the law, which prohibits rich and poor alike from sleeping under bridges, begging in the streets, and stealing loaves of bread!)

Anatole France, *Le Lys Rouge* [@france_lys_1894]

# Context-Free Fairness {.smaller .not-title-slide .crunch-title}

![From <a href='https://www.cs.sfu.ca/~anoop/courses/MACM-300-Spring-2006/complexity.pdf' target='_blank'>*Introduction to Formal Languages and Automata*</a>, Simon Fraser University (2006). This figure summarizes the **Chomsky Hierarchy** of Languages, developed by Noam Chomsky, who also has a lot to say about Ethics and Policy!](images/chomsky-hierarchy.jpeg){.no-stretch fig-align="center" width="200"}

## The Brogrammer's Criterion {.crunch-title .crunch-ul}

```python
df.drop(columns=["race"], inplace=True)
```

* Racism solved, folks! ü•≥üéäüéâ End of the course, have a great rest of your data science career ‚úåÔ∏è

![](images/flocka.jpeg){fig-align="center"}

## (No) Fairness Through Unawareness {.smaller .crunch-title .crunch-ul .crunch-figcaption}

* **HW1**: Using tiny sample ($N < 10K$) of Florida voter registrations... <a href='https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html' target='_blank'>RandomForestClassifier</a> (default settings, no hyperparameter tuning, no cross-validation, no ensembling with other methods) will predict self-reported race with $>90\%$ accuracy (in balanced sample) from just **surname** and **county of residence**
  * Can reach $70\text{-}75\%$ with **just** surname or **just** county of residence
* Also in HW1: **Facebook** ad matching service provides **over 1,000 different user attributes** for **(micro)targeting**

![From @datta_proxy_2017](images/proxy.svg){fig-align="center"}

## To Make It Even More Concrete... {.smaller .crunch-title}

* *Bloomberg* analysis of neighborhoods with same-day delivery from Amazon:

::: {#fig-bloomberg layout="[1,1,1]" layout-valign="center"}

![](images/amazon-six-cities-at.png){fig-align="center"}

![](images/amazon-six-cities-ch.png){fig-align="center"}

![](images/amazon-six-cities-dc.png){fig-align="center"}

Figures from @ingold_amazon_2016
:::

## We Can Do (A Bit) Better... {.smaller}

* Use **random variables** to model inferences made by an algorithm (or a human!)
* $\implies$ fairness by statistically **equalizing** loan rejections, error rate, etc. between groups
* Obvious **societal** drawback: **equality** does not ameliorate the effects of **past injustices** (see: police contact vs. trust-in-government plot from last week)
  * This one we saw coming, given "context-free" nature!
* Less obvious **mathematical** drawback: **impossibility results** (because algebra üò≥)
  * Roughly: can't satisfy [more than] two statistical fairness criteria at once; similar to how setting $\Pr(X) = p$ also determines $\Pr(\text{not }X) = 1 - p$, or how plugging $x = 3$ into $x + y = 5$ leaves only one possibility $y = 2$
* **BUT**, "impossibility" $\neq$ impossibility: (a) one criteria may be "all you need" in given setting; (b) can derive **more robust** measures by "relaxing" confusion-matrix measures

## What the Fairness Measures Will Feel Like For Now {.smaller .crunch-title .title-10}

![](images/rock_on_rich_brian.jpeg){fig-align="center"}

* (They will get more robust and will **incorporate context** soon, I promise!)

## Who Remembers... üéâ*Confusion Matrices!!!*üéâ {.smaller .crunch-title .title-11}

* Terrifyingly higher stakes than in DSAN 5000, however!
* Now $D = 1$ could literally mean *"shoot this person"* or *"throw this person in jail for life"*

![From @mitchell_algorithmic_2021](images/mitchell_et_al.svg){fig-align="center"}

## Our First Fairness Measure (Finally)! {.crunch-title .smaller .crunch-ul .crunch-math}

* Standard across the literature: Random Variable $A_i$ "encoding" membership in protected/sensitive group. In HW1, for example:

$$
A_i = \begin{cases}
0 &\text{if }i\text{ self-reported ``white''} \\
1 &\text{if }i\text{ self-reported ``black''}
\end{cases}
$$

* **Notice**: choice of mapping into $\{0, 1\}$ here **non-arbitrary**!
* We want our models/criteria to be **descriptively** but also **normatively robust**; e.g.:
* **If** (antecedent I hold, though <a href='https://www.pewresearch.org/politics/2021/08/12/deep-divisions-in-americans-views-of-nations-racial-history-and-how-to-address-it/' target='_blank'>majority in US</a> do not) one believes that ending (much less repairing) centuries of unrelenting white supremacist violence here might require asymmetric race-based policies,
* **Then** our model should allow different **normative labels** and differential **weights** on

  $$
  \begin{align*}
  \Delta &= (\text{Fairness} \mid A = 1) - (\text{Fairness} \mid A = 0) \\
  \nabla &= (\text{Fairness} \mid A = 0) - (\text{Fairness} \mid A = 1)
  \end{align*}
  $$

  despite the **descriptive** fact that $\Delta = -\nabla$.

## Where Descriptive and Normative Become Intertwined {.crunch-title .title-07}

* Allowing this **asymmetry** is precisely what enables bring **descriptive** facts to bear on **normative** concerns!
* **Mathematically** we can always "flip" the mapping from racial labels into $\{0, 1\}$...
* But this (in a precise, mathematical sense: namely, *isomorphism*) implies that we're treating **racial categorization** as the same type of phenomenon as **driving on left or right side of road** (see: prev slides on why we make the descriptive vs. normative distinction)
* (See also: Sweden's <a href='https://en.wikipedia.org/wiki/Dagen_H' target='_blank'>Dagen H</a>!)

## "Fairness" Through Equalized *Positive* Rates {.crunch-title .crunch-ul .title-08 .math-90}

$$
\Pr(D = 1 \mid A = 0) = \Pr(D = 1 \mid A = 1)
$$

* This works specifically for discrete, **binary**-valued categories
* For general attributes (whether discrete or continuous!), generalizes to:

$$
D \perp A \iff \Pr(D = d, A = a) = \Pr(D = d)\Pr(A = a)
$$

## "Fairness" Through Equalized *Error* Rates {.smaller .crunch-title .title-12}

* Equalized **False Positive Rate**:

$$
\Pr(D = 1 \mid Y = 0, A = 0) = \Pr(D = 1 \mid Y = 0, A = 1)
$$

* Equalized **False Negative Rate**:

$$
\Pr(D = 0 \mid Y = 1, A = 0) = \Pr(D = 0 \mid Y = 1, A = 1)
$$

* For general (non-binary) attributes: $(D \perp A) \mid Y$:

$$
\Pr(D = d, A = a \mid Y = y) = \Pr(D = d \mid Y = y)\Pr(A = a \mid Y = y)
$$

## NO MORE EQUATIONS! üò§ {.smaller}

* Depending on your background and/or learning style (say, visual vs. auditory), you may be able to look at equations on previous slides and "see" what they're "saying"
* If your brain works similarly to **mine**, however, your eyes glazed over, you began dissociating, planning an escape route, looking for open ventilation ducts, etc.
* If you're in the latter group, welcome to the **cult of Probabilistic Graphical Models** üòà

## Baby Steps: A Real-World Confusion Matrix {.title-11 .crunch-title .smaller}

| | Labeled Low-Risk | Labeled High-Risk |
| - | - | - |
| **Didn't Do More Crimes** | *True Negative* | *False Positive* |
**Did More Crimes** | *False Negative* | *True Positive* |

: {tbl-colwidths="[30,40,40]"}

* What kinds of **causal connections** and/or **feedback loops** might there be between our **decision variable** (low vs. high risk) and our **outcome variable** (did vs. didn't do more crimes)
* What types of **policy implications** might this process have, after it "runs" for several "iterations"?
* Why might some segments of society, with some shared ethical framework(s), **weigh** the **"costs"** of false negatives and false positives **differently** from other segments of society with different shared ethical framework(s)?
* (Non-rhetorical questions!)

<!-- ## Minimizing Loss Function Penalizing (Only) These Errors $\iff$ Single-Threshold Fairness {.smaller .crunch-title .title-09}

* Loss function: $\ell(d, \widehat{d})$
* An **optimal classifier** minimizes the expected loss: $\mathbb{E}[\ell(\widehat{d},d)]$
* A **decision** is considered to be fair if individuals with the same score $s_i = \psi(v_i)$ are treated equally, regardless of group membership (Corbett-Davies & Goel 2018). -->

## References

::: {#refs}
:::
